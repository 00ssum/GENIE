[37m[36mINFO[0m[0m 04/28 13:39:56 | Command :: /jsm0707/GENIE/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm GENIE --test_envs 1 --dataset DomainNet --trial_seed 2 --hparams_seed 9
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: GENIE
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_sgd.yaml']
	data_dir: data
	dataset: DomainNet
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 9
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_sgd
	out_dir: train_output/DomainNet/GENIE/[1]/250428_13-39-56_resnet50_sgd
	out_root: train_output/DomainNet/GENIE/[1]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [1]
	trial_seed: 2
	unique_name: 250428_13-39-56_resnet50_sgd
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: sgd
	freeze_bn: False
	pretrained: True
	lr: 2.716671579524612e-05
	batch_size: 23
	weight_decay: 1.71368232883332e-06
	momentum: 0.9092933546128503
	convergence_rate: 0.02426611940613899
	moving_avg: 0.947722940872739
	p: 0.5933807106679234
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[DomainNet] #envs=6, #classes=345
	env0: clip (#48129)
	env1: info (#51605)
	env2: paint (#72266)
	env3: quick (#172500)
	env4: real (#172947)
	env5: sketch (#69128)

[37m[36mINFO[0m[0m 04/28 13:39:57 | n_steps = 15001
[37m[36mINFO[0m[0m 04/28 13:39:57 | checkpoint_freq = 1000
[37m[36mINFO[0m[0m 04/28 13:39:57 | n_steps is updated to 15001 => 15001 for checkpointing
[37m[36mINFO[0m[0m 04/28 13:39:57 | 
[37m[36mINFO[0m[0m 04/28 13:39:58 | Testenv name escaping te_info -> te_info
[37m[36mINFO[0m[0m 04/28 13:39:58 | Test envs = [1], name = te_info
[37m[36mINFO[0m[0m 04/28 13:39:58 | Train environments: [0, 2, 3, 4, 5], Test environments: [1]
[37m[36mINFO[0m[0m 04/28 13:39:58 | Batch sizes for each domain: [23, 0, 23, 23, 23, 23] (total=115)
[37m[36mINFO[0m[0m 04/28 13:39:58 | steps-per-epoch for each domain: 1674.09, 2513.61, 6000.00, 6015.57, 2404.48 -> min = 1674.09
[37m[36mINFO[0m[0m 04/28 13:39:59 | # of params = 24214937
[37m[36mINFO[0m[0m 04/28 14:20:03 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    env4_in     env4_out    env5_in     env5_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 04/28 14:20:03 | 0.002519    0.003004    0.003407    0.002886    5.901588    0.003766    0.002805    0.002519    0.003004    0.003702    0.002837    0.004406    0.003971    0.002414    0.002718    0.002748    0.002098    0           0.000000    5.916861    1.749658    2402.03458 
[37m[36mINFO[0m[0m 04/28 15:06:50 | 0.145650    0.148726    0.500413    0.506984    2.201403    0.569889    0.577662    0.145650    0.148726    0.492294    0.499412    0.348964    0.368116    0.594089    0.609731    0.496827    0.480000    1000        0.597341    3.196885    0.375264    2431.30905 
[37m[36mINFO[0m[0m 04/28 15:51:17 | 0.168055    0.169460    0.564582    0.561811    1.933955    0.648114    0.632416    0.168055    0.169460    0.543770    0.541410    0.428754    0.447217    0.649048    0.653907    0.553225    0.534105    2000        1.194681    2.042949    0.291359    2376.08659 
[37m[36mINFO[0m[0m 04/28 16:36:23 | 0.165875    0.165972    0.598760    0.585747    1.805484    0.681903    0.657247    0.165875    0.165972    0.576756    0.562582    0.475884    0.484116    0.667789    0.667033    0.591469    0.557758    3000        1.792022    1.806589    0.306076    2399.77776 
[37m[36mINFO[0m[0m 04/28 17:22:24 | 0.178738    0.180118    0.623025    0.608678    1.699366    0.705641    0.675429    0.178738    0.180118    0.602287    0.588321    0.505167    0.512783    0.687940    0.690653    0.614090    0.576203    4000        2.389362    1.666760    0.324503    2436.11829 
[37m[36mINFO[0m[0m 04/28 18:06:59 | 0.182783    0.180215    0.644497    0.619700    1.645177    0.733274    0.688623    0.182783    0.180215    0.622178    0.593164    0.527130    0.531652    0.706573    0.698951    0.633329    0.586112    5000        2.986703    1.550064    0.307561    2368.13947 
[37m[36mINFO[0m[0m 04/28 18:53:42 | 0.179997    0.176921    0.656588    0.625809    1.614343    0.754026    0.695688    0.179997    0.176921    0.630446    0.596831    0.545007    0.542928    0.709536    0.696927    0.643925    0.596673    6000        3.584043    1.471138    0.332702    2469.45638 
[37m[36mINFO[0m[0m 04/28 19:39:57 | 0.175080    0.170332    0.667502    0.631718    1.595086    0.758778    0.700260    0.175080    0.170332    0.650373    0.609285    0.560746    0.561246    0.713598    0.695828    0.654015    0.591971    7000        4.181384    1.408293    0.311529    2463.57399 
[37m[36mINFO[0m[0m 04/28 20:24:38 | 0.193319    0.196202    0.673786    0.638869    1.564418    0.767764    0.707117    0.193319    0.196202    0.654784    0.611638    0.565761    0.565797    0.721433    0.710081    0.659187    0.599711    8000        4.778724    1.348771    0.290306    2390.64985 
