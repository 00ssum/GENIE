[37m[36mINFO[0m[0m 05/14 16:50:00 | Command :: /jsm0707/GENIE/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm GENIE --test_envs 4 --dataset DomainNet --trial_seed 1 --hparams_seed 19
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: GENIE
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_sgd.yaml']
	data_dir: data
	dataset: DomainNet
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 19
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_sgd
	out_dir: train_output/DomainNet/GENIE/[4]/250514_16-50-00_resnet50_sgd
	out_root: train_output/DomainNet/GENIE/[4]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [4]
	trial_seed: 1
	unique_name: 250514_16-50-00_resnet50_sgd
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.5
	class_balanced: False
	optimizer: sgd
	freeze_bn: False
	pretrained: True
	lr: 3.7692486045276154e-05
	batch_size: 10
	weight_decay: 0.0003178970604685295
	momentum: 0.9165556259775216
	convergence_rate: 0.0045022255777150055
	moving_avg: 0.9505603649371388
	p: 0.48130275915591436
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[DomainNet] #envs=6, #classes=345
	env0: clip (#48129)
	env1: info (#51605)
	env2: paint (#72266)
	env3: quick (#172500)
	env4: real (#172947)
	env5: sketch (#69128)

[37m[36mINFO[0m[0m 05/14 16:50:01 | n_steps = 15001
[37m[36mINFO[0m[0m 05/14 16:50:01 | checkpoint_freq = 1000
[37m[36mINFO[0m[0m 05/14 16:50:01 | n_steps is updated to 15001 => 15001 for checkpointing
[37m[36mINFO[0m[0m 05/14 16:50:01 | 
[37m[36mINFO[0m[0m 05/14 16:50:02 | Testenv name escaping te_real -> te_real
[37m[36mINFO[0m[0m 05/14 16:50:02 | Test envs = [4], name = te_real
[37m[36mINFO[0m[0m 05/14 16:50:02 | Train environments: [0, 1, 2, 3, 5], Test environments: [4]
[37m[36mINFO[0m[0m 05/14 16:50:02 | Batch sizes for each domain: [10, 10, 10, 10, 0, 10] (total=50)
[37m[36mINFO[0m[0m 05/14 16:50:02 | steps-per-epoch for each domain: 3850.40, 4128.40, 5781.30, 13800.00, 5530.30 -> min = 3850.40
[37m[36mINFO[0m[0m 05/14 16:50:03 | # of params = 24214937
[37m[36mINFO[0m[0m 05/14 17:24:33 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    env4_in     env4_out    env5_in     env5_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 05/14 17:24:33 | 0.002031    0.002053    0.003237    0.003026    5.898475    0.003532    0.003740    0.001889    0.002616    0.004186    0.003529    0.003703    0.003217    0.002031    0.002053    0.002875    0.002025    0           0.000000    6.137769    1.131500    2069.12974 
[37m[36mINFO[0m[0m 05/14 18:01:40 | 0.046307    0.047009    0.046391    0.045804    5.488012    0.054644    0.053506    0.042074    0.038659    0.066075    0.067598    0.015891    0.017971    0.046307    0.047009    0.053270    0.051284    1000        0.259713    5.773482    0.158825    2068.01447 
[37m[36mINFO[0m[0m 05/14 18:38:44 | 0.362082    0.359045    0.279331    0.277870    3.643111    0.373286    0.372987    0.172367    0.158027    0.359573    0.360479    0.144920    0.154928    0.362082    0.359045    0.346509    0.342929    2000        0.519427    4.699583    0.159516    2064.37425 
[37m[36mINFO[0m[0m 05/14 19:17:28 | 0.462337    0.459424    0.367687    0.366570    3.102392    0.487040    0.499636    0.223040    0.198527    0.446543    0.446551    0.241906    0.251826    0.462337    0.459424    0.439904    0.436311    3000        0.779140    3.633761    0.257986    2065.84100 
[37m[36mINFO[0m[0m 05/14 19:56:04 | 0.503874    0.500130    0.412061    0.408465    2.824978    0.540879    0.545974    0.251865    0.225850    0.475706    0.473950    0.307254    0.317130    0.503874    0.500130    0.484603    0.479421    4000        1.038853    3.192190    0.240415    2075.88710 
[37m[36mINFO[0m[0m 05/14 20:33:46 | 0.537815    0.534274    0.446378    0.440880    2.661127    0.578927    0.580052    0.269862    0.234183    0.517098    0.513457    0.355413    0.370957    0.537815    0.534274    0.510587    0.505750    5000        1.298566    2.960649    0.179810    2082.22367 
[37m[36mINFO[0m[0m 05/14 21:11:11 | 0.552494    0.548990    0.465480    0.460655    2.525650    0.603729    0.599481    0.280545    0.250170    0.527096    0.526327    0.383543    0.404116    0.552494    0.548990    0.532485    0.523183    6000        1.558280    2.811760    0.182055    2063.20060 
[37m[36mINFO[0m[0m 05/14 21:48:17 | 0.564615    0.563243    0.485314    0.478650    2.468245    0.629493    0.629610    0.291784    0.256758    0.550516    0.544178    0.409688    0.430261    0.564615    0.563243    0.545088    0.532441    7000        1.817993    2.661602    0.168748    2057.20519 
[37m[36mINFO[0m[0m 05/14 22:25:57 | 0.576353    0.574749    0.499660    0.487477    2.396078    0.639648    0.637299    0.306850    0.264122    0.557747    0.547291    0.432696    0.448348    0.576353    0.574749    0.561362    0.540325    8000        2.077706    2.577091    0.167670    2092.11977 
