[37m[36mINFO[0m[0m 05/28 10:50:23 | Command :: /jsm0707/GENIE/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm GENIE --test_envs 5 --dataset DomainNet --trial_seed 1 --hparams_seed 5
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: GENIE
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_sgd.yaml']
	data_dir: data
	dataset: DomainNet
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 5
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_sgd
	out_dir: train_output/DomainNet/GENIE/[5]/250528_10-50-23_resnet50_sgd
	out_root: train_output/DomainNet/GENIE/[5]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [5]
	trial_seed: 1
	unique_name: 250528_10-50-23_resnet50_sgd
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.1
	class_balanced: False
	optimizer: sgd
	freeze_bn: False
	pretrained: True
	lr: 0.0002591339485391279
	batch_size: 10
	weight_decay: 0.00020150290684242954
	momentum: 0.8110007225854301
	convergence_rate: 0.020578351292485038
	moving_avg: 0.994868011928886
	p: 0.3153694343112224
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[DomainNet] #envs=6, #classes=345
	env0: clip (#48129)
	env1: info (#51605)
	env2: paint (#72266)
	env3: quick (#172500)
	env4: real (#172947)
	env5: sketch (#69128)

[37m[36mINFO[0m[0m 05/28 10:50:24 | n_steps = 15001
[37m[36mINFO[0m[0m 05/28 10:50:24 | checkpoint_freq = 1000
[37m[36mINFO[0m[0m 05/28 10:50:24 | n_steps is updated to 15001 => 15001 for checkpointing
[37m[36mINFO[0m[0m 05/28 10:50:24 | 
[37m[36mINFO[0m[0m 05/28 10:50:25 | Testenv name escaping te_sketch -> te_sketch
[37m[36mINFO[0m[0m 05/28 10:50:25 | Test envs = [5], name = te_sketch
[37m[36mINFO[0m[0m 05/28 10:50:25 | Train environments: [0, 1, 2, 3, 4], Test environments: [5]
[37m[36mINFO[0m[0m 05/28 10:50:25 | Batch sizes for each domain: [10, 10, 10, 10, 10, 0] (total=50)
[37m[36mINFO[0m[0m 05/28 10:50:25 | steps-per-epoch for each domain: 3850.40, 4128.40, 5781.30, 13800.00, 13835.80 -> min = 3850.40
[37m[36mINFO[0m[0m 05/28 10:50:26 | # of params = 24214937
[37m[36mINFO[0m[0m 05/28 11:28:17 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    env4_in     env4_out    env5_in     env5_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 05/28 11:28:17 | 0.002640    0.001519    0.003535    0.003476    5.893223    0.003143    0.003013    0.001768    0.002616    0.005051    0.004774    0.003826    0.003333    0.003888    0.003643    0.002640    0.001519    0           0.000000    5.963614    1.599401    2269.54772 
[37m[36mINFO[0m[0m 05/28 12:09:54 | 0.262608    0.258807    0.274914    0.279857    3.546640    0.345549    0.364779    0.162121    0.147951    0.321519    0.321525    0.133051    0.143797    0.412329    0.421232    0.262608    0.258807    1000        0.259713    4.985799    0.220883    2276.52611 
[37m[36mINFO[0m[0m 05/28 12:51:10 | 0.372765    0.370416    0.394418    0.393770    2.841863    0.503091    0.512935    0.231857    0.203856    0.435369    0.430914    0.272703    0.286406    0.529070    0.534736    0.372765    0.370416    2000        0.519427    3.170634    0.214793    2261.12479 
[37m[36mINFO[0m[0m 05/28 13:32:34 | 0.383542    0.388354    0.439512    0.439977    2.596619    0.550852    0.550649    0.258090    0.230792    0.469341    0.468207    0.346899    0.368377    0.572377    0.581861    0.383542    0.388354    3000        0.779140    2.729305    0.214376    2269.50591 
[37m[36mINFO[0m[0m 05/28 14:13:38 | 0.413413    0.414033    0.470569    0.463497    2.453663    0.580199    0.579429    0.277105    0.241062    0.501289    0.490210    0.393667    0.400638    0.600587    0.606146    0.413413    0.414033    4000        1.038853    2.521787    0.192776    2270.67183 
[37m[36mINFO[0m[0m 05/28 14:55:24 | 0.427047    0.428210    0.495042    0.485495    2.351809    0.615443    0.605922    0.293843    0.252882    0.524726    0.512696    0.424348    0.438493    0.616849    0.617480    0.427047    0.428210    5000        1.298566    2.374484    0.232724    2273.94883 
[37m[36mINFO[0m[0m 05/28 15:36:36 | 0.422057    0.422785    0.510710    0.500293    2.304935    0.641284    0.632623    0.294061    0.250170    0.538080    0.522383    0.453072    0.466899    0.627054    0.629391    0.422057    0.422785    6000        1.558280    2.280405    0.219190    2252.22536 
