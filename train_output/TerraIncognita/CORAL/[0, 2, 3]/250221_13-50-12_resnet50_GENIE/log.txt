[37m[36mINFO[0m[0m 02/21 13:50:12 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 0 2 3 --dataset TerraIncognita --trial_seed 2 --hparams_seed 8
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: TerraIncognita
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 8
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/TerraIncognita/CORAL/[0, 2, 3]/250221_13-50-12_resnet50_GENIE
	out_root: train_output/TerraIncognita/CORAL/[0, 2, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 2, 3]
	trial_seed: 2
	unique_name: 250221_13-50-12_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 3.019123985218396e-05
	batch_size: 9
	weight_decay: 0.0020603523571546007
	mmd_gamma: 7.360960263393403
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[TerraIncognita] #envs=4, #classes=10
	env0: L100 (#4741)
	env1: L38 (#9736)
	env2: L43 (#3970)
	env3: L46 (#5883)

[37m[36mINFO[0m[0m 02/21 13:50:12 | n_steps = 5001
[37m[36mINFO[0m[0m 02/21 13:50:12 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/21 13:50:12 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/21 13:50:12 | 
[37m[36mINFO[0m[0m 02/21 13:50:12 | Testenv name escaping te_L100_L43_L46 -> te_L100_L43_L46
[37m[36mINFO[0m[0m 02/21 13:50:12 | Test envs = [0, 2, 3], name = te_L100_L43_L46
[37m[36mINFO[0m[0m 02/21 13:50:12 | Train environments: [1], Test environments: [0, 2, 3]
[37m[36mINFO[0m[0m 02/21 13:50:12 | Batch sizes for each domain: [0, 9, 0, 0] (total=9)
[37m[36mINFO[0m[0m 02/21 13:50:12 | steps-per-epoch for each domain: 865.44 -> min = 865.44
[37m[36mINFO[0m[0m 02/21 13:50:13 | # of params = 23528522
[37m[36mINFO[0m[0m 02/21 13:53:06 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 02/21 13:53:06 | 0.210241    0.196002    0.532674    0.519260    1.649261    0.211706    0.200422    0.532674    0.519260    0.196159    0.180101    0.222860    0.207483    0           0.000000    2.243616    0.000000    1.234901    171.634067 
[37m[36mINFO[0m[0m 02/21 13:56:31 | 0.226455    0.212653    0.543074    0.528505    1.257626    0.266280    0.260549    0.543074    0.528505    0.194899    0.177582    0.218186    0.199830    200         0.231095    1.226379    0.000000    0.143855    176.531788 
[37m[36mINFO[0m[0m 02/21 14:00:03 | 0.223844    0.213181    0.577224    0.562917    1.209312    0.212760    0.205696    0.577224    0.562917    0.202771    0.186398    0.256002    0.247449    400         0.462190    1.131066    0.000000    0.122081    186.969377 
[37m[36mINFO[0m[0m 02/21 14:03:26 | 0.177895    0.158788    0.579920    0.569081    1.156765    0.201687    0.183544    0.579920    0.569081    0.189232    0.176322    0.142766    0.116497    600         0.693285    1.126211    0.000000    0.106947    181.931497 
[37m[36mINFO[0m[0m 02/21 14:06:49 | 0.206301    0.192963    0.601233    0.564972    1.146259    0.205906    0.199367    0.601233    0.564972    0.193325    0.178841    0.219673    0.200680    800         0.924381    1.107937    0.000000    0.115670    180.141754 
[37m[36mINFO[0m[0m 02/21 14:10:18 | 0.158851    0.141752    0.595455    0.571135    1.126036    0.150804    0.141350    0.595455    0.571135    0.187657    0.175063    0.138092    0.108844    1000        1.155476    1.097823    0.000000    0.133934    181.964477 
[37m[36mINFO[0m[0m 02/21 14:13:32 | 0.197452    0.180502    0.617923    0.592707    1.099671    0.211706    0.199367    0.617923    0.592707    0.189232    0.176322    0.191417    0.165816    1200        1.386571    1.140726    0.000000    0.151227    163.724548 
[37m[36mINFO[0m[0m 02/21 14:16:58 | 0.194329    0.180502    0.603030    0.581407    1.103800    0.207224    0.199367    0.603030    0.581407    0.189232    0.176322    0.186531    0.165816    1400        1.617666    1.072493    0.000000    0.114523    183.382595 
[37m[36mINFO[0m[0m 02/21 14:20:24 | 0.205432    0.191840    0.607909    0.586543    1.108221    0.205906    0.199367    0.607909    0.586543    0.189232    0.176322    0.221160    0.199830    1600        1.848761    1.096226    0.000000    0.126977    180.782217 
[37m[36mINFO[0m[0m 02/21 14:23:38 | 0.195079    0.181646    0.598151    0.571135    1.112997    0.204587    0.195148    0.598151    0.571135    0.189232    0.176322    0.191417    0.173469    1800        2.079856    1.081610    0.000000    0.121415    169.503583 
[37m[36mINFO[0m[0m 02/21 14:27:11 | 0.203459    0.190842    0.595840    0.571135    1.118779    0.208278    0.199367    0.595840    0.571135    0.189861    0.177582    0.212237    0.195578    2000        2.310951    1.033299    0.000000    0.120844    188.959354 
[37m[36mINFO[0m[0m 02/21 14:30:37 | 0.087535    0.077562    0.651046    0.618387    1.019076    0.085421    0.074895    0.651046    0.618387    0.105164    0.095718    0.072020    0.062075    2200        2.542046    1.078179    0.000000    0.130497    179.123213 
[37m[36mINFO[0m[0m 02/21 14:34:02 | 0.151707    0.141690    0.692643    0.681048    0.952912    0.181650    0.172996    0.692643    0.681048    0.145151    0.137280    0.128320    0.114796    2400        2.773142    1.001917    0.000000    0.104818    184.569969 
[37m[36mINFO[0m[0m 02/21 14:37:21 | 0.199468    0.183835    0.693799    0.686184    0.929319    0.218033    0.204641    0.693799    0.686184    0.185768    0.172544    0.194604    0.174320    2600        3.004237    0.986802    0.000000    0.114201    176.409540 
