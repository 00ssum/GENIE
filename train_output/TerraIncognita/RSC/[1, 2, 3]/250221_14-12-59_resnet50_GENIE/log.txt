[37m[36mINFO[0m[0m 02/21 14:12:59 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm RSC --test_envs 1 2 3 --dataset TerraIncognita --trial_seed 2 --hparams_seed 13
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: RSC
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: TerraIncognita
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 13
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/TerraIncognita/RSC/[1, 2, 3]/250221_14-12-59_resnet50_GENIE
	out_root: train_output/TerraIncognita/RSC/[1, 2, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [1, 2, 3]
	trial_seed: 2
	unique_name: 250221_14-12-59_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 0.00010514591448387436
	batch_size: 9
	weight_decay: 2.4366015497066046e-05
	rsc_f_drop_factor: 0.01448541980108109
	rsc_b_drop_factor: 0.13409305572855784
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[TerraIncognita] #envs=4, #classes=10
	env0: L100 (#4741)
	env1: L38 (#9736)
	env2: L43 (#3970)
	env3: L46 (#5883)

[37m[36mINFO[0m[0m 02/21 14:12:59 | n_steps = 5001
[37m[36mINFO[0m[0m 02/21 14:12:59 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/21 14:12:59 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/21 14:12:59 | 
[37m[36mINFO[0m[0m 02/21 14:13:00 | Testenv name escaping te_L38_L43_L46 -> te_L38_L43_L46
[37m[36mINFO[0m[0m 02/21 14:13:00 | Test envs = [1, 2, 3], name = te_L38_L43_L46
[37m[36mINFO[0m[0m 02/21 14:13:00 | Train environments: [0], Test environments: [1, 2, 3]
[37m[36mINFO[0m[0m 02/21 14:13:00 | Batch sizes for each domain: [9, 0, 0, 0] (total=9)
[37m[36mINFO[0m[0m 02/21 14:13:00 | steps-per-epoch for each domain: 421.44 -> min = 421.44
[37m[36mINFO[0m[0m 02/21 14:13:01 | # of params = 23528522
[37m[36mINFO[0m[0m 02/21 14:15:55 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 02/21 14:15:55 | 0.118521    0.118391    0.518587    0.534810    1.680653    0.518587    0.534810    0.021184    0.015408    0.097922    0.095718    0.236456    0.244048    0           0.000000    3.241709    1.282586    172.769385 
[37m[36mINFO[0m[0m 02/21 14:19:13 | 0.144714    0.150599    0.595307    0.608650    1.063874    0.595307    0.608650    0.051868    0.054443    0.142632    0.147355    0.239643    0.250000    200         0.474558    1.299321    0.140575    169.555551 
[37m[36mINFO[0m[0m 02/21 14:22:29 | 0.142483    0.145743    0.599262    0.616034    1.050425    0.599262    0.616034    0.088843    0.094504    0.099811    0.096977    0.238793    0.245748    400         0.949117    1.084986    0.141051    167.970311 
[37m[36mINFO[0m[0m 02/21 14:25:43 | 0.140873    0.143240    0.598735    0.618143    1.078507    0.598735    0.618143    0.084863    0.090395    0.099811    0.096977    0.237943    0.242347    600         1.423675    1.087153    0.135351    166.926268 
[37m[36mINFO[0m[0m 02/21 14:28:54 | 0.135065    0.138497    0.627735    0.657173    1.018772    0.627735    0.657173    0.051996    0.055984    0.113980    0.114610    0.239218    0.244898    800         1.898234    1.110819    0.143225    162.503132 
[37m[36mINFO[0m[0m 02/21 14:32:19 | 0.138247    0.141854    0.595834    0.621308    1.042568    0.595834    0.621308    0.076775    0.083719    0.099811    0.099496    0.238156    0.242347    1000        2.372792    1.100288    0.159950    173.027804 
[37m[36mINFO[0m[0m 02/21 14:35:36 | 0.143237    0.148845    0.628526    0.644515    1.023924    0.628526    0.644515    0.046476    0.050847    0.142317    0.144836    0.240918    0.250850    1200        2.847350    1.062523    0.124278    171.778055 
