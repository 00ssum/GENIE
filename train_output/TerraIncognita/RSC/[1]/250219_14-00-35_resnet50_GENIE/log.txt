[37m[36mINFO[0m[0m 02/19 14:00:35 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm RSC --test_envs 1 --dataset TerraIncognita --trial_seed 2 --hparams_seed 4
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: RSC
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: TerraIncognita
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 4
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/TerraIncognita/RSC/[1]/250219_14-00-35_resnet50_GENIE
	out_root: train_output/TerraIncognita/RSC/[1]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [1]
	trial_seed: 2
	unique_name: 250219_14-00-35_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 6.164076981615215e-05
	batch_size: 11
	weight_decay: 3.184710792983041e-06
	rsc_f_drop_factor: 0.4783019889594706
	rsc_b_drop_factor: 0.3428937454434034
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[TerraIncognita] #envs=4, #classes=10
	env0: L100 (#4741)
	env1: L38 (#9736)
	env2: L43 (#3970)
	env3: L46 (#5883)

[37m[36mINFO[0m[0m 02/19 14:00:35 | n_steps = 5001
[37m[36mINFO[0m[0m 02/19 14:00:35 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/19 14:00:35 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/19 14:00:35 | 
[37m[36mINFO[0m[0m 02/19 14:00:35 | Testenv name escaping te_L38 -> te_L38
[37m[36mINFO[0m[0m 02/19 14:00:35 | Test envs = [1], name = te_L38
[37m[36mINFO[0m[0m 02/19 14:00:35 | Train environments: [0, 2, 3], Test environments: [1]
[37m[36mINFO[0m[0m 02/19 14:00:35 | Batch sizes for each domain: [11, 0, 11, 11] (total=33)
[37m[36mINFO[0m[0m 02/19 14:00:35 | steps-per-epoch for each domain: 344.82, 288.73, 427.91 -> min = 288.73
[37m[36mINFO[0m[0m 02/19 14:00:36 | # of params = 23528522
[37m[36mINFO[0m[0m 02/19 14:03:16 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 02/19 14:03:16 | 0.010271    0.011299    0.124585    0.151433    2.204597    0.032955    0.063291    0.010271    0.011299    0.199307    0.211587    0.141491    0.179422    0           0.000000    3.693913    0.896716    159.277760 
[37m[36mINFO[0m[0m 02/19 14:06:37 | 0.021569    0.015408    0.353927    0.364059    1.681821    0.516214    0.535865    0.021569    0.015408    0.254723    0.251889    0.290843    0.304422    200         0.692695    2.066698    0.156496    169.539283 
[37m[36mINFO[0m[0m 02/19 14:09:51 | 0.045705    0.048793    0.394737    0.409105    1.630646    0.590562    0.608650    0.045705    0.048793    0.275189    0.263224    0.318462    0.355442    400         1.385390    1.900160    0.167654    160.297813 
[37m[36mINFO[0m[0m 02/19 14:13:10 | 0.098215    0.094504    0.430211    0.441011    1.526201    0.597153    0.633966    0.098215    0.094504    0.364610    0.343829    0.328872    0.345238    600         2.078086    1.830227    0.166973    165.181785 
[37m[36mINFO[0m[0m 02/19 14:16:25 | 0.045192    0.046225    0.437880    0.454042    1.469807    0.597153    0.608650    0.045192    0.046225    0.315806    0.327456    0.400680    0.426020    800         2.770781    1.769676    0.174106    160.193376 
[37m[36mINFO[0m[0m 02/19 14:19:43 | 0.051996    0.057524    0.470227    0.481778    1.436716    0.617980    0.649789    0.051996    0.057524    0.381612    0.362720    0.411090    0.432823    1000        3.463476    1.763686    0.162558    165.907683 
[37m[36mINFO[0m[0m 02/19 14:23:05 | 0.036077    0.033385    0.467766    0.485315    1.408520    0.609017    0.647679    0.036077    0.033385    0.374055    0.365239    0.420225    0.443027    1200        4.156171    1.716340    0.189119    163.771319 
[37m[36mINFO[0m[0m 02/19 14:26:49 | 0.032610    0.025681    0.485102    0.496352    1.370808    0.622462    0.650844    0.032610    0.025681    0.391373    0.384131    0.441470    0.454082    1400        4.848866    1.703270    0.188363    186.439167 
[37m[36mINFO[0m[0m 02/19 14:30:48 | 0.031198    0.028762    0.488209    0.504397    1.357526    0.605589    0.628692    0.031198    0.028762    0.412469    0.421914    0.446569    0.462585    1600        5.541562    1.688507    0.195034    200.289562 
[37m[36mINFO[0m[0m 02/19 14:35:00 | 0.029914    0.026194    0.493211    0.498247    1.321443    0.636699    0.649789    0.029914    0.026194    0.400189    0.389169    0.442745    0.455782    1800        6.234257    1.677617    0.260216    199.716668 
[37m[36mINFO[0m[0m 02/19 14:38:49 | 0.030428    0.027221    0.464566    0.477780    1.329839    0.626944    0.647679    0.030428    0.027221    0.348866    0.337531    0.417888    0.448129    2000        6.926952    1.655871    0.192391    191.007429 
[37m[36mINFO[0m[0m 02/19 14:42:49 | 0.023110    0.018490    0.464599    0.481172    1.312412    0.606380    0.619198    0.023110    0.018490    0.388224    0.406801    0.399193    0.417517    2200        7.619647    1.651835    0.232865    193.575409 
