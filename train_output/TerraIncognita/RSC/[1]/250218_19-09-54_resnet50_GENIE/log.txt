[37m[36mINFO[0m[0m 02/18 19:09:54 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm RSC --test_envs 1 --dataset TerraIncognita --trial_seed 1 --hparams_seed 12
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: RSC
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: TerraIncognita
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 12
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/TerraIncognita/RSC/[1]/250218_19-09-54_resnet50_GENIE
	out_root: train_output/TerraIncognita/RSC/[1]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [1]
	trial_seed: 1
	unique_name: 250218_19-09-54_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.1
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 3.0065625733392338e-05
	batch_size: 34
	weight_decay: 4.89485556145273e-06
	rsc_f_drop_factor: 0.23818860955359455
	rsc_b_drop_factor: 0.46131243462788474
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[TerraIncognita] #envs=4, #classes=10
	env0: L100 (#4741)
	env1: L38 (#9736)
	env2: L43 (#3970)
	env3: L46 (#5883)

[37m[36mINFO[0m[0m 02/18 19:09:54 | n_steps = 5001
[37m[36mINFO[0m[0m 02/18 19:09:54 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/18 19:09:54 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/18 19:09:54 | 
[37m[36mINFO[0m[0m 02/18 19:09:54 | Testenv name escaping te_L38 -> te_L38
[37m[36mINFO[0m[0m 02/18 19:09:54 | Test envs = [1], name = te_L38
[37m[36mINFO[0m[0m 02/18 19:09:54 | Train environments: [0, 2, 3], Test environments: [1]
[37m[36mINFO[0m[0m 02/18 19:09:54 | Batch sizes for each domain: [34, 0, 34, 34] (total=102)
[37m[36mINFO[0m[0m 02/18 19:09:54 | steps-per-epoch for each domain: 111.56, 93.41, 138.44 -> min = 93.41
[37m[36mINFO[0m[0m 02/18 19:09:55 | # of params = 23528522
[37m[36mINFO[0m[0m 02/18 19:12:47 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 02/18 19:12:47 | 0.449737    0.442219    0.216230    0.206165    2.165356    0.242816    0.263713    0.449737    0.442219    0.167506    0.118388    0.238368    0.236395    0           0.000000    3.751459    1.377308    169.983353 
[37m[36mINFO[0m[0m 02/18 19:16:55 | 0.019643    0.023112    0.358078    0.361475    1.605408    0.514896    0.542194    0.019643    0.023112    0.257872    0.255668    0.301466    0.286565    200         2.141058    1.986258    0.397914    168.781877 
[37m[36mINFO[0m[0m 02/18 19:21:06 | 0.028887    0.031330    0.402972    0.395888    1.474282    0.585816    0.614979    0.028887    0.031330    0.290617    0.268262    0.332484    0.304422    400         4.282116    1.771737    0.416782    168.030258 
[37m[36mINFO[0m[0m 02/18 19:25:20 | 0.322634    0.320493    0.453317    0.459274    1.401887    0.648036    0.642405    0.322634    0.320493    0.342254    0.376574    0.369662    0.358844    600         6.423174    1.628274    0.410712    171.845064 
[37m[36mINFO[0m[0m 02/18 19:29:35 | 0.038516    0.046739    0.456258    0.475674    1.382025    0.597680    0.627637    0.038516    0.046739    0.341310    0.361461    0.429785    0.437925    800         8.564232    1.582315    0.430385    168.477510 
[37m[36mINFO[0m[0m 02/18 19:33:31 | 0.029529    0.035439    0.434895    0.464046    1.349621    0.597944    0.622363    0.029529    0.035439    0.348552    0.382872    0.358190    0.386905    1000        10.705290   1.586754    0.341565    167.571571 
[37m[36mINFO[0m[0m 02/18 19:37:27 | 0.181281    0.177709    0.473736    0.496442    1.302477    0.627472    0.656118    0.181281    0.177709    0.348866    0.376574    0.444869    0.456633    1200        12.846348   1.561448    0.292137    178.197816 
[37m[36mINFO[0m[0m 02/18 19:41:15 | 0.087431    0.083719    0.500457    0.535871    1.271445    0.675191    0.693038    0.087431    0.083719    0.371537    0.430730    0.454642    0.483844    1400        14.987406   1.547809    0.281888    171.535021 
[37m[36mINFO[0m[0m 02/18 19:45:18 | 0.032738    0.039034    0.524450    0.530205    1.246326    0.685473    0.690928    0.032738    0.039034    0.416877    0.397985    0.471001    0.501701    1600        17.128463   1.502386    0.294656    183.506211 
[37m[36mINFO[0m[0m 02/18 19:49:19 | 0.035049    0.037494    0.541015    0.560370    1.152804    0.712365    0.714135    0.035049    0.037494    0.419710    0.455919    0.490971    0.511054    1800        19.269521   1.466869    0.302034    180.466477 
