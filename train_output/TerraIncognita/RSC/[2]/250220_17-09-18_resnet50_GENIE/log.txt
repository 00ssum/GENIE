[37m[36mINFO[0m[0m 02/20 17:09:18 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm RSC --test_envs 2 --dataset TerraIncognita --trial_seed 0 --hparams_seed 19
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: RSC
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: TerraIncognita
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 19
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/TerraIncognita/RSC/[2]/250220_17-09-18_resnet50_GENIE
	out_root: train_output/TerraIncognita/RSC/[2]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [2]
	trial_seed: 0
	unique_name: 250220_17-09-18_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 5.513854977685438e-05
	batch_size: 27
	weight_decay: 0.0014556716107047517
	rsc_f_drop_factor: 0.4585839564743606
	rsc_b_drop_factor: 0.22347318786657766
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[TerraIncognita] #envs=4, #classes=10
	env0: L100 (#4741)
	env1: L38 (#9736)
	env2: L43 (#3970)
	env3: L46 (#5883)

[37m[36mINFO[0m[0m 02/20 17:09:18 | n_steps = 5001
[37m[36mINFO[0m[0m 02/20 17:09:18 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/20 17:09:18 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/20 17:09:18 | 
[37m[36mINFO[0m[0m 02/20 17:09:18 | Testenv name escaping te_L43 -> te_L43
[37m[36mINFO[0m[0m 02/20 17:09:18 | Test envs = [2], name = te_L43
[37m[36mINFO[0m[0m 02/20 17:09:18 | Train environments: [0, 1, 3], Test environments: [2]
[37m[36mINFO[0m[0m 02/20 17:09:18 | Batch sizes for each domain: [27, 27, 0, 27] (total=81)
[37m[36mINFO[0m[0m 02/20 17:09:18 | steps-per-epoch for each domain: 140.48, 288.48, 174.33 -> min = 140.48
[37m[36mINFO[0m[0m 02/20 17:09:19 | # of params = 23528522
[37m[36mINFO[0m[0m 02/20 17:12:50 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 02/20 17:12:50 | 0.186398    0.221662    0.292861    0.300049    2.065046    0.200633    0.208861    0.455514    0.481253    0.186398    0.221662    0.222435    0.210034    0           0.000000    3.311525    1.142428    209.410321 
[37m[36mINFO[0m[0m 02/20 17:17:14 | 0.207494    0.241814    0.436269    0.497868    1.483285    0.511996    0.635021    0.529336    0.576271    0.207494    0.241814    0.267474    0.282313    200         1.423675    1.912020    0.286546    207.279741 
[37m[36mINFO[0m[0m 02/20 17:21:38 | 0.328715    0.380353    0.502962    0.508461    1.324322    0.612708    0.595992    0.544999    0.585003    0.328715    0.380353    0.351179    0.344388    400         2.847350    1.687079    0.330589    197.244378 
[37m[36mINFO[0m[0m 02/20 17:25:54 | 0.312028    0.363980    0.560947    0.563592    1.229294    0.658845    0.627637    0.569778    0.596302    0.312028    0.363980    0.454217    0.466837    600         4.271026    1.571233    0.296526    197.137830 
[37m[36mINFO[0m[0m 02/20 17:30:21 | 0.318640    0.369018    0.574679    0.561091    1.191832    0.691801    0.619198    0.587367    0.609142    0.318640    0.369018    0.444869    0.454932    800         5.694701    1.510828    0.344259    198.046304 
[37m[36mINFO[0m[0m 02/20 17:34:34 | 0.307620    0.361461    0.601332    0.613843    1.136865    0.706037    0.712025    0.627808    0.653313    0.307620    0.361461    0.470151    0.476190    1000        7.118376    1.483711    0.339557    184.863766 
[37m[36mINFO[0m[0m 02/20 17:38:30 | 0.337531    0.384131    0.609896    0.616146    1.149383    0.730820    0.714135    0.636154    0.658963    0.337531    0.384131    0.462715    0.475340    1200        8.542051    1.413731    0.278940    179.923456 
[37m[36mINFO[0m[0m 02/20 17:42:37 | 0.280227    0.293451    0.606848    0.612977    1.080913    0.736884    0.740506    0.594813    0.608629    0.280227    0.293451    0.488846    0.489796    1400        9.965726    1.386934    0.317835    183.720287 
