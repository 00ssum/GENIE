[37m[36mINFO[0m[0m 03/19 17:02:46 | Command :: /jsm0707/GENIE/train_all.py resnet50_Sign_GENIE config/resnet50_Sign_GENIE.yaml --algorithm ERM --test_envs 0 --dataset TerraIncognita --trial_seed 0 --hparams_seed 15
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: ERM
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_Sign_GENIE.yaml']
	data_dir: data
	dataset: TerraIncognita
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 15
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_Sign_GENIE
	out_dir: train_output/TerraIncognita/ERM/[0]/250319_17-02-46_resnet50_Sign_GENIE
	out_root: train_output/TerraIncognita/ERM/[0]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0]
	trial_seed: 0
	unique_name: 250319_17-02-46_resnet50_Sign_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.5
	class_balanced: False
	optimizer: sign_genie
	freeze_bn: False
	pretrained: True
	lr: 0.00010661763546249327
	batch_size: 14
	weight_decay: 9.086452814323981e-06
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[TerraIncognita] #envs=4, #classes=10
	env0: L100 (#4741)
	env1: L38 (#9736)
	env2: L43 (#3970)
	env3: L46 (#5883)

[37m[36mINFO[0m[0m 03/19 17:02:46 | n_steps = 5001
[37m[36mINFO[0m[0m 03/19 17:02:46 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/19 17:02:46 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/19 17:02:46 | 
[37m[36mINFO[0m[0m 03/19 17:02:46 | Testenv name escaping te_L100 -> te_L100
[37m[36mINFO[0m[0m 03/19 17:02:46 | Test envs = [0], name = te_L100
[37m[36mINFO[0m[0m 03/19 17:02:46 | Train environments: [1, 2, 3], Test environments: [0]
[37m[36mINFO[0m[0m 03/19 17:02:46 | Batch sizes for each domain: [0, 14, 14, 14] (total=42)
[37m[36mINFO[0m[0m 03/19 17:02:46 | steps-per-epoch for each domain: 556.36, 226.86, 336.21 -> min = 226.86
[37m[36mINFO[0m[0m 03/19 17:02:48 | # of params = 23528522
[37m[36mINFO[0m[0m 03/19 17:05:43 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/19 17:05:43 | 0.239388    0.251055    0.274516    0.303603    2.028602    0.239388    0.251055    0.436641    0.481253    0.172544    0.222922    0.214362    0.206633    0           0.000000    2.355394    0.901522    174.347824 
[37m[36mINFO[0m[0m 03/19 17:09:05 | 0.211178    0.218354    0.509915    0.503408    1.268159    0.211178    0.218354    0.615098    0.633282    0.443010    0.414358    0.471638    0.462585    200         0.881612    1.528434    0.151422    172.047121 
[37m[36mINFO[0m[0m 03/19 17:12:31 | 0.452676    0.473629    0.646884    0.671329    0.864688    0.452676    0.473629    0.723585    0.750899    0.627519    0.673804    0.589547    0.589286    400         1.763224    1.152289    0.146596    176.697401 
[37m[36mINFO[0m[0m 03/19 17:15:54 | 0.525178    0.534810    0.692146    0.696497    0.825931    0.525178    0.534810    0.757864    0.789420    0.657431    0.641058    0.661143    0.659014    600         2.644836    0.933283    0.180196    167.193671 
[37m[36mINFO[0m[0m 03/19 17:19:24 | 0.414448    0.439873    0.720126    0.734917    0.753561    0.414448    0.439873    0.753242    0.768362    0.703715    0.720403    0.703420    0.715986    800         3.526448    0.870662    0.176617    174.427802 
[37m[36mINFO[0m[0m 03/19 17:22:58 | 0.508568    0.541139    0.731986    0.734784    0.712470    0.508568    0.541139    0.785082    0.813559    0.710642    0.695214    0.700234    0.695578    1000        4.408060    0.781419    0.183591    176.819982 
[37m[36mINFO[0m[0m 03/19 17:26:19 | 0.495914    0.490506    0.748363    0.777418    0.629961    0.495914    0.490506    0.783156    0.833077    0.748741    0.764484    0.713193    0.734694    1200        5.289673    0.753655    0.164445    168.811992 
[37m[36mINFO[0m[0m 03/19 17:29:54 | 0.625099    0.613924    0.749276    0.769100    0.632019    0.625099    0.613924    0.782899    0.815614    0.738350    0.751889    0.726577    0.739796    1400        6.171285    0.720621    0.177794    178.530101 
[37m[36mINFO[0m[0m 03/19 17:33:18 | 0.527551    0.527426    0.766717    0.779537    0.624399    0.527551    0.527426    0.793298    0.821263    0.767317    0.773300    0.739537    0.744048    1600        7.052897    0.677789    0.155847    172.885647 
[37m[36mINFO[0m[0m 03/19 17:36:47 | 0.539151    0.553797    0.775046    0.785076    0.596895    0.539151    0.553797    0.811786    0.834104    0.765743    0.777078    0.747610    0.744048    1800        7.934509    0.641816    0.154390    178.032696 
[37m[36mINFO[0m[0m 03/19 17:40:10 | 0.556552    0.553797    0.781722    0.788075    0.573598    0.556552    0.553797    0.816279    0.841808    0.772355    0.775819    0.756533    0.746599    2000        8.816121    0.628302    0.156249    172.405485 
[37m[36mINFO[0m[0m 03/19 17:43:33 | 0.471922    0.501055    0.788788    0.791163    0.571419    0.471922    0.501055    0.830402    0.838726    0.775819    0.774559    0.760144    0.760204    2200        9.697733    0.591934    0.155022    171.800747 
[37m[36mINFO[0m[0m 03/19 17:47:04 | 0.477986    0.484177    0.797741    0.801947    0.549384    0.477986    0.484177    0.834510    0.852594    0.800693    0.792191    0.758020    0.761054    2400        10.579345   0.596595    0.158100    179.806153 
[37m[36mINFO[0m[0m 03/19 17:50:32 | 0.549433    0.547468    0.783602    0.776240    0.609119    0.549433    0.547468    0.803441    0.801233    0.781486    0.778338    0.765881    0.749150    2600        11.460957   0.555686    0.147013    178.046943 
[37m[36mINFO[0m[0m 03/19 17:53:53 | 0.573425    0.602321    0.801773    0.805092    0.541698    0.573425    0.602321    0.828604    0.838726    0.796599    0.798489    0.780115    0.778061    2800        12.342569   0.541334    0.148718    171.570103 
[37m[36mINFO[0m[0m 03/19 17:57:16 | 0.485631    0.509494    0.815665    0.814204    0.508498    0.485631    0.509494    0.818590    0.830508    0.826196    0.811083    0.802209    0.801020    3000        13.224181   0.535682    0.144776    173.808547 
[37m[36mINFO[0m[0m 03/19 18:00:40 | 0.497495    0.515823    0.828488    0.826435    0.484824    0.497495    0.515823    0.860316    0.875706    0.823363    0.811083    0.801785    0.792517    3200        14.105793   0.502506    0.148985    174.601011 
[37m[36mINFO[0m[0m 03/19 18:03:59 | 0.504614    0.506329    0.808837    0.806032    0.590320    0.504614    0.506329    0.851072    0.865948    0.796599    0.778338    0.778840    0.773810    3400        14.987406   0.504097    0.154523    167.534783 
[37m[36mINFO[0m[0m 03/19 18:07:24 | 0.506723    0.528481    0.827102    0.829101    0.468763    0.506723    0.528481    0.838233    0.854135    0.825567    0.826196    0.817506    0.806973    3600        15.869018   0.484015    0.153840    174.407378 
[37m[36mINFO[0m[0m 03/19 18:10:49 | 0.516741    0.517932    0.814984    0.828252    0.497468    0.516741    0.517932    0.837720    0.860812    0.802897    0.816121    0.804334    0.807823    3800        16.750630   0.475701    0.155941    174.031399 
[37m[36mINFO[0m[0m 03/19 18:14:15 | 0.431848    0.428270    0.841490    0.834689    0.464877    0.431848    0.428270    0.866478    0.868002    0.847922    0.832494    0.810070    0.803571    4000        17.632242   0.474891    0.154262    174.992158 
[37m[36mINFO[0m[0m 03/19 18:17:35 | 0.486422    0.490506    0.843438    0.836524    0.465120    0.486422    0.490506    0.858647    0.871084    0.850126    0.842569    0.821542    0.795918    4200        18.513854   0.466324    0.154095    169.538100 
[37m[36mINFO[0m[0m 03/19 18:21:03 | 0.496441    0.503165    0.832837    0.819673    0.482605    0.496441    0.503165    0.849531    0.858757    0.837846    0.806045    0.811132    0.794218    4400        19.395466   0.481338    0.165005    174.982423 
[37m[36mINFO[0m[0m 03/19 18:24:25 | 0.421830    0.436709    0.852717    0.840492    0.440803    0.421830    0.436709    0.863654    0.871084    0.859572    0.842569    0.834927    0.807823    4600        20.277078   0.434161    0.150035    171.999883 
