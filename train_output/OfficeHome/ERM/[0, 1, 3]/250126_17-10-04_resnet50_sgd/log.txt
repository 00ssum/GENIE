[37m[36mINFO[0m[0m 01/26 17:10:04 | Command :: /jsm0707/Large-scale/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm ERM --test_envs 0 1 3 --dataset OfficeHome
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: ERM
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_sgd.yaml']
	data_dir: data
	dataset: OfficeHome
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_sgd
	out_dir: train_output/OfficeHome/ERM/[0, 1, 3]/250126_17-10-04_resnet50_sgd
	out_root: train_output/OfficeHome/ERM/[0, 1, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 1, 3]
	trial_seed: 0
	unique_name: 250126_17-10-04_resnet50_sgd
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: sgd
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[OfficeHome] #envs=4, #classes=65
	env0: A (#2427)
	env1: C (#4365)
	env2: P (#4439)
	env3: R (#4357)

[37m[36mINFO[0m[0m 01/26 17:10:04 | n_steps = 5001
[37m[36mINFO[0m[0m 01/26 17:10:04 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 01/26 17:10:04 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 01/26 17:10:04 | 
[37m[36mINFO[0m[0m 01/26 17:10:04 | Testenv name escaping te_A_C_R -> te_A_C_R
[37m[36mINFO[0m[0m 01/26 17:10:04 | Test envs = [0, 1, 3], name = te_A_C_R
[37m[36mINFO[0m[0m 01/26 17:10:04 | Train environments: [2], Test environments: [0, 1, 3]
[37m[36mINFO[0m[0m 01/26 17:10:04 | Batch sizes for each domain: [0, 0, 32, 0] (total=32)
[37m[36mINFO[0m[0m 01/26 17:10:04 | steps-per-epoch for each domain: 111.00 -> min = 111.00
[37m[36mINFO[0m[0m 01/26 17:10:06 | # of params = 23641217
[37m[36mINFO[0m[0m 01/26 17:11:56 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 01/26 17:11:56 | 0.017585    0.016577    0.012950    0.015784    4.259601    0.020082    0.026804    0.016609    0.014891    0.012950    0.015784    0.016064    0.008037    0           0.000000    4.328662    1.233350    109.187852 
[37m[36mINFO[0m[0m 01/26 17:14:18 | 0.019610    0.018716    0.014921    0.019166    4.204405    0.022142    0.030928    0.018328    0.016037    0.014921    0.019166    0.018359    0.009185    200         1.801802    4.248487    0.148318    112.273967 
[37m[36mINFO[0m[0m 01/26 17:16:42 | 0.019706    0.020244    0.016610    0.022548    4.161532    0.019567    0.030928    0.020905    0.020619    0.016610    0.022548    0.018646    0.009185    400         3.603604    4.195623    0.146413    113.971284 
[37m[36mINFO[0m[0m 01/26 17:18:55 | 0.021559    0.024597    0.026745    0.030440    4.123094    0.021112    0.037113    0.022910    0.026346    0.026745    0.030440    0.020654    0.010333    600         5.405405    4.152222    0.146697    103.836946 
[37m[36mINFO[0m[0m 01/26 17:21:15 | 0.026028    0.026969    0.039696    0.034949    4.083265    0.024202    0.035052    0.027778    0.029782    0.039696    0.034949    0.026104    0.016073    800         7.207207    4.107548    0.150105    109.290028 
[37m[36mINFO[0m[0m 01/26 17:23:34 | 0.033269    0.036986    0.057995    0.048478    4.038887    0.024717    0.032990    0.039519    0.044674    0.057995    0.048478    0.035571    0.033295    1000        9.009009    4.058444    0.142229    110.341402 
[37m[36mINFO[0m[0m 01/26 17:25:50 | 0.043659    0.043180    0.081363    0.074408    3.988595    0.030381    0.030928    0.054410    0.054983    0.081363    0.074408    0.046185    0.043628    1200        10.810811   4.018544    0.147243    105.941206 
[37m[36mINFO[0m[0m 01/26 17:28:11 | 0.057682    0.055107    0.117399    0.103720    3.930193    0.036045    0.039175    0.069874    0.063001    0.117399    0.103720    0.067126    0.063146    1400        12.612613   3.952838    0.148472    111.863945 
[37m[36mINFO[0m[0m 01/26 17:30:30 | 0.071322    0.072313    0.155687    0.134160    3.856465    0.041710    0.039175    0.085338    0.083620    0.155687    0.134160    0.086919    0.094145    1600        14.414414   3.886133    0.156026    106.919542 
[37m[36mINFO[0m[0m 01/26 17:32:48 | 0.084463    0.086987    0.190034    0.162345    3.764838    0.053038    0.055670    0.095647    0.096220    0.190034    0.162345    0.104705    0.109070    1800        16.216216   3.807491    0.144511    108.787467 
[37m[36mINFO[0m[0m 01/26 17:35:06 | 0.097068    0.103047    0.234234    0.207441    3.639648    0.063337    0.055670    0.108534    0.113402    0.234234    0.207441    0.119334    0.140069    2000        18.018018   3.689988    0.147913    107.897234 
[37m[36mINFO[0m[0m 01/26 17:37:24 | 0.115885    0.118719    0.284065    0.264938    3.463847    0.076210    0.065979    0.124570    0.128293    0.284065    0.264938    0.146873    0.161883    2200        19.819820   3.545207    0.145277    109.199336 
[37m[36mINFO[0m[0m 01/26 17:39:39 | 0.144364    0.147842    0.356700    0.348365    3.198953    0.104016    0.094845    0.140034    0.150057    0.356700    0.348365    0.189042    0.198622    2400        21.621622   3.322418    0.143850    106.055718 
[37m[36mINFO[0m[0m 01/26 17:42:03 | 0.187205    0.189888    0.419482    0.434047    2.783038    0.143666    0.125773    0.172394    0.185567    0.419482    0.434047    0.245554    0.258324    2600        23.423423   2.965414    0.140708    114.936655 
[37m[36mINFO[0m[0m 01/26 17:44:18 | 0.237487    0.247292    0.514077    0.533258    2.208699    0.173532    0.195876    0.215063    0.216495    0.514077    0.533258    0.323867    0.329506    2800        25.225225   2.510867    0.145875    106.469593 
[37m[36mINFO[0m[0m 01/26 17:46:34 | 0.286309    0.294845    0.599381    0.615558    1.656046    0.219361    0.232990    0.245132    0.252005    0.599381    0.615558    0.394435    0.399541    3000        27.027027   1.925171    0.139543    107.211576 
[37m[36mINFO[0m[0m 01/26 17:48:54 | 0.325601    0.328642    0.662725    0.676437    1.287465    0.254377    0.259794    0.269759    0.269187    0.662725    0.676437    0.452668    0.456946    3200        28.828829   1.477104    0.142829    110.834631 
[37m[36mINFO[0m[0m 01/26 17:51:12 | 0.346462    0.348902    0.713964    0.722661    1.080504    0.271370    0.280412    0.282360    0.279496    0.713964    0.722661    0.485657    0.486797    3400        30.630631   1.192876    0.141545    109.972970 
[37m[36mINFO[0m[0m 01/26 17:53:29 | 0.364374    0.361742    0.743243    0.742954    0.955759    0.290422    0.294845    0.298969    0.288660    0.743243    0.742954    0.503729    0.501722    3600        32.432432   0.966162    0.142595    108.474391 
[37m[36mINFO[0m[0m 01/26 17:55:55 | 0.383510    0.380171    0.774212    0.763247    0.849159    0.312564    0.313402    0.308133    0.293242    0.774212    0.763247    0.529834    0.533869    3800        34.234234   0.853643    0.147781    115.716402 
[37m[36mINFO[0m[0m 01/26 17:58:14 | 0.397624    0.390569    0.801239    0.780158    0.785742    0.328527    0.321649    0.315865    0.300115    0.801239    0.780158    0.548480    0.549943    4000        36.036036   0.730983    0.137302    110.957291 
[37m[36mINFO[0m[0m 01/26 18:00:30 | 0.409864    0.404931    0.815878    0.797069    0.733959    0.338311    0.346392    0.332188    0.311569    0.815878    0.797069    0.559094    0.556831    4200        37.837838   0.687104    0.140685    108.356525 
[37m[36mINFO[0m[0m 01/26 18:02:49 | 0.421570    0.415786    0.831081    0.808343    0.694506    0.354789    0.342268    0.335338    0.333333    0.831081    0.808343    0.574584    0.571757    4400        39.639640   0.629784    0.142698    109.509881 
[37m[36mINFO[0m[0m 01/26 18:05:08 | 0.421287    0.419842    0.855574    0.813980    0.648391    0.349640    0.356701    0.337056    0.319588    0.855574    0.813980    0.577166    0.583238    4600        41.441441   0.538262    0.148182    109.395609 
[37m[36mINFO[0m[0m 01/26 18:07:27 | 0.435705    0.429398    0.865146    0.827508    0.628973    0.370237    0.367010    0.340779    0.324170    0.865146    0.827508    0.596099    0.597015    4800        43.243243   0.508267    0.142283    109.640476 
[37m[36mINFO[0m[0m 01/26 18:09:43 | 0.432304    0.433607    0.872185    0.829763    0.620278    0.371782    0.367010    0.332474    0.325315    0.872185    0.829763    0.592656    0.608496    5000        45.045045   0.482843    0.142325    107.538579 
[37m[36mINFO[0m[0m 01/26 18:09:44 | Cumulative gradient change saved at train_output/OfficeHome/ERM/[0, 1, 3]/250126_17-10-04_resnet50_sgd/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 01/26 18:09:45 | ---
[37m[36mINFO[0m[0m 01/26 18:09:45 | test-domain validation(oracle) = 43.230%
[37m[36mINFO[0m[0m 01/26 18:09:45 | training-domain validation(iid) = 43.230%
[37m[36mINFO[0m[0m 01/26 18:09:45 | last = 43.230%
[37m[36mINFO[0m[0m 01/26 18:09:45 | last (inD) = 82.976%
[37m[36mINFO[0m[0m 01/26 18:09:45 | training-domain validation (iid, inD) = 82.976%
[37m[36mINFO[0m[0m 01/26 18:09:45 | === Summary ===
[37m[36mINFO[0m[0m 01/26 18:09:45 | Command: /jsm0707/Large-scale/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm ERM --test_envs 0 1 3 --dataset OfficeHome
[37m[36mINFO[0m[0m 01/26 18:09:45 | Unique name: 250126_17-10-04_resnet50_sgd
[37m[36mINFO[0m[0m 01/26 18:09:45 | Out path: train_output/OfficeHome/ERM/[0, 1, 3]/250126_17-10-04_resnet50_sgd
[37m[36mINFO[0m[0m 01/26 18:09:45 | Algorithm: ERM
[37m[36mINFO[0m[0m 01/26 18:09:45 | Dataset: OfficeHome
