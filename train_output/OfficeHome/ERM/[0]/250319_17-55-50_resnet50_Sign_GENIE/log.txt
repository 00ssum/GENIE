[37m[36mINFO[0m[0m 03/19 17:55:50 | Command :: /jsm0707/GENIE/train_all.py resnet50_Sign_GENIE config/resnet50_Sign_GENIE.yaml --algorithm ERM --test_envs 0 --dataset OfficeHome --trial_seed 0 --hparams_seed 16
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: ERM
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_Sign_GENIE.yaml']
	data_dir: data
	dataset: OfficeHome
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 16
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_Sign_GENIE
	out_dir: train_output/OfficeHome/ERM/[0]/250319_17-55-50_resnet50_Sign_GENIE
	out_root: train_output/OfficeHome/ERM/[0]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0]
	trial_seed: 0
	unique_name: 250319_17-55-50_resnet50_Sign_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: sign_genie
	freeze_bn: False
	pretrained: True
	lr: 4.249952708249365e-05
	batch_size: 17
	weight_decay: 9.786966598736845e-06
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[OfficeHome] #envs=4, #classes=65
	env0: A (#2427)
	env1: C (#4365)
	env2: P (#4439)
	env3: R (#4357)

[37m[36mINFO[0m[0m 03/19 17:55:50 | n_steps = 5001
[37m[36mINFO[0m[0m 03/19 17:55:50 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/19 17:55:50 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/19 17:55:50 | 
[37m[36mINFO[0m[0m 03/19 17:55:50 | Testenv name escaping te_A -> te_A
[37m[36mINFO[0m[0m 03/19 17:55:50 | Test envs = [0], name = te_A
[37m[36mINFO[0m[0m 03/19 17:55:50 | Train environments: [1, 2, 3], Test environments: [0]
[37m[36mINFO[0m[0m 03/19 17:55:50 | Batch sizes for each domain: [0, 17, 17, 17] (total=51)
[37m[36mINFO[0m[0m 03/19 17:55:50 | steps-per-epoch for each domain: 205.41, 208.94, 205.06 -> min = 205.06
[37m[36mINFO[0m[0m 03/19 17:55:52 | # of params = 23641217
[37m[36mINFO[0m[0m 03/19 17:57:55 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/19 17:57:55 | 0.014933    0.006186    0.017014    0.012180    4.226673    0.014933    0.006186    0.017755    0.014891    0.014640    0.009019    0.018646    0.012629    0           0.000000    4.266669    2.384599    120.832892 
[37m[36mINFO[0m[0m 03/19 18:01:07 | 0.516478    0.552577    0.759009    0.714947    1.023612    0.516478    0.552577    0.677835    0.599084    0.806306    0.790304    0.792886    0.755454    200         0.975330    1.777678    0.335483    124.187976 
[37m[36mINFO[0m[0m 03/19 18:04:21 | 0.576210    0.622680    0.824974    0.773538    0.844805    0.576210    0.622680    0.782360    0.707904    0.859516    0.833145    0.833046    0.779564    400         1.950660    0.757855    0.361938    122.137485 
[37m[36mINFO[0m[0m 03/19 18:07:37 | 0.558702    0.589691    0.856299    0.774978    0.865218    0.558702    0.589691    0.808419    0.690722    0.893581    0.850056    0.866896    0.784156    600         2.925990    0.565071    0.360912    123.805320 
[37m[36mINFO[0m[0m 03/19 18:10:52 | 0.585479    0.626804    0.884304    0.784641    0.864805    0.585479    0.626804    0.850229    0.728522    0.906813    0.829763    0.895869    0.795637    800         3.901320    0.454489    0.364862    121.433725 
[37m[36mINFO[0m[0m 03/19 18:14:06 | 0.586509    0.628866    0.908672    0.796618    0.850795    0.586509    0.628866    0.880871    0.719359    0.936655    0.874859    0.908491    0.795637    1000        4.876649    0.362128    0.370432    120.833408 
[37m[36mINFO[0m[0m 03/19 18:17:20 | 0.569516    0.564948    0.892001    0.766584    0.982668    0.569516    0.564948    0.865407    0.693013    0.913007    0.845547    0.897590    0.761194    1200        5.851979    0.310195    0.361273    121.042710 
[37m[36mINFO[0m[0m 03/19 18:20:20 | 0.578270    0.604124    0.917273    0.775753    0.935375    0.578270    0.604124    0.886312    0.705613    0.936937    0.846674    0.928571    0.774971    1400        6.827309    0.269934    0.305676    118.870610 
[37m[36mINFO[0m[0m 03/19 18:23:18 | 0.604016    0.618557    0.942175    0.807778    0.803284    0.604016    0.618557    0.917526    0.746850    0.958052    0.861330    0.950947    0.815155    1600        7.802639    0.223860    0.283784    121.548117 
[37m[36mINFO[0m[0m 03/19 18:26:17 | 0.596292    0.608247    0.941328    0.806922    0.880678    0.596292    0.608247    0.924685    0.739977    0.955236    0.877114    0.944062    0.803674    1800        8.777969    0.201833    0.285746    121.623741 
