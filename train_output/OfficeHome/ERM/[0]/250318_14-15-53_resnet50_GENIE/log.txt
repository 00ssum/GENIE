[37m[36mINFO[0m[0m 03/18 14:15:53 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm ERM --test_envs 0 --dataset OfficeHome
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: ERM
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: OfficeHome
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/OfficeHome/ERM/[0]/250318_14-15-53_resnet50_GENIE
	out_root: train_output/OfficeHome/ERM/[0]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0]
	trial_seed: 0
	unique_name: 250318_14-15-53_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[OfficeHome] #envs=4, #classes=65
	env0: A (#2427)
	env1: C (#4365)
	env2: P (#4439)
	env3: R (#4357)

[37m[36mINFO[0m[0m 03/18 14:15:53 | n_steps = 5001
[37m[36mINFO[0m[0m 03/18 14:15:53 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/18 14:15:53 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/18 14:15:53 | 
[37m[36mINFO[0m[0m 03/18 14:15:53 | Testenv name escaping te_A -> te_A
[37m[36mINFO[0m[0m 03/18 14:15:53 | Test envs = [0], name = te_A
[37m[36mINFO[0m[0m 03/18 14:15:53 | Train environments: [1, 2, 3], Test environments: [0]
[37m[36mINFO[0m[0m 03/18 14:15:53 | Batch sizes for each domain: [0, 32, 32, 32] (total=96)
[37m[36mINFO[0m[0m 03/18 14:15:53 | steps-per-epoch for each domain: 109.12, 111.00, 108.94 -> min = 108.94
[37m[36mINFO[0m[0m 03/18 14:15:55 | # of params = 23641217
[37m[36mINFO[0m[0m 03/18 14:18:01 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/18 14:18:01 | 0.020597    0.020619    0.010651    0.011040    4.225116    0.020597    0.020619    0.008877    0.004582    0.008446    0.009019    0.014630    0.019518    0           0.000000    4.273489    2.702147    122.797928 
[37m[36mINFO[0m[0m 03/18 14:21:55 | 0.581874    0.618557    0.815889    0.759046    0.850198    0.581874    0.618557    0.740836    0.658648    0.863457    0.830891    0.843373    0.787600    200         1.835915    1.439218    0.562391    122.035166 
[37m[36mINFO[0m[0m 03/18 14:25:38 | 0.569516    0.587629    0.872559    0.777304    0.874647    0.569516    0.587629    0.821592    0.697595    0.906813    0.844419    0.889271    0.789897    400         3.671830    0.543608    0.528007    117.407135 
[37m[36mINFO[0m[0m 03/18 14:29:24 | 0.577240    0.597938    0.906807    0.799347    0.792926    0.577240    0.597938    0.885166    0.726231    0.928773    0.865840    0.906483    0.805970    600         5.507745    0.345967    0.533934    118.918334 
[37m[36mINFO[0m[0m 03/18 14:33:09 | 0.611740    0.659794    0.922032    0.788372    0.870361    0.611740    0.659794    0.894903    0.710195    0.939752    0.847802    0.931440    0.807118    800         7.343660    0.269880    0.531782    119.295233 
[37m[36mINFO[0m[0m 03/18 14:36:56 | 0.606591    0.626804    0.952443    0.817935    0.825759    0.606591    0.626804    0.936712    0.751432    0.965653    0.889515    0.954963    0.812859    1000        9.179575    0.196383    0.538423    119.023603 
[37m[36mINFO[0m[0m 03/18 14:40:39 | 0.599382    0.602062    0.957771    0.812612    0.895492    0.599382    0.602062    0.941867    0.751432    0.969313    0.883878    0.962134    0.802526    1200        11.015491   0.151982    0.527944    116.820414 
[37m[36mINFO[0m[0m 03/18 14:44:22 | 0.607621    0.618557    0.959397    0.819094    0.916203    0.607621    0.618557    0.945017    0.765178    0.969032    0.886133    0.964142    0.805970    1400        12.851406   0.129577    0.522876    118.362557 
[37m[36mINFO[0m[0m 03/18 14:48:08 | 0.613800    0.649485    0.972501    0.823266    0.905388    0.613800    0.649485    0.959049    0.768614    0.982264    0.891770    0.976190    0.809414    1600        14.687321   0.116111    0.532640    119.958904 
[37m[36mINFO[0m[0m 03/18 14:51:51 | 0.636972    0.628866    0.973189    0.819154    0.944148    0.636972    0.628866    0.964204    0.749141    0.978885    0.878241    0.976477    0.830080    1800        16.523236   0.092912    0.525945    117.800709 
[37m[36mINFO[0m[0m 03/18 14:55:37 | 0.608651    0.614433    0.968608    0.811809    0.951314    0.608651    0.614433    0.955326    0.746850    0.978322    0.890643    0.972174    0.797933    2000        18.359151   0.091765    0.537392    118.028548 
[37m[36mINFO[0m[0m 03/18 14:59:24 | 0.612770    0.632990    0.979259    0.816030    0.995978    0.612770    0.632990    0.969931    0.750286    0.986205    0.888388    0.981641    0.809414    2200        20.195066   0.071805    0.540392    119.759776 
[37m[36mINFO[0m[0m 03/18 15:03:10 | 0.621009    0.663918    0.982676    0.826968    0.948153    0.621009    0.663918    0.973081    0.760596    0.989865    0.913191    0.985083    0.807118    2400        22.030981   0.062725    0.528926    119.508671 
[37m[36mINFO[0m[0m 03/18 15:06:54 | 0.600927    0.602062    0.980230    0.821383    0.931047    0.600927    0.602062    0.971936    0.765178    0.983671    0.887260    0.985083    0.811711    2600        23.866896   0.056813    0.535019    117.776238 
[37m[36mINFO[0m[0m 03/18 15:10:38 | 0.604531    0.608247    0.982769    0.827440    0.966612    0.604531    0.608247    0.974800    0.769759    0.990146    0.897407    0.983362    0.815155    2800        25.702811   0.060680    0.516706    119.988656 
[37m[36mINFO[0m[0m 03/18 15:14:19 | 0.612770    0.604124    0.985251    0.819803    0.986731    0.612770    0.604124    0.973940    0.757159    0.990991    0.896280    0.990820    0.805970    3000        27.538726   0.048529    0.522275    117.041893 
[37m[36mINFO[0m[0m 03/18 15:17:59 | 0.614315    0.595876    0.985162    0.822468    1.039940    0.614315    0.595876    0.977663    0.747995    0.989583    0.899662    0.988239    0.819747    3200        29.374641   0.050485    0.500683    119.185098 
[37m[36mINFO[0m[0m 03/18 15:21:44 | 0.622554    0.626804    0.986010    0.830904    1.052768    0.622554    0.626804    0.978236    0.772050    0.991554    0.894025    0.988239    0.826636    3400        31.210557   0.044547    0.526523    119.766723 
[37m[36mINFO[0m[0m 03/18 15:25:28 | 0.619464    0.632990    0.984670    0.818287    1.014191    0.619464    0.632990    0.975945    0.756014    0.991836    0.894025    0.986231    0.804822    3600        33.046472   0.046562    0.521820    120.425953 
[37m[36mINFO[0m[0m 03/18 15:29:12 | 0.615860    0.606186    0.986685    0.832367    0.941236    0.615860    0.606186    0.977090    0.769759    0.990709    0.905299    0.992255    0.822044    3800        34.882387   0.039609    0.520590    119.261989 
[37m[36mINFO[0m[0m 03/18 15:32:53 | 0.622039    0.624742    0.987810    0.835779    1.041748    0.622039    0.624742    0.978236    0.767468    0.994088    0.910936    0.991107    0.828932    4000        36.718302   0.036333    0.520199    117.458896 
[37m[36mINFO[0m[0m 03/18 15:36:41 | 0.606591    0.612371    0.984292    0.817141    1.141624    0.606591    0.612371    0.975086    0.753723    0.991273    0.894025    0.986517    0.803674    4200        38.554217   0.036085    0.545779    118.704907 
[37m[36mINFO[0m[0m 03/18 15:40:23 | 0.627188    0.639175    0.989729    0.833524    0.957827    0.627188    0.639175    0.982532    0.767468    0.992680    0.904171    0.993976    0.828932    4400        40.390132   0.036784    0.507687    120.598089 
[37m[36mINFO[0m[0m 03/18 15:44:10 | 0.618435    0.616495    0.989246    0.822478    1.052009    0.618435    0.616495    0.982245    0.761741    0.993525    0.896280    0.991968    0.809414    4600        42.226047   0.031357    0.537576    119.438627 
[37m[36mINFO[0m[0m 03/18 15:47:55 | 0.625129    0.647423    0.990287    0.833909    0.995982    0.625129    0.647423    0.981959    0.773196    0.995214    0.903044    0.993689    0.825488    4800        44.061962   0.036140    0.537964    117.420825 
[37m[36mINFO[0m[0m 03/18 15:51:38 | 0.616890    0.630928    0.989720    0.827073    1.068852    0.616890    0.630928    0.982532    0.759450    0.994088    0.896280    0.992542    0.825488    5000        45.897877   0.030081    0.528801    117.096321 
[37m[36mINFO[0m[0m 03/18 15:51:38 | Cumulative gradient change saved at train_output/OfficeHome/ERM/[0]/250318_14-15-53_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/18 15:51:40 | ---
[37m[36mINFO[0m[0m 03/18 15:51:40 | test-domain validation(oracle) = 62.101%
[37m[36mINFO[0m[0m 03/18 15:51:40 | training-domain validation(iid) = 62.204%
[37m[36mINFO[0m[0m 03/18 15:51:40 | last = 61.689%
[37m[36mINFO[0m[0m 03/18 15:51:40 | last (inD) = 82.707%
[37m[36mINFO[0m[0m 03/18 15:51:40 | training-domain validation (iid, inD) = 83.578%
[37m[36mINFO[0m[0m 03/18 15:51:40 | === Summary ===
[37m[36mINFO[0m[0m 03/18 15:51:40 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm ERM --test_envs 0 --dataset OfficeHome
[37m[36mINFO[0m[0m 03/18 15:51:40 | Unique name: 250318_14-15-53_resnet50_GENIE
[37m[36mINFO[0m[0m 03/18 15:51:40 | Out path: train_output/OfficeHome/ERM/[0]/250318_14-15-53_resnet50_GENIE
[37m[36mINFO[0m[0m 03/18 15:51:40 | Algorithm: ERM
[37m[36mINFO[0m[0m 03/18 15:51:40 | Dataset: OfficeHome
