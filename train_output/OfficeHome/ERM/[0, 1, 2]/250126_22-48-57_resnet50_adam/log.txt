[37m[36mINFO[0m[0m 01/26 22:48:57 | Command :: /jsm0707/Large-scale/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm ERM --test_envs 0 1 2 --dataset OfficeHome
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: ERM
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_adam.yaml']
	data_dir: data
	dataset: OfficeHome
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_adam
	out_dir: train_output/OfficeHome/ERM/[0, 1, 2]/250126_22-48-57_resnet50_adam
	out_root: train_output/OfficeHome/ERM/[0, 1, 2]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 1, 2]
	trial_seed: 0
	unique_name: 250126_22-48-57_resnet50_adam
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: adam
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[OfficeHome] #envs=4, #classes=65
	env0: A (#2427)
	env1: C (#4365)
	env2: P (#4439)
	env3: R (#4357)

[37m[36mINFO[0m[0m 01/26 22:48:57 | n_steps = 5001
[37m[36mINFO[0m[0m 01/26 22:48:57 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 01/26 22:48:57 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 01/26 22:48:57 | 
[37m[36mINFO[0m[0m 01/26 22:48:57 | Testenv name escaping te_A_C_P -> te_A_C_P
[37m[36mINFO[0m[0m 01/26 22:48:57 | Test envs = [0, 1, 2], name = te_A_C_P
[37m[36mINFO[0m[0m 01/26 22:48:57 | Train environments: [3], Test environments: [0, 1, 2]
[37m[36mINFO[0m[0m 01/26 22:48:57 | Batch sizes for each domain: [0, 0, 0, 32] (total=32)
[37m[36mINFO[0m[0m 01/26 22:48:57 | steps-per-epoch for each domain: 108.94 -> min = 108.94
[37m[36mINFO[0m[0m 01/26 22:48:59 | # of params = 23641217
[37m[36mINFO[0m[0m 01/26 22:50:54 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 01/26 22:50:54 | 0.022084    0.026014    0.020367    0.013777    4.203832    0.024202    0.037113    0.022623    0.021764    0.019426    0.019166    0.020367    0.013777    0           0.000000    4.254128    1.193996    113.897347 
[37m[36mINFO[0m[0m 01/26 22:54:34 | 0.483008    0.473718    0.824441    0.721010    0.981232    0.443357    0.447423    0.368843    0.335624    0.636824    0.638106    0.824441    0.721010    200         1.835915    1.416077    0.540381    112.286994 
[37m[36mINFO[0m[0m 01/26 22:58:22 | 0.546262    0.532191    0.903614    0.749713    0.955265    0.548404    0.534021    0.417239    0.391753    0.673142    0.670800    0.903614    0.749713    400         3.671830    0.460510    0.523000    122.981802 
[37m[36mINFO[0m[0m 01/26 23:02:04 | 0.533838    0.510453    0.929432    0.743972    0.966182    0.529866    0.525773    0.391466    0.353952    0.680180    0.651635    0.929432    0.743972    600         5.507745    0.299542    0.548365    111.818718 
[37m[36mINFO[0m[0m 01/26 23:05:40 | 0.565017    0.567349    0.948365    0.777268    0.900648    0.547374    0.579381    0.442440    0.414662    0.705236    0.708005    0.948365    0.777268    800         7.343660    0.222908    0.532078    109.302234 
[37m[36mINFO[0m[0m 01/26 23:09:17 | 0.550381    0.547778    0.959266    0.784156    0.903809    0.524717    0.531959    0.434422    0.413517    0.692005    0.697858    0.959266    0.784156    1000        9.179575    0.168168    0.526078    111.598053 
[37m[36mINFO[0m[0m 01/26 23:12:56 | 0.539629    0.527059    0.939472    0.772675    1.023103    0.535015    0.529897    0.415235    0.391753    0.668637    0.659526    0.939472    0.772675    1200        11.015491   0.154672    0.535943    111.619518 
[37m[36mINFO[0m[0m 01/26 23:16:37 | 0.566830    0.562550    0.970453    0.778416    0.912426    0.574665    0.575258    0.432131    0.406644    0.693694    0.705750    0.970453    0.778416    1400        12.851406   0.130856    0.544765    112.175090 
[37m[36mINFO[0m[0m 01/26 23:20:13 | 0.551874    0.550927    0.971314    0.785304    0.913865    0.533471    0.540206    0.431271    0.418099    0.690878    0.694476    0.971314    0.785304    1600        14.687321   0.109071    0.536088    109.384241 
[37m[36mINFO[0m[0m 01/26 23:23:52 | 0.546434    0.545316    0.974469    0.795637    0.863422    0.537590    0.546392    0.404639    0.388316    0.697072    0.701240    0.974469    0.795637    1800        16.523236   0.094519    0.545477    109.486595 
[37m[36mINFO[0m[0m 01/26 23:27:27 | 0.547444    0.541194    0.963569    0.757750    1.073104    0.535530    0.546392    0.406071    0.390607    0.700732    0.686584    0.963569    0.757750    2000        18.359151   0.098976    0.532130    108.647177 
[37m[36mINFO[0m[0m 01/26 23:31:05 | 0.539462    0.528676    0.963569    0.760046    1.147850    0.510299    0.503093    0.415521    0.397480    0.692568    0.685457    0.963569    0.760046    2200        20.195066   0.086176    0.523830    113.265792 
[37m[36mINFO[0m[0m 01/26 23:34:40 | 0.544978    0.538869    0.974182    0.757750    1.170208    0.520082    0.517526    0.415808    0.420389    0.699043    0.678692    0.974182    0.757750    2400        22.030981   0.086540    0.531656    108.555181 
[37m[36mINFO[0m[0m 01/26 23:38:22 | 0.559916    0.545041    0.983075    0.802526    0.961927    0.528321    0.523711    0.447881    0.415808    0.703547    0.695603    0.983075    0.802526    2600        23.866896   0.106813    0.555619    111.436482 
[37m[36mINFO[0m[0m 01/26 23:42:08 | 0.565321    0.543544    0.985370    0.771527    1.042708    0.536045    0.544330    0.450458    0.396334    0.709459    0.689966    0.985370    0.771527    2800        25.702811   0.064627    0.529137    119.219956 
[37m[36mINFO[0m[0m 01/26 23:45:55 | 0.552347    0.526249    0.976190    0.780712    0.908410    0.526777    0.521649    0.445017    0.403207    0.685248    0.653890    0.976190    0.780712    3000        27.538726   0.064011    0.540441    118.883149 
[37m[36mINFO[0m[0m 01/26 23:49:41 | 0.558308    0.538568    0.968732    0.765786    1.140495    0.523172    0.513402    0.450458    0.410080    0.701295    0.692221    0.968732    0.765786    3200        29.374641   0.070270    0.550292    116.142467 
[37m[36mINFO[0m[0m 01/26 23:53:29 | 0.577748    0.561210    0.986231    0.783008    0.919342    0.563852    0.538144    0.461340    0.431844    0.708052    0.713641    0.986231    0.783008    3400        31.210557   0.069074    0.551900    117.294289 
[37m[36mINFO[0m[0m 01/26 23:57:08 | 0.538624    0.531735    0.980207    0.756602    1.122169    0.498970    0.490722    0.420676    0.405498    0.696227    0.698985    0.980207    0.756602    3600        33.046472   0.085446    0.546044    109.327172 
[37m[36mINFO[0m[0m 01/27 00:00:42 | 0.533505    0.524283    0.968732    0.770379    1.112092    0.510299    0.519588    0.407503    0.374570    0.682714    0.678692    0.968732    0.770379    3800        34.882387   0.079728    0.525170    109.830292 
[37m[36mINFO[0m[0m 01/27 00:04:20 | 0.583250    0.565000    0.990247    0.792193    0.953021    0.546344    0.540206    0.491695    0.450172    0.711712    0.704622    0.990247    0.792193    4000        36.718302   0.065381    0.530590    111.700708 
[37m[36mINFO[0m[0m 01/27 00:07:59 | 0.579695    0.572534    0.990247    0.816303    0.916673    0.567456    0.550515    0.460481    0.443299    0.711149    0.723788    0.990247    0.816303    4200        38.554217   0.058240    0.535350    111.634193 
[37m[36mINFO[0m[0m 01/27 00:11:38 | 0.567976    0.553240    0.993402    0.810563    0.942173    0.547889    0.548454    0.437572    0.406644    0.718468    0.704622    0.993402    0.810563    4400        40.390132   0.057442    0.526325    112.795987 
[37m[36mINFO[0m[0m 01/27 00:15:19 | 0.582028    0.575225    0.989386    0.794489    1.078015    0.564882    0.571134    0.460481    0.434135    0.720721    0.720406    0.989386    0.794489    4600        42.226047   0.049899    0.534724    114.817024 
[37m[36mINFO[0m[0m 01/27 00:19:04 | 0.562241    0.553969    0.980207    0.788749    1.021153    0.538620    0.550515    0.451031    0.414662    0.697072    0.696731    0.980207    0.788749    4800        44.061962   0.072697    0.552269    113.953009 
[37m[36mINFO[0m[0m 01/27 00:22:43 | 0.567306    0.554622    0.985083    0.776119    1.046254    0.530381    0.554639    0.455040    0.420389    0.716498    0.688839    0.985083    0.776119    5000        45.897877   0.057299    0.523175    114.649219 
[37m[36mINFO[0m[0m 01/27 00:22:43 | Cumulative gradient change saved at train_output/OfficeHome/ERM/[0, 1, 2]/250126_22-48-57_resnet50_adam/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 01/27 00:22:44 | ---
[37m[36mINFO[0m[0m 01/27 00:22:44 | test-domain validation(oracle) = 58.203%
[37m[36mINFO[0m[0m 01/27 00:22:44 | training-domain validation(iid) = 57.970%
[37m[36mINFO[0m[0m 01/27 00:22:44 | last = 56.731%
[37m[36mINFO[0m[0m 01/27 00:22:44 | last (inD) = 77.612%
[37m[36mINFO[0m[0m 01/27 00:22:44 | training-domain validation (iid, inD) = 81.630%
[37m[36mINFO[0m[0m 01/27 00:22:45 | === Summary ===
[37m[36mINFO[0m[0m 01/27 00:22:45 | Command: /jsm0707/Large-scale/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm ERM --test_envs 0 1 2 --dataset OfficeHome
[37m[36mINFO[0m[0m 01/27 00:22:45 | Unique name: 250126_22-48-57_resnet50_adam
[37m[36mINFO[0m[0m 01/27 00:22:45 | Out path: train_output/OfficeHome/ERM/[0, 1, 2]/250126_22-48-57_resnet50_adam
[37m[36mINFO[0m[0m 01/27 00:22:45 | Algorithm: ERM
[37m[36mINFO[0m[0m 01/27 00:22:45 | Dataset: OfficeHome
