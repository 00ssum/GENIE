[37m[36mINFO[0m[0m 01/27 15:52:36 | Command :: /jsm0707/Large-scale/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm CORAL --test_envs 1 2 3 --dataset OfficeHome
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_sgd.yaml']
	data_dir: data
	dataset: OfficeHome
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_sgd
	out_dir: train_output/OfficeHome/CORAL/[1, 2, 3]/250127_15-52-36_resnet50_sgd
	out_root: train_output/OfficeHome/CORAL/[1, 2, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [1, 2, 3]
	trial_seed: 0
	unique_name: 250127_15-52-36_resnet50_sgd
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: sgd
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	mmd_gamma: 1.0
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[OfficeHome] #envs=4, #classes=65
	env0: A (#2427)
	env1: C (#4365)
	env2: P (#4439)
	env3: R (#4357)

[37m[36mINFO[0m[0m 01/27 15:52:36 | n_steps = 5001
[37m[36mINFO[0m[0m 01/27 15:52:36 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 01/27 15:52:36 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 01/27 15:52:36 | 
[37m[36mINFO[0m[0m 01/27 15:52:36 | Testenv name escaping te_C_P_R -> te_C_P_R
[37m[36mINFO[0m[0m 01/27 15:52:36 | Test envs = [1, 2, 3], name = te_C_P_R
[37m[36mINFO[0m[0m 01/27 15:52:36 | Train environments: [0], Test environments: [1, 2, 3]
[37m[36mINFO[0m[0m 01/27 15:52:36 | Batch sizes for each domain: [32, 0, 0, 0] (total=32)
[37m[36mINFO[0m[0m 01/27 15:52:36 | steps-per-epoch for each domain: 60.69 -> min = 60.69
[37m[36mINFO[0m[0m 01/27 15:52:38 | # of params = 23641217
[37m[36mINFO[0m[0m 01/27 15:54:28 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 01/27 15:54:28 | 0.015211    0.012904    0.015963    0.026804    4.255101    0.015963    0.026804    0.017182    0.014891    0.012387    0.015784    0.016064    0.008037    0           0.000000    4.231345    0.000000    1.178917    108.890388 
[37m[36mINFO[0m[0m 01/27 15:57:05 | 0.018542    0.014044    0.027806    0.045361    4.196039    0.027806    0.045361    0.020905    0.016037    0.014640    0.016911    0.020080    0.009185    200         3.295572    4.196058    0.000000    0.233956    110.375622 
[37m[36mINFO[0m[0m 01/27 15:59:46 | 0.021779    0.017863    0.043769    0.051546    4.149818    0.043769    0.051546    0.025773    0.018328    0.016329    0.018038    0.023236    0.017222    400         6.591143    4.145958    0.000000    0.241006    111.646478 
[37m[36mINFO[0m[0m 01/27 16:02:23 | 0.025772    0.020159    0.055098    0.063918    4.107423    0.055098    0.063918    0.028923    0.018328    0.019707    0.018038    0.028686    0.024110    600         9.886715    4.092258    0.000000    0.230995    111.129173 
[37m[36mINFO[0m[0m 01/27 16:05:07 | 0.030150    0.023988    0.064367    0.080412    4.066344    0.064367    0.080412    0.034078    0.024055    0.022523    0.016911    0.033850    0.030999    800         13.182286   4.061811    0.000000    0.234960    116.744294 
[37m[36mINFO[0m[0m 01/27 16:07:45 | 0.036807    0.030467    0.077755    0.084536    4.024037    0.077755    0.084536    0.038660    0.032073    0.027872    0.020293    0.043890    0.039036    1000        16.477858   4.024929    0.000000    0.235096    110.251475 
[37m[36mINFO[0m[0m 01/27 16:10:14 | 0.043758    0.036565    0.097837    0.096907    3.975445    0.097837    0.096907    0.043528    0.038946    0.032095    0.023675    0.055651    0.047072    1200        19.773429   3.968928    0.000000    0.231171    103.157226 
[37m[36mINFO[0m[0m 01/27 16:12:45 | 0.054126    0.048355    0.109681    0.123711    3.917759    0.109681    0.123711    0.051260    0.044674    0.039977    0.034949    0.071142    0.065442    1400        23.069001   3.907086    0.000000    0.233736    103.609854 
[37m[36mINFO[0m[0m 01/27 16:15:26 | 0.068874    0.068108    0.143666    0.164948    3.852352    0.143666    0.164948    0.061569    0.057274    0.050676    0.057497    0.094378    0.089552    1600        26.364573   3.851916    0.000000    0.227835    114.707211 
[37m[36mINFO[0m[0m 01/27 16:18:01 | 0.086451    0.083348    0.180227    0.197938    3.776543    0.180227    0.197938    0.075029    0.073310    0.067286    0.066516    0.117040    0.110218    1800        29.660144   3.766910    0.000000    0.236473    107.956091 
[37m[36mINFO[0m[0m 01/27 16:20:38 | 0.105382    0.103873    0.210093    0.228866    3.681572    0.210093    0.228866    0.094788    0.085911    0.081081    0.087937    0.140275    0.137773    2000        32.955716   3.682019    0.000000    0.230529    110.327888 
[37m[36mINFO[0m[0m 01/27 16:23:14 | 0.122473    0.126296    0.251287    0.257732    3.560691    0.251287    0.257732    0.109107    0.109966    0.098818    0.110485    0.159495    0.158439    2200        36.251287   3.565455    0.000000    0.231314    109.667526 
[37m[36mINFO[0m[0m 01/27 16:25:51 | 0.141858    0.144958    0.271370    0.276289    3.412321    0.271370    0.276289    0.126861    0.129439    0.116554    0.122886    0.182157    0.182549    2400        39.546859   3.428389    0.000000    0.230868    110.670924 
[37m[36mINFO[0m[0m 01/27 16:28:30 | 0.164939    0.166578    0.312049    0.305155    3.229731    0.312049    0.305155    0.142325    0.147766    0.139640    0.152198    0.212851    0.199770    2600        42.842430   3.295654    0.000000    0.238154    110.785012 
[37m[36mINFO[0m[0m 01/27 16:31:08 | 0.194073    0.193593    0.357878    0.352577    3.001751    0.357878    0.352577    0.162085    0.163803    0.172860    0.175874    0.247275    0.241102    2800        46.138002   3.063743    0.000000    0.234130    110.674627 
[37m[36mINFO[0m[0m 01/27 16:33:45 | 0.221026    0.221739    0.401648    0.391753    2.763277    0.401648    0.391753    0.173826    0.174112    0.204110    0.202931    0.285141    0.288175    3000        49.433574   2.804590    0.000000    0.233532    110.049385 
[37m[36mINFO[0m[0m 01/27 16:36:16 | 0.252454    0.254069    0.460865    0.453608    2.492073    0.460865    0.453608    0.195876    0.200458    0.237331    0.232244    0.324154    0.329506    3200        52.729145   2.520331    0.000000    0.235611    104.112135 
[37m[36mINFO[0m[0m 01/27 16:38:51 | 0.291640    0.295817    0.511843    0.501031    2.239558    0.511843    0.501031    0.219931    0.233677    0.283502    0.285231    0.371486    0.368542    3400        56.024717   2.210299    0.000000    0.230723    107.746327 
[37m[36mINFO[0m[0m 01/27 16:41:24 | 0.332389    0.331563    0.565396    0.527835    2.002124    0.565396    0.527835    0.250859    0.261168    0.323761    0.319053    0.422547    0.414466    3600        59.320288   1.913038    0.000000    0.234294    106.570865 
[37m[36mINFO[0m[0m 01/27 16:43:58 | 0.367903    0.366511    0.604531    0.538144    1.834428    0.604531    0.538144    0.275773    0.276060    0.360923    0.359639    0.467011    0.463835    3800        62.615860   1.657433    0.000000    0.228336    107.430511 
[37m[36mINFO[0m[0m 01/27 16:46:33 | 0.387906    0.385136    0.642122    0.589691    1.719982    0.642122    0.589691    0.291237    0.289805    0.386824    0.378805    0.485657    0.486797    4000        65.911432   1.470755    0.000000    0.231000    108.192774 
[37m[36mINFO[0m[0m 01/27 16:49:08 | 0.420646    0.422384    0.679197    0.595876    1.632387    0.679197    0.595876    0.317583    0.318442    0.423986    0.417136    0.520367    0.531573    4200        69.207003   1.276628    0.000000    0.231173    108.359671 
[37m[36mINFO[0m[0m 01/27 16:51:41 | 0.434110    0.431486    0.717817    0.591753    1.555945    0.717817    0.591753    0.326460    0.327606    0.441160    0.429538    0.534710    0.537313    4400        72.502575   1.135766    0.000000    0.231077    106.650343 
[37m[36mINFO[0m[0m 01/27 16:54:13 | 0.453155    0.448927    0.735839    0.610309    1.496319    0.735839    0.610309    0.337342    0.333333    0.467905    0.455468    0.554217    0.557979    4600        75.798146   0.997944    0.000000    0.234954    104.684961 
[37m[36mINFO[0m[0m 01/27 16:56:45 | 0.466181    0.462953    0.751802    0.624742    1.448146    0.751802    0.624742    0.351088    0.355097    0.478322    0.474634    0.569134    0.559127    4800        79.093718   0.925137    0.000000    0.235530    104.461749 
[37m[36mINFO[0m[0m 01/27 16:59:17 | 0.476680    0.475446    0.775489    0.637113    1.416550    0.775489    0.637113    0.350802    0.352806    0.496622    0.497182    0.582616    0.576349    5000        82.389289   0.862491    0.000000    0.232605    105.087292 
[37m[36mINFO[0m[0m 01/27 16:59:17 | Cumulative gradient change saved at train_output/OfficeHome/CORAL/[1, 2, 3]/250127_15-52-36_resnet50_sgd/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 01/27 16:59:19 | ---
[37m[36mINFO[0m[0m 01/27 16:59:19 | test-domain validation(oracle) = 47.668%
[37m[36mINFO[0m[0m 01/27 16:59:19 | training-domain validation(iid) = 47.668%
[37m[36mINFO[0m[0m 01/27 16:59:19 | last = 47.668%
[37m[36mINFO[0m[0m 01/27 16:59:19 | last (inD) = 63.711%
[37m[36mINFO[0m[0m 01/27 16:59:19 | training-domain validation (iid, inD) = 63.711%
[37m[36mINFO[0m[0m 01/27 16:59:19 | === Summary ===
[37m[36mINFO[0m[0m 01/27 16:59:19 | Command: /jsm0707/Large-scale/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm CORAL --test_envs 1 2 3 --dataset OfficeHome
[37m[36mINFO[0m[0m 01/27 16:59:19 | Unique name: 250127_15-52-36_resnet50_sgd
[37m[36mINFO[0m[0m 01/27 16:59:19 | Out path: train_output/OfficeHome/CORAL/[1, 2, 3]/250127_15-52-36_resnet50_sgd
[37m[36mINFO[0m[0m 01/27 16:59:19 | Algorithm: CORAL
[37m[36mINFO[0m[0m 01/27 16:59:19 | Dataset: OfficeHome
