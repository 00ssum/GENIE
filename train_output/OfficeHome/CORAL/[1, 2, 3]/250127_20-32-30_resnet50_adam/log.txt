[37m[36mINFO[0m[0m 01/27 20:32:30 | Command :: /jsm0707/Large-scale/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm CORAL --test_envs 1 2 3 --dataset OfficeHome
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_adam.yaml']
	data_dir: data
	dataset: OfficeHome
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_adam
	out_dir: train_output/OfficeHome/CORAL/[1, 2, 3]/250127_20-32-30_resnet50_adam
	out_root: train_output/OfficeHome/CORAL/[1, 2, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [1, 2, 3]
	trial_seed: 0
	unique_name: 250127_20-32-30_resnet50_adam
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: adam
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	mmd_gamma: 1.0
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[OfficeHome] #envs=4, #classes=65
	env0: A (#2427)
	env1: C (#4365)
	env2: P (#4439)
	env3: R (#4357)

[37m[36mINFO[0m[0m 01/27 20:32:30 | n_steps = 5001
[37m[36mINFO[0m[0m 01/27 20:32:30 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 01/27 20:32:30 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 01/27 20:32:30 | 
[37m[36mINFO[0m[0m 01/27 20:32:30 | Testenv name escaping te_C_P_R -> te_C_P_R
[37m[36mINFO[0m[0m 01/27 20:32:30 | Test envs = [1, 2, 3], name = te_C_P_R
[37m[36mINFO[0m[0m 01/27 20:32:30 | Train environments: [0], Test environments: [1, 2, 3]
[37m[36mINFO[0m[0m 01/27 20:32:30 | Batch sizes for each domain: [32, 0, 0, 0] (total=32)
[37m[36mINFO[0m[0m 01/27 20:32:30 | steps-per-epoch for each domain: 60.69 -> min = 60.69
[37m[36mINFO[0m[0m 01/27 20:32:31 | # of params = 23641217
[37m[36mINFO[0m[0m 01/27 20:34:16 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 01/27 20:34:16 | 0.022082    0.020934    0.039135    0.024742    4.202395    0.039135    0.024742    0.025487    0.022910    0.013795    0.015784    0.026965    0.024110    0           0.000000    4.231345    0.000000    1.143840    103.466994 
[37m[36mINFO[0m[0m 01/27 20:37:00 | 0.464857    0.445106    0.835221    0.630928    1.669351    0.835221    0.630928    0.335338    0.343643    0.477477    0.453213    0.581756    0.538462    200         3.295572    1.669345    0.000000    0.245613    114.593038 
[37m[36mINFO[0m[0m 01/27 20:39:38 | 0.514322    0.490692    0.928424    0.651546    1.593725    0.928424    0.651546    0.396907    0.379152    0.527872    0.503946    0.618187    0.588978    400         6.591143    0.399927    0.000000    0.233764    111.640339 
[37m[36mINFO[0m[0m 01/27 20:42:14 | 0.529726    0.516195    0.970649    0.698969    1.408100    0.970649    0.698969    0.423826    0.415808    0.539133    0.521984    0.626219    0.610792    600         9.886715    0.229373    0.000000    0.229599    108.798937 
[37m[36mINFO[0m[0m 01/27 20:44:45 | 0.490227    0.475527    0.944902    0.680412    1.656097    0.944902    0.680412    0.373711    0.372279    0.499437    0.481398    0.597533    0.572905    800         13.182286   0.152866    0.000000    0.233335    104.555458 
[37m[36mINFO[0m[0m 01/27 20:47:16 | 0.493989    0.477027    0.964985    0.686598    1.710838    0.964985    0.686598    0.382589    0.358534    0.493525    0.488162    0.605852    0.584386    1000        16.477858   0.120388    0.000000    0.234239    104.483322 
[37m[36mINFO[0m[0m 01/27 20:49:46 | 0.500266    0.492752    0.989701    0.698969    1.635562    0.989701    0.698969    0.382302    0.368843    0.498874    0.481398    0.619621    0.628014    1200        19.773429   0.106518    0.000000    0.226953    104.287312 
[37m[36mINFO[0m[0m 01/27 20:52:16 | 0.516514    0.491511    0.979918    0.694845    1.592289    0.979918    0.694845    0.384307    0.390607    0.530124    0.493799    0.635112    0.590126    1400        23.069001   0.068347    0.000000    0.233149    103.265483 
[37m[36mINFO[0m[0m 01/27 20:54:50 | 0.546929    0.539016    0.991761    0.721649    1.531262    0.991761    0.721649    0.440722    0.446735    0.554054    0.541150    0.646013    0.629162    1600        26.364573   0.064215    0.000000    0.236532    106.534141 
[37m[36mINFO[0m[0m 01/27 20:57:21 | 0.495656    0.482073    0.961380    0.678351    1.829006    0.961380    0.678351    0.387171    0.383734    0.501689    0.473506    0.598107    0.588978    1800        29.660144   0.081667    0.000000    0.233339    103.922887 
[37m[36mINFO[0m[0m 01/27 20:59:51 | 0.490737    0.483991    0.972194    0.682474    1.826607    0.972194    0.682474    0.374284    0.396334    0.494369    0.471251    0.603557    0.584386    2000        32.955716   0.110285    0.000000    0.234125    103.687110 
[37m[36mINFO[0m[0m 01/27 21:02:23 | 0.507387    0.491589    0.989186    0.715464    1.704465    0.989186    0.715464    0.379725    0.388316    0.522241    0.481398    0.620195    0.605052    2200        36.251287   0.062278    0.000000    0.234389    105.098588 
[37m[36mINFO[0m[0m 01/27 21:04:56 | 0.517990    0.506757    0.989701    0.711340    1.733453    0.989701    0.711340    0.391466    0.399771    0.538007    0.502818    0.624498    0.617681    2400        39.546859   0.056440    0.000000    0.232777    106.632755 
[37m[36mINFO[0m[0m 01/27 21:07:29 | 0.517590    0.513600    0.979403    0.672165    1.753116    0.979403    0.672165    0.401489    0.413517    0.524775    0.508455    0.626506    0.618829    2600        42.842430   0.048303    0.000000    0.230209    106.265640 
[37m[36mINFO[0m[0m 01/27 21:10:03 | 0.492873    0.482856    0.986612    0.692784    1.380126    0.986612    0.692784    0.350515    0.360825    0.506475    0.473506    0.621629    0.614237    2800        46.138002   0.064126    0.000000    0.237628    106.926445 
[37m[36mINFO[0m[0m 01/27 21:12:34 | 0.464469    0.444122    0.966014    0.665979    1.704580    0.966014    0.665979    0.348797    0.345934    0.477196    0.426156    0.567413    0.560276    3000        49.433574   0.077019    0.000000    0.230622    104.293660 
[37m[36mINFO[0m[0m 01/27 21:15:02 | 0.515290    0.497334    0.981462    0.692784    1.717980    0.981462    0.692784    0.423253    0.418099    0.508446    0.476888    0.614171    0.597015    3200        52.729145   0.077634    0.000000    0.229396    102.811267 
[37m[36mINFO[0m[0m 01/27 21:17:34 | 0.497542    0.488828    0.984552    0.696907    1.641058    0.984552    0.696907    0.371134    0.378007    0.507320    0.496054    0.614171    0.592423    3400        56.024717   0.067965    0.000000    0.228032    105.897725 
[37m[36mINFO[0m[0m 01/27 21:20:02 | 0.501635    0.486675    0.983522    0.676289    1.757359    0.983522    0.676289    0.393471    0.389462    0.508164    0.471251    0.603270    0.599311    3600        59.320288   0.035652    0.000000    0.221805    103.367066 
[37m[36mINFO[0m[0m 01/27 21:22:31 | 0.470673    0.462591    0.947992    0.641237    1.976646    0.947992    0.641237    0.383448    0.381443    0.475788    0.467869    0.552783    0.538462    3800        62.615860   0.052531    0.000000    0.231927    103.222783 
[37m[36mINFO[0m[0m 01/27 21:25:03 | 0.526097    0.498923    0.994851    0.748454    1.560585    0.994851    0.748454    0.421821    0.405498    0.523367    0.468997    0.633104    0.622273    4000        65.911432   0.034907    0.000000    0.237213    104.716095 
[37m[36mINFO[0m[0m 01/27 21:27:36 | 0.476044    0.469540    0.974768    0.661856    1.802955    0.974768    0.661856    0.365120    0.366552    0.474944    0.459977    0.588067    0.582090    4200        69.207003   0.034123    0.000000    0.244108    104.104549 
[37m[36mINFO[0m[0m 01/27 21:30:12 | 0.501762    0.497328    0.986097    0.690722    1.694701    0.986097    0.690722    0.404353    0.416953    0.502252    0.478016    0.598680    0.597015    4400        72.502575   0.071842    0.000000    0.243329    107.253756 
[37m[36mINFO[0m[0m 01/27 21:32:42 | 0.496841    0.491795    0.978888    0.668041    1.920482    0.978888    0.668041    0.379152    0.374570    0.511543    0.511838    0.599828    0.588978    4600        75.798146   0.044616    0.000000    0.236629    102.416760 
[37m[36mINFO[0m[0m 01/27 21:35:09 | 0.483314    0.469439    0.983522    0.661856    1.874427    0.983522    0.661856    0.362543    0.344788    0.489865    0.479143    0.597533    0.584386    4800        79.093718   0.056063    0.000000    0.232029    100.473765 
[37m[36mINFO[0m[0m 01/27 21:37:37 | 0.485702    0.473039    0.987642    0.680412    1.891519    0.987642    0.680412    0.365693    0.375716    0.489865    0.449831    0.601549    0.593571    5000        82.389289   0.055267    0.000000    0.228766    102.270228 
[37m[36mINFO[0m[0m 01/27 21:37:37 | Cumulative gradient change saved at train_output/OfficeHome/CORAL/[1, 2, 3]/250127_20-32-30_resnet50_adam/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 01/27 21:37:38 | ---
[37m[36mINFO[0m[0m 01/27 21:37:38 | test-domain validation(oracle) = 54.693%
[37m[36mINFO[0m[0m 01/27 21:37:38 | training-domain validation(iid) = 52.610%
[37m[36mINFO[0m[0m 01/27 21:37:38 | last = 48.570%
[37m[36mINFO[0m[0m 01/27 21:37:38 | last (inD) = 68.041%
[37m[36mINFO[0m[0m 01/27 21:37:38 | training-domain validation (iid, inD) = 74.845%
[37m[36mINFO[0m[0m 01/27 21:37:38 | === Summary ===
[37m[36mINFO[0m[0m 01/27 21:37:38 | Command: /jsm0707/Large-scale/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm CORAL --test_envs 1 2 3 --dataset OfficeHome
[37m[36mINFO[0m[0m 01/27 21:37:38 | Unique name: 250127_20-32-30_resnet50_adam
[37m[36mINFO[0m[0m 01/27 21:37:38 | Out path: train_output/OfficeHome/CORAL/[1, 2, 3]/250127_20-32-30_resnet50_adam
[37m[36mINFO[0m[0m 01/27 21:37:38 | Algorithm: CORAL
[37m[36mINFO[0m[0m 01/27 21:37:38 | Dataset: OfficeHome
