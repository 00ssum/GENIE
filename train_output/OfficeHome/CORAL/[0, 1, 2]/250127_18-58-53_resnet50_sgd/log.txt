[37m[36mINFO[0m[0m 01/27 18:58:53 | Command :: /jsm0707/Large-scale/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm CORAL --test_envs 0 1 2 --dataset OfficeHome
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_sgd.yaml']
	data_dir: data
	dataset: OfficeHome
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_sgd
	out_dir: train_output/OfficeHome/CORAL/[0, 1, 2]/250127_18-58-53_resnet50_sgd
	out_root: train_output/OfficeHome/CORAL/[0, 1, 2]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 1, 2]
	trial_seed: 0
	unique_name: 250127_18-58-53_resnet50_sgd
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: sgd
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	mmd_gamma: 1.0
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[OfficeHome] #envs=4, #classes=65
	env0: A (#2427)
	env1: C (#4365)
	env2: P (#4439)
	env3: R (#4357)

[37m[36mINFO[0m[0m 01/27 18:58:53 | n_steps = 5001
[37m[36mINFO[0m[0m 01/27 18:58:53 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 01/27 18:58:53 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 01/27 18:58:53 | 
[37m[36mINFO[0m[0m 01/27 18:58:53 | Testenv name escaping te_A_C_P -> te_A_C_P
[37m[36mINFO[0m[0m 01/27 18:58:53 | Test envs = [0, 1, 2], name = te_A_C_P
[37m[36mINFO[0m[0m 01/27 18:58:53 | Train environments: [3], Test environments: [0, 1, 2]
[37m[36mINFO[0m[0m 01/27 18:58:53 | Batch sizes for each domain: [0, 0, 0, 32] (total=32)
[37m[36mINFO[0m[0m 01/27 18:58:53 | steps-per-epoch for each domain: 108.94 -> min = 108.94
[37m[36mINFO[0m[0m 01/27 18:58:54 | # of params = 23641217
[37m[36mINFO[0m[0m 01/27 19:00:44 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 01/27 19:00:44 | 0.016455    0.019160    0.013769    0.008037    4.263515    0.020082    0.026804    0.016896    0.014891    0.012387    0.015784    0.013769    0.008037    0           0.000000    4.254128    0.000000    1.383728    108.473337 
[37m[36mINFO[0m[0m 01/27 19:04:29 | 0.017753    0.019777    0.014917    0.013777    4.214749    0.021112    0.030928    0.019759    0.013746    0.012387    0.014656    0.014917    0.013777    200         1.835915    4.228240    0.000000    0.551109    114.956385 
[37m[36mINFO[0m[0m 01/27 19:08:12 | 0.019097    0.022972    0.016351    0.013777    4.176698    0.023172    0.037113    0.019759    0.014891    0.014358    0.016911    0.016351    0.013777    400         3.671830    4.187386    0.000000    0.537167    115.168328 
[37m[36mINFO[0m[0m 01/27 19:11:51 | 0.022081    0.025568    0.022088    0.016073    4.144891    0.027291    0.039175    0.022623    0.020619    0.016329    0.016911    0.022088    0.016073    600         5.507745    4.149702    0.000000    0.561310    106.644698 
[37m[36mINFO[0m[0m 01/27 19:15:29 | 0.028622    0.031406    0.029260    0.021814    4.114204    0.037590    0.045361    0.024628    0.024055    0.023649    0.024803    0.029260    0.021814    800         7.343660    4.113619    0.000000    0.549643    107.511328 
[37m[36mINFO[0m[0m 01/27 19:19:11 | 0.036105    0.033321    0.043316    0.035591    4.082546    0.048404    0.045361    0.030069    0.030928    0.029842    0.023675    0.043316    0.035591    1000        9.179575    4.084772    0.000000    0.540551    113.981100 
[37m[36mINFO[0m[0m 01/27 19:22:49 | 0.044183    0.042355    0.062823    0.047072    4.047946    0.052523    0.057732    0.037514    0.035510    0.042511    0.033822    0.062823    0.047072    1200        11.015491   4.041901    0.000000    0.539714    109.167888 
[37m[36mINFO[0m[0m 01/27 19:26:31 | 0.057434    0.054018    0.091222    0.083812    4.008301    0.071576    0.070103    0.046392    0.040092    0.054336    0.051860    0.091222    0.083812    1400        12.851406   4.008123    0.000000    0.551042    112.151690 
[37m[36mINFO[0m[0m 01/27 19:30:10 | 0.070079    0.072897    0.124211    0.112514    3.960414    0.091658    0.105155    0.053265    0.050401    0.065315    0.063134    0.124211    0.112514    1600        14.687321   3.960148    0.000000    0.539771    110.801345 
[37m[36mINFO[0m[0m 01/27 19:33:49 | 0.083004    0.086628    0.141997    0.130884    3.903266    0.112255    0.123711    0.062715    0.056128    0.074043    0.080045    0.141997    0.130884    1800        16.523236   3.909651    0.000000    0.541082    109.799773 
[37m[36mINFO[0m[0m 01/27 19:37:33 | 0.100485    0.103185    0.173551    0.152698    3.829586    0.132338    0.138144    0.078465    0.074456    0.090653    0.096956    0.173551    0.152698    2000        18.359151   3.846576    0.000000    0.551626    114.123935 
[37m[36mINFO[0m[0m 01/27 19:41:12 | 0.120339    0.120136    0.207114    0.185993    3.734142    0.154480    0.162887    0.093643    0.085911    0.112894    0.111612    0.207114    0.185993    2200        20.195066   3.749559    0.000000    0.528790    112.527005 
[37m[36mINFO[0m[0m 01/27 19:44:48 | 0.144794    0.145333    0.246127    0.231917    3.606491    0.183316    0.189691    0.113116    0.105384    0.137950    0.140924    0.246127    0.231917    2400        22.030981   3.643115    0.000000    0.541427    107.754287 
[37m[36mINFO[0m[0m 01/27 19:48:36 | 0.181052    0.179826    0.299197    0.304248    3.422302    0.211123    0.220619    0.139748    0.130584    0.192286    0.188275    0.299197    0.304248    2600        23.866896   3.467066    0.000000    0.553466    116.287708 
[37m[36mINFO[0m[0m 01/27 19:52:11 | 0.223579    0.227134    0.366322    0.349024    3.139098    0.260556    0.274227    0.166094    0.154639    0.244088    0.252537    0.366322    0.349024    2800        25.702811   3.224089    0.000000    0.544078    106.822266 
[37m[36mINFO[0m[0m 01/27 19:55:55 | 0.278012    0.282800    0.434309    0.422503    2.732463    0.312049    0.327835    0.201604    0.195876    0.320383    0.324690    0.434309    0.422503    3000        27.538726   2.877004    0.000000    0.552936    112.359434 
[37m[36mINFO[0m[0m 01/27 19:59:43 | 0.328840    0.328027    0.511188    0.489093    2.243844    0.352729    0.352577    0.237113    0.224513    0.396678    0.406990    0.511188    0.489093    3200        29.374641   2.404205    0.000000    0.566638    114.687413 
[37m[36mINFO[0m[0m 01/27 20:03:21 | 0.376110    0.369529    0.584337    0.554535    1.800750    0.381050    0.364948    0.272337    0.257732    0.474944    0.485908    0.584337    0.554535    3400        31.210557   1.900209    0.000000    0.549453    108.212644 
[37m[36mINFO[0m[0m 01/27 20:06:58 | 0.409094    0.393562    0.633678    0.603904    1.498164    0.393924    0.381443    0.301546    0.280641    0.531813    0.518602    0.633678    0.603904    3600        33.046472   1.493628    0.000000    0.552019    105.658713 
[37m[36mINFO[0m[0m 01/27 20:10:36 | 0.431340    0.417473    0.675273    0.636051    1.308090    0.417611    0.412371    0.316724    0.294387    0.559685    0.545660    0.675273    0.636051    3800        34.882387   1.242873    0.000000    0.531866    111.245033 
[37m[36mINFO[0m[0m 01/27 20:14:16 | 0.456434    0.438610    0.722031    0.662457    1.188604    0.435118    0.435052    0.337056    0.303551    0.597128    0.577227    0.722031    0.662457    4000        36.718302   1.076461    0.000000    0.533630    112.691648 
[37m[36mINFO[0m[0m 01/27 20:17:55 | 0.475437    0.458760    0.745267    0.688863    1.079498    0.451081    0.443299    0.350229    0.325315    0.625000    0.607666    0.745267    0.688863    4200        38.554217   0.921535    0.000000    0.538787    111.138821 
[37m[36mINFO[0m[0m 01/27 20:21:28 | 0.490371    0.470424    0.770797    0.701493    1.003289    0.465499    0.455670    0.365693    0.329897    0.639921    0.625705    0.770797    0.701493    4400        40.390132   0.851318    0.000000    0.537474    105.516368 
[37m[36mINFO[0m[0m 01/27 20:25:10 | 0.502485    0.486816    0.784854    0.719862    0.973183    0.477343    0.474227    0.382589    0.341352    0.647523    0.644870    0.784854    0.719862    4600        42.226047   0.784984    0.000000    0.559493    109.871239 
[37m[36mINFO[0m[0m 01/27 20:28:48 | 0.506970    0.479552    0.801205    0.723307    0.939821    0.489701    0.476289    0.380871    0.329897    0.650338    0.632469    0.801205    0.723307    4800        44.061962   0.685111    0.000000    0.553629    107.101164 
[37m[36mINFO[0m[0m 01/27 20:32:25 | 0.514773    0.499163    0.820998    0.748565    0.873735    0.489701    0.501031    0.383448    0.347079    0.671171    0.649380    0.820998    0.748565    5000        45.897877   0.666806    0.000000    0.540870    108.084942 
[37m[36mINFO[0m[0m 01/27 20:32:25 | Cumulative gradient change saved at train_output/OfficeHome/CORAL/[0, 1, 2]/250127_18-58-53_resnet50_sgd/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 01/27 20:32:26 | ---
[37m[36mINFO[0m[0m 01/27 20:32:26 | test-domain validation(oracle) = 51.477%
[37m[36mINFO[0m[0m 01/27 20:32:26 | training-domain validation(iid) = 51.477%
[37m[36mINFO[0m[0m 01/27 20:32:26 | last = 51.477%
[37m[36mINFO[0m[0m 01/27 20:32:26 | last (inD) = 74.856%
[37m[36mINFO[0m[0m 01/27 20:32:26 | training-domain validation (iid, inD) = 74.856%
[37m[36mINFO[0m[0m 01/27 20:32:26 | === Summary ===
[37m[36mINFO[0m[0m 01/27 20:32:26 | Command: /jsm0707/Large-scale/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm CORAL --test_envs 0 1 2 --dataset OfficeHome
[37m[36mINFO[0m[0m 01/27 20:32:26 | Unique name: 250127_18-58-53_resnet50_sgd
[37m[36mINFO[0m[0m 01/27 20:32:26 | Out path: train_output/OfficeHome/CORAL/[0, 1, 2]/250127_18-58-53_resnet50_sgd
[37m[36mINFO[0m[0m 01/27 20:32:26 | Algorithm: CORAL
[37m[36mINFO[0m[0m 01/27 20:32:26 | Dataset: OfficeHome
