[37m[36mINFO[0m[0m 03/28 06:18:46 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 0 1 2 --dataset OfficeHome --trial_seed 1 --hparams_seed 7
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.22.4
	PIL: 9.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: OfficeHome
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 7
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/OfficeHome/CORAL/[0, 1, 2]/250328_06-18-46_resnet50_GENIE
	out_root: train_output/OfficeHome/CORAL/[0, 1, 2]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 1, 2]
	trial_seed: 1
	unique_name: 250328_06-18-46_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.5
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 0.00025471109765784857
	batch_size: 39
	weight_decay: 9.10622179414602e-05
	mmd_gamma: 8.495822994867268
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[OfficeHome] #envs=4, #classes=65
	env0: A (#2427)
	env1: C (#4365)
	env2: P (#4439)
	env3: R (#4357)

[37m[36mINFO[0m[0m 03/28 06:18:46 | n_steps = 5001
[37m[36mINFO[0m[0m 03/28 06:18:46 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/28 06:18:46 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/28 06:18:46 | 
[37m[36mINFO[0m[0m 03/28 06:18:46 | Testenv name escaping te_A_C_P -> te_A_C_P
[37m[36mINFO[0m[0m 03/28 06:18:46 | Test envs = [0, 1, 2], name = te_A_C_P
[37m[36mINFO[0m[0m 03/28 06:18:46 | Train environments: [3], Test environments: [0, 1, 2]
[37m[36mINFO[0m[0m 03/28 06:18:46 | Batch sizes for each domain: [0, 0, 0, 39] (total=39)
[37m[36mINFO[0m[0m 03/28 06:18:46 | steps-per-epoch for each domain: 89.38 -> min = 89.38
[37m[36mINFO[0m[0m 03/28 06:18:47 | # of params = 23641217
[37m[36mINFO[0m[0m 03/28 06:20:37 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 03/28 06:20:37 | 0.020692    0.016869    0.022088    0.022962    4.199550    0.023687    0.016495    0.022623    0.018328    0.015766    0.015784    0.022088    0.022962    0           0.000000    4.305207    0.000000    1.140063    108.777694 
[37m[36mINFO[0m[0m 03/28 06:24:36 | 0.549958    0.542866    0.800344    0.745121    0.902166    0.523687    0.536082    0.436999    0.432990    0.689189    0.659526    0.800344    0.745121    200         2.237522    1.759504    0.000000    0.653169    107.939557 
[37m[36mINFO[0m[0m 03/28 06:28:30 | 0.570203    0.568718    0.886116    0.779564    0.760469    0.562307    0.562887    0.446163    0.434135    0.702140    0.709132    0.886116    0.779564    400         4.475043    0.605258    0.000000    0.659336    102.142827 
[37m[36mINFO[0m[0m 03/28 06:32:33 | 0.569605    0.575749    0.938038    0.794489    0.739943    0.557158    0.579381    0.428121    0.439863    0.723536    0.708005    0.938038    0.794489    600         6.712565    0.357759    0.000000    0.669803    108.572287 
[37m[36mINFO[0m[0m 03/28 06:36:33 | 0.590284    0.598098    0.953528    0.802526    0.795652    0.569001    0.602062    0.466208    0.465063    0.735642    0.727170    0.953528    0.802526    800         8.950086    0.259197    0.000000    0.670799    105.852466 
[37m[36mINFO[0m[0m 03/28 06:40:34 | 0.576216    0.592049    0.949512    0.793341    0.877267    0.565911    0.602062    0.450745    0.458190    0.711993    0.715896    0.949512    0.793341    1000        11.187608   0.213025    0.000000    0.658988    109.480070 
[37m[36mINFO[0m[0m 03/28 06:44:35 | 0.586226    0.580741    0.974182    0.808266    0.793095    0.576210    0.587629    0.452176    0.437572    0.730293    0.717024    0.974182    0.808266    1200        13.425129   0.167410    0.000000    0.667100    107.473752 
[37m[36mINFO[0m[0m 03/28 06:48:34 | 0.591750    0.585932    0.977051    0.828932    0.740634    0.576725    0.616495    0.469359    0.452463    0.729167    0.688839    0.977051    0.828932    1400        15.662651   0.122753    0.000000    0.679011    103.211466 
[37m[36mINFO[0m[0m 03/28 06:52:36 | 0.579869    0.596079    0.982215    0.804822    0.802090    0.564882    0.585567    0.460481    0.483391    0.714245    0.719278    0.982215    0.804822    1600        17.900172   0.120113    0.000000    0.678267    106.556336 
[37m[36mINFO[0m[0m 03/28 06:56:41 | 0.594298    0.587210    0.986804    0.819747    0.926974    0.601957    0.600000    0.444731    0.454754    0.736205    0.706877    0.986804    0.819747    1800        20.137694   0.067573    0.000000    0.694232    106.282312 
[37m[36mINFO[0m[0m 03/28 07:00:43 | 0.573452    0.587887    0.980207    0.793341    0.990799    0.569001    0.614433    0.443585    0.454754    0.707770    0.694476    0.980207    0.793341    2000        22.375215   0.091883    0.000000    0.672259    107.900154 
[37m[36mINFO[0m[0m 03/28 07:04:46 | 0.590033    0.586224    0.987665    0.822044    0.823124    0.582389    0.585567    0.462486    0.467354    0.725225    0.705750    0.987665    0.822044    2200        24.612737   0.064587    0.000000    0.662465    110.361685 
[37m[36mINFO[0m[0m 03/28 07:08:48 | 0.591709    0.590182    0.985657    0.828932    0.859275    0.604531    0.612371    0.449313    0.450172    0.721284    0.708005    0.985657    0.828932    2400        26.850258   0.048713    0.000000    0.683363    104.878450 
[37m[36mINFO[0m[0m 03/28 07:12:46 | 0.592637    0.601685    0.982215    0.824340    0.864895    0.572091    0.622680    0.484536    0.483391    0.721284    0.698985    0.982215    0.824340    2600        29.087780   0.059437    0.000000    0.651457    107.541965 
[37m[36mINFO[0m[0m 03/28 07:16:41 | 0.619139    0.623245    0.990534    0.822044    0.823311    0.597837    0.612371    0.517182    0.520046    0.742399    0.737317    0.990534    0.822044    2800        31.325301   0.057947    0.000000    0.649022    105.923354 
[37m[36mINFO[0m[0m 03/28 07:20:46 | 0.593085    0.603579    0.991107    0.819747    0.979497    0.572606    0.618557    0.467068    0.461627    0.739583    0.730552    0.991107    0.819747    3000        33.562823   0.044817    0.000000    0.672983    109.807500 
[37m[36mINFO[0m[0m 03/28 07:24:52 | 0.591719    0.575354    0.993115    0.810563    0.949035    0.564367    0.546392    0.478809    0.454754    0.731982    0.724915    0.993115    0.810563    3200        35.800344   0.039846    0.000000    0.685161    108.636176 
[37m[36mINFO[0m[0m 03/28 07:28:48 | 0.619114    0.628156    0.995410    0.845006    0.844855    0.605046    0.655670    0.502577    0.495991    0.749718    0.732807    0.995410    0.845006    3400        38.037866   0.033062    0.000000    0.647908    106.941291 
[37m[36mINFO[0m[0m 03/28 07:32:47 | 0.599491    0.604252    0.991681    0.826636    0.878194    0.602987    0.624742    0.472795    0.483391    0.722691    0.704622    0.991681    0.826636    3600        40.275387   0.033361    0.000000    0.658348    107.461213 
[37m[36mINFO[0m[0m 03/28 07:36:57 | 0.589078    0.581407    0.995410    0.814007    1.064389    0.562822    0.581443    0.467927    0.455899    0.736486    0.706877    0.995410    0.814007    3800        42.512909   0.029895    0.000000    0.676891    114.776982 
[37m[36mINFO[0m[0m 03/28 07:40:57 | 0.591921    0.592877    0.993689    0.819747    1.095729    0.578785    0.620619    0.461054    0.439863    0.735923    0.718151    0.993689    0.819747    4000        44.750430   0.027477    0.000000    0.665372    106.096188 
[37m[36mINFO[0m[0m 03/28 07:45:01 | 0.590812    0.584381    0.990820    0.797933    1.338660    0.556643    0.575258    0.491695    0.484536    0.724099    0.693348    0.990820    0.797933    4200        46.987952   0.021696    0.000000    0.689469    106.715542 
[37m[36mINFO[0m[0m 03/28 07:49:01 | 0.594726    0.596521    0.990247    0.826636    0.952938    0.572606    0.616495    0.491695    0.465063    0.719876    0.708005    0.990247    0.826636    4400        49.225473   0.040368    0.000000    0.666592    106.180445 
[37m[36mINFO[0m[0m 03/28 07:52:55 | 0.596010    0.602805    0.995984    0.809414    0.906874    0.577240    0.610309    0.478809    0.479954    0.731982    0.718151    0.995984    0.809414    4600        51.462995   0.039763    0.000000    0.647832    104.485890 
[37m[36mINFO[0m[0m 03/28 07:56:55 | 0.610966    0.622093    0.993976    0.828932    0.872372    0.582389    0.622680    0.513459    0.505155    0.737050    0.738444    0.993976    0.828932    4800        53.700516   0.033617    0.000000    0.679692    104.189976 
[37m[36mINFO[0m[0m 03/28 08:00:57 | 0.593490    0.595992    0.995123    0.824340    0.924680    0.578270    0.600000    0.470218    0.481100    0.731982    0.706877    0.995123    0.824340    5000        55.938038   0.027925    0.000000    0.671483    108.242154 
[37m[36mINFO[0m[0m 03/28 08:00:58 | Cumulative gradient change saved at train_output/OfficeHome/CORAL/[0, 1, 2]/250328_06-18-46_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/28 08:00:59 | ---
[37m[36mINFO[0m[0m 03/28 08:00:59 | test-domain validation(oracle) = 61.911%
[37m[36mINFO[0m[0m 03/28 08:00:59 | training-domain validation(iid) = 61.911%
[37m[36mINFO[0m[0m 03/28 08:00:59 | last = 59.349%
[37m[36mINFO[0m[0m 03/28 08:00:59 | last (inD) = 82.434%
[37m[36mINFO[0m[0m 03/28 08:00:59 | training-domain validation (iid, inD) = 84.501%
[37m[36mINFO[0m[0m 03/28 08:00:59 | === Summary ===
[37m[36mINFO[0m[0m 03/28 08:00:59 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 0 1 2 --dataset OfficeHome --trial_seed 1 --hparams_seed 7
[37m[36mINFO[0m[0m 03/28 08:00:59 | Unique name: 250328_06-18-46_resnet50_GENIE
[37m[36mINFO[0m[0m 03/28 08:00:59 | Out path: train_output/OfficeHome/CORAL/[0, 1, 2]/250328_06-18-46_resnet50_GENIE
[37m[36mINFO[0m[0m 03/28 08:00:59 | Algorithm: CORAL
[37m[36mINFO[0m[0m 03/28 08:00:59 | Dataset: OfficeHome
