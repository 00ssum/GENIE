[37m[36mINFO[0m[0m 02/10 15:09:27 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 0 --dataset OfficeHome --trial_seed 1 --hparams_seed 7
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: OfficeHome
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 7
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/OfficeHome/CORAL/[0]/250210_15-09-27_resnet50_GENIE
	out_root: train_output/OfficeHome/CORAL/[0]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0]
	trial_seed: 1
	unique_name: 250210_15-09-27_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.5
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 0.00025471109765784857
	batch_size: 39
	weight_decay: 9.10622179414602e-05
	mmd_gamma: 8.495822994867268
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[OfficeHome] #envs=4, #classes=65
	env0: A (#2427)
	env1: C (#4365)
	env2: P (#4439)
	env3: R (#4357)

[37m[36mINFO[0m[0m 02/10 15:09:27 | n_steps = 5001
[37m[36mINFO[0m[0m 02/10 15:09:27 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/10 15:09:27 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/10 15:09:27 | 
[37m[36mINFO[0m[0m 02/10 15:09:27 | Testenv name escaping te_A -> te_A
[37m[36mINFO[0m[0m 02/10 15:09:27 | Test envs = [0], name = te_A
[37m[36mINFO[0m[0m 02/10 15:09:27 | Train environments: [1, 2, 3], Test environments: [0]
[37m[36mINFO[0m[0m 02/10 15:09:27 | Batch sizes for each domain: [0, 39, 39, 39] (total=117)
[37m[36mINFO[0m[0m 02/10 15:09:27 | steps-per-epoch for each domain: 89.54, 91.08, 89.38 -> min = 89.38
[37m[36mINFO[0m[0m 02/10 15:09:28 | # of params = 23641217
[37m[36mINFO[0m[0m 02/10 15:11:35 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 02/10 15:11:35 | 0.025232    0.022680    0.022626    0.028924    4.179703    0.025232    0.022680    0.018328    0.029782    0.019144    0.022548    0.030407    0.034443    0           0.000000    4.340063    0.056241    1.220511    125.620211 
[37m[36mINFO[0m[0m 02/10 15:15:52 | 0.323378    0.352577    0.471956    0.457732    2.578940    0.323378    0.352577    0.395475    0.387171    0.528998    0.510710    0.491394    0.475316    200         2.237522    3.709133    0.011074    0.669843    123.101429 
[37m[36mINFO[0m[0m 02/10 15:20:09 | 0.523687    0.567010    0.710760    0.662671    1.431860    0.523687    0.567010    0.635166    0.583047    0.773649    0.704622    0.723465    0.700344    400         4.475043    1.848327    0.037576    0.661120    124.649355 
[37m[36mINFO[0m[0m 02/10 15:24:48 | 0.571576    0.614433    0.796238    0.752351    1.066203    0.571576    0.614433    0.737400    0.676976    0.841216    0.797069    0.810098    0.783008    600         6.712565    1.147623    0.034208    0.709578    137.362141 
[37m[36mINFO[0m[0m 02/10 15:29:33 | 0.599382    0.618557    0.834085    0.780820    0.893972    0.599382    0.618557    0.787801    0.711340    0.869932    0.830891    0.844521    0.800230    800         8.950086    0.863903    0.030333    0.750773    134.725695 
[37m[36mINFO[0m[0m 02/10 15:34:27 | 0.606591    0.655670    0.868134    0.784526    0.823779    0.606591    0.655670    0.831615    0.715922    0.894989    0.850056    0.877797    0.787600    1000        11.187608   0.665915    0.027424    0.749314    144.097219 
[37m[36mINFO[0m[0m 02/10 15:39:16 | 0.621009    0.674227    0.895941    0.810057    0.739997    0.621009    0.674227    0.859107    0.743414    0.925676    0.864713    0.903041    0.822044    1200        13.425129   0.571804    0.024783    0.740166    140.462714 
[37m[36mINFO[0m[0m 02/10 15:43:59 | 0.617405    0.678351    0.916217    0.815349    0.685636    0.617405    0.678351    0.884593    0.747995    0.937782    0.874859    0.926277    0.823192    1400        15.662651   0.463669    0.023229    0.752376    132.463991 
[37m[36mINFO[0m[0m 02/10 15:48:45 | 0.629763    0.663918    0.927459    0.818782    0.682024    0.629763    0.663918    0.904066    0.753723    0.942568    0.875986    0.935743    0.826636    1600        17.900172   0.384529    0.021389    0.739478    138.771587 
[37m[36mINFO[0m[0m 02/10 15:53:27 | 0.623069    0.655670    0.944472    0.832502    0.656987    0.623069    0.655670    0.922680    0.774341    0.957207    0.882751    0.953528    0.840413    1800        20.137694   0.320893    0.020315    0.720617    137.139373 
[37m[36mINFO[0m[0m 02/10 15:58:21 | 0.638517    0.674227    0.948102    0.828314    0.666080    0.638517    0.674227    0.934422    0.781214    0.956644    0.878241    0.953242    0.825488    2000        22.375215   0.284042    0.019240    0.758663    142.871477 
[37m[36mINFO[0m[0m 02/10 16:03:07 | 0.625644    0.661856    0.960168    0.833229    0.648327    0.625644    0.661856    0.944444    0.778923    0.968187    0.888388    0.967871    0.832377    2200        24.612737   0.241009    0.018062    0.745538    136.222182 
[37m[36mINFO[0m[0m 02/10 16:07:58 | 0.622554    0.692784    0.967366    0.833602    0.623578    0.622554    0.692784    0.950458    0.774341    0.978604    0.890643    0.973035    0.835821    2400        26.850258   0.213704    0.017234    0.731610    144.704691 
[37m[36mINFO[0m[0m 02/10 16:12:38 | 0.612255    0.649485    0.971175    0.838572    0.627616    0.612255    0.649485    0.956186    0.789233    0.980574    0.889515    0.976764    0.836969    2600        29.087780   0.188575    0.016319    0.695467    140.929245 
[37m[36mINFO[0m[0m 02/10 16:17:23 | 0.622554    0.676289    0.974807    0.830562    0.646293    0.622554    0.676289    0.964204    0.764032    0.980011    0.888388    0.980207    0.839265    2800        31.325301   0.166386    0.015591    0.751205    135.273185 
[37m[36mINFO[0m[0m 02/10 16:22:21 | 0.622554    0.668041    0.979637    0.838144    0.637980    0.622554    0.668041    0.967640    0.776632    0.987050    0.898534    0.984223    0.839265    3000        33.562823   0.145204    0.014831    0.766474    144.545781 
[37m[36mINFO[0m[0m 02/10 16:27:02 | 0.622554    0.674227    0.979174    0.832493    0.621020    0.622554    0.674227    0.967640    0.776632    0.984797    0.883878    0.985083    0.836969    3200        35.800344   0.137157    0.014308    0.734364    134.391005 
[37m[36mINFO[0m[0m 02/10 16:31:39 | 0.633883    0.672165    0.980399    0.839300    0.625954    0.633883    0.672165    0.967354    0.775487    0.987613    0.897407    0.986231    0.845006    3400        38.037866   0.128953    0.013796    0.740983    128.565113 
[37m[36mINFO[0m[0m 02/10 16:36:23 | 0.628218    0.672165    0.985251    0.835872    0.642158    0.628218    0.672165    0.975659    0.772050    0.990709    0.895152    0.989386    0.840413    3600        40.275387   0.111081    0.013151    0.744862    135.416344 
[37m[36mINFO[0m[0m 02/10 16:41:06 | 0.625129    0.674227    0.984390    0.839294    0.634032    0.625129    0.674227    0.971649    0.783505    0.991273    0.897407    0.990247    0.836969    3800        42.512909   0.102322    0.012771    0.738566    135.292752 
[37m[36mINFO[0m[0m 02/10 16:45:47 | 0.617405    0.696907    0.987250    0.832826    0.638162    0.617405    0.696907    0.979095    0.769759    0.991836    0.892897    0.990820    0.835821    4000        44.750430   0.091638    0.012217    0.734540    133.675273 
[37m[36mINFO[0m[0m 02/10 16:50:22 | 0.621009    0.661856    0.987341    0.838563    0.627358    0.621009    0.661856    0.975372    0.783505    0.992962    0.891770    0.993689    0.840413    4200        46.987952   0.088311    0.011857    0.702530    134.828034 
[37m[36mINFO[0m[0m 02/10 16:54:56 | 0.637487    0.672165    0.989249    0.844960    0.621283    0.637487    0.672165    0.979954    0.790378    0.993243    0.908681    0.994550    0.835821    4400        49.225473   0.086761    0.011538    0.682679    137.455326 
[37m[36mINFO[0m[0m 02/10 16:59:27 | 0.626159    0.663918    0.989527    0.833950    0.634580    0.626159    0.663918    0.979381    0.765178    0.994651    0.897407    0.994550    0.839265    4600        51.462995   0.082268    0.011040    0.740741    122.479642 
[37m[36mINFO[0m[0m 02/10 17:04:03 | 0.630793    0.672165    0.989146    0.839637    0.624864    0.630793    0.672165    0.977950    0.781214    0.994651    0.904171    0.994836    0.833525    4800        53.700516   0.077665    0.010859    0.734010    129.586842 
[37m[36mINFO[0m[0m 02/10 17:08:30 | 0.625644    0.661856    0.990290    0.834357    0.642439    0.625644    0.661856    0.981100    0.777778    0.994932    0.891770    0.994836    0.833525    5000        55.938038   0.078258    0.010581    0.701340    126.783627 
[37m[36mINFO[0m[0m 02/10 17:08:31 | Cumulative gradient change saved at train_output/OfficeHome/CORAL/[0]/250210_15-09-27_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/10 17:08:32 | ---
[37m[36mINFO[0m[0m 02/10 17:08:32 | test-domain validation(oracle) = 61.740%
[37m[36mINFO[0m[0m 02/10 17:08:32 | training-domain validation(iid) = 63.749%
[37m[36mINFO[0m[0m 02/10 17:08:32 | last = 62.564%
[37m[36mINFO[0m[0m 02/10 17:08:32 | last (inD) = 83.436%
[37m[36mINFO[0m[0m 02/10 17:08:32 | training-domain validation (iid, inD) = 84.496%
[37m[36mINFO[0m[0m 02/10 17:08:32 | === Summary ===
[37m[36mINFO[0m[0m 02/10 17:08:32 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 0 --dataset OfficeHome --trial_seed 1 --hparams_seed 7
[37m[36mINFO[0m[0m 02/10 17:08:32 | Unique name: 250210_15-09-27_resnet50_GENIE
[37m[36mINFO[0m[0m 02/10 17:08:32 | Out path: train_output/OfficeHome/CORAL/[0]/250210_15-09-27_resnet50_GENIE
[37m[36mINFO[0m[0m 02/10 17:08:32 | Algorithm: CORAL
[37m[36mINFO[0m[0m 02/10 17:08:32 | Dataset: OfficeHome
