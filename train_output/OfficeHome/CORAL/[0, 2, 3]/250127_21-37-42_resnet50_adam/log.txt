[37m[36mINFO[0m[0m 01/27 21:37:42 | Command :: /jsm0707/Large-scale/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm CORAL --test_envs 0 2 3 --dataset OfficeHome
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_adam.yaml']
	data_dir: data
	dataset: OfficeHome
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_adam
	out_dir: train_output/OfficeHome/CORAL/[0, 2, 3]/250127_21-37-42_resnet50_adam
	out_root: train_output/OfficeHome/CORAL/[0, 2, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 2, 3]
	trial_seed: 0
	unique_name: 250127_21-37-42_resnet50_adam
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: adam
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	mmd_gamma: 1.0
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[OfficeHome] #envs=4, #classes=65
	env0: A (#2427)
	env1: C (#4365)
	env2: P (#4439)
	env3: R (#4357)

[37m[36mINFO[0m[0m 01/27 21:37:42 | n_steps = 5001
[37m[36mINFO[0m[0m 01/27 21:37:42 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 01/27 21:37:42 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 01/27 21:37:42 | 
[37m[36mINFO[0m[0m 01/27 21:37:42 | Testenv name escaping te_A_P_R -> te_A_P_R
[37m[36mINFO[0m[0m 01/27 21:37:42 | Test envs = [0, 2, 3], name = te_A_P_R
[37m[36mINFO[0m[0m 01/27 21:37:42 | Train environments: [1], Test environments: [0, 2, 3]
[37m[36mINFO[0m[0m 01/27 21:37:42 | Batch sizes for each domain: [0, 32, 0, 0] (total=32)
[37m[36mINFO[0m[0m 01/27 21:37:42 | steps-per-epoch for each domain: 109.12 -> min = 109.12
[37m[36mINFO[0m[0m 01/27 21:37:44 | # of params = 23641217
[37m[36mINFO[0m[0m 01/27 21:39:31 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 01/27 21:39:31 | 0.012806    0.016201    0.022910    0.017182    4.205110    0.016478    0.024742    0.022910    0.017182    0.007883    0.013529    0.014056    0.010333    0           0.000000    4.196661    0.000000    1.092404    105.982094 
[37m[36mINFO[0m[0m 01/27 21:41:49 | 0.434870    0.432371    0.754009    0.633448    1.536159    0.332647    0.338144    0.754009    0.633448    0.496059    0.483653    0.475904    0.475316    200         1.832761    1.804711    0.000000    0.143890    109.516075 
[37m[36mINFO[0m[0m 01/27 21:44:12 | 0.468933    0.456648    0.869416    0.674685    1.306972    0.394954    0.383505    0.869416    0.674685    0.495495    0.488162    0.516351    0.498278    400         3.665521    0.638468    0.000000    0.137615    115.393170 
[37m[36mINFO[0m[0m 01/27 21:46:24 | 0.450714    0.460004    0.898053    0.699885    1.542415    0.348610    0.373196    0.898053    0.699885    0.495214    0.503946    0.508319    0.502870    600         5.498282    0.388044    0.000000    0.140447    103.082034 
[37m[36mINFO[0m[0m 01/27 21:48:38 | 0.482522    0.487827    0.914662    0.715922    1.325220    0.385170    0.414433    0.914662    0.715922    0.522523    0.517475    0.539874    0.531573    800         7.331042    0.306374    0.000000    0.135674    106.912715 
[37m[36mINFO[0m[0m 01/27 21:50:55 | 0.486187    0.480608    0.941294    0.736541    1.300173    0.386715    0.391753    0.941294    0.736541    0.538570    0.524239    0.533276    0.525832    1000        9.163803    0.232785    0.000000    0.148981    106.587544 
[37m[36mINFO[0m[0m 01/27 21:53:06 | 0.476398    0.474853    0.951317    0.739977    1.300653    0.391864    0.408247    0.951317    0.739977    0.498029    0.487035    0.539300    0.529277    1200        10.996564   0.192094    0.000000    0.136243    103.739130 
[37m[36mINFO[0m[0m 01/27 21:55:17 | 0.450557    0.453634    0.938717    0.728522    1.620482    0.371267    0.393814    0.938717    0.728522    0.489583    0.479143    0.490820    0.487945    1400        12.829324   0.176039    0.000000    0.131836    104.666726 
[37m[36mINFO[0m[0m 01/27 21:57:29 | 0.496903    0.486758    0.964204    0.738832    1.413399    0.405252    0.402062    0.964204    0.738832    0.531813    0.518602    0.553643    0.539610    1600        14.662085   0.156076    0.000000    0.134121    105.060454 
[37m[36mINFO[0m[0m 01/27 21:59:45 | 0.466470    0.466662    0.956472    0.741123    1.462318    0.372812    0.391753    0.956472    0.741123    0.504223    0.489290    0.522375    0.518944    1800        16.494845   0.156984    0.000000    0.138274    108.101518 
[37m[36mINFO[0m[0m 01/27 22:02:01 | 0.446760    0.441669    0.958190    0.736541    1.573711    0.323378    0.354639    0.958190    0.736541    0.501126    0.488162    0.515777    0.482204    2000        18.327606   0.142800    0.000000    0.144526    107.161406 
[37m[36mINFO[0m[0m 01/27 22:04:21 | 0.480575    0.480711    0.965349    0.743414    1.515705    0.381050    0.402062    0.965349    0.743414    0.522523    0.506201    0.538153    0.533869    2200        20.160367   0.123082    0.000000    0.144152    111.223084 
[37m[36mINFO[0m[0m 01/27 22:06:39 | 0.457833    0.457854    0.960767    0.720504    1.608422    0.370752    0.381443    0.960767    0.720504    0.491273    0.491545    0.511474    0.500574    2400        21.993127   0.106516    0.000000    0.137893    109.956049 
[37m[36mINFO[0m[0m 01/27 22:08:59 | 0.445516    0.436118    0.959622    0.737686    1.407968    0.354789    0.342268    0.959622    0.737686    0.478604    0.471251    0.503155    0.494834    2600        23.825888   0.128681    0.000000    0.138935    112.169808 
[37m[36mINFO[0m[0m 01/27 22:11:30 | 0.469774    0.466656    0.972222    0.746850    1.635501    0.380021    0.400000    0.972222    0.746850    0.512950    0.501691    0.516351    0.498278    2800        25.658648   0.098100    0.000000    0.152500    120.523615 
[37m[36mINFO[0m[0m 01/27 22:14:09 | 0.441950    0.449353    0.963631    0.734250    1.294239    0.320803    0.377320    0.963631    0.734250    0.490991    0.467869    0.514056    0.502870    3000        27.491409   0.113047    0.000000    0.168483    125.845767 
[37m[36mINFO[0m[0m 01/27 22:16:46 | 0.460421    0.468367    0.969645    0.743414    1.438511    0.350154    0.364948    0.969645    0.743414    0.523649    0.501691    0.507458    0.538462    3200        29.324170   0.104951    0.000000    0.150970    126.300071 
[37m[36mINFO[0m[0m 01/27 22:19:25 | 0.480445    0.479853    0.969931    0.739977    1.626792    0.387230    0.404124    0.969931    0.739977    0.521115    0.508455    0.532989    0.526980    3400        31.156930   0.118972    0.000000    0.163238    126.343978 
[37m[36mINFO[0m[0m 01/27 22:22:06 | 0.487218    0.495233    0.973081    0.754868    1.566781    0.392894    0.420619    0.973081    0.754868    0.519707    0.519729    0.549053    0.545350    3600        32.989691   0.086103    0.000000    0.178441    125.377640 
[37m[36mINFO[0m[0m 01/27 22:24:43 | 0.497257    0.502309    0.980527    0.752577    1.424380    0.414521    0.447423    0.980527    0.752577    0.525901    0.510710    0.551348    0.548794    3800        34.822451   0.061186    0.000000    0.148063    127.460615 
[37m[36mINFO[0m[0m 01/27 22:27:25 | 0.468522    0.475621    0.968786    0.736541    1.410610    0.375386    0.406186    0.968786    0.736541    0.496903    0.499436    0.533276    0.521240    4000        36.655212   0.082591    0.000000    0.163142    128.986662 
[37m[36mINFO[0m[0m 01/27 22:30:05 | 0.468668    0.461610    0.973940    0.727377    1.808170    0.361483    0.383505    0.973940    0.727377    0.527309    0.490417    0.517212    0.510907    4200        38.487973   0.086394    0.000000    0.166749    126.451479 
[37m[36mINFO[0m[0m 01/27 22:32:44 | 0.459475    0.466389    0.962199    0.721649    1.503437    0.369207    0.385567    0.962199    0.721649    0.498029    0.509583    0.511188    0.504018    4400        40.320733   0.111221    0.000000    0.151372    128.840433 
[37m[36mINFO[0m[0m 01/27 22:35:32 | 0.460869    0.473505    0.968499    0.749141    1.469013    0.371782    0.408247    0.968499    0.749141    0.503941    0.519729    0.506885    0.492537    4600        42.153494   0.116314    0.000000    0.179436    132.265450 
[37m[36mINFO[0m[0m 01/27 22:38:09 | 0.465042    0.479662    0.975086    0.758305    1.535119    0.361998    0.389691    0.975086    0.758305    0.507883    0.503946    0.525244    0.545350    4800        43.986254   0.082743    0.000000    0.141701    128.787452 
[37m[36mINFO[0m[0m 01/27 22:40:54 | 0.429294    0.430521    0.971363    0.743414    1.494917    0.307415    0.327835    0.971363    0.743414    0.486205    0.474634    0.494263    0.489093    5000        45.819015   0.110286    0.000000    0.172845    130.526695 
[37m[36mINFO[0m[0m 01/27 22:40:54 | Cumulative gradient change saved at train_output/OfficeHome/CORAL/[0, 2, 3]/250127_21-37-42_resnet50_adam/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 01/27 22:40:56 | ---
[37m[36mINFO[0m[0m 01/27 22:40:56 | test-domain validation(oracle) = 49.726%
[37m[36mINFO[0m[0m 01/27 22:40:56 | training-domain validation(iid) = 46.504%
[37m[36mINFO[0m[0m 01/27 22:40:56 | last = 42.929%
[37m[36mINFO[0m[0m 01/27 22:40:56 | last (inD) = 74.341%
[37m[36mINFO[0m[0m 01/27 22:40:56 | training-domain validation (iid, inD) = 75.830%
[37m[36mINFO[0m[0m 01/27 22:40:56 | === Summary ===
[37m[36mINFO[0m[0m 01/27 22:40:56 | Command: /jsm0707/Large-scale/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm CORAL --test_envs 0 2 3 --dataset OfficeHome
[37m[36mINFO[0m[0m 01/27 22:40:56 | Unique name: 250127_21-37-42_resnet50_adam
[37m[36mINFO[0m[0m 01/27 22:40:56 | Out path: train_output/OfficeHome/CORAL/[0, 2, 3]/250127_21-37-42_resnet50_adam
[37m[36mINFO[0m[0m 01/27 22:40:56 | Algorithm: CORAL
[37m[36mINFO[0m[0m 01/27 22:40:56 | Dataset: OfficeHome
