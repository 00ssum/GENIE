[37m[36mINFO[0m[0m 01/27 16:59:23 | Command :: /jsm0707/Large-scale/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm CORAL --test_envs 0 2 3 --dataset OfficeHome
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_sgd.yaml']
	data_dir: data
	dataset: OfficeHome
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_sgd
	out_dir: train_output/OfficeHome/CORAL/[0, 2, 3]/250127_16-59-23_resnet50_sgd
	out_root: train_output/OfficeHome/CORAL/[0, 2, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 2, 3]
	trial_seed: 0
	unique_name: 250127_16-59-23_resnet50_sgd
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: sgd
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	mmd_gamma: 1.0
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[OfficeHome] #envs=4, #classes=65
	env0: A (#2427)
	env1: C (#4365)
	env2: P (#4439)
	env3: R (#4357)

[37m[36mINFO[0m[0m 01/27 16:59:23 | n_steps = 5001
[37m[36mINFO[0m[0m 01/27 16:59:23 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 01/27 16:59:23 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 01/27 16:59:23 | 
[37m[36mINFO[0m[0m 01/27 16:59:23 | Testenv name escaping te_A_P_R -> te_A_P_R
[37m[36mINFO[0m[0m 01/27 16:59:23 | Test envs = [0, 2, 3], name = te_A_P_R
[37m[36mINFO[0m[0m 01/27 16:59:23 | Train environments: [1], Test environments: [0, 2, 3]
[37m[36mINFO[0m[0m 01/27 16:59:23 | Batch sizes for each domain: [0, 32, 0, 0] (total=32)
[37m[36mINFO[0m[0m 01/27 16:59:23 | steps-per-epoch for each domain: 109.12 -> min = 109.12
[37m[36mINFO[0m[0m 01/27 16:59:25 | # of params = 23641217
[37m[36mINFO[0m[0m 01/27 17:01:17 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 01/27 17:01:17 | 0.016178    0.016875    0.016609    0.014891    4.233406    0.020082    0.026804    0.016609    0.014891    0.012387    0.015784    0.016064    0.008037    0           0.000000    4.196661    0.000000    1.202706    110.533760 
[37m[36mINFO[0m[0m 01/27 17:03:40 | 0.016918    0.016194    0.018328    0.016037    4.192951    0.020597    0.024742    0.018328    0.016037    0.013232    0.014656    0.016925    0.009185    200         1.832761    4.204093    0.000000    0.139411    114.764938 
[37m[36mINFO[0m[0m 01/27 17:06:02 | 0.016118    0.016116    0.019759    0.021764    4.161602    0.019053    0.026804    0.019759    0.021764    0.012950    0.014656    0.016351    0.006889    400         3.665521    4.168877    0.000000    0.140308    113.631660 
[37m[36mINFO[0m[0m 01/27 17:08:25 | 0.017904    0.018950    0.027205    0.026346    4.133663    0.022142    0.032990    0.027205    0.026346    0.014358    0.013529    0.017212    0.010333    600         5.498282    4.129139    0.000000    0.144353    113.989691 
[37m[36mINFO[0m[0m 01/27 17:10:43 | 0.021287    0.023295    0.038087    0.032073    4.106284    0.025747    0.039175    0.038087    0.032073    0.017173    0.015784    0.020941    0.014925    800         7.331042    4.097798    0.000000    0.137467    109.963786 
[37m[36mINFO[0m[0m 01/27 17:13:02 | 0.024156    0.025513    0.046964    0.036655    4.078514    0.025232    0.041237    0.046964    0.036655    0.020270    0.015784    0.026965    0.019518    1000        9.163803    4.079866    0.000000    0.135246    112.263324 
[37m[36mINFO[0m[0m 01/27 17:15:22 | 0.033764    0.032319    0.062142    0.045819    4.045634    0.032441    0.041237    0.062142    0.045819    0.030124    0.029312    0.038726    0.026406    1200        10.996564   4.047121    0.000000    0.144675    110.458972 
[37m[36mINFO[0m[0m 01/27 17:17:38 | 0.044380    0.039904    0.093356    0.059565    4.010434    0.045829    0.041237    0.093356    0.059565    0.039977    0.040586    0.047332    0.037887    1400        12.829324   4.004026    0.000000    0.139925    107.296159 
[37m[36mINFO[0m[0m 01/27 17:19:52 | 0.056300    0.052402    0.108247    0.089347    3.969934    0.054583    0.041237    0.108247    0.089347    0.052928    0.062007    0.061388    0.053961    1600        14.662085   3.971571    0.000000    0.137780    106.322894 
[37m[36mINFO[0m[0m 01/27 17:22:08 | 0.067183    0.064726    0.138889    0.114548    3.918551    0.060247    0.057732    0.138889    0.114548    0.067005    0.072153    0.074297    0.064294    1800        16.494845   3.912054    0.000000    0.135121    109.098022 
[37m[36mINFO[0m[0m 01/27 17:24:28 | 0.082262    0.084650    0.155785    0.138603    3.854334    0.070546    0.074227    0.155785    0.138603    0.085304    0.091319    0.090935    0.088404    2000        18.327606   3.862315    0.000000    0.137087    111.525422 
[37m[36mINFO[0m[0m 01/27 17:26:44 | 0.097470    0.102145    0.170676    0.150057    3.773105    0.079815    0.082474    0.170676    0.150057    0.104448    0.120631    0.108147    0.103330    2200        20.160367   3.789327    0.000000    0.141194    108.302211 
[37m[36mINFO[0m[0m 01/27 17:29:03 | 0.111534    0.116284    0.195017    0.168385    3.673847    0.092688    0.101031    0.195017    0.168385    0.116554    0.134160    0.125359    0.113662    2400        21.993127   3.707544    0.000000    0.135553    110.955959 
[37m[36mINFO[0m[0m 01/27 17:31:22 | 0.124105    0.131962    0.227377    0.202749    3.530791    0.109681    0.119588    0.227377    0.202749    0.128097    0.146561    0.134538    0.129736    2600        23.825888   3.557487    0.000000    0.137142    111.519998 
[37m[36mINFO[0m[0m 01/27 17:33:38 | 0.149100    0.150230    0.257732    0.222222    3.347234    0.128733    0.117526    0.257732    0.222222    0.158784    0.175874    0.159782    0.157290    2800        25.658648   3.388149    0.000000    0.141158    107.865556 
[37m[36mINFO[0m[0m 01/27 17:35:52 | 0.174692    0.183385    0.315578    0.288660    3.099442    0.150360    0.156701    0.315578    0.288660    0.185248    0.206313    0.188468    0.187141    3000        27.491409   3.131666    0.000000    0.139193    105.826020 
[37m[36mINFO[0m[0m 01/27 17:38:12 | 0.221654    0.223723    0.380584    0.326460    2.798363    0.193615    0.185567    0.380584    0.326460    0.240709    0.252537    0.230637    0.233065    3200        29.324170   2.823581    0.000000    0.135422    112.424446 
[37m[36mINFO[0m[0m 01/27 17:40:30 | 0.257191    0.257147    0.438144    0.365407    2.532454    0.221421    0.218557    0.438144    0.365407    0.275338    0.277339    0.274814    0.275545    3400        31.156930   2.456192    0.000000    0.133612    111.196680 
[37m[36mINFO[0m[0m 01/27 17:42:46 | 0.289610    0.292503    0.489404    0.410080    2.327569    0.239959    0.247423    0.489404    0.410080    0.314471    0.324690    0.314400    0.305396    3600        32.989691   2.165221    0.000000    0.138755    107.837314 
[37m[36mINFO[0m[0m 01/27 17:45:01 | 0.312853    0.308536    0.528923    0.451317    2.147332    0.250257    0.255670    0.528923    0.451317    0.342061    0.342728    0.346242    0.327210    3800        34.822451   1.923515    0.000000    0.140103    106.769065 
[37m[36mINFO[0m[0m 01/27 17:47:19 | 0.343765    0.351621    0.573597    0.481100    2.041792    0.279094    0.294845    0.573597    0.481100    0.376126    0.376550    0.376076    0.383467    4000        36.655212   1.703784    0.000000    0.142667    109.254041 
[37m[36mINFO[0m[0m 01/27 17:49:39 | 0.357064    0.370965    0.601947    0.499427    1.917791    0.288877    0.305155    0.601947    0.499427    0.391610    0.403608    0.390706    0.404133    4200        38.487973   1.534155    0.000000    0.133392    112.461478 
[37m[36mINFO[0m[0m 01/27 17:51:59 | 0.374159    0.381130    0.630584    0.536082    1.813621    0.303296    0.307216    0.630584    0.536082    0.414133    0.418264    0.405049    0.417910    4400        40.320733   1.457329    0.000000    0.136800    112.590869 
[37m[36mINFO[0m[0m 01/27 17:54:12 | 0.383608    0.396387    0.658648    0.544101    1.729587    0.309475    0.338144    0.658648    0.544101    0.425113    0.422773    0.416236    0.428243    4600        42.153494   1.279259    0.000000    0.140276    104.162451 
[37m[36mINFO[0m[0m 01/27 17:56:33 | 0.391524    0.396873    0.682990    0.568156    1.667461    0.313594    0.313402    0.682990    0.568156    0.433840    0.434047    0.427137    0.443169    4800        43.986254   1.155378    0.000000    0.144344    112.311451 
[37m[36mINFO[0m[0m 01/27 17:58:48 | 0.413758    0.422749    0.698740    0.587629    1.646117    0.331102    0.344330    0.698740    0.587629    0.456644    0.454340    0.453528    0.469575    5000        45.819015   1.107943    0.000000    0.138529    106.894196 
[37m[36mINFO[0m[0m 01/27 17:58:49 | Cumulative gradient change saved at train_output/OfficeHome/CORAL/[0, 2, 3]/250127_16-59-23_resnet50_sgd/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 01/27 17:58:50 | ---
[37m[36mINFO[0m[0m 01/27 17:58:50 | test-domain validation(oracle) = 41.376%
[37m[36mINFO[0m[0m 01/27 17:58:50 | training-domain validation(iid) = 41.376%
[37m[36mINFO[0m[0m 01/27 17:58:50 | last = 41.376%
[37m[36mINFO[0m[0m 01/27 17:58:50 | last (inD) = 58.763%
[37m[36mINFO[0m[0m 01/27 17:58:50 | training-domain validation (iid, inD) = 58.763%
[37m[36mINFO[0m[0m 01/27 17:58:50 | === Summary ===
[37m[36mINFO[0m[0m 01/27 17:58:50 | Command: /jsm0707/Large-scale/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm CORAL --test_envs 0 2 3 --dataset OfficeHome
[37m[36mINFO[0m[0m 01/27 17:58:50 | Unique name: 250127_16-59-23_resnet50_sgd
[37m[36mINFO[0m[0m 01/27 17:58:50 | Out path: train_output/OfficeHome/CORAL/[0, 2, 3]/250127_16-59-23_resnet50_sgd
[37m[36mINFO[0m[0m 01/27 17:58:50 | Algorithm: CORAL
[37m[36mINFO[0m[0m 01/27 17:58:50 | Dataset: OfficeHome
