[37m[36mINFO[0m[0m 02/22 03:59:10 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 0 2 3 --dataset OfficeHome --trial_seed 0 --hparams_seed 1
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: OfficeHome
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 1
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/OfficeHome/CORAL/[0, 2, 3]/250222_03-59-10_resnet50_GENIE
	out_root: train_output/OfficeHome/CORAL/[0, 2, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 2, 3]
	trial_seed: 0
	unique_name: 250222_03-59-10_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.1
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 5.0781288859686544e-05
	batch_size: 44
	weight_decay: 0.00046410133598234803
	mmd_gamma: 1.1642706271054615
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[OfficeHome] #envs=4, #classes=65
	env0: A (#2427)
	env1: C (#4365)
	env2: P (#4439)
	env3: R (#4357)

[37m[36mINFO[0m[0m 02/22 03:59:10 | n_steps = 5001
[37m[36mINFO[0m[0m 02/22 03:59:10 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/22 03:59:10 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/22 03:59:10 | 
[37m[36mINFO[0m[0m 02/22 03:59:10 | Testenv name escaping te_A_P_R -> te_A_P_R
[37m[36mINFO[0m[0m 02/22 03:59:10 | Test envs = [0, 2, 3], name = te_A_P_R
[37m[36mINFO[0m[0m 02/22 03:59:10 | Train environments: [1], Test environments: [0, 2, 3]
[37m[36mINFO[0m[0m 02/22 03:59:10 | Batch sizes for each domain: [0, 44, 0, 0] (total=44)
[37m[36mINFO[0m[0m 02/22 03:59:10 | steps-per-epoch for each domain: 79.36 -> min = 79.36
[37m[36mINFO[0m[0m 02/22 03:59:12 | # of params = 23641217
[37m[36mINFO[0m[0m 02/22 04:01:25 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 02/22 04:01:25 | 0.017150    0.020468    0.020046    0.026346    4.209926    0.019053    0.022680    0.020046    0.026346    0.016047    0.016911    0.016351    0.021814    0           0.000000    4.201800    0.000000    1.722655    131.125274 
[37m[36mINFO[0m[0m 02/22 04:04:19 | 0.478145    0.491558    0.769759    0.643757    1.356756    0.390319    0.439175    0.769759    0.643757    0.518300    0.505073    0.525818    0.530425    200         2.520046    1.799483    0.000000    0.201243    134.081401 
[37m[36mINFO[0m[0m 02/22 04:06:59 | 0.517197    0.520484    0.882589    0.689576    1.410042    0.450566    0.468041    0.882589    0.689576    0.542793    0.540023    0.558233    0.553387    400         5.040092    0.565023    0.000000    0.218749    115.781270 
[37m[36mINFO[0m[0m 02/22 04:10:00 | 0.519984    0.529904    0.916094    0.711340    1.366915    0.452111    0.505155    0.916094    0.711340    0.546453    0.521984    0.561388    0.562572    600         7.560137    0.368852    0.000000    0.220063    137.140981 
[37m[36mINFO[0m[0m 02/22 04:12:36 | 0.542485    0.549199    0.947595    0.721649    1.396200    0.459835    0.515464    0.947595    0.721649    0.570946    0.556933    0.596672    0.575201    800         10.080183   0.229499    0.000000    0.199548    116.354712 
[37m[36mINFO[0m[0m 02/22 04:15:35 | 0.531010    0.524047    0.949885    0.737686    1.345649    0.452111    0.465979    0.949885    0.737686    0.556869    0.533258    0.584050    0.572905    1000        12.600229   0.184257    0.000000    0.266182    125.880247 
[37m[36mINFO[0m[0m 02/22 04:18:20 | 0.547430    0.534939    0.964777    0.747995    1.401703    0.459320    0.465979    0.964777    0.747995    0.578266    0.567080    0.604705    0.571757    1200        15.120275   0.129616    0.000000    0.195164    126.105643 
[37m[36mINFO[0m[0m 02/22 04:21:06 | 0.550829    0.551875    0.972222    0.754868    1.456764    0.462410    0.503093    0.972222    0.754868    0.581644    0.571590    0.608434    0.580941    1400        17.640321   0.111194    0.000000    0.209810    123.504371 
[37m[36mINFO[0m[0m 02/22 04:24:07 | 0.539268    0.538626    0.975659    0.756014    1.369254    0.453656    0.457732    0.975659    0.756014    0.572354    0.578354    0.591796    0.579793    1600        20.160367   0.097013    0.000000    0.242119    132.904132 
[37m[36mINFO[0m[0m 02/22 04:27:03 | 0.522276    0.526207    0.969645    0.749141    1.433946    0.423275    0.455670    0.969645    0.749141    0.569257    0.556933    0.574297    0.566016    1800        22.680412   0.109441    0.000000    0.211250    133.362548 
[37m[36mINFO[0m[0m 02/22 04:29:55 | 0.554916    0.555656    0.976231    0.744559    1.442513    0.470649    0.490722    0.976231    0.744559    0.596565    0.593010    0.597533    0.583238    2000        25.200458   0.085118    0.000000    0.232095    126.403580 
[37m[36mINFO[0m[0m 02/22 04:32:51 | 0.554207    0.555435    0.979954    0.767468    1.471644    0.464985    0.488660    0.979954    0.767468    0.591498    0.579481    0.606139    0.598163    2200        27.720504   0.075984    0.000000    0.219597    132.031690 
[37m[36mINFO[0m[0m 02/22 04:35:44 | 0.524379    0.525248    0.974800    0.750286    1.435979    0.434604    0.461856    0.974800    0.750286    0.561655    0.550169    0.576879    0.563720    2400        30.240550   0.067408    0.000000    0.209861    130.789528 
[37m[36mINFO[0m[0m 02/22 04:38:35 | 0.557915    0.566379    0.981959    0.767468    1.470436    0.481977    0.544330    0.981959    0.767468    0.583333    0.572717    0.608434    0.582090    2600        32.760596   0.057246    0.000000    0.265637    117.209490 
[37m[36mINFO[0m[0m 02/22 04:41:38 | 0.548036    0.562157    0.983391    0.769759    1.517173    0.465499    0.523711    0.983391    0.769759    0.581363    0.577227    0.597246    0.585534    2800        35.280641   0.047296    0.000000    0.217027    140.066136 
[37m[36mINFO[0m[0m 02/22 04:44:25 | 0.545736    0.541338    0.981672    0.767468    1.706508    0.467559    0.503093    0.981672    0.767468    0.569820    0.542277    0.599828    0.578645    3000        37.800687   0.041611    0.000000    0.198875    127.002819 
[37m[36mINFO[0m[0m 02/22 04:47:04 | 0.532888    0.532277    0.981100    0.764032    1.525232    0.440268    0.478351    0.981100    0.764032    0.573198    0.550169    0.585198    0.568312    3200        40.320733   0.052071    0.000000    0.239246    111.083239 
[37m[36mINFO[0m[0m 02/22 04:50:03 | 0.521571    0.538320    0.980241    0.758305    1.731131    0.435633    0.501031    0.980241    0.758305    0.561092    0.547914    0.567986    0.566016    3400        42.840779   0.049009    0.000000    0.216518    135.656278 
[37m[36mINFO[0m[0m 02/22 04:53:04 | 0.540108    0.533446    0.983104    0.757159    1.587411    0.454686    0.478351    0.983104    0.757159    0.569538    0.546787    0.596099    0.575201    3600        45.360825   0.051829    0.000000    0.229967    135.093865 
[37m[36mINFO[0m[0m 02/22 04:55:44 | 0.529952    0.533902    0.982532    0.757159    1.607257    0.451081    0.474227    0.982532    0.757159    0.564189    0.560316    0.574584    0.567164    3800        47.880871   0.052458    0.000000    0.222330    116.117744 
[37m[36mINFO[0m[0m 02/22 04:58:35 | 0.527629    0.532618    0.982245    0.756014    1.614903    0.439238    0.488660    0.982245    0.756014    0.564189    0.555806    0.579461    0.553387    4000        50.400916   0.048941    0.000000    0.271411    115.975276 
[37m[36mINFO[0m[0m 02/22 05:01:31 | 0.552719    0.563649    0.984250    0.752577    1.524773    0.467559    0.503093    0.984250    0.752577    0.584459    0.586246    0.606139    0.601607    4200        52.920962   0.046146    0.000000    0.208064    134.795521 
[37m[36mINFO[0m[0m 02/22 05:04:30 | 0.511418    0.517172    0.981672    0.743414    1.483260    0.417096    0.441237    0.981672    0.743414    0.554336    0.559188    0.562823    0.551091    4400        55.441008   0.046062    0.000000    0.214890    135.706706 
[37m[36mINFO[0m[0m 02/22 05:07:12 | 0.544838    0.546106    0.984536    0.759450    1.532004    0.459320    0.484536    0.984536    0.759450    0.579955    0.565953    0.595238    0.587830    4600        57.961054   0.047963    0.000000    0.227415    116.924467 
[37m[36mINFO[0m[0m 02/22 05:10:15 | 0.562938    0.568828    0.984822    0.772050    1.479828    0.492276    0.527835    0.984822    0.772050    0.588964    0.587373    0.607573    0.591274    4800        60.481100   0.035358    0.000000    0.251038    132.896084 
[37m[36mINFO[0m[0m 02/22 05:12:55 | 0.529287    0.541264    0.982245    0.766323    1.513492    0.437693    0.482474    0.982245    0.766323    0.568412    0.556933    0.581756    0.584386    5000        63.001145   0.037468    0.000000    0.196222    120.363453 
[37m[36mINFO[0m[0m 02/22 05:12:55 | Cumulative gradient change saved at train_output/OfficeHome/CORAL/[0, 2, 3]/250222_03-59-10_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/22 05:12:58 | ---
[37m[36mINFO[0m[0m 02/22 05:12:58 | test-domain validation(oracle) = 56.294%
[37m[36mINFO[0m[0m 02/22 05:12:58 | training-domain validation(iid) = 56.294%
[37m[36mINFO[0m[0m 02/22 05:12:58 | last = 52.929%
[37m[36mINFO[0m[0m 02/22 05:12:58 | last (inD) = 76.632%
[37m[36mINFO[0m[0m 02/22 05:12:58 | training-domain validation (iid, inD) = 77.205%
[37m[36mINFO[0m[0m 02/22 05:12:58 | === Summary ===
[37m[36mINFO[0m[0m 02/22 05:12:58 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 0 2 3 --dataset OfficeHome --trial_seed 0 --hparams_seed 1
[37m[36mINFO[0m[0m 02/22 05:12:58 | Unique name: 250222_03-59-10_resnet50_GENIE
[37m[36mINFO[0m[0m 02/22 05:12:58 | Out path: train_output/OfficeHome/CORAL/[0, 2, 3]/250222_03-59-10_resnet50_GENIE
[37m[36mINFO[0m[0m 02/22 05:12:58 | Algorithm: CORAL
[37m[36mINFO[0m[0m 02/22 05:12:58 | Dataset: OfficeHome
