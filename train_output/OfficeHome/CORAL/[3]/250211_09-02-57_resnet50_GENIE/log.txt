[37m[36mINFO[0m[0m 02/11 09:02:57 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 3 --dataset OfficeHome --trial_seed 2 --hparams_seed 1
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: OfficeHome
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 1
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/OfficeHome/CORAL/[3]/250211_09-02-57_resnet50_GENIE
	out_root: train_output/OfficeHome/CORAL/[3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [3]
	trial_seed: 2
	unique_name: 250211_09-02-57_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.5
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 3.1159521264763664e-05
	batch_size: 11
	weight_decay: 1.4650833494643601e-05
	mmd_gamma: 0.310538435991174
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[OfficeHome] #envs=4, #classes=65
	env0: A (#2427)
	env1: C (#4365)
	env2: P (#4439)
	env3: R (#4357)

[37m[36mINFO[0m[0m 02/11 09:02:57 | n_steps = 5001
[37m[36mINFO[0m[0m 02/11 09:02:57 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/11 09:02:57 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/11 09:02:57 | 
[37m[36mINFO[0m[0m 02/11 09:02:57 | Testenv name escaping te_R -> te_R
[37m[36mINFO[0m[0m 02/11 09:02:57 | Test envs = [3], name = te_R
[37m[36mINFO[0m[0m 02/11 09:02:57 | Train environments: [0, 1, 2], Test environments: [3]
[37m[36mINFO[0m[0m 02/11 09:02:57 | Batch sizes for each domain: [11, 11, 11, 0] (total=33)
[37m[36mINFO[0m[0m 02/11 09:02:57 | steps-per-epoch for each domain: 176.55, 317.45, 322.91 -> min = 176.55
[37m[36mINFO[0m[0m 02/11 09:02:59 | # of params = 23641217
[37m[36mINFO[0m[0m 02/11 09:05:08 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 02/11 09:05:08 | 0.039587    0.035591    0.027472    0.031951    4.200444    0.031411    0.039175    0.019473    0.019473    0.031532    0.037204    0.039587    0.035591    0           0.000000    4.338253    0.162570    1.305217    127.840906 
[37m[36mINFO[0m[0m 02/11 09:08:00 | 0.577740    0.588978    0.570745    0.538841    1.778252    0.566941    0.494845    0.501432    0.494845    0.643863    0.626832    0.577740    0.588978    200         1.132853    3.162492    0.300477    0.242270    123.561981 
[37m[36mINFO[0m[0m 02/11 09:10:50 | 0.677854    0.663605    0.703508    0.674783    1.273108    0.705973    0.661856    0.649485    0.609393    0.755068    0.753100    0.677854    0.663605    400         2.265705    1.407105    0.506578    0.221627    125.394023 
[37m[36mINFO[0m[0m 02/11 09:13:34 | 0.735227    0.718714    0.770917    0.713171    1.048230    0.774974    0.680412    0.719645    0.658648    0.818131    0.800451    0.735227    0.718714    600         3.398558    1.062882    0.402194    0.194363    125.250296 
[37m[36mINFO[0m[0m 02/11 09:16:17 | 0.727768    0.725603    0.798738    0.733741    1.000968    0.805870    0.680412    0.748282    0.711340    0.842061    0.809470    0.727768    0.725603    800         4.531411    0.866314    0.366469    0.206920    122.282980 
[37m[36mINFO[0m[0m 02/11 09:19:00 | 0.750430    0.740528    0.846377    0.750091    0.887190    0.865088    0.729897    0.786655    0.683849    0.887387    0.836528    0.750430    0.740528    1000        5.664264    0.731324    0.339478    0.174694    128.179011 
[37m[36mINFO[0m[0m 02/11 09:21:49 | 0.757315    0.727899    0.873837    0.792142    0.792799    0.886715    0.767010    0.833333    0.753723    0.901464    0.855693    0.757315    0.727899    1200        6.797116    0.606563    0.321971    0.236776    121.189649 
[37m[36mINFO[0m[0m 02/11 09:24:34 | 0.757889    0.712974    0.886440    0.768499    0.855109    0.905252    0.715464    0.840779    0.739977    0.913288    0.850056    0.757889    0.712974    1400        7.929969    0.497339    0.304247    0.202350    124.109138 
[37m[36mINFO[0m[0m 02/11 09:27:20 | 0.760470    0.738232    0.892604    0.772335    0.845142    0.905767    0.736082    0.855097    0.734250    0.916948    0.846674    0.760470    0.738232    1600        9.062822    0.460583    0.287433    0.203372    125.663375 
[37m[36mINFO[0m[0m 02/11 09:29:57 | 0.761905    0.747417    0.916102    0.799113    0.757862    0.930999    0.762887    0.884593    0.768614    0.932714    0.865840    0.761905    0.747417    1800        10.195675   0.427191    0.264741    0.195203    118.416600 
[37m[36mINFO[0m[0m 02/11 09:32:48 | 0.738669    0.739380    0.914225    0.775189    0.835185    0.931514    0.709278    0.887457    0.760596    0.923705    0.855693    0.738669    0.739380    2000        11.328527   0.364401    0.258965    0.232904    124.045191 
[37m[36mINFO[0m[0m 02/11 09:35:29 | 0.758176    0.745121    0.927198    0.783260    0.785543    0.949022    0.738144    0.888316    0.751432    0.944257    0.860203    0.758176    0.745121    2200        12.461380   0.321711    0.254680    0.176774    125.419319 
[37m[36mINFO[0m[0m 02/11 09:38:08 | 0.759897    0.764638    0.935975    0.785645    0.791671    0.959320    0.736082    0.904066    0.764032    0.944538    0.856821    0.759897    0.764638    2400        13.594233   0.293945    0.236033    0.200613    118.977895 
[37m[36mINFO[0m[0m 02/11 09:41:01 | 0.759036    0.754305    0.942024    0.784918    0.779000    0.964985    0.756701    0.909794    0.747995    0.951295    0.850056    0.759036    0.754305    2600        14.727085   0.259716    0.227325    0.202712    132.996704 
