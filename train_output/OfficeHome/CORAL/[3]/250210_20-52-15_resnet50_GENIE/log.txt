[37m[36mINFO[0m[0m 02/10 20:52:15 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 3 --dataset OfficeHome --trial_seed 0 --hparams_seed 7
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: OfficeHome
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 7
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/OfficeHome/CORAL/[3]/250210_20-52-15_resnet50_GENIE
	out_root: train_output/OfficeHome/CORAL/[3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [3]
	trial_seed: 0
	unique_name: 250210_20-52-15_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 1.6632780446310692e-05
	batch_size: 24
	weight_decay: 5.717289389191427e-06
	mmd_gamma: 3.812683559377669
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[OfficeHome] #envs=4, #classes=65
	env0: A (#2427)
	env1: C (#4365)
	env2: P (#4439)
	env3: R (#4357)

[37m[36mINFO[0m[0m 02/10 20:52:15 | n_steps = 5001
[37m[36mINFO[0m[0m 02/10 20:52:15 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/10 20:52:15 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/10 20:52:15 | 
[37m[36mINFO[0m[0m 02/10 20:52:15 | Testenv name escaping te_R -> te_R
[37m[36mINFO[0m[0m 02/10 20:52:15 | Test envs = [3], name = te_R
[37m[36mINFO[0m[0m 02/10 20:52:15 | Train environments: [0, 1, 2], Test environments: [3]
[37m[36mINFO[0m[0m 02/10 20:52:15 | Batch sizes for each domain: [24, 24, 24, 0] (total=72)
[37m[36mINFO[0m[0m 02/10 20:52:15 | steps-per-epoch for each domain: 80.92, 145.50, 148.00 -> min = 80.92
[37m[36mINFO[0m[0m 02/10 20:52:16 | # of params = 23641217
[37m[36mINFO[0m[0m 02/10 20:54:28 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 02/10 20:54:28 | 0.023523    0.030999    0.019712    0.016023    4.219036    0.029351    0.018557    0.013173    0.012600    0.016610    0.016911    0.023523    0.030999    0           0.000000    4.287438    0.031895    1.412162    130.563825 
[37m[36mINFO[0m[0m 02/10 20:57:22 | 0.719736    0.694604    0.732552    0.707059    1.208854    0.716787    0.705155    0.684135    0.643757    0.796734    0.772266    0.719736    0.694604    200         2.471679    2.415644    0.054845    0.259759    122.125266 
[37m[36mINFO[0m[0m 02/10 21:00:21 | 0.763626    0.745121    0.835335    0.760943    0.973551    0.851184    0.758763    0.782073    0.703322    0.872748    0.820744    0.763626    0.745121    400         4.943357    0.860573    0.058721    0.236389    131.338094 
[37m[36mINFO[0m[0m 02/10 21:03:20 | 0.772232    0.761194    0.868018    0.767619    0.891094    0.887745    0.750515    0.822165    0.709049    0.894144    0.843292    0.772232    0.761194    600         7.415036    0.579957    0.048351    0.256834    128.031294 
[37m[36mINFO[0m[0m 02/10 21:06:20 | 0.769363    0.769231    0.912459    0.785251    0.810357    0.931514    0.746392    0.873711    0.750286    0.932151    0.859076    0.769363    0.769231    800         9.886715    0.453436    0.042929    0.253636    128.305219 
[37m[36mINFO[0m[0m 02/10 21:09:11 | 0.788009    0.781860    0.931993    0.796881    0.772438    0.958290    0.771134    0.891180    0.750286    0.946509    0.869222    0.788009    0.781860    1000        12.358393   0.346031    0.039339    0.238346    123.486227 
[37m[36mINFO[0m[0m 02/10 21:12:06 | 0.791452    0.785304    0.950730    0.803434    0.756885    0.973223    0.756701    0.918099    0.767468    0.960867    0.886133    0.791452    0.785304    1200        14.830072   0.275811    0.036230    0.252542    124.676350 
[37m[36mINFO[0m[0m 02/10 21:15:03 | 0.798049    0.791045    0.958172    0.804481    0.743428    0.979918    0.771134    0.926976    0.766323    0.967624    0.875986    0.798049    0.791045    1400        17.301751   0.214569    0.033144    0.239993    128.792873 
[37m[36mINFO[0m[0m 02/10 21:17:54 | 0.769937    0.778416    0.961386    0.795765    0.762051    0.979918    0.760825    0.930985    0.762887    0.973255    0.863585    0.769937    0.778416    1600        19.773429   0.186156    0.030830    0.242143    122.476264 
[37m[36mINFO[0m[0m 02/10 21:20:48 | 0.791738    0.786452    0.973580    0.817526    0.718664    0.992276    0.787629    0.948454    0.772050    0.980011    0.892897    0.791738    0.786452    1800        22.245108   0.149974    0.029036    0.249381    124.183743 
[37m[36mINFO[0m[0m 02/10 21:23:39 | 0.789443    0.794489    0.975829    0.809931    0.746983    0.990731    0.777320    0.955899    0.767468    0.980856    0.885006    0.789443    0.794489    2000        24.716787   0.128867    0.026955    0.245545    121.995409 
[37m[36mINFO[0m[0m 02/10 21:26:43 | 0.792886    0.789897    0.981881    0.817620    0.709934    0.988671    0.785567    0.969359    0.777778    0.987613    0.889515    0.792886    0.789897    2200        27.188465   0.113866    0.025224    0.251476    133.931666 
[37m[36mINFO[0m[0m 02/10 21:29:38 | 0.790304    0.780712    0.979981    0.814370    0.723875    0.988671    0.769072    0.965349    0.776632    0.985923    0.897407    0.790304    0.780712    2400        29.660144   0.096911    0.023952    0.262269    122.533697 
[37m[36mINFO[0m[0m 02/10 21:32:35 | 0.794320    0.799082    0.985128    0.818952    0.713843    0.993306    0.779381    0.971649    0.780069    0.990428    0.897407    0.794320    0.799082    2600        32.131823   0.089819    0.022759    0.238849    129.254546 
[37m[36mINFO[0m[0m 02/10 21:35:31 | 0.794607    0.791045    0.986077    0.819276    0.717351    0.993306    0.781443    0.973654    0.782360    0.991273    0.894025    0.794607    0.791045    2800        34.603502   0.086285    0.021802    0.249998    125.831285 
[37m[36mINFO[0m[0m 02/10 21:38:30 | 0.794320    0.784156    0.986726    0.807741    0.729969    0.993821    0.764948    0.975086    0.777778    0.991273    0.880496    0.794320    0.784156    3000        37.075180   0.078237    0.020386    0.238330    131.345492 
[37m[36mINFO[0m[0m 02/10 21:41:22 | 0.792886    0.780712    0.988000    0.817819    0.712237    0.995366    0.779381    0.976518    0.778923    0.992117    0.895152    0.792886    0.780712    3200        39.546859   0.068583    0.019815    0.257147    120.975775 
[37m[36mINFO[0m[0m 02/10 21:44:20 | 0.794894    0.797933    0.988816    0.809644    0.734140    0.996395    0.775258    0.977090    0.772050    0.992962    0.881623    0.794894    0.797933    3400        42.018538   0.060139    0.018816    0.259129    125.913380 
[37m[36mINFO[0m[0m 02/10 21:47:12 | 0.788870    0.785304    0.990605    0.820843    0.718073    0.996910    0.779381    0.981100    0.782360    0.993806    0.900789    0.788870    0.785304    3600        44.490216   0.058850    0.018080    0.244078    123.233819 
[37m[36mINFO[0m[0m 02/10 21:50:11 | 0.792025    0.787600    0.987225    0.822548    0.726452    0.993306    0.785567    0.977377    0.785796    0.990991    0.896280    0.792025    0.787600    3800        46.961895   0.063897    0.017727    0.247383    129.360189 
[37m[36mINFO[0m[0m 02/10 21:53:06 | 0.789157    0.812859    0.989262    0.808826    0.740523    0.994336    0.764948    0.978236    0.769759    0.995214    0.891770    0.789157    0.812859    4000        49.433574   0.059085    0.016935    0.232792    128.134646 
[37m[36mINFO[0m[0m 02/10 21:56:06 | 0.785714    0.780712    0.989798    0.813362    0.739472    0.995366    0.777320    0.979095    0.776632    0.994932    0.886133    0.785714    0.780712    4200        51.905252   0.053919    0.016294    0.249163    130.649275 
[37m[36mINFO[0m[0m 02/10 21:58:50 | 0.798623    0.801378    0.990720    0.814401    0.715377    0.996395    0.769072    0.981959    0.782360    0.993806    0.891770    0.798623    0.801378    4400        54.376931   0.054251    0.016180    0.232343    117.215757 
[37m[36mINFO[0m[0m 02/10 22:01:38 | 0.798049    0.807118    0.989940    0.818882    0.714840    0.994336    0.781443    0.981959    0.778923    0.993525    0.896280    0.798049    0.807118    4600        56.848610   0.048172    0.015494    0.217225    125.147954 
[37m[36mINFO[0m[0m 02/10 22:04:34 | 0.798336    0.787600    0.991058    0.827793    0.697617    0.994851    0.797938    0.983391    0.784651    0.994932    0.900789    0.798336    0.787600    4800        59.320288   0.044698    0.015121    0.237093    128.086956 
[37m[36mINFO[0m[0m 02/10 22:07:18 | 0.798910    0.801378    0.990351    0.816286    0.723358    0.995881    0.779381    0.980241    0.773196    0.994932    0.896280    0.798910    0.801378    5000        61.791967   0.047029    0.014516    0.222541    119.627259 
[37m[36mINFO[0m[0m 02/10 22:07:18 | Cumulative gradient change saved at train_output/OfficeHome/CORAL/[3]/250210_20-52-15_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/10 22:07:20 | ---
[37m[36mINFO[0m[0m 02/10 22:07:20 | test-domain validation(oracle) = 78.916%
[37m[36mINFO[0m[0m 02/10 22:07:20 | training-domain validation(iid) = 79.834%
[37m[36mINFO[0m[0m 02/10 22:07:20 | last = 79.891%
[37m[36mINFO[0m[0m 02/10 22:07:20 | last (inD) = 81.629%
[37m[36mINFO[0m[0m 02/10 22:07:20 | training-domain validation (iid, inD) = 82.779%
[37m[36mINFO[0m[0m 02/10 22:07:20 | === Summary ===
[37m[36mINFO[0m[0m 02/10 22:07:20 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 3 --dataset OfficeHome --trial_seed 0 --hparams_seed 7
[37m[36mINFO[0m[0m 02/10 22:07:20 | Unique name: 250210_20-52-15_resnet50_GENIE
[37m[36mINFO[0m[0m 02/10 22:07:20 | Out path: train_output/OfficeHome/CORAL/[3]/250210_20-52-15_resnet50_GENIE
[37m[36mINFO[0m[0m 02/10 22:07:20 | Algorithm: CORAL
[37m[36mINFO[0m[0m 02/10 22:07:20 | Dataset: OfficeHome
