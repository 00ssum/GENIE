[37m[36mINFO[0m[0m 02/11 04:11:07 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 3 --dataset OfficeHome --trial_seed 1 --hparams_seed 17
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: OfficeHome
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 17
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/OfficeHome/CORAL/[3]/250211_04-11-07_resnet50_GENIE
	out_root: train_output/OfficeHome/CORAL/[3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [3]
	trial_seed: 1
	unique_name: 250211_04-11-07_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.5
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 0.0002990700776954947
	batch_size: 8
	weight_decay: 4.0966675521600606e-05
	mmd_gamma: 0.10200134949133195
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[OfficeHome] #envs=4, #classes=65
	env0: A (#2427)
	env1: C (#4365)
	env2: P (#4439)
	env3: R (#4357)

[37m[36mINFO[0m[0m 02/11 04:11:07 | n_steps = 5001
[37m[36mINFO[0m[0m 02/11 04:11:07 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/11 04:11:07 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/11 04:11:07 | 
[37m[36mINFO[0m[0m 02/11 04:11:07 | Testenv name escaping te_R -> te_R
[37m[36mINFO[0m[0m 02/11 04:11:07 | Test envs = [3], name = te_R
[37m[36mINFO[0m[0m 02/11 04:11:07 | Train environments: [0, 1, 2], Test environments: [3]
[37m[36mINFO[0m[0m 02/11 04:11:07 | Batch sizes for each domain: [8, 8, 8, 0] (total=24)
[37m[36mINFO[0m[0m 02/11 04:11:07 | steps-per-epoch for each domain: 242.75, 436.50, 444.00 -> min = 242.75
[37m[36mINFO[0m[0m 02/11 04:11:08 | # of params = 23641217
[37m[36mINFO[0m[0m 02/11 04:13:07 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 02/11 04:13:07 | 0.019507    0.035591    0.022471    0.020723    4.207500    0.037590    0.026804    0.015464    0.026346    0.014358    0.009019    0.019507    0.035591    0           0.000000    4.307939    0.271127    1.118225    118.439316 
[37m[36mINFO[0m[0m 02/11 04:15:50 | 0.591796    0.557979    0.532770    0.536490    1.826432    0.520082    0.531959    0.481100    0.482245    0.597128    0.595265    0.591796    0.557979    200         0.823893    3.146692    0.572307    0.207480    121.499807 
[37m[36mINFO[0m[0m 02/11 04:18:22 | 0.664945    0.641791    0.671444    0.628962    1.409229    0.647786    0.620619    0.632875    0.584192    0.733671    0.682074    0.664945    0.641791    400         1.647786    1.584992    0.912726    0.166787    118.024960 
[37m[36mINFO[0m[0m 02/11 04:21:06 | 0.702811    0.691160    0.722937    0.664717    1.256573    0.723481    0.668041    0.663517    0.589920    0.781813    0.736189    0.702811    0.691160    600         2.471679    1.256749    0.786226    0.188527    126.042931 
[37m[36mINFO[0m[0m 02/11 04:23:40 | 0.716867    0.711825    0.775092    0.703036    1.076657    0.783728    0.670103    0.726231    0.671249    0.815315    0.767756    0.716867    0.711825    800         3.295572    1.086643    0.673196    0.170905    120.581649 
[37m[36mINFO[0m[0m 02/11 04:26:18 | 0.702524    0.706085    0.780342    0.700978    1.122871    0.770855    0.661856    0.737400    0.659794    0.832770    0.781285    0.702524    0.706085    1000        4.119464    0.945338    0.655890    0.193629    118.435275 
[37m[36mINFO[0m[0m 02/11 04:28:54 | 0.718876    0.723307    0.822590    0.738066    0.993015    0.820288    0.719588    0.780928    0.694158    0.866554    0.800451    0.718876    0.723307    1200        4.943357    0.769374    0.612533    0.189059    119.129399 
[37m[36mINFO[0m[0m 02/11 04:31:40 | 0.736087    0.740528    0.844156    0.747042    0.960756    0.851184    0.736082    0.798683    0.712486    0.882601    0.792559    0.736087    0.740528    1400        5.767250    0.732767    0.590743    0.191168    127.485162 
[37m[36mINFO[0m[0m 02/11 04:34:10 | 0.730924    0.717566    0.838382    0.739181    0.951122    0.857364    0.709278    0.790664    0.702176    0.867117    0.806088    0.730924    0.717566    1600        6.591143    0.614897    0.591998    0.164457    117.360535 
[37m[36mINFO[0m[0m 02/11 04:36:55 | 0.738669    0.727899    0.858709    0.744631    0.936553    0.861998    0.705155    0.826460    0.713631    0.887669    0.815107    0.738669    0.727899    1800        7.415036    0.559248    0.583425    0.214129    121.849095 
[37m[36mINFO[0m[0m 02/11 04:39:31 | 0.723752    0.721010    0.874849    0.743660    0.964901    0.892894    0.709278    0.830470    0.696449    0.901182    0.825254    0.723752    0.721010    2000        8.238929    0.557526    0.531717    0.174039    121.446509 
[37m[36mINFO[0m[0m 02/11 04:42:10 | 0.734940    0.700344    0.895588    0.769012    0.859284    0.918641    0.734021    0.856243    0.733104    0.911881    0.839910    0.734940    0.700344    2200        9.062822    0.500261    0.550032    0.171057    124.858567 
[37m[36mINFO[0m[0m 02/11 04:44:47 | 0.731497    0.733639    0.904323    0.771795    0.847503    0.928424    0.740206    0.861684    0.727377    0.922860    0.847802    0.731497    0.733639    2400        9.886715    0.405926    0.512556    0.191769    118.274887 
[37m[36mINFO[0m[0m 02/11 04:47:33 | 0.757028    0.745121    0.899639    0.767723    0.903610    0.916066    0.725773    0.861397    0.725086    0.921453    0.852311    0.757028    0.745121    2600        10.710608   0.390435    0.510339    0.217209    122.055924 
[37m[36mINFO[0m[0m 02/11 04:50:06 | 0.741251    0.729047    0.914063    0.764446    0.914992    0.940783    0.721649    0.876575    0.720504    0.924831    0.851184    0.741251    0.729047    2800        11.534501   0.423083    0.464194    0.172048    118.771221 
[37m[36mINFO[0m[0m 02/11 04:52:43 | 0.734079    0.734788    0.922936    0.778949    0.850294    0.947477    0.731959    0.889462    0.752577    0.931869    0.852311    0.734079    0.734788    3000        12.358393   0.323935    0.500701    0.165288    124.488571 
[37m[36mINFO[0m[0m 02/11 04:55:20 | 0.751578    0.742824    0.932055    0.792082    0.828782    0.949537    0.746392    0.903780    0.762887    0.942849    0.866967    0.751578    0.742824    3200        13.182286   0.341591    0.491765    0.204510    115.520564 
[37m[36mINFO[0m[0m 02/11 04:57:52 | 0.746988    0.747417    0.934805    0.779154    0.842538    0.952626    0.746392    0.909221    0.734250    0.942568    0.856821    0.746988    0.747417    3400        14.006179   0.271381    0.466801    0.159807    120.153095 
[37m[36mINFO[0m[0m 02/11 05:00:30 | 0.729776    0.746269    0.936601    0.773656    0.850967    0.947477    0.709278    0.916380    0.754868    0.945946    0.856821    0.729776    0.746269    3600        14.830072   0.248475    0.455291    0.182334    121.215134 
[37m[36mINFO[0m[0m 02/11 05:03:07 | 0.755881    0.749713    0.947676    0.788035    0.801087    0.960865    0.742268    0.924112    0.754868    0.958052    0.866967    0.755881    0.749713    3800        15.653965   0.239279    0.435015    0.194878    118.160851 
[37m[36mINFO[0m[0m 02/11 05:05:50 | 0.770511    0.764638    0.954307    0.795747    0.769571    0.968589    0.760825    0.927835    0.759450    0.966498    0.866967    0.770511    0.764638    4000        16.477858   0.216440    0.424899    0.207382    121.829996 
[37m[36mINFO[0m[0m 02/11 05:08:26 | 0.757028    0.749713    0.955954    0.796957    0.775614    0.973738    0.758763    0.932131    0.762887    0.961993    0.869222    0.757028    0.749713    4200        17.301751   0.222227    0.417599    0.155527    124.434113 
[37m[36mINFO[0m[0m 02/11 05:10:53 | 0.751291    0.741676    0.961903    0.800163    0.822014    0.977343    0.752577    0.941867    0.764032    0.966498    0.883878    0.751291    0.741676    4400        18.125644   0.207615    0.396243    0.171729    113.151190 
[37m[36mINFO[0m[0m 02/11 05:13:33 | 0.737808    0.730195    0.953463    0.775923    0.908615    0.974253    0.719588    0.925830    0.746850    0.960304    0.861330    0.737808    0.730195    4600        18.949537   0.169583    0.409927    0.197869    120.670735 
[37m[36mINFO[0m[0m 02/11 05:16:08 | 0.759610    0.746269    0.959556    0.799652    0.774437    0.973738    0.756701    0.938431    0.762887    0.966498    0.879369    0.759610    0.746269    4800        19.773429   0.162007    0.390520    0.155339    123.845836 
[37m[36mINFO[0m[0m 02/11 05:18:45 | 0.775961    0.766935    0.974105    0.821390    0.709430    0.988157    0.775258    0.952176    0.790378    0.981982    0.898534    0.775961    0.766935    5000        20.597322   0.142792    0.384775    0.184877    119.619812 
[37m[36mINFO[0m[0m 02/11 05:18:45 | Cumulative gradient change saved at train_output/OfficeHome/CORAL/[3]/250211_04-11-07_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/11 05:18:46 | ---
[37m[36mINFO[0m[0m 02/11 05:18:46 | test-domain validation(oracle) = 77.596%
[37m[36mINFO[0m[0m 02/11 05:18:46 | training-domain validation(iid) = 77.596%
[37m[36mINFO[0m[0m 02/11 05:18:46 | last = 77.596%
[37m[36mINFO[0m[0m 02/11 05:18:46 | last (inD) = 82.139%
[37m[36mINFO[0m[0m 02/11 05:18:46 | training-domain validation (iid, inD) = 82.139%
[37m[36mINFO[0m[0m 02/11 05:18:46 | === Summary ===
[37m[36mINFO[0m[0m 02/11 05:18:46 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 3 --dataset OfficeHome --trial_seed 1 --hparams_seed 17
[37m[36mINFO[0m[0m 02/11 05:18:46 | Unique name: 250211_04-11-07_resnet50_GENIE
[37m[36mINFO[0m[0m 02/11 05:18:46 | Out path: train_output/OfficeHome/CORAL/[3]/250211_04-11-07_resnet50_GENIE
[37m[36mINFO[0m[0m 02/11 05:18:46 | Algorithm: CORAL
[37m[36mINFO[0m[0m 02/11 05:18:46 | Dataset: OfficeHome
