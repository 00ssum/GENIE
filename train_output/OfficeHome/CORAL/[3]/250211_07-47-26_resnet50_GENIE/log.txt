[37m[36mINFO[0m[0m 02/11 07:47:26 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 3 --dataset OfficeHome --trial_seed 2 --hparams_seed 0
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: OfficeHome
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/OfficeHome/CORAL/[3]/250211_07-47-26_resnet50_GENIE
	out_root: train_output/OfficeHome/CORAL/[3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [3]
	trial_seed: 2
	unique_name: 250211_07-47-26_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	mmd_gamma: 1.0
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[OfficeHome] #envs=4, #classes=65
	env0: A (#2427)
	env1: C (#4365)
	env2: P (#4439)
	env3: R (#4357)

[37m[36mINFO[0m[0m 02/11 07:47:26 | n_steps = 5001
[37m[36mINFO[0m[0m 02/11 07:47:26 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/11 07:47:26 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/11 07:47:26 | 
[37m[36mINFO[0m[0m 02/11 07:47:26 | Testenv name escaping te_R -> te_R
[37m[36mINFO[0m[0m 02/11 07:47:26 | Test envs = [3], name = te_R
[37m[36mINFO[0m[0m 02/11 07:47:26 | Train environments: [0, 1, 2], Test environments: [3]
[37m[36mINFO[0m[0m 02/11 07:47:26 | Batch sizes for each domain: [32, 32, 32, 0] (total=96)
[37m[36mINFO[0m[0m 02/11 07:47:26 | steps-per-epoch for each domain: 60.69, 109.12, 111.00 -> min = 60.69
[37m[36mINFO[0m[0m 02/11 07:47:27 | # of params = 23641217
[37m[36mINFO[0m[0m 02/11 07:49:40 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 02/11 07:49:40 | 0.024096    0.029851    0.018393    0.024228    4.212186    0.023687    0.022680    0.014318    0.025200    0.017173    0.024803    0.024096    0.029851    0           0.000000    4.265642    0.030254    1.450229    131.034748 
[37m[36mINFO[0m[0m 02/11 07:52:25 | 0.769363    0.773823    0.797053    0.748423    0.934267    0.787848    0.713402    0.749427    0.697595    0.853885    0.834273    0.769363    0.773823    200         3.295572    1.727166    0.139698    0.248687    115.732149 
[37m[36mINFO[0m[0m 02/11 07:55:29 | 0.769076    0.766935    0.868052    0.773463    0.811968    0.887230    0.746392    0.825315    0.723940    0.891610    0.850056    0.769076    0.766935    400         6.591143    0.615257    0.121255    0.305523    122.485213 
[37m[36mINFO[0m[0m 02/11 07:58:22 | 0.778830    0.780712    0.908621    0.785738    0.776615    0.924820    0.752577    0.871707    0.736541    0.929336    0.868095    0.778830    0.780712    600         9.886715    0.405391    0.105247    0.246589    123.831158 
[37m[36mINFO[0m[0m 02/11 08:01:14 | 0.787149    0.783008    0.935220    0.796845    0.731557    0.956231    0.750515    0.902921    0.764032    0.946509    0.875986    0.787149    0.783008    800         13.182286   0.281968    0.093837    0.236008    124.503453 
[37m[36mINFO[0m[0m 02/11 08:04:08 | 0.793746    0.791045    0.962052    0.810500    0.688738    0.983522    0.781443    0.935853    0.757159    0.966779    0.892897    0.793746    0.791045    1000        16.477858   0.210342    0.085527    0.257834    122.779667 
[37m[36mINFO[0m[0m 02/11 08:07:02 | 0.795754    0.799082    0.969537    0.812984    0.681852    0.986097    0.764948    0.946163    0.774341    0.976351    0.899662    0.795754    0.799082    1200        19.773429   0.165980    0.076682    0.228658    128.643840 
[37m[36mINFO[0m[0m 02/11 08:09:53 | 0.789443    0.787600    0.971592    0.804515    0.684871    0.987127    0.758763    0.950172    0.770905    0.977477    0.883878    0.789443    0.787600    1400        23.069001   0.121573    0.069715    0.258713    119.220392 
[37m[36mINFO[0m[0m 02/11 08:12:51 | 0.801492    0.805970    0.978081    0.804855    0.691307    0.991246    0.758763    0.958763    0.764032    0.984234    0.891770    0.801492    0.805970    1600        26.364573   0.109402    0.064553    0.272018    123.575762 
[37m[36mINFO[0m[0m 02/11 08:15:56 | 0.797189    0.803674    0.984468    0.811181    0.693921    0.993306    0.762887    0.971077    0.776632    0.989020    0.894025    0.797189    0.803674    1800        29.660144   0.089026    0.060256    0.250805    134.529569 
[37m[36mINFO[0m[0m 02/11 08:18:52 | 0.795468    0.796785    0.983179    0.812250    0.688307    0.992276    0.764948    0.969931    0.777778    0.987331    0.894025    0.795468    0.796785    2000        32.955716   0.079622    0.054998    0.237484    128.220868 
[37m[36mINFO[0m[0m 02/11 08:21:53 | 0.792312    0.778416    0.984048    0.816392    0.688692    0.991761    0.767010    0.971363    0.791523    0.989020    0.890643    0.792312    0.778416    2200        36.251287   0.070604    0.051159    0.261370    128.966941 
[37m[36mINFO[0m[0m 02/11 08:24:45 | 0.802065    0.795637    0.984977    0.815046    0.691226    0.992276    0.771134    0.972509    0.774341    0.990146    0.899662    0.802065    0.795637    2400        39.546859   0.065378    0.047994    0.268037    118.320797 
[37m[36mINFO[0m[0m 02/11 08:27:44 | 0.803500    0.800230    0.989119    0.815393    0.684270    0.993306    0.773196    0.980527    0.781214    0.993525    0.891770    0.803500    0.800230    2600        42.842430   0.060965    0.046421    0.283370    121.903185 
[37m[36mINFO[0m[0m 02/11 08:30:41 | 0.800918    0.805970    0.990406    0.821631    0.673833    0.994336    0.779381    0.981386    0.789233    0.995495    0.896280    0.800918    0.805970    2800        46.138002   0.054483    0.043351    0.303816    116.664291 
[37m[36mINFO[0m[0m 02/11 08:33:45 | 0.798336    0.796785    0.991016    0.820092    0.680120    0.995881    0.779381    0.981672    0.782360    0.995495    0.898534    0.798336    0.796785    3000        49.433574   0.050401    0.041601    0.269435    129.754740 
[37m[36mINFO[0m[0m 02/11 08:36:35 | 0.806081    0.796785    0.989819    0.816350    0.671466    0.994851    0.777320    0.979954    0.773196    0.994651    0.898534    0.806081    0.796785    3200        52.729145   0.047505    0.039324    0.250522    120.342952 
[37m[36mINFO[0m[0m 02/11 08:39:31 | 0.802639    0.787600    0.990932    0.814324    0.682004    0.995881    0.771134    0.983391    0.780069    0.993525    0.891770    0.802639    0.787600    3400        56.024717   0.042834    0.037617    0.238767    128.174517 
[37m[36mINFO[0m[0m 02/11 08:42:25 | 0.805795    0.791045    0.990971    0.819081    0.679520    0.996910    0.775258    0.979381    0.780069    0.996622    0.901917    0.805795    0.791045    3600        59.320288   0.047271    0.036968    0.267812    119.958925 
[37m[36mINFO[0m[0m 02/11 08:45:18 | 0.798336    0.796785    0.992841    0.820837    0.672013    0.995366    0.779381    0.986254    0.781214    0.996903    0.901917    0.798336    0.796785    3800        62.615860   0.037756    0.035582    0.268790    119.612969 
[37m[36mINFO[0m[0m 02/11 08:48:14 | 0.807516    0.809414    0.990086    0.821876    0.685553    0.995366    0.781443    0.980241    0.776632    0.994651    0.907554    0.807516    0.809414    4000        65.911432   0.038000    0.034036    0.256495    124.664276 
[37m[36mINFO[0m[0m 02/11 08:51:13 | 0.808950    0.799082    0.991364    0.816720    0.680900    0.994336    0.756701    0.984822    0.792669    0.994932    0.900789    0.808950    0.799082    4200        69.207003   0.034439    0.032707    0.264061    126.595177 
[37m[36mINFO[0m[0m 02/11 08:54:02 | 0.800918    0.801378    0.991131    0.816985    0.693746    0.995366    0.771134    0.982532    0.785796    0.995495    0.894025    0.800918    0.801378    4400        72.502575   0.035985    0.031807    0.237626    120.753053 
[37m[36mINFO[0m[0m 02/11 08:56:57 | 0.803213    0.797933    0.991985    0.820321    0.688494    0.995366    0.773196    0.984250    0.789233    0.996340    0.898534    0.803213    0.797933    4600        75.798146   0.035911    0.031009    0.269127    121.690450 
[37m[36mINFO[0m[0m 02/11 08:59:53 | 0.802352    0.788749    0.992615    0.821571    0.689019    0.996395    0.769072    0.985109    0.788087    0.996340    0.907554    0.802352    0.788749    4800        79.093718   0.034808    0.030137    0.254878    125.085225 
[37m[36mINFO[0m[0m 02/11 09:02:51 | 0.802926    0.812859    0.991971    0.815317    0.681639    0.995881    0.764948    0.984536    0.789233    0.995495    0.891770    0.802926    0.812859    5000        82.389289   0.033064    0.029081    0.284999    121.264900 
[37m[36mINFO[0m[0m 02/11 09:02:52 | Cumulative gradient change saved at train_output/OfficeHome/CORAL/[3]/250211_07-47-26_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/11 09:02:53 | ---
[37m[36mINFO[0m[0m 02/11 09:02:53 | test-domain validation(oracle) = 80.293%
[37m[36mINFO[0m[0m 02/11 09:02:53 | training-domain validation(iid) = 80.752%
[37m[36mINFO[0m[0m 02/11 09:02:53 | last = 80.293%
[37m[36mINFO[0m[0m 02/11 09:02:53 | last (inD) = 81.532%
[37m[36mINFO[0m[0m 02/11 09:02:53 | training-domain validation (iid, inD) = 82.188%
[37m[36mINFO[0m[0m 02/11 09:02:53 | === Summary ===
[37m[36mINFO[0m[0m 02/11 09:02:53 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 3 --dataset OfficeHome --trial_seed 2 --hparams_seed 0
[37m[36mINFO[0m[0m 02/11 09:02:53 | Unique name: 250211_07-47-26_resnet50_GENIE
[37m[36mINFO[0m[0m 02/11 09:02:53 | Out path: train_output/OfficeHome/CORAL/[3]/250211_07-47-26_resnet50_GENIE
[37m[36mINFO[0m[0m 02/11 09:02:53 | Algorithm: CORAL
[37m[36mINFO[0m[0m 02/11 09:02:53 | Dataset: OfficeHome
