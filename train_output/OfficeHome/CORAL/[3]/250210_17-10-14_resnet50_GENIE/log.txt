[37m[36mINFO[0m[0m 02/10 17:10:14 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 3 --dataset OfficeHome --trial_seed 0 --hparams_seed 4
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: OfficeHome
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 4
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/OfficeHome/CORAL/[3]/250210_17-10-14_resnet50_GENIE
	out_root: train_output/OfficeHome/CORAL/[3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [3]
	trial_seed: 0
	unique_name: 250210_17-10-14_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.5
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 2.0793009436922532e-05
	batch_size: 30
	weight_decay: 0.0007980067844361917
	mmd_gamma: 0.10537155511080055
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[OfficeHome] #envs=4, #classes=65
	env0: A (#2427)
	env1: C (#4365)
	env2: P (#4439)
	env3: R (#4357)

[37m[36mINFO[0m[0m 02/10 17:10:14 | n_steps = 5001
[37m[36mINFO[0m[0m 02/10 17:10:14 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/10 17:10:14 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/10 17:10:14 | 
[37m[36mINFO[0m[0m 02/10 17:10:14 | Testenv name escaping te_R -> te_R
[37m[36mINFO[0m[0m 02/10 17:10:14 | Test envs = [3], name = te_R
[37m[36mINFO[0m[0m 02/10 17:10:14 | Train environments: [0, 1, 2], Test environments: [3]
[37m[36mINFO[0m[0m 02/10 17:10:14 | Batch sizes for each domain: [30, 30, 30, 0] (total=90)
[37m[36mINFO[0m[0m 02/10 17:10:14 | steps-per-epoch for each domain: 64.73, 116.40, 118.40 -> min = 64.73
[37m[36mINFO[0m[0m 02/10 17:10:16 | # of params = 23641217
[37m[36mINFO[0m[0m 02/10 17:12:29 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 02/10 17:12:29 | 0.020080    0.029851    0.017163    0.011312    4.219672    0.023687    0.012371    0.012600    0.009164    0.015203    0.012401    0.020080    0.029851    0           0.000000    4.347947    0.081246    1.615116    131.548320 
[37m[36mINFO[0m[0m 02/10 17:15:21 | 0.724613    0.708381    0.745042    0.711671    1.087611    0.725026    0.705155    0.697881    0.663230    0.812218    0.766629    0.724613    0.708381    200         3.089598    2.319133    0.559292    0.256543    121.366330 
[37m[36mINFO[0m[0m 02/10 17:18:23 | 0.766781    0.777268    0.850604    0.767585    0.889791    0.865088    0.752577    0.804124    0.714777    0.882601    0.835400    0.766781    0.777268    400         6.179197    0.826901    0.623720    0.266682    128.192494 
[37m[36mINFO[0m[0m 02/10 17:21:23 | 0.777969    0.781860    0.893498    0.781109    0.793755    0.915551    0.754639    0.851375    0.726231    0.913570    0.862458    0.777969    0.781860    600         9.268795    0.565325    0.562135    0.260946    128.090345 
[37m[36mINFO[0m[0m 02/10 17:24:19 | 0.789443    0.781860    0.930328    0.801879    0.760078    0.952111    0.779381    0.894616    0.749141    0.944257    0.877114    0.789443    0.781860    800         12.358393   0.421333    0.512248    0.279064    119.958300 
[37m[36mINFO[0m[0m 02/10 17:27:25 | 0.784854    0.777268    0.944470    0.801903    0.742344    0.968074    0.769072    0.911226    0.764032    0.954110    0.872604    0.784854    0.777268    1000        15.447992   0.306452    0.496679    0.295452    126.614129 
[37m[36mINFO[0m[0m 02/10 17:30:28 | 0.781698    0.772675    0.954471    0.804961    0.745216    0.974768    0.767010    0.924399    0.761741    0.964245    0.886133    0.781698    0.772675    1200        18.537590   0.237747    0.459063    0.295166    123.741707 
[37m[36mINFO[0m[0m 02/10 17:33:33 | 0.794894    0.772675    0.963293    0.811095    0.761330    0.983522    0.787629    0.939576    0.764032    0.966779    0.881623    0.794894    0.772675    1400        21.627188   0.194111    0.423053    0.276318    130.045789 
[37m[36mINFO[0m[0m 02/10 17:36:30 | 0.793746    0.784156    0.971077    0.820192    0.729153    0.985582    0.787629    0.950172    0.778923    0.977477    0.894025    0.793746    0.784156    1600        24.716787   0.155343    0.398525    0.267448    123.323577 
[37m[36mINFO[0m[0m 02/10 17:39:26 | 0.798049    0.777268    0.976376    0.810002    0.739110    0.986097    0.775258    0.960767    0.768614    0.982264    0.886133    0.798049    0.777268    1800        27.806385   0.123887    0.372375    0.239958    128.831379 
[37m[36mINFO[0m[0m 02/10 17:42:21 | 0.792886    0.791045    0.981119    0.806648    0.736327    0.993821    0.762887    0.962486    0.772050    0.987050    0.885006    0.792886    0.791045    2000        30.895984   0.117259    0.339379    0.276876    119.188972 
[37m[36mINFO[0m[0m 02/10 17:45:21 | 0.791738    0.791045    0.983325    0.811951    0.726911    0.990731    0.773196    0.970504    0.769759    0.988739    0.892897    0.791738    0.791045    2200        33.985582   0.093517    0.321786    0.296217    120.654693 
[37m[36mINFO[0m[0m 02/10 17:48:17 | 0.800344    0.791045    0.983337    0.818024    0.740606    0.992791    0.773196    0.967354    0.781214    0.989865    0.899662    0.800344    0.791045    2400        37.075180   0.089131    0.307529    0.236526    128.837658 
[37m[36mINFO[0m[0m 02/10 17:51:14 | 0.799771    0.793341    0.986248    0.813279    0.772048    0.993821    0.779381    0.973368    0.773196    0.991554    0.887260    0.799771    0.793341    2600        40.164779   0.077278    0.282220    0.263776    124.594219 
[37m[36mINFO[0m[0m 02/10 17:54:04 | 0.804073    0.791045    0.987456    0.820040    0.716891    0.994336    0.791753    0.974227    0.774341    0.993806    0.894025    0.804073    0.791045    2800        43.254377   0.069343    0.275459    0.226284    124.466650 
[37m[36mINFO[0m[0m 02/10 17:57:05 | 0.790017    0.763490    0.987775    0.809971    0.774607    0.993821    0.764948    0.977950    0.773196    0.991554    0.891770    0.790017    0.763490    3000        46.343975   0.062308    0.260076    0.291928    122.892223 
[37m[36mINFO[0m[0m 02/10 18:00:09 | 0.793460    0.785304    0.987841    0.818653    0.738799    0.994336    0.777320    0.975945    0.782360    0.993243    0.896280    0.793460    0.785304    3200        49.433574   0.056498    0.248818    0.297562    123.605132 
[37m[36mINFO[0m[0m 02/10 18:03:10 | 0.797476    0.784156    0.989104    0.817284    0.727685    0.996395    0.783505    0.978236    0.773196    0.992680    0.895152    0.797476    0.784156    3400        52.523172   0.053670    0.236404    0.297851    121.319294 
[37m[36mINFO[0m[0m 02/10 18:06:23 | 0.806081    0.796785    0.989308    0.813225    0.756626    0.995881    0.769072    0.978236    0.773196    0.993806    0.897407    0.806081    0.796785    3600        55.612770   0.053011    0.232226    0.301903    132.678478 
[37m[36mINFO[0m[0m 02/10 18:09:08 | 0.795754    0.796785    0.989078    0.814300    0.731990    0.991761    0.771134    0.981386    0.775487    0.994088    0.896280    0.795754    0.796785    3800        58.702369   0.050211    0.213629    0.228700    119.214361 
[37m[36mINFO[0m[0m 02/10 18:12:08 | 0.796041    0.788749    0.991220    0.822359    0.745501    0.995366    0.779381    0.981672    0.784651    0.996622    0.903044    0.796041    0.788749    4000        61.791967   0.043753    0.211763    0.275802    125.516001 
[37m[36mINFO[0m[0m 02/10 18:15:04 | 0.791452    0.784156    0.991581    0.824820    0.739989    0.995881    0.795876    0.981959    0.778923    0.996903    0.899662    0.791452    0.784156    4200        64.881565   0.040477    0.203470    0.266354    122.396172 
[37m[36mINFO[0m[0m 02/10 18:18:05 | 0.794894    0.789897    0.990902    0.822323    0.761153    0.993821    0.779381    0.983391    0.777778    0.995495    0.909808    0.794894    0.789897    4400        67.971164   0.043076    0.194217    0.275715    126.215533 
[37m[36mINFO[0m[0m 02/10 18:21:01 | 0.791165    0.796785    0.991689    0.826171    0.744506    0.995881    0.789691    0.984536    0.784651    0.994651    0.904171    0.791165    0.796785    4600        71.060762   0.039529    0.192386    0.255182    125.032315 
[37m[36mINFO[0m[0m 02/10 18:24:05 | 0.794607    0.783008    0.991398    0.815663    0.773530    0.995881    0.775258    0.982818    0.773196    0.995495    0.898534    0.794607    0.783008    4800        74.150360   0.039335    0.186930    0.270873    129.541469 
[37m[36mINFO[0m[0m 02/10 18:27:07 | 0.791738    0.783008    0.991493    0.817865    0.766273    0.995881    0.777320    0.983104    0.775487    0.995495    0.900789    0.791738    0.783008    5000        77.239959   0.036967    0.184427    0.267475    128.059284 
[37m[36mINFO[0m[0m 02/10 18:27:07 | Cumulative gradient change saved at train_output/OfficeHome/CORAL/[3]/250210_17-10-14_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/10 18:27:08 | ---
[37m[36mINFO[0m[0m 02/10 18:27:08 | test-domain validation(oracle) = 80.608%
[37m[36mINFO[0m[0m 02/10 18:27:08 | training-domain validation(iid) = 79.116%
[37m[36mINFO[0m[0m 02/10 18:27:08 | last = 79.174%
[37m[36mINFO[0m[0m 02/10 18:27:08 | last (inD) = 81.787%
[37m[36mINFO[0m[0m 02/10 18:27:08 | training-domain validation (iid, inD) = 82.617%
[37m[36mINFO[0m[0m 02/10 18:27:08 | === Summary ===
[37m[36mINFO[0m[0m 02/10 18:27:08 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 3 --dataset OfficeHome --trial_seed 0 --hparams_seed 4
[37m[36mINFO[0m[0m 02/10 18:27:08 | Unique name: 250210_17-10-14_resnet50_GENIE
[37m[36mINFO[0m[0m 02/10 18:27:08 | Out path: train_output/OfficeHome/CORAL/[3]/250210_17-10-14_resnet50_GENIE
[37m[36mINFO[0m[0m 02/10 18:27:08 | Algorithm: CORAL
[37m[36mINFO[0m[0m 02/10 18:27:08 | Dataset: OfficeHome
