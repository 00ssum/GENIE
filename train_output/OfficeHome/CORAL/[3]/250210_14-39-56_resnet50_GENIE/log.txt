[37m[36mINFO[0m[0m 02/10 14:39:56 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 3 --dataset OfficeHome --trial_seed 0 --hparams_seed 2
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: OfficeHome
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 2
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/OfficeHome/CORAL/[3]/250210_14-39-56_resnet50_GENIE
	out_root: train_output/OfficeHome/CORAL/[3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [3]
	trial_seed: 0
	unique_name: 250210_14-39-56_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 1.9041073434446342e-05
	batch_size: 9
	weight_decay: 0.0006566989842279891
	mmd_gamma: 1.5832433896458313
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[OfficeHome] #envs=4, #classes=65
	env0: A (#2427)
	env1: C (#4365)
	env2: P (#4439)
	env3: R (#4357)

[37m[36mINFO[0m[0m 02/10 14:39:56 | n_steps = 5001
[37m[36mINFO[0m[0m 02/10 14:39:56 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/10 14:39:56 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/10 14:39:56 | 
[37m[36mINFO[0m[0m 02/10 14:39:56 | Testenv name escaping te_R -> te_R
[37m[36mINFO[0m[0m 02/10 14:39:56 | Test envs = [3], name = te_R
[37m[36mINFO[0m[0m 02/10 14:39:56 | Train environments: [0, 1, 2], Test environments: [3]
[37m[36mINFO[0m[0m 02/10 14:39:56 | Batch sizes for each domain: [9, 9, 9, 0] (total=27)
[37m[36mINFO[0m[0m 02/10 14:39:56 | steps-per-epoch for each domain: 215.78, 388.00, 394.67 -> min = 215.78
[37m[36mINFO[0m[0m 02/10 14:39:57 | # of params = 23641217
[37m[36mINFO[0m[0m 02/10 14:42:01 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 02/10 14:42:01 | 0.027252    0.033295    0.026108    0.022248    4.215288    0.027806    0.014433    0.024055    0.028637    0.026464    0.023675    0.027252    0.033295    0           0.000000    4.371908    0.054630    1.010291    122.775967 
[37m[36mINFO[0m[0m 02/10 14:44:45 | 0.599254    0.588978    0.599565    0.579124    1.660708    0.587539    0.558763    0.550401    0.530355    0.660755    0.648253    0.599254    0.588978    200         0.926880    2.938896    0.100843    0.202343    123.744327 
[37m[36mINFO[0m[0m 02/10 14:47:26 | 0.711704    0.712974    0.721372    0.676172    1.218455    0.712152    0.668041    0.672967    0.624284    0.778998    0.736189    0.711704    0.712974    400         1.853759    1.318350    0.134429    0.223528    115.542180 
[37m[36mINFO[0m[0m 02/10 14:50:09 | 0.716294    0.723307    0.761363    0.707727    1.137144    0.748198    0.674227    0.724800    0.658648    0.811092    0.790304    0.716294    0.723307    600         2.780639    1.013195    0.114399    0.195915    123.670099 
[37m[36mINFO[0m[0m 02/10 14:52:50 | 0.744406    0.742824    0.792734    0.715088    1.078616    0.796087    0.692784    0.744559    0.667812    0.837556    0.784667    0.744406    0.742824    800         3.707518    0.836424    0.102327    0.205234    119.968444 
[37m[36mINFO[0m[0m 02/10 14:55:25 | 0.755881    0.745121    0.846340    0.751058    0.938253    0.851699    0.727835    0.806128    0.712486    0.881194    0.812852    0.755881    0.745121    1000        4.634398    0.658529    0.096657    0.193015    116.886842 
[37m[36mINFO[0m[0m 02/10 14:58:05 | 0.764200    0.764638    0.870266    0.757281    0.908381    0.877446    0.721649    0.831042    0.715922    0.902309    0.834273    0.764200    0.764638    1200        5.561277    0.623886    0.088547    0.195171    120.563046 
[37m[36mINFO[0m[0m 02/10 15:00:41 | 0.760470    0.753157    0.884399    0.769633    0.855846    0.904222    0.746392    0.839347    0.710195    0.909628    0.852311    0.760470    0.753157    1400        6.488157    0.496256    0.086381    0.186174    118.786936 
[37m[36mINFO[0m[0m 02/10 15:03:19 | 0.754446    0.729047    0.894459    0.767991    0.849353    0.921730    0.742268    0.856243    0.730813    0.905405    0.830891    0.754446    0.729047    1600        7.415036    0.401168    0.080336    0.190974    120.017115 
[37m[36mINFO[0m[0m 02/10 15:05:55 | 0.748709    0.734788    0.909766    0.779371    0.833401    0.924305    0.740206    0.872279    0.738832    0.932714    0.859076    0.748709    0.734788    1800        8.341916    0.391056    0.077308    0.189228    117.883269 
[37m[36mINFO[0m[0m 02/10 15:08:37 | 0.753586    0.753157    0.913299    0.777223    0.858616    0.934604    0.748454    0.873425    0.736541    0.931869    0.846674    0.753586    0.753157    2000        9.268795    0.328725    0.074209    0.208524    120.218849 
[37m[36mINFO[0m[0m 02/10 15:11:13 | 0.769937    0.769231    0.928677    0.786067    0.831317    0.947477    0.754639    0.892325    0.739977    0.946227    0.863585    0.769937    0.769231    2200        10.195675   0.300956    0.070800    0.191870    117.525751 
[37m[36mINFO[0m[0m 02/10 15:13:46 | 0.757028    0.725603    0.928238    0.785539    0.837392    0.946962    0.748454    0.894903    0.745704    0.942849    0.862458    0.757028    0.725603    2400        11.122554   0.268903    0.069535    0.174185    118.956416 
[37m[36mINFO[0m[0m 02/10 15:16:21 | 0.752438    0.750861    0.937815    0.777715    0.830824    0.961380    0.734021    0.908935    0.744559    0.943131    0.854566    0.752438    0.750861    2600        12.049434   0.241262    0.065753    0.197731    115.150792 
[37m[36mINFO[0m[0m 02/10 15:18:57 | 0.760757    0.763490    0.945077    0.776921    0.825642    0.962410    0.713402    0.920962    0.757159    0.951858    0.860203    0.760757    0.763490    2800        12.976313   0.225283    0.063177    0.181922    119.431446 
[37m[36mINFO[0m[0m 02/10 15:21:39 | 0.749570    0.739380    0.938841    0.780396    0.821862    0.955716    0.756701    0.909794    0.745704    0.951014    0.838782    0.749570    0.739380    3000        13.903193   0.210245    0.060879    0.193504    123.730550 
[37m[36mINFO[0m[0m 02/10 15:24:31 | 0.761905    0.770379    0.947973    0.794813    0.812966    0.963440    0.764948    0.924399    0.749141    0.956081    0.870349    0.761905    0.770379    3200        14.830072   0.181412    0.059292    0.231051    125.823422 
[37m[36mINFO[0m[0m 02/10 15:27:28 | 0.764773    0.768083    0.959008    0.804547    0.787747    0.970134    0.781443    0.937858    0.768614    0.969032    0.863585    0.764773    0.768083    3400        15.756952   0.178571    0.057618    0.236849    129.118994 
[37m[36mINFO[0m[0m 02/10 15:30:21 | 0.769650    0.763490    0.964533    0.795559    0.786781    0.983007    0.754639    0.940435    0.758305    0.970158    0.873732    0.769650    0.763490    3600        16.683831   0.148462    0.054819    0.219144    129.576643 
[37m[36mINFO[0m[0m 02/10 15:33:25 | 0.775961    0.768083    0.970354    0.804035    0.778737    0.985067    0.752577    0.952176    0.785796    0.973818    0.873732    0.775961    0.768083    3800        17.610711   0.135523    0.053567    0.222654    139.165185 
[37m[36mINFO[0m[0m 02/10 15:36:29 | 0.773092    0.773823    0.968785    0.796628    0.790923    0.986097    0.736082    0.945876    0.780069    0.974381    0.873732    0.773092    0.773823    4000        18.537590   0.133474    0.051296    0.250846    133.524748 
[37m[36mINFO[0m[0m 02/10 15:39:27 | 0.768503    0.771527    0.970736    0.797425    0.781122    0.981462    0.734021    0.950172    0.776632    0.980574    0.881623    0.768503    0.771527    4200        19.464470   0.130272    0.050234    0.244247    129.564752 
[37m[36mINFO[0m[0m 02/10 15:42:29 | 0.767929    0.778416    0.973292    0.796893    0.809193    0.984552    0.760825    0.954467    0.762887    0.980856    0.866967    0.767929    0.778416    4400        20.391349   0.125983    0.048783    0.242998    133.297642 
[37m[36mINFO[0m[0m 02/10 15:45:31 | 0.773666    0.785304    0.980069    0.819670    0.734288    0.993821    0.791753    0.959336    0.775487    0.987050    0.891770    0.773666    0.785304    4600        21.318229   0.114791    0.046925    0.241658    133.834620 
[37m[36mINFO[0m[0m 02/10 15:48:34 | 0.788296    0.795637    0.980500    0.813420    0.759666    0.990216    0.775258    0.965922    0.775487    0.985360    0.889515    0.788296    0.795637    4800        22.245108   0.088144    0.046349    0.274390    127.524919 
[37m[36mINFO[0m[0m 02/10 15:51:36 | 0.790304    0.793341    0.981980    0.810900    0.757021    0.991246    0.781443    0.967927    0.761741    0.986768    0.889515    0.790304    0.793341    5000        23.171988   0.098987    0.044556    0.253427    131.531364 
[37m[36mINFO[0m[0m 02/10 15:51:36 | Cumulative gradient change saved at train_output/OfficeHome/CORAL/[3]/250210_14-39-56_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/10 15:51:37 | ---
[37m[36mINFO[0m[0m 02/10 15:51:37 | test-domain validation(oracle) = 78.830%
[37m[36mINFO[0m[0m 02/10 15:51:37 | training-domain validation(iid) = 77.367%
[37m[36mINFO[0m[0m 02/10 15:51:37 | last = 79.030%
[37m[36mINFO[0m[0m 02/10 15:51:37 | last (inD) = 81.090%
[37m[36mINFO[0m[0m 02/10 15:51:37 | training-domain validation (iid, inD) = 81.967%
[37m[36mINFO[0m[0m 02/10 15:51:37 | === Summary ===
[37m[36mINFO[0m[0m 02/10 15:51:37 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 3 --dataset OfficeHome --trial_seed 0 --hparams_seed 2
[37m[36mINFO[0m[0m 02/10 15:51:37 | Unique name: 250210_14-39-56_resnet50_GENIE
[37m[36mINFO[0m[0m 02/10 15:51:37 | Out path: train_output/OfficeHome/CORAL/[3]/250210_14-39-56_resnet50_GENIE
[37m[36mINFO[0m[0m 02/10 15:51:37 | Algorithm: CORAL
[37m[36mINFO[0m[0m 02/10 15:51:37 | Dataset: OfficeHome
