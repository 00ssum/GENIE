[37m[36mINFO[0m[0m 02/10 15:51:42 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 3 --dataset OfficeHome --trial_seed 0 --hparams_seed 3
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: OfficeHome
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 3
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/OfficeHome/CORAL/[3]/250210_15-51-42_resnet50_GENIE
	out_root: train_output/OfficeHome/CORAL/[3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [3]
	trial_seed: 0
	unique_name: 250210_15-51-42_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.5
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 6.166705009429313e-05
	batch_size: 14
	weight_decay: 3.4412812120883604e-06
	mmd_gamma: 0.7404937726102715
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[OfficeHome] #envs=4, #classes=65
	env0: A (#2427)
	env1: C (#4365)
	env2: P (#4439)
	env3: R (#4357)

[37m[36mINFO[0m[0m 02/10 15:51:42 | n_steps = 5001
[37m[36mINFO[0m[0m 02/10 15:51:42 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/10 15:51:42 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/10 15:51:42 | 
[37m[36mINFO[0m[0m 02/10 15:51:42 | Testenv name escaping te_R -> te_R
[37m[36mINFO[0m[0m 02/10 15:51:42 | Test envs = [3], name = te_R
[37m[36mINFO[0m[0m 02/10 15:51:42 | Train environments: [0, 1, 2], Test environments: [3]
[37m[36mINFO[0m[0m 02/10 15:51:42 | Batch sizes for each domain: [14, 14, 14, 0] (total=42)
[37m[36mINFO[0m[0m 02/10 15:51:42 | steps-per-epoch for each domain: 138.71, 249.43, 253.71 -> min = 138.71
[37m[36mINFO[0m[0m 02/10 15:51:44 | # of params = 23641217
[37m[36mINFO[0m[0m 02/10 15:54:03 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 02/10 15:54:03 | 0.026678    0.041332    0.020631    0.017638    4.210774    0.024717    0.016495    0.017468    0.021764    0.019707    0.014656    0.026678    0.041332    0           0.000000    4.364376    0.153952    2.299362    136.478489 
[37m[36mINFO[0m[0m 02/10 15:57:11 | 0.583477    0.588978    0.562925    0.556795    1.849571    0.537590    0.548454    0.516896    0.510882    0.634291    0.611048    0.583477    0.588978    200         1.441813    3.303984    0.144423    0.250870    138.149119 
[37m[36mINFO[0m[0m 02/10 16:00:11 | 0.723465    0.725603    0.734533    0.701653    1.214441    0.736354    0.694845    0.677549    0.626575    0.789696    0.783540    0.723465    0.725603    400         2.883625    1.431644    0.270984    0.259404    127.328388 
[37m[36mINFO[0m[0m 02/10 16:03:14 | 0.730350    0.721010    0.794640    0.725700    1.083097    0.809990    0.713402    0.743414    0.664376    0.830518    0.799324    0.730350    0.721010    600         4.325438    1.010577    0.231166    0.291742    125.350748 
[37m[36mINFO[0m[0m 02/10 16:06:33 | 0.752725    0.733639    0.842022    0.762498    0.931990    0.858908    0.756701    0.795819    0.701031    0.871340    0.829763    0.752725    0.733639    800         5.767250    0.764118    0.200488    0.264567    146.107143 
[37m[36mINFO[0m[0m 02/10 16:09:37 | 0.760757    0.747417    0.862561    0.752907    0.921461    0.873326    0.727835    0.823310    0.706758    0.891047    0.824126    0.760757    0.747417    1000        7.209063    0.668059    0.184075    0.261965    131.136113 
[37m[36mINFO[0m[0m 02/10 16:12:43 | 0.769076    0.770379    0.889479    0.769028    0.873207    0.903708    0.731959    0.855384    0.723940    0.909347    0.851184    0.769076    0.770379    1200        8.650875    0.566676    0.171190    0.261735    133.593953 
[37m[36mINFO[0m[0m 02/10 16:15:47 | 0.749857    0.753157    0.891164    0.770469    0.870525    0.911432    0.736082    0.847365    0.736541    0.914696    0.838782    0.749857    0.753157    1400        10.092688   0.473424    0.159805    0.286971    126.897459 
[37m[36mINFO[0m[0m 02/10 16:18:57 | 0.769076    0.749713    0.915741    0.787608    0.796532    0.941298    0.767010    0.877434    0.749141    0.928491    0.846674    0.769076    0.749713    1600        11.534501   0.403744    0.148181    0.292316    131.431040 
[37m[36mINFO[0m[0m 02/10 16:22:04 | 0.768216    0.756602    0.923350    0.788688    0.810122    0.940783    0.746392    0.892612    0.760596    0.936655    0.859076    0.768216    0.756602    1800        12.976313   0.333056    0.143282    0.260062    135.120836 
[37m[36mINFO[0m[0m 02/10 16:25:15 | 0.760757    0.778416    0.936276    0.799600    0.786892    0.959320    0.769072    0.907503    0.754868    0.942005    0.874859    0.760757    0.778416    2000        14.418126   0.292871    0.137190    0.267761    137.345032 
[37m[36mINFO[0m[0m 02/10 16:28:17 | 0.781985    0.774971    0.949370    0.795619    0.779376    0.969619    0.754639    0.923253    0.769759    0.955236    0.862458    0.781985    0.774971    2200        15.859938   0.252923    0.129105    0.252596    131.462735 
[37m[36mINFO[0m[0m 02/10 16:31:29 | 0.783133    0.784156    0.958011    0.800757    0.769685    0.981977    0.779381    0.926403    0.750286    0.965653    0.872604    0.783133    0.784156    2400        17.301751   0.230566    0.122509    0.307501    130.125117 
[37m[36mINFO[0m[0m 02/10 16:34:38 | 0.773379    0.779564    0.961958    0.809344    0.735963    0.977858    0.762887    0.937858    0.784651    0.970158    0.880496    0.773379    0.779564    2600        18.743563   0.206610    0.118010    0.274095    134.669058 
[37m[36mINFO[0m[0m 02/10 16:37:32 | 0.780264    0.780712    0.962818    0.794883    0.795678    0.980433    0.752577    0.938144    0.760596    0.969876    0.871477    0.780264    0.780712    2800        20.185376   0.177778    0.113676    0.232218    127.087668 
[37m[36mINFO[0m[0m 02/10 16:40:48 | 0.782272    0.791045    0.966783    0.804827    0.755021    0.981462    0.740206    0.948167    0.791523    0.970721    0.882751    0.782272    0.791045    3000        21.627188   0.177943    0.108939    0.313731    133.195925 
[37m[36mINFO[0m[0m 02/10 16:43:59 | 0.781411    0.783008    0.973528    0.806443    0.751727    0.991246    0.758763    0.950172    0.780069    0.979167    0.880496    0.781411    0.783008    3200        23.069001   0.155624    0.102661    0.289951    133.571360 
[37m[36mINFO[0m[0m 02/10 16:46:56 | 0.780264    0.774971    0.971173    0.799670    0.780590    0.986097    0.756701    0.953322    0.766323    0.974099    0.875986    0.780264    0.774971    3400        24.510814   0.146058    0.100412    0.251481    126.025598 
[37m[36mINFO[0m[0m 02/10 16:49:51 | 0.774814    0.785304    0.975597    0.809302    0.734479    0.989701    0.762887    0.959049    0.776632    0.978041    0.888388    0.774814    0.785304    3600        25.952626   0.124461    0.096570    0.235171    127.863503 
[37m[36mINFO[0m[0m 02/10 16:52:47 | 0.779403    0.780712    0.979551    0.825721    0.706144    0.992791    0.804124    0.961627    0.784651    0.984234    0.888388    0.779403    0.780712    3800        27.394439   0.113894    0.092561    0.273661    121.524291 
[37m[36mINFO[0m[0m 02/10 16:55:44 | 0.774527    0.774971    0.979699    0.799793    0.784434    0.991246    0.742268    0.962772    0.775487    0.985079    0.881623    0.774527    0.774971    4000        28.836251   0.112289    0.088542    0.251961    126.459305 
[37m[36mINFO[0m[0m 02/10 16:58:43 | 0.784567    0.794489    0.979408    0.808709    0.769516    0.991246    0.769072    0.961054    0.772050    0.985923    0.885006    0.784567    0.794489    4200        30.278064   0.108928    0.088750    0.265847    126.576514 
[37m[36mINFO[0m[0m 02/10 17:01:36 | 0.771658    0.769231    0.979714    0.799576    0.780199    0.991246    0.738144    0.965349    0.781214    0.982545    0.879369    0.771658    0.769231    4400        31.719876   0.096849    0.083157    0.216973    129.300743 
[37m[36mINFO[0m[0m 02/10 17:04:23 | 0.788009    0.796785    0.983359    0.806065    0.729812    0.992276    0.746392    0.968499    0.777778    0.989302    0.894025    0.788009    0.796785    4600        33.161689   0.085371    0.079888    0.219042    123.175597 
[37m[36mINFO[0m[0m 02/10 17:07:22 | 0.786862    0.802526    0.985854    0.810289    0.783062    0.994336    0.767010    0.973081    0.774341    0.990146    0.889515    0.786862    0.802526    4800        34.603502   0.086395    0.078849    0.253338    128.055663 
[37m[36mINFO[0m[0m 02/10 17:10:08 | 0.779690    0.785304    0.985904    0.810243    0.769748    0.992791    0.769072    0.973368    0.777778    0.991554    0.883878    0.779690    0.785304    5000        36.045314   0.084707    0.076167    0.241074    117.523275 
[37m[36mINFO[0m[0m 02/10 17:10:08 | Cumulative gradient change saved at train_output/OfficeHome/CORAL/[3]/250210_15-51-42_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/10 17:10:09 | ---
[37m[36mINFO[0m[0m 02/10 17:10:09 | test-domain validation(oracle) = 78.686%
[37m[36mINFO[0m[0m 02/10 17:10:09 | training-domain validation(iid) = 77.940%
[37m[36mINFO[0m[0m 02/10 17:10:09 | last = 77.969%
[37m[36mINFO[0m[0m 02/10 17:10:09 | last (inD) = 81.024%
[37m[36mINFO[0m[0m 02/10 17:10:09 | training-domain validation (iid, inD) = 82.572%
[37m[36mINFO[0m[0m 02/10 17:10:09 | === Summary ===
[37m[36mINFO[0m[0m 02/10 17:10:09 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 3 --dataset OfficeHome --trial_seed 0 --hparams_seed 3
[37m[36mINFO[0m[0m 02/10 17:10:09 | Unique name: 250210_15-51-42_resnet50_GENIE
[37m[36mINFO[0m[0m 02/10 17:10:09 | Out path: train_output/OfficeHome/CORAL/[3]/250210_15-51-42_resnet50_GENIE
[37m[36mINFO[0m[0m 02/10 17:10:09 | Algorithm: CORAL
[37m[36mINFO[0m[0m 02/10 17:10:09 | Dataset: OfficeHome
