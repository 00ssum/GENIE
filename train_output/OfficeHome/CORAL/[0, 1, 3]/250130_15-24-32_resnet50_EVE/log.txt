[37m[36mINFO[0m[0m 01/30 15:24:33 | Command :: /jsm0707/Large-scale/train_all.py resnet50_EVE config/resnet50_EVE.yaml --algorithm CORAL --test_envs 0 1 3 --dataset OfficeHome --trial_seed 1 --hparams_seed 15
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_EVE.yaml']
	data_dir: data
	dataset: OfficeHome
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 15
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_EVE
	out_dir: train_output/OfficeHome/CORAL/[0, 1, 3]/250130_15-24-32_resnet50_EVE
	out_root: train_output/OfficeHome/CORAL/[0, 1, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 1, 3]
	trial_seed: 1
	unique_name: 250130_15-24-32_resnet50_EVE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: GENIE
	freeze_bn: False
	pretrained: True
	lr: 1.7812453400894684e-05
	batch_size: 36
	weight_decay: 3.1651536009272826e-06
	mmd_gamma: 3.440541362473826
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[OfficeHome] #envs=4, #classes=65
	env0: A (#2427)
	env1: C (#4365)
	env2: P (#4439)
	env3: R (#4357)

[37m[36mINFO[0m[0m 01/30 15:24:33 | n_steps = 5001
[37m[36mINFO[0m[0m 01/30 15:24:33 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 01/30 15:24:33 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 01/30 15:24:33 | 
[37m[36mINFO[0m[0m 01/30 15:24:33 | Testenv name escaping te_A_C_R -> te_A_C_R
[37m[36mINFO[0m[0m 01/30 15:24:33 | Test envs = [0, 1, 3], name = te_A_C_R
[37m[36mINFO[0m[0m 01/30 15:24:33 | Train environments: [2], Test environments: [0, 1, 3]
[37m[36mINFO[0m[0m 01/30 15:24:33 | Batch sizes for each domain: [0, 0, 36, 0] (total=36)
[37m[36mINFO[0m[0m 01/30 15:24:33 | steps-per-epoch for each domain: 98.67 -> min = 98.67
[37m[36mINFO[0m[0m 01/30 15:24:35 | # of params = 23641217
[37m[36mINFO[0m[0m 01/30 15:27:14 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 01/30 15:27:14 | 0.020529    0.018035    0.029842    0.032694    4.222780    0.020597    0.018557    0.018041    0.018328    0.029842    0.032694    0.022949    0.017222    0           0.000000    4.226127    0.000000    2.325714    156.826418 
[37m[36mINFO[0m[0m 01/30 15:30:58 | 0.474894    0.476293    0.875845    0.827508    0.603181    0.417611    0.430928    0.392325    0.391753    0.875845    0.827508    0.614745    0.606200    200         2.027027    1.318743    0.000000    0.281058    167.079823 
[37m[36mINFO[0m[0m 01/30 15:34:22 | 0.491753    0.503270    0.927083    0.837655    0.630962    0.421730    0.455670    0.398912    0.421535    0.927083    0.837655    0.654618    0.632606    400         4.054054    0.316337    0.000000    0.245557    154.848809 
[37m[36mINFO[0m[0m 01/30 15:37:53 | 0.511706    0.526059    0.958333    0.874859    0.431950    0.434604    0.470103    0.434422    0.434135    0.958333    0.874859    0.666093    0.673938    600         6.081081    0.205804    0.000000    0.301967    149.370717 
[37m[36mINFO[0m[0m 01/30 15:41:37 | 0.509442    0.514073    0.966498    0.872604    0.484469    0.469619    0.484536    0.392039    0.379152    0.966498    0.872604    0.666667    0.678530    800         8.108108    0.147632    0.000000    0.236039    177.000684 
[37m[36mINFO[0m[0m 01/30 15:45:07 | 0.495542    0.499778    0.984234    0.887260    0.432901    0.425335    0.447423    0.390034    0.392898    0.984234    0.887260    0.671256    0.659013    1000        10.135135   0.100180    0.000000    0.212465    167.215978 
[37m[36mINFO[0m[0m 01/30 15:48:29 | 0.480943    0.481498    0.968750    0.864713    0.561275    0.401648    0.424742    0.406644    0.398625    0.968750    0.864713    0.634538    0.621125    1200        12.162162   0.063895    0.000000    0.197303    162.212822 
[37m[36mINFO[0m[0m 01/30 15:51:46 | 0.490659    0.488981    0.984234    0.878241    0.572942    0.415036    0.459794    0.416667    0.386025    0.984234    0.878241    0.640275    0.621125    1400        14.189189   0.065689    0.000000    0.246375    147.665346 
[37m[36mINFO[0m[0m 01/30 15:55:16 | 0.495469    0.495259    0.981137    0.880496    0.519210    0.442327    0.455670    0.389748    0.388316    0.981137    0.880496    0.654332    0.641791    1600        16.216216   0.046839    0.000000    0.222909    165.323538 
[37m[36mINFO[0m[0m 01/30 15:58:39 | 0.493896    0.489680    0.989020    0.899662    0.435902    0.433574    0.461856    0.378866    0.371134    0.989020    0.899662    0.669248    0.636051    1800        18.243243   0.063910    0.000000    0.215915    160.326796 
[37m[36mINFO[0m[0m 01/30 16:02:09 | 0.494480    0.490907    0.989020    0.892897    0.525875    0.435633    0.449485    0.391466    0.380298    0.989020    0.892897    0.656340    0.642939    2000        20.270270   0.033448    0.000000    0.277795    153.877341 
[37m[36mINFO[0m[0m 01/30 16:05:37 | 0.475205    0.490523    0.987050    0.875986    0.592085    0.378991    0.428866    0.412085    0.403207    0.987050    0.875986    0.634538    0.639495    2200        22.297297   0.024234    0.000000    0.229107    162.088548 
[37m[36mINFO[0m[0m 01/30 16:09:05 | 0.492146    0.492130    0.989020    0.894025    0.521108    0.406282    0.437113    0.406930    0.395189    0.989020    0.894025    0.663224    0.644087    2400        24.324324   0.024635    0.000000    0.243160    159.885140 
[37m[36mINFO[0m[0m 01/30 16:12:35 | 0.475059    0.486705    0.987050    0.886133    0.602235    0.416066    0.449485    0.373425    0.369989    0.987050    0.886133    0.635686    0.640643    2600        26.351351   0.030638    0.000000    0.224600    164.856086 
[37m[36mINFO[0m[0m 01/30 16:15:58 | 0.499925    0.509545    0.991554    0.907554    0.437545    0.433059    0.461856    0.404066    0.418099    0.991554    0.907554    0.662651    0.648680    2800        28.378378   0.038740    0.000000    0.235782    155.850897 
[37m[36mINFO[0m[0m 01/30 16:19:24 | 0.491280    0.507253    0.992962    0.891770    0.514961    0.408857    0.451546    0.411798    0.422680    0.992962    0.891770    0.653184    0.647532    3000        30.405405   0.020878    0.000000    0.212579    163.861951 
[37m[36mINFO[0m[0m 01/30 16:22:53 | 0.506329    0.524994    0.994369    0.905299    0.482976    0.430484    0.478351    0.413803    0.416953    0.994369    0.905299    0.674699    0.679679    3200        32.432432   0.015516    0.000000    0.209826    166.767579 
[37m[36mINFO[0m[0m 01/30 16:26:15 | 0.491284    0.494653    0.994651    0.906426    0.434168    0.406282    0.430928    0.408076    0.404353    0.994651    0.906426    0.659495    0.648680    3400        34.459459   0.027716    0.000000    0.290158    143.248203 
[37m[36mINFO[0m[0m 01/30 16:29:36 | 0.480453    0.477299    0.986486    0.890643    0.619266    0.412461    0.424742    0.376575    0.383734    0.986486    0.890643    0.652324    0.623421    3600        36.486486   0.018391    0.000000    0.206490    159.809168 
[37m[36mINFO[0m[0m 01/30 16:32:44 | 0.505337    0.506125    0.995777    0.905299    0.527246    0.431514    0.441237    0.406644    0.406644    0.995777    0.905299    0.677854    0.670494    3800        38.513514   0.012921    0.000000    0.244499    139.680158 
[37m[36mINFO[0m[0m 01/30 16:35:42 | 0.503861    0.509933    0.994369    0.901917    0.559227    0.432544    0.461856    0.411798    0.410080    0.994369    0.901917    0.667240    0.657865    4000        40.540541   0.014147    0.000000    0.209928    135.239499 
[37m[36mINFO[0m[0m 01/30 16:38:27 | 0.502430    0.509028    0.994088    0.895152    0.532320    0.419670    0.445361    0.425544    0.410080    0.994088    0.895152    0.662077    0.671642    4200        42.567568   0.021835    0.000000    0.184124    128.161179 
[37m[36mINFO[0m[0m 01/30 16:41:31 | 0.513444    0.514140    0.994088    0.905299    0.474619    0.452111    0.492784    0.410080    0.383734    0.994088    0.905299    0.678141    0.665901    4400        44.594595   0.019100    0.000000    0.212302    141.702682 
[37m[36mINFO[0m[0m 01/30 16:44:07 | 0.511806    0.513227    0.996059    0.913191    0.489280    0.450051    0.465979    0.401203    0.403207    0.996059    0.913191    0.684165    0.670494    4600        46.621622   0.014429    0.000000    0.188206    118.382811 
[37m[36mINFO[0m[0m 01/30 16:47:14 | 0.489217    0.491741    0.994932    0.908681    0.544231    0.415551    0.457732    0.396621    0.382589    0.994932    0.908681    0.655479    0.634902    4800        48.648649   0.009948    0.000000    0.200609    147.347320 
[37m[36mINFO[0m[0m 01/30 16:50:24 | 0.503097    0.497484    0.994932    0.908681    0.504724    0.445417    0.447423    0.390034    0.389462    0.994932    0.908681    0.673838    0.655568    5000        50.675676   0.017179    0.000000    0.194531    150.644014 
[37m[36mINFO[0m[0m 01/30 16:50:24 | Cumulative gradient change saved at train_output/OfficeHome/CORAL/[0, 1, 3]/250130_15-24-32_resnet50_EVE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 01/30 16:50:25 | ---
[37m[36mINFO[0m[0m 01/30 16:50:25 | test-domain validation(oracle) = 51.171%
[37m[36mINFO[0m[0m 01/30 16:50:25 | training-domain validation(iid) = 51.181%
[37m[36mINFO[0m[0m 01/30 16:50:25 | last = 50.310%
[37m[36mINFO[0m[0m 01/30 16:50:25 | last (inD) = 90.868%
[37m[36mINFO[0m[0m 01/30 16:50:25 | training-domain validation (iid, inD) = 91.319%
[37m[36mINFO[0m[0m 01/30 16:50:25 | === Summary ===
[37m[36mINFO[0m[0m 01/30 16:50:25 | Command: /jsm0707/Large-scale/train_all.py resnet50_EVE config/resnet50_EVE.yaml --algorithm CORAL --test_envs 0 1 3 --dataset OfficeHome --trial_seed 1 --hparams_seed 15
[37m[36mINFO[0m[0m 01/30 16:50:25 | Unique name: 250130_15-24-32_resnet50_EVE
[37m[36mINFO[0m[0m 01/30 16:50:25 | Out path: train_output/OfficeHome/CORAL/[0, 1, 3]/250130_15-24-32_resnet50_EVE
[37m[36mINFO[0m[0m 01/30 16:50:25 | Algorithm: CORAL
[37m[36mINFO[0m[0m 01/30 16:50:25 | Dataset: OfficeHome
