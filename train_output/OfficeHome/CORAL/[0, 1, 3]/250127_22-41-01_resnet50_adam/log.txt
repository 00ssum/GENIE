[37m[36mINFO[0m[0m 01/27 22:41:01 | Command :: /jsm0707/Large-scale/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm CORAL --test_envs 0 1 3 --dataset OfficeHome
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_adam.yaml']
	data_dir: data
	dataset: OfficeHome
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_adam
	out_dir: train_output/OfficeHome/CORAL/[0, 1, 3]/250127_22-41-01_resnet50_adam
	out_root: train_output/OfficeHome/CORAL/[0, 1, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 1, 3]
	trial_seed: 0
	unique_name: 250127_22-41-01_resnet50_adam
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: adam
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	mmd_gamma: 1.0
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[OfficeHome] #envs=4, #classes=65
	env0: A (#2427)
	env1: C (#4365)
	env2: P (#4439)
	env3: R (#4357)

[37m[36mINFO[0m[0m 01/27 22:41:01 | n_steps = 5001
[37m[36mINFO[0m[0m 01/27 22:41:01 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 01/27 22:41:01 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 01/27 22:41:01 | 
[37m[36mINFO[0m[0m 01/27 22:41:01 | Testenv name escaping te_A_C_R -> te_A_C_R
[37m[36mINFO[0m[0m 01/27 22:41:01 | Test envs = [0, 1, 3], name = te_A_C_R
[37m[36mINFO[0m[0m 01/27 22:41:01 | Train environments: [2], Test environments: [0, 1, 3]
[37m[36mINFO[0m[0m 01/27 22:41:01 | Batch sizes for each domain: [0, 0, 32, 0] (total=32)
[37m[36mINFO[0m[0m 01/27 22:41:01 | steps-per-epoch for each domain: 111.00 -> min = 111.00
[37m[36mINFO[0m[0m 01/27 22:41:02 | # of params = 23641217
[37m[36mINFO[0m[0m 01/27 22:43:12 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 01/27 22:43:12 | 0.020448    0.020095    0.023367    0.023675    4.195304    0.025232    0.024742    0.019187    0.021764    0.023367    0.023675    0.016925    0.013777    0           0.000000    4.328662    0.000000    1.191226    128.839419 
[37m[36mINFO[0m[0m 01/27 22:46:02 | 0.452641    0.437105    0.895552    0.836528    0.587231    0.389804    0.375258    0.355670    0.347079    0.895552    0.836528    0.612450    0.588978    200         1.801802    1.286840    0.000000    0.181716    133.907945 
[37m[36mINFO[0m[0m 01/27 22:48:54 | 0.417151    0.429446    0.900338    0.808343    0.650445    0.377961    0.395876    0.333906    0.333333    0.900338    0.808343    0.539587    0.559127    400         3.603604    0.367479    0.000000    0.172103    136.724749 
[37m[36mINFO[0m[0m 01/27 22:51:44 | 0.456163    0.458126    0.957770    0.864713    0.505788    0.392379    0.395876    0.379725    0.363116    0.957770    0.864713    0.596386    0.615385    600         5.405405    0.231315    0.000000    0.170737    136.401764 
[37m[36mINFO[0m[0m 01/27 22:54:28 | 0.454571    0.459980    0.971284    0.885006    0.463518    0.369207    0.387629    0.357961    0.348225    0.971284    0.885006    0.636546    0.644087    800         7.207207    0.149224    0.000000    0.151407    133.265577 
[37m[36mINFO[0m[0m 01/27 22:57:06 | 0.424936    0.423664    0.949043    0.859076    0.537969    0.359423    0.346392    0.327892    0.336770    0.949043    0.859076    0.587493    0.587830    1000        9.009009    0.140103    0.000000    0.158966    125.701302 
[37m[36mINFO[0m[0m 01/27 22:59:47 | 0.435274    0.434139    0.976914    0.862458    0.555159    0.348610    0.331959    0.359393    0.365407    0.976914    0.862458    0.597820    0.605052    1200        10.810811   0.103064    0.000000    0.183899    123.622645 
[37m[36mINFO[0m[0m 01/27 23:02:23 | 0.429792    0.414886    0.975507    0.868095    0.558866    0.349640    0.325773    0.346793    0.325315    0.975507    0.868095    0.592943    0.593571    1400        12.612613   0.086316    0.000000    0.201922    115.650568 
[37m[36mINFO[0m[0m 01/27 23:05:07 | 0.429410    0.434674    0.979167    0.872604    0.478884    0.354789    0.358763    0.337915    0.340206    0.979167    0.872604    0.595525    0.605052    1600        14.414414   0.101246    0.000000    0.201442    123.520379 
[37m[36mINFO[0m[0m 01/27 23:07:45 | 0.426026    0.426408    0.974944    0.866967    0.587235    0.345520    0.354639    0.350515    0.343643    0.974944    0.866967    0.582042    0.580941    1800        16.216216   0.103397    0.000000    0.162750    125.472987 
[37m[36mINFO[0m[0m 01/27 23:10:21 | 0.391409    0.393307    0.956363    0.848929    0.625967    0.298146    0.298969    0.331042    0.345934    0.956363    0.848929    0.545037    0.535017    2000        18.018018   0.087245    0.000000    0.173352    122.129792 
[37m[36mINFO[0m[0m 01/27 23:13:03 | 0.435770    0.462786    0.977477    0.870349    0.518021    0.355819    0.404124    0.349943    0.365407    0.977477    0.870349    0.601549    0.618829    2200        19.819820   0.086237    0.000000    0.181833    125.536916 
[37m[36mINFO[0m[0m 01/27 23:15:35 | 0.456226    0.458671    0.981700    0.891770    0.553758    0.368177    0.381443    0.375716    0.364261    0.981700    0.891770    0.624785    0.630310    2400        21.621622   0.063077    0.000000    0.153905    121.311214 
[37m[36mINFO[0m[0m 01/27 23:18:15 | 0.441833    0.451330    0.972973    0.873732    0.542517    0.380021    0.383505    0.343070    0.353952    0.972973    0.873732    0.602410    0.616533    2600        23.423423   0.069104    0.000000    0.181586    123.134437 
[37m[36mINFO[0m[0m 01/27 23:20:58 | 0.466624    0.473558    0.990146    0.889515    0.477445    0.393924    0.422680    0.377721    0.373425    0.990146    0.889515    0.628227    0.624569    2800        25.225225   0.041583    0.000000    0.188959    125.513799 
[37m[36mINFO[0m[0m 01/27 23:23:38 | 0.458285    0.441463    0.987894    0.889515    0.515133    0.382080    0.371134    0.364548    0.357388    0.987894    0.889515    0.628227    0.595867    3000        27.027027   0.067627    0.000000    0.157186    127.928576 
[37m[36mINFO[0m[0m 01/27 23:26:26 | 0.433654    0.437350    0.988176    0.881623    0.564912    0.338311    0.338144    0.366552    0.364261    0.988176    0.881623    0.596099    0.609644    3200        28.828829   0.071387    0.000000    0.197377    128.799454 
[37m[36mINFO[0m[0m 01/27 23:29:07 | 0.429189    0.416263    0.982264    0.866967    0.596354    0.330072    0.319588    0.362829    0.333333    0.982264    0.866967    0.594664    0.595867    3400        30.630631   0.090601    0.000000    0.150001    130.137088 
[37m[36mINFO[0m[0m 01/27 23:31:51 | 0.424293    0.425127    0.985360    0.869222    0.611176    0.346035    0.358763    0.337629    0.312715    0.985360    0.869222    0.589214    0.603904    3600        32.432432   0.059278    0.000000    0.184233    127.421573 
[37m[36mINFO[0m[0m 01/27 23:34:40 | 0.431611    0.424275    0.985642    0.878241    0.514459    0.347065    0.350515    0.346220    0.334479    0.985642    0.878241    0.601549    0.587830    3800        34.234234   0.045929    0.000000    0.193777    130.372011 
[37m[36mINFO[0m[0m 01/27 23:37:27 | 0.436492    0.438257    0.980293    0.870349    0.530456    0.354274    0.375258    0.361111    0.341352    0.980293    0.870349    0.594091    0.598163    4000        36.036036   0.045860    0.000000    0.203027    125.944319 
[37m[36mINFO[0m[0m 01/27 23:40:13 | 0.453722    0.444067    0.990991    0.888388    0.486956    0.358393    0.352577    0.389748    0.373425    0.990991    0.888388    0.613024    0.606200    4200        37.837838   0.059771    0.000000    0.185928    129.727232 
[37m[36mINFO[0m[0m 01/27 23:43:05 | 0.415928    0.416175    0.980574    0.872604    0.647547    0.319258    0.321649    0.359393    0.345934    0.980574    0.872604    0.569134    0.580941    4400        39.639640   0.050055    0.000000    0.186089    133.897270 
[37m[36mINFO[0m[0m 01/27 23:45:53 | 0.429638    0.422216    0.992399    0.880496    0.545636    0.340886    0.344330    0.361397    0.329897    0.992399    0.880496    0.586632    0.592423    4600        41.441441   0.043362    0.000000    0.184811    131.167554 
[37m[36mINFO[0m[0m 01/27 23:48:35 | 0.429432    0.439636    0.977759    0.860203    0.591613    0.331102    0.348454    0.370848    0.366552    0.977759    0.860203    0.586345    0.603904    4800        43.243243   0.077612    0.000000    0.167246    129.318426 
[37m[36mINFO[0m[0m 01/27 23:51:13 | 0.415621    0.418238    0.985079    0.865840    0.690590    0.324923    0.327835    0.353379    0.344788    0.985079    0.865840    0.568560    0.582090    5000        45.045045   0.035176    0.000000    0.159169    126.133825 
[37m[36mINFO[0m[0m 01/27 23:51:14 | Cumulative gradient change saved at train_output/OfficeHome/CORAL/[0, 1, 3]/250127_22-41-01_resnet50_adam/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 01/27 23:51:15 | ---
[37m[36mINFO[0m[0m 01/27 23:51:15 | test-domain validation(oracle) = 46.662%
[37m[36mINFO[0m[0m 01/27 23:51:15 | training-domain validation(iid) = 45.623%
[37m[36mINFO[0m[0m 01/27 23:51:15 | last = 41.562%
[37m[36mINFO[0m[0m 01/27 23:51:15 | last (inD) = 86.584%
[37m[36mINFO[0m[0m 01/27 23:51:15 | training-domain validation (iid, inD) = 89.177%
[37m[36mINFO[0m[0m 01/27 23:51:15 | === Summary ===
[37m[36mINFO[0m[0m 01/27 23:51:15 | Command: /jsm0707/Large-scale/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm CORAL --test_envs 0 1 3 --dataset OfficeHome
[37m[36mINFO[0m[0m 01/27 23:51:15 | Unique name: 250127_22-41-01_resnet50_adam
[37m[36mINFO[0m[0m 01/27 23:51:15 | Out path: train_output/OfficeHome/CORAL/[0, 1, 3]/250127_22-41-01_resnet50_adam
[37m[36mINFO[0m[0m 01/27 23:51:15 | Algorithm: CORAL
[37m[36mINFO[0m[0m 01/27 23:51:15 | Dataset: OfficeHome
