[37m[36mINFO[0m[0m 01/27 17:58:54 | Command :: /jsm0707/Large-scale/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm CORAL --test_envs 0 1 3 --dataset OfficeHome
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_sgd.yaml']
	data_dir: data
	dataset: OfficeHome
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_sgd
	out_dir: train_output/OfficeHome/CORAL/[0, 1, 3]/250127_17-58-54_resnet50_sgd
	out_root: train_output/OfficeHome/CORAL/[0, 1, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 1, 3]
	trial_seed: 0
	unique_name: 250127_17-58-54_resnet50_sgd
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: sgd
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	mmd_gamma: 1.0
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[OfficeHome] #envs=4, #classes=65
	env0: A (#2427)
	env1: C (#4365)
	env2: P (#4439)
	env3: R (#4357)

[37m[36mINFO[0m[0m 01/27 17:58:54 | n_steps = 5001
[37m[36mINFO[0m[0m 01/27 17:58:54 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 01/27 17:58:54 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 01/27 17:58:54 | 
[37m[36mINFO[0m[0m 01/27 17:58:54 | Testenv name escaping te_A_C_R -> te_A_C_R
[37m[36mINFO[0m[0m 01/27 17:58:54 | Test envs = [0, 1, 3], name = te_A_C_R
[37m[36mINFO[0m[0m 01/27 17:58:54 | Train environments: [2], Test environments: [0, 1, 3]
[37m[36mINFO[0m[0m 01/27 17:58:54 | Batch sizes for each domain: [0, 0, 32, 0] (total=32)
[37m[36mINFO[0m[0m 01/27 17:58:54 | steps-per-epoch for each domain: 111.00 -> min = 111.00
[37m[36mINFO[0m[0m 01/27 17:58:56 | # of params = 23641217
[37m[36mINFO[0m[0m 01/27 18:00:48 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 01/27 18:00:48 | 0.017585    0.016577    0.012950    0.015784    4.259601    0.020082    0.026804    0.016609    0.014891    0.012950    0.015784    0.016064    0.008037    0           0.000000    4.328662    0.000000    1.485541    111.314367 
[37m[36mINFO[0m[0m 01/27 18:03:12 | 0.019610    0.018716    0.014921    0.019166    4.204405    0.022142    0.030928    0.018328    0.016037    0.014921    0.019166    0.018359    0.009185    200         1.801802    4.248487    0.000000    0.154612    111.955010 
[37m[36mINFO[0m[0m 01/27 18:05:37 | 0.019706    0.020244    0.016610    0.022548    4.161532    0.019567    0.030928    0.020905    0.020619    0.016610    0.022548    0.018646    0.009185    400         3.603604    4.195623    0.000000    0.138917    117.597249 
[37m[36mINFO[0m[0m 01/27 18:07:56 | 0.021559    0.024597    0.026745    0.030440    4.123094    0.021112    0.037113    0.022910    0.026346    0.026745    0.030440    0.020654    0.010333    600         5.405405    4.152222    0.000000    0.151249    108.720395 
[37m[36mINFO[0m[0m 01/27 18:10:17 | 0.026028    0.026969    0.039696    0.034949    4.083265    0.024202    0.035052    0.027778    0.029782    0.039696    0.034949    0.026104    0.016073    800         7.207207    4.107548    0.000000    0.147987    111.180443 
[37m[36mINFO[0m[0m 01/27 18:12:34 | 0.033269    0.036986    0.057995    0.048478    4.038887    0.024717    0.032990    0.039519    0.044674    0.057995    0.048478    0.035571    0.033295    1000        9.009009    4.058444    0.000000    0.143465    107.300002 
[37m[36mINFO[0m[0m 01/27 18:14:56 | 0.043659    0.043180    0.081363    0.074408    3.988595    0.030381    0.030928    0.054410    0.054983    0.081363    0.074408    0.046185    0.043628    1200        10.810811   4.018544    0.000000    0.147815    112.468809 
[37m[36mINFO[0m[0m 01/27 18:17:11 | 0.057682    0.055107    0.117399    0.103720    3.930193    0.036045    0.039175    0.069874    0.063001    0.117399    0.103720    0.067126    0.063146    1400        12.612613   3.952838    0.000000    0.141029    106.160439 
[37m[36mINFO[0m[0m 01/27 18:19:31 | 0.071322    0.072313    0.155687    0.134160    3.856465    0.041710    0.039175    0.085338    0.083620    0.155687    0.134160    0.086919    0.094145    1600        14.414414   3.886133    0.000000    0.149553    110.531458 
[37m[36mINFO[0m[0m 01/27 18:21:52 | 0.084463    0.086987    0.190034    0.162345    3.764838    0.053038    0.055670    0.095647    0.096220    0.190034    0.162345    0.104705    0.109070    1800        16.216216   3.807491    0.000000    0.137398    112.891047 
[37m[36mINFO[0m[0m 01/27 18:24:13 | 0.097068    0.103047    0.234234    0.207441    3.639648    0.063337    0.055670    0.108534    0.113402    0.234234    0.207441    0.119334    0.140069    2000        18.018018   3.689988    0.000000    0.143004    112.529113 
[37m[36mINFO[0m[0m 01/27 18:26:32 | 0.115885    0.118719    0.284065    0.264938    3.463847    0.076210    0.065979    0.124570    0.128293    0.284065    0.264938    0.146873    0.161883    2200        19.819820   3.545207    0.000000    0.151640    107.585015 
[37m[36mINFO[0m[0m 01/27 18:28:49 | 0.144364    0.147842    0.356700    0.348365    3.198953    0.104016    0.094845    0.140034    0.150057    0.356700    0.348365    0.189042    0.198622    2400        21.621622   3.322418    0.000000    0.142488    108.235222 
[37m[36mINFO[0m[0m 01/27 18:31:13 | 0.187205    0.189888    0.419482    0.434047    2.783038    0.143666    0.125773    0.172394    0.185567    0.419482    0.434047    0.245554    0.258324    2600        23.423423   2.965414    0.000000    0.141287    116.011872 
[37m[36mINFO[0m[0m 01/27 18:33:31 | 0.237487    0.247292    0.514077    0.533258    2.208699    0.173532    0.195876    0.215063    0.216495    0.514077    0.533258    0.323867    0.329506    2800        25.225225   2.510867    0.000000    0.148210    108.144322 
[37m[36mINFO[0m[0m 01/27 18:35:50 | 0.286309    0.294845    0.599381    0.615558    1.656046    0.219361    0.232990    0.245132    0.252005    0.599381    0.615558    0.394435    0.399541    3000        27.027027   1.925171    0.000000    0.150054    108.337380 
[37m[36mINFO[0m[0m 01/27 18:38:03 | 0.325601    0.328642    0.662725    0.676437    1.287465    0.254377    0.259794    0.269759    0.269187    0.662725    0.676437    0.452668    0.456946    3200        28.828829   1.477104    0.000000    0.143683    104.265099 
[37m[36mINFO[0m[0m 01/27 18:40:22 | 0.346462    0.348902    0.713964    0.722661    1.080504    0.271370    0.280412    0.282360    0.279496    0.713964    0.722661    0.485657    0.486797    3400        30.630631   1.192876    0.000000    0.144636    109.674461 
[37m[36mINFO[0m[0m 01/27 18:42:36 | 0.364374    0.361742    0.743243    0.742954    0.955759    0.290422    0.294845    0.298969    0.288660    0.743243    0.742954    0.503729    0.501722    3600        32.432432   0.966162    0.000000    0.142414    105.526416 
[37m[36mINFO[0m[0m 01/27 18:44:57 | 0.383510    0.380171    0.774212    0.763247    0.849159    0.312564    0.313402    0.308133    0.293242    0.774212    0.763247    0.529834    0.533869    3800        34.234234   0.853643    0.000000    0.140874    112.353168 
[37m[36mINFO[0m[0m 01/27 18:47:16 | 0.397624    0.390569    0.801239    0.780158    0.785742    0.328527    0.321649    0.315865    0.300115    0.801239    0.780158    0.548480    0.549943    4000        36.036036   0.730983    0.000000    0.140749    110.314443 
[37m[36mINFO[0m[0m 01/27 18:49:36 | 0.409864    0.404931    0.815878    0.797069    0.733959    0.338311    0.346392    0.332188    0.311569    0.815878    0.797069    0.559094    0.556831    4200        37.837838   0.687104    0.000000    0.146157    111.121727 
[37m[36mINFO[0m[0m 01/27 18:51:52 | 0.421570    0.415786    0.831081    0.808343    0.694506    0.354789    0.342268    0.335338    0.333333    0.831081    0.808343    0.574584    0.571757    4400        39.639640   0.629784    0.000000    0.145955    106.037181 
[37m[36mINFO[0m[0m 01/27 18:54:09 | 0.421287    0.419842    0.855574    0.813980    0.648391    0.349640    0.356701    0.337056    0.319588    0.855574    0.813980    0.577166    0.583238    4600        41.441441   0.538262    0.000000    0.140671    109.108554 
[37m[36mINFO[0m[0m 01/27 18:56:26 | 0.435705    0.429398    0.865146    0.827508    0.628973    0.370237    0.367010    0.340779    0.324170    0.865146    0.827508    0.596099    0.597015    4800        43.243243   0.508267    0.000000    0.142191    107.897756 
[37m[36mINFO[0m[0m 01/27 18:58:47 | 0.432304    0.433607    0.872185    0.829763    0.620278    0.371782    0.367010    0.332474    0.325315    0.872185    0.829763    0.592656    0.608496    5000        45.045045   0.482843    0.000000    0.143171    111.353589 
[37m[36mINFO[0m[0m 01/27 18:58:47 | Cumulative gradient change saved at train_output/OfficeHome/CORAL/[0, 1, 3]/250127_17-58-54_resnet50_sgd/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 01/27 18:58:48 | ---
[37m[36mINFO[0m[0m 01/27 18:58:48 | test-domain validation(oracle) = 43.230%
[37m[36mINFO[0m[0m 01/27 18:58:48 | training-domain validation(iid) = 43.230%
[37m[36mINFO[0m[0m 01/27 18:58:48 | last = 43.230%
[37m[36mINFO[0m[0m 01/27 18:58:48 | last (inD) = 82.976%
[37m[36mINFO[0m[0m 01/27 18:58:48 | training-domain validation (iid, inD) = 82.976%
[37m[36mINFO[0m[0m 01/27 18:58:48 | === Summary ===
[37m[36mINFO[0m[0m 01/27 18:58:48 | Command: /jsm0707/Large-scale/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm CORAL --test_envs 0 1 3 --dataset OfficeHome
[37m[36mINFO[0m[0m 01/27 18:58:48 | Unique name: 250127_17-58-54_resnet50_sgd
[37m[36mINFO[0m[0m 01/27 18:58:48 | Out path: train_output/OfficeHome/CORAL/[0, 1, 3]/250127_17-58-54_resnet50_sgd
[37m[36mINFO[0m[0m 01/27 18:58:48 | Algorithm: CORAL
[37m[36mINFO[0m[0m 01/27 18:58:48 | Dataset: OfficeHome
