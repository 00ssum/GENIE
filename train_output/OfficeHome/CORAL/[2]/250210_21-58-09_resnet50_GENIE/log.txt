[37m[36mINFO[0m[0m 02/10 21:58:09 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 2 --dataset OfficeHome --trial_seed 0 --hparams_seed 8
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: OfficeHome
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 8
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/OfficeHome/CORAL/[2]/250210_21-58-09_resnet50_GENIE
	out_root: train_output/OfficeHome/CORAL/[2]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [2]
	trial_seed: 0
	unique_name: 250210_21-58-09_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.1
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 2.9932388835350315e-05
	batch_size: 16
	weight_decay: 0.0025315391809104006
	mmd_gamma: 0.16699877508053515
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[OfficeHome] #envs=4, #classes=65
	env0: A (#2427)
	env1: C (#4365)
	env2: P (#4439)
	env3: R (#4357)

[37m[36mINFO[0m[0m 02/10 21:58:10 | n_steps = 5001
[37m[36mINFO[0m[0m 02/10 21:58:10 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/10 21:58:10 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/10 21:58:10 | 
[37m[36mINFO[0m[0m 02/10 21:58:10 | Testenv name escaping te_P -> te_P
[37m[36mINFO[0m[0m 02/10 21:58:10 | Test envs = [2], name = te_P
[37m[36mINFO[0m[0m 02/10 21:58:10 | Train environments: [0, 1, 3], Test environments: [2]
[37m[36mINFO[0m[0m 02/10 21:58:10 | Batch sizes for each domain: [16, 16, 0, 16] (total=48)
[37m[36mINFO[0m[0m 02/10 21:58:10 | steps-per-epoch for each domain: 121.38, 218.25, 217.88 -> min = 121.38
[37m[36mINFO[0m[0m 02/10 21:58:11 | # of params = 23641217
[37m[36mINFO[0m[0m 02/10 22:00:16 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 02/10 22:00:16 | 0.017455    0.020293    0.028874    0.025453    4.216833    0.035015    0.024742    0.016609    0.020619    0.017455    0.020293    0.034997    0.030999    0           0.000000    4.360458    0.046524    1.060631    123.935659 
[37m[36mINFO[0m[0m 02/10 22:03:22 | 0.685811    0.674183    0.732548    0.677603    1.185538    0.743563    0.688660    0.679553    0.623139    0.685811    0.674183    0.774527    0.721010    200         1.647786    2.067069    0.399168    0.291271    127.944144 
[37m[36mINFO[0m[0m 02/10 22:06:26 | 0.716498    0.701240    0.805688    0.727068    1.013108    0.833162    0.705155    0.753436    0.680412    0.716498    0.701240    0.830465    0.795637    400         3.295572    0.844599    0.396114    0.294049    124.965938 
[37m[36mINFO[0m[0m 02/10 22:09:33 | 0.729448    0.701240    0.842214    0.728433    0.966626    0.870237    0.719588    0.796105    0.682703    0.729448    0.701240    0.860298    0.783008    600         4.943357    0.650556    0.352406    0.293171    128.682389 
[37m[36mINFO[0m[0m 02/10 22:12:37 | 0.732264    0.708005    0.865829    0.745080    0.972720    0.900103    0.734021    0.820447    0.719359    0.732264    0.708005    0.876936    0.781860    800         6.591143    0.490896    0.342002    0.300472    123.639338 
[37m[36mINFO[0m[0m 02/10 22:15:39 | 0.727477    0.701240    0.902036    0.757239    0.902957    0.927909    0.746392    0.866838    0.720504    0.727477    0.701240    0.911360    0.804822    1000        8.238929    0.401949    0.315992    0.274098    127.267416 
[37m[36mINFO[0m[0m 02/10 22:18:37 | 0.740709    0.726043    0.924220    0.765182    0.860860    0.955201    0.738144    0.890034    0.751432    0.740709    0.726043    0.927424    0.805970    1200        9.886715    0.322252    0.298180    0.302135    117.898080 
[37m[36mINFO[0m[0m 02/10 22:21:40 | 0.759009    0.724915    0.941440    0.782221    0.859624    0.972194    0.762887    0.914662    0.765178    0.759009    0.724915    0.937464    0.818599    1400        11.534501   0.264631    0.285869    0.275117    127.763702 
[37m[36mINFO[0m[0m 02/10 22:24:38 | 0.754786    0.717024    0.942498    0.771369    0.877376    0.964470    0.736082    0.915521    0.769759    0.754786    0.717024    0.947504    0.808266    1600        13.182286   0.222003    0.280511    0.283684    121.298287 
[37m[36mINFO[0m[0m 02/10 22:27:42 | 0.771396    0.737317    0.954225    0.778862    0.846654    0.972709    0.740206    0.929553    0.776632    0.771396    0.737317    0.960413    0.819747    1800        14.830072   0.207272    0.259694    0.291795    125.761868 
[37m[36mINFO[0m[0m 02/10 22:30:40 | 0.755349    0.735062    0.964633    0.782137    0.867238    0.980433    0.764948    0.941867    0.773196    0.755349    0.735062    0.971601    0.808266    2000        16.477858   0.158716    0.251513    0.286374    121.163471 
[37m[36mINFO[0m[0m 02/10 22:33:42 | 0.762669    0.745209    0.966790    0.779541    0.855680    0.981462    0.762887    0.948167    0.766323    0.762669    0.745209    0.970740    0.809414    2200        18.125644   0.145836    0.238598    0.281735    125.663770 
[37m[36mINFO[0m[0m 02/10 22:36:46 | 0.754505    0.741826    0.965432    0.784665    0.864920    0.981977    0.758763    0.946735    0.776632    0.754505    0.741826    0.967585    0.818599    2400        19.773429   0.132907    0.229906    0.305790    121.930988 
[37m[36mINFO[0m[0m 02/10 22:39:51 | 0.755068    0.731680    0.969864    0.777179    0.862597    0.983522    0.754639    0.953322    0.760596    0.755068    0.731680    0.972748    0.816303    2600        21.421215   0.125812    0.219213    0.292517    126.960389 
[37m[36mINFO[0m[0m 02/10 22:42:52 | 0.757038    0.728298    0.975326    0.781604    0.864700    0.985582    0.758763    0.962486    0.775487    0.757038    0.728298    0.977912    0.810563    2800        23.069001   0.119441    0.210734    0.281188    124.796557 
[37m[36mINFO[0m[0m 02/10 22:45:56 | 0.752534    0.742954    0.976244    0.779928    0.855762    0.989186    0.752577    0.958190    0.772050    0.752534    0.742954    0.981354    0.815155    3000        24.716787   0.092259    0.203518    0.282669    127.758070 
[37m[36mINFO[0m[0m 02/10 22:48:59 | 0.746622    0.724915    0.977827    0.786570    0.874006    0.990216    0.779381    0.962772    0.767468    0.746622    0.724915    0.980493    0.812859    3200        26.364573   0.093075    0.193004    0.290296    124.256149 
[37m[36mINFO[0m[0m 02/10 22:52:01 | 0.756475    0.747463    0.976796    0.781139    0.890534    0.987127    0.771134    0.965349    0.770905    0.756475    0.747463    0.977912    0.801378    3400        28.012358   0.079755    0.186653    0.284174    125.695539 
[37m[36mINFO[0m[0m 02/10 22:55:01 | 0.770270    0.759865    0.983708    0.786201    0.820502    0.993821    0.758763    0.972795    0.769759    0.770270    0.759865    0.984509    0.830080    3600        29.660144   0.073990    0.181612    0.273393    124.669268 
[37m[36mINFO[0m[0m 02/10 22:58:00 | 0.740991    0.729425    0.982772    0.773430    0.873598    0.993306    0.742268    0.971936    0.770905    0.740991    0.729425    0.983075    0.807118    3800        31.307930   0.080400    0.177012    0.281440    122.638323 
[37m[36mINFO[0m[0m 02/10 23:01:09 | 0.757883    0.732807    0.984111    0.784055    0.866099    0.993306    0.754639    0.971077    0.777778    0.757883    0.732807    0.987952    0.819747    4000        32.955716   0.077307    0.169332    0.288821    131.318858 
[37m[36mINFO[0m[0m 02/10 23:04:06 | 0.753941    0.733935    0.978919    0.781765    0.920478    0.986612    0.754639    0.965349    0.769759    0.753941    0.733935    0.984796    0.820896    4200        34.603502   0.080497    0.165424    0.280633    121.354666 
[37m[36mINFO[0m[0m 02/10 23:07:05 | 0.748592    0.733935    0.983251    0.777480    0.890624    0.990731    0.756701    0.974800    0.765178    0.748592    0.733935    0.984223    0.810563    4400        36.251287   0.082801    0.169568    0.287469    121.605437 
[37m[36mINFO[0m[0m 02/10 23:10:05 | 0.737331    0.715896    0.981283    0.776790    0.883821    0.992276    0.754639    0.969072    0.769759    0.737331    0.715896    0.982501    0.805970    4600        37.899073   0.079746    0.157371    0.284440    123.146677 
[37m[36mINFO[0m[0m 02/10 23:13:07 | 0.753378    0.747463    0.985985    0.779390    0.884382    0.991761    0.746392    0.974227    0.781214    0.753378    0.747463    0.991968    0.810563    4800        39.546859   0.067082    0.159826    0.286221    124.110605 
[37m[36mINFO[0m[0m 02/10 23:16:08 | 0.744932    0.726043    0.977293    0.763420    0.920476    0.986612    0.734021    0.966495    0.758305    0.744932    0.726043    0.978772    0.797933    5000        41.194645   0.067692    0.153203    0.282825    125.237410 
[37m[36mINFO[0m[0m 02/10 23:16:09 | Cumulative gradient change saved at train_output/OfficeHome/CORAL/[2]/250210_21-58-09_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/10 23:16:10 | ---
[37m[36mINFO[0m[0m 02/10 23:16:10 | test-domain validation(oracle) = 77.027%
[37m[36mINFO[0m[0m 02/10 23:16:10 | training-domain validation(iid) = 74.662%
[37m[36mINFO[0m[0m 02/10 23:16:10 | last = 74.493%
[37m[36mINFO[0m[0m 02/10 23:16:10 | last (inD) = 76.342%
[37m[36mINFO[0m[0m 02/10 23:16:10 | training-domain validation (iid, inD) = 78.657%
[37m[36mINFO[0m[0m 02/10 23:16:10 | === Summary ===
[37m[36mINFO[0m[0m 02/10 23:16:10 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 2 --dataset OfficeHome --trial_seed 0 --hparams_seed 8
[37m[36mINFO[0m[0m 02/10 23:16:10 | Unique name: 250210_21-58-09_resnet50_GENIE
[37m[36mINFO[0m[0m 02/10 23:16:10 | Out path: train_output/OfficeHome/CORAL/[2]/250210_21-58-09_resnet50_GENIE
[37m[36mINFO[0m[0m 02/10 23:16:10 | Algorithm: CORAL
[37m[36mINFO[0m[0m 02/10 23:16:10 | Dataset: OfficeHome
