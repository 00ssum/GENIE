[37m[36mINFO[0m[0m 02/11 07:58:06 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 2 --dataset OfficeHome --trial_seed 2 --hparams_seed 0
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: OfficeHome
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/OfficeHome/CORAL/[2]/250211_07-58-06_resnet50_GENIE
	out_root: train_output/OfficeHome/CORAL/[2]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [2]
	trial_seed: 2
	unique_name: 250211_07-58-06_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	mmd_gamma: 1.0
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[OfficeHome] #envs=4, #classes=65
	env0: A (#2427)
	env1: C (#4365)
	env2: P (#4439)
	env3: R (#4357)

[37m[36mINFO[0m[0m 02/11 07:58:06 | n_steps = 5001
[37m[36mINFO[0m[0m 02/11 07:58:06 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/11 07:58:06 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/11 07:58:06 | 
[37m[36mINFO[0m[0m 02/11 07:58:06 | Testenv name escaping te_P -> te_P
[37m[36mINFO[0m[0m 02/11 07:58:06 | Test envs = [2], name = te_P
[37m[36mINFO[0m[0m 02/11 07:58:06 | Train environments: [0, 1, 3], Test environments: [2]
[37m[36mINFO[0m[0m 02/11 07:58:06 | Batch sizes for each domain: [32, 32, 0, 32] (total=96)
[37m[36mINFO[0m[0m 02/11 07:58:06 | steps-per-epoch for each domain: 60.69, 109.12, 108.94 -> min = 60.69
[37m[36mINFO[0m[0m 02/11 07:58:08 | # of params = 23641217
[37m[36mINFO[0m[0m 02/11 08:00:12 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 02/11 08:00:12 | 0.012950    0.012401    0.016765    0.023314    4.209538    0.021627    0.020619    0.010309    0.019473    0.012950    0.012401    0.018359    0.029851    0           0.000000    4.248386    0.029358    1.490019    123.007988 
[37m[36mINFO[0m[0m 02/11 08:04:12 | 0.716498    0.706877    0.792586    0.732032    0.972804    0.795572    0.715464    0.749714    0.684994    0.716498    0.706877    0.832473    0.795637    200         3.295572    1.700063    0.135346    0.595482    120.411780 
[37m[36mINFO[0m[0m 02/11 08:08:17 | 0.740428    0.737317    0.863044    0.757384    0.837344    0.895469    0.752577    0.815006    0.725086    0.740428    0.737317    0.878657    0.794489    400         6.591143    0.624574    0.117238    0.591226    127.531829 
[37m[36mINFO[0m[0m 02/11 08:12:24 | 0.769426    0.772266    0.904598    0.780251    0.760532    0.925850    0.744330    0.871134    0.757159    0.769426    0.772266    0.916810    0.839265    600         9.886715    0.408478    0.102929    0.562814    133.658413 
[37m[36mINFO[0m[0m 02/11 08:16:30 | 0.775338    0.772266    0.934152    0.796588    0.721509    0.955201    0.787629    0.911512    0.769759    0.775338    0.772266    0.935743    0.832377    800         13.182286   0.291628    0.093795    0.589805    128.628150 
[37m[36mINFO[0m[0m 02/11 08:20:32 | 0.772241    0.759865    0.952294    0.791011    0.749181    0.970649    0.773196    0.931844    0.770905    0.772241    0.759865    0.954389    0.828932    1000        16.477858   0.224593    0.084237    0.577552    126.724402 
[37m[36mINFO[0m[0m 02/11 08:24:37 | 0.775338    0.768884    0.963597    0.800252    0.721623    0.982492    0.781443    0.944444    0.789233    0.775338    0.768884    0.963855    0.830080    1200        19.773429   0.163369    0.076511    0.608616    122.866897 
[37m[36mINFO[0m[0m 02/11 08:28:52 | 0.777027    0.771139    0.975897    0.801331    0.706767    0.990731    0.773196    0.960195    0.788087    0.777027    0.771139    0.976764    0.842710    1400        23.069001   0.133045    0.070324    0.603635    133.772903 
[37m[36mINFO[0m[0m 02/11 08:32:56 | 0.780968    0.762120    0.978305    0.812326    0.702298    0.992791    0.806186    0.959622    0.790378    0.780968    0.762120    0.982501    0.840413    1600        26.364573   0.116751    0.064929    0.546968    134.559561 
[37m[36mINFO[0m[0m 02/11 08:36:53 | 0.783221    0.758737    0.979203    0.799494    0.746814    0.991761    0.771134    0.961627    0.790378    0.783221    0.758737    0.984223    0.836969    1800        29.660144   0.101904    0.060845    0.574313    123.038638 
[37m[36mINFO[0m[0m 02/11 08:41:02 | 0.784910    0.773393    0.983672    0.803617    0.710542    0.992276    0.793814    0.971649    0.780069    0.784910    0.773393    0.987091    0.836969    2000        32.955716   0.079980    0.056429    0.589180    130.558717 
[37m[36mINFO[0m[0m 02/11 08:45:03 | 0.782095    0.766629    0.986691    0.803545    0.714649    0.993306    0.775258    0.974800    0.793814    0.782095    0.766629    0.991968    0.841561    2200        36.251287   0.075479    0.052178    0.584338    124.164317 
[37m[36mINFO[0m[0m 02/11 08:49:09 | 0.783784    0.773393    0.986270    0.805608    0.723828    0.994336    0.791753    0.973368    0.781214    0.783784    0.773393    0.991107    0.843858    2400        39.546859   0.066261    0.049449    0.614330    123.022949 
[37m[36mINFO[0m[0m 02/11 08:53:12 | 0.771959    0.765502    0.986349    0.804004    0.720414    0.992276    0.783505    0.973081    0.785796    0.771959    0.765502    0.993689    0.842710    2600        42.842430   0.057503    0.045744    0.599992    123.553956 
[37m[36mINFO[0m[0m 02/11 08:57:14 | 0.785191    0.770011    0.988887    0.802699    0.725818    0.995881    0.777320    0.976518    0.796105    0.785191    0.770011    0.994263    0.834673    2800        46.138002   0.056378    0.043553    0.601084    121.287476 
[37m[36mINFO[0m[0m 02/11 09:01:31 | 0.788288    0.782413    0.989364    0.808887    0.719888    0.995881    0.795876    0.978236    0.793814    0.788288    0.782413    0.993976    0.836969    3000        49.433574   0.049473    0.042183    0.600261    137.222325 
[37m[36mINFO[0m[0m 02/11 09:05:40 | 0.783784    0.772266    0.989536    0.800640    0.720848    0.996395    0.781443    0.977950    0.782360    0.783784    0.772266    0.994263    0.838117    3200        52.729145   0.048620    0.040084    0.577069    133.935482 
[37m[36mINFO[0m[0m 02/11 09:09:46 | 0.783221    0.768884    0.991025    0.805073    0.706735    0.997425    0.785567    0.981100    0.786942    0.783221    0.768884    0.994550    0.842710    3400        56.024717   0.045461    0.038637    0.591983    126.995684 
[37m[36mINFO[0m[0m 02/11 09:13:54 | 0.781250    0.768884    0.990128    0.808511    0.724107    0.995881    0.795876    0.980241    0.784651    0.781250    0.768884    0.994263    0.845006    3600        59.320288   0.042653    0.036646    0.596528    129.115361 
[37m[36mINFO[0m[0m 02/11 09:17:52 | 0.782658    0.766629    0.991791    0.811029    0.710115    0.994851    0.800000    0.983391    0.790378    0.782658    0.766629    0.997131    0.842710    3800        62.615860   0.038131    0.035711    0.592676    118.923248 
[37m[36mINFO[0m[0m 02/11 09:21:55 | 0.783502    0.771139    0.991560    0.804458    0.735995    0.995881    0.781443    0.984250    0.793814    0.783502    0.771139    0.994550    0.838117    4000        65.911432   0.038257    0.033955    0.613461    120.249832 
[37m[36mINFO[0m[0m 02/11 09:25:59 | 0.788851    0.780158    0.992306    0.812406    0.714933    0.996395    0.793814    0.983677    0.798396    0.788851    0.780158    0.996845    0.845006    4200        69.207003   0.035769    0.033347    0.592620    125.426317 
[37m[36mINFO[0m[0m 02/11 09:29:54 | 0.780405    0.768884    0.991560    0.808051    0.729870    0.995881    0.787629    0.983391    0.793814    0.780405    0.768884    0.995410    0.842710    4400        72.502575   0.037082    0.031823    0.579009    119.582886 
[37m[36mINFO[0m[0m 02/11 09:33:54 | 0.783221    0.767756    0.991485    0.810646    0.725227    0.995366    0.800000    0.983104    0.791523    0.783221    0.767756    0.995984    0.840413    4600        75.798146   0.035053    0.031352    0.606659    118.409329 
[37m[36mINFO[0m[0m 02/11 09:37:52 | 0.776182    0.766629    0.991886    0.809964    0.734848    0.994851    0.797938    0.984250    0.784651    0.776182    0.766629    0.996558    0.847302    4800        79.093718   0.036772    0.030487    0.576549    122.423867 
[37m[36mINFO[0m[0m 02/11 09:42:00 | 0.778716    0.759865    0.992516    0.807742    0.741344    0.995881    0.795876    0.985395    0.789233    0.778716    0.759865    0.996271    0.838117    5000        82.389289   0.036544    0.029412    0.629391    123.054205 
[37m[36mINFO[0m[0m 02/11 09:42:01 | Cumulative gradient change saved at train_output/OfficeHome/CORAL/[2]/250211_07-58-06_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/11 09:42:02 | ---
[37m[36mINFO[0m[0m 02/11 09:42:02 | test-domain validation(oracle) = 78.829%
[37m[36mINFO[0m[0m 02/11 09:42:02 | training-domain validation(iid) = 78.885%
[37m[36mINFO[0m[0m 02/11 09:42:02 | last = 77.872%
[37m[36mINFO[0m[0m 02/11 09:42:02 | last (inD) = 80.774%
[37m[36mINFO[0m[0m 02/11 09:42:02 | training-domain validation (iid, inD) = 81.241%
[37m[36mINFO[0m[0m 02/11 09:42:02 | === Summary ===
[37m[36mINFO[0m[0m 02/11 09:42:02 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 2 --dataset OfficeHome --trial_seed 2 --hparams_seed 0
[37m[36mINFO[0m[0m 02/11 09:42:02 | Unique name: 250211_07-58-06_resnet50_GENIE
[37m[36mINFO[0m[0m 02/11 09:42:02 | Out path: train_output/OfficeHome/CORAL/[2]/250211_07-58-06_resnet50_GENIE
[37m[36mINFO[0m[0m 02/11 09:42:02 | Algorithm: CORAL
[37m[36mINFO[0m[0m 02/11 09:42:02 | Dataset: OfficeHome
