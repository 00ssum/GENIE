[37m[36mINFO[0m[0m 02/10 20:27:25 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 2 --dataset OfficeHome --trial_seed 0 --hparams_seed 7
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: OfficeHome
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 7
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/OfficeHome/CORAL/[2]/250210_20-27-25_resnet50_GENIE
	out_root: train_output/OfficeHome/CORAL/[2]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [2]
	trial_seed: 0
	unique_name: 250210_20-27-25_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 1.6632780446310692e-05
	batch_size: 24
	weight_decay: 5.717289389191427e-06
	mmd_gamma: 3.812683559377669
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[OfficeHome] #envs=4, #classes=65
	env0: A (#2427)
	env1: C (#4365)
	env2: P (#4439)
	env3: R (#4357)

[37m[36mINFO[0m[0m 02/10 20:27:25 | n_steps = 5001
[37m[36mINFO[0m[0m 02/10 20:27:25 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/10 20:27:25 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/10 20:27:25 | 
[37m[36mINFO[0m[0m 02/10 20:27:26 | Testenv name escaping te_P -> te_P
[37m[36mINFO[0m[0m 02/10 20:27:26 | Test envs = [2], name = te_P
[37m[36mINFO[0m[0m 02/10 20:27:26 | Train environments: [0, 1, 3], Test environments: [2]
[37m[36mINFO[0m[0m 02/10 20:27:26 | Batch sizes for each domain: [24, 24, 0, 24] (total=72)
[37m[36mINFO[0m[0m 02/10 20:27:26 | steps-per-epoch for each domain: 80.92, 145.50, 145.25 -> min = 80.92
[37m[36mINFO[0m[0m 02/10 20:27:27 | # of params = 23641217
[37m[36mINFO[0m[0m 02/10 20:29:33 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 02/10 20:29:33 | 0.010698    0.013529    0.023031    0.018650    4.215000    0.027806    0.022680    0.012600    0.011455    0.010698    0.013529    0.028686    0.021814    0           0.000000    4.284766    0.031966    1.079382    124.733164 
[37m[36mINFO[0m[0m 02/10 20:33:08 | 0.695946    0.689966    0.733466    0.695492    1.214343    0.736869    0.701031    0.689576    0.639175    0.695946    0.689966    0.773953    0.746269    200         2.471679    2.358905    0.055451    0.429388    129.795624 
[37m[36mINFO[0m[0m 02/10 20:36:38 | 0.727196    0.726043    0.827417    0.751518    0.982306    0.847065    0.736082    0.790664    0.705613    0.727196    0.726043    0.844521    0.812859    400         4.943357    0.862969    0.057454    0.428945    123.602326 
[37m[36mINFO[0m[0m 02/10 20:40:09 | 0.751408    0.723788    0.871407    0.765341    0.885028    0.891349    0.754639    0.844215    0.727377    0.751408    0.723788    0.878657    0.814007    600         7.415036    0.580005    0.047557    0.424739    126.414563 
[37m[36mINFO[0m[0m 02/10 20:43:46 | 0.755631    0.724915    0.899608    0.782148    0.840212    0.926365    0.775258    0.867698    0.747995    0.755631    0.724915    0.904762    0.823192    800         9.886715    0.463536    0.042755    0.415676    133.566017 
[37m[36mINFO[0m[0m 02/10 20:47:18 | 0.744932    0.732807    0.922580    0.777409    0.848110    0.953141    0.769072    0.884880    0.745704    0.744932    0.732807    0.929719    0.817451    1000        12.358393   0.354726    0.038758    0.430904    125.778692 
[37m[36mINFO[0m[0m 02/10 20:50:58 | 0.760135    0.740699    0.946943    0.790475    0.791548    0.973223    0.767010    0.921249    0.777778    0.760135    0.740699    0.946357    0.826636    1200        14.830072   0.278689    0.036077    0.454015    129.555643 
[37m[36mINFO[0m[0m 02/10 20:54:32 | 0.757601    0.748591    0.953647    0.790705    0.785188    0.980433    0.771134    0.924685    0.773196    0.757601    0.748591    0.955823    0.827784    1400        17.301751   0.222431    0.033539    0.424447    129.305902 
[37m[36mINFO[0m[0m 02/10 20:58:04 | 0.766329    0.745209    0.960657    0.787654    0.798582    0.979403    0.760825    0.941867    0.769759    0.766329    0.745209    0.960700    0.832377    1600        19.773429   0.191044    0.030828    0.444012    123.211727 
[37m[36mINFO[0m[0m 02/10 21:01:39 | 0.771396    0.748591    0.971503    0.797266    0.769067    0.990731    0.789691    0.952463    0.782360    0.771396    0.748591    0.971314    0.819747    1800        22.245108   0.159376    0.029228    0.423226    130.412980 
[37m[36mINFO[0m[0m 02/10 21:05:13 | 0.756475    0.738444    0.971811    0.790163    0.802177    0.987642    0.775258    0.953608    0.776632    0.756475    0.738444    0.974182    0.818599    2000        24.716787   0.133396    0.026912    0.431831    126.914178 
[37m[36mINFO[0m[0m 02/10 21:08:42 | 0.757601    0.745209    0.978798    0.803380    0.757366    0.992276    0.789691    0.967354    0.793814    0.757601    0.745209    0.976764    0.826636    2200        27.188465   0.123645    0.025350    0.426973    123.673963 
[37m[36mINFO[0m[0m 02/10 21:12:15 | 0.768863    0.749718    0.979183    0.787567    0.788928    0.992276    0.762887    0.963631    0.781214    0.768863    0.749718    0.981641    0.818599    2400        29.660144   0.103424    0.024163    0.450815    123.230781 
[37m[36mINFO[0m[0m 02/10 21:15:40 | 0.763514    0.742954    0.984074    0.803077    0.755207    0.991761    0.797938    0.972795    0.782360    0.763514    0.742954    0.987665    0.828932    2600        32.131823   0.095074    0.023217    0.405351    124.149969 
[37m[36mINFO[0m[0m 02/10 21:19:13 | 0.768300    0.750846    0.984627    0.800625    0.780149    0.994851    0.791753    0.969645    0.791523    0.768300    0.750846    0.989386    0.818599    2800        34.603502   0.089170    0.021590    0.422991    127.730203 
[37m[36mINFO[0m[0m 02/10 21:22:41 | 0.764640    0.758737    0.985831    0.808349    0.764244    0.993306    0.800000    0.974800    0.792669    0.764640    0.758737    0.989386    0.832377    3000        37.075180   0.073242    0.020495    0.421436    124.155406 
[37m[36mINFO[0m[0m 02/10 21:26:10 | 0.771115    0.762120    0.987570    0.806288    0.750149    0.995366    0.793814    0.972795    0.790378    0.771115    0.762120    0.994550    0.834673    3200        39.546859   0.071668    0.020014    0.413779    126.181352 
[37m[36mINFO[0m[0m 02/10 21:29:45 | 0.762669    0.749718    0.986212    0.796891    0.799467    0.993306    0.779381    0.975659    0.782360    0.762669    0.749718    0.989673    0.828932    3400        42.018538   0.062722    0.018807    0.448836    125.695847 
[37m[36mINFO[0m[0m 02/10 21:33:18 | 0.766329    0.745209    0.990147    0.796429    0.779977    0.995366    0.771134    0.981386    0.793814    0.766329    0.745209    0.993689    0.824340    3600        44.490216   0.064480    0.018205    0.423492    127.503810 
[37m[36mINFO[0m[0m 02/10 21:36:43 | 0.772523    0.745209    0.988868    0.807427    0.757871    0.993821    0.804124    0.979381    0.792669    0.772523    0.745209    0.993402    0.825488    3800        46.961895   0.064366    0.017702    0.411026    122.690291 
[37m[36mINFO[0m[0m 02/10 21:40:19 | 0.773086    0.735062    0.988810    0.802849    0.777331    0.995366    0.793814    0.978522    0.783505    0.773086    0.735062    0.992542    0.831228    4000        49.433574   0.058077    0.017218    0.448704    126.559256 
[37m[36mINFO[0m[0m 02/10 21:43:52 | 0.769144    0.741826    0.989498    0.810943    0.761077    0.994851    0.802062    0.979954    0.800687    0.769144    0.741826    0.993689    0.830080    4200        51.905252   0.055822    0.016312    0.415535    129.585235 
[37m[36mINFO[0m[0m 02/10 21:47:25 | 0.775338    0.746336    0.989860    0.804607    0.770791    0.995366    0.797938    0.981672    0.783505    0.775338    0.746336    0.992542    0.832377    4400        54.376931   0.049324    0.015865    0.435360    126.619577 
[37m[36mINFO[0m[0m 02/10 21:51:04 | 0.773930    0.754228    0.991216    0.803307    0.775269    0.997425    0.791753    0.980813    0.788087    0.773930    0.754228    0.995410    0.830080    4600        56.848610   0.050367    0.015608    0.430894    132.302996 
[37m[36mINFO[0m[0m 02/10 21:54:36 | 0.771115    0.751973    0.991102    0.810187    0.763282    0.995366    0.791753    0.982532    0.799542    0.771115    0.751973    0.995410    0.839265    4800        59.320288   0.042773    0.015248    0.416154    128.649803 
[37m[36mINFO[0m[0m 02/10 21:58:03 | 0.766329    0.744081    0.990683    0.802312    0.791246    0.993821    0.797938    0.983391    0.781214    0.766329    0.744081    0.994836    0.827784    5000        61.791967   0.047248    0.014597    0.436082    120.548288 
[37m[36mINFO[0m[0m 02/10 21:58:04 | Cumulative gradient change saved at train_output/OfficeHome/CORAL/[2]/250210_20-27-25_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/10 21:58:05 | ---
[37m[36mINFO[0m[0m 02/10 21:58:05 | test-domain validation(oracle) = 77.111%
[37m[36mINFO[0m[0m 02/10 21:58:05 | training-domain validation(iid) = 76.914%
[37m[36mINFO[0m[0m 02/10 21:58:05 | last = 76.633%
[37m[36mINFO[0m[0m 02/10 21:58:05 | last (inD) = 80.231%
[37m[36mINFO[0m[0m 02/10 21:58:05 | training-domain validation (iid, inD) = 81.094%
[37m[36mINFO[0m[0m 02/10 21:58:05 | === Summary ===
[37m[36mINFO[0m[0m 02/10 21:58:05 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 2 --dataset OfficeHome --trial_seed 0 --hparams_seed 7
[37m[36mINFO[0m[0m 02/10 21:58:05 | Unique name: 250210_20-27-25_resnet50_GENIE
[37m[36mINFO[0m[0m 02/10 21:58:05 | Out path: train_output/OfficeHome/CORAL/[2]/250210_20-27-25_resnet50_GENIE
[37m[36mINFO[0m[0m 02/10 21:58:05 | Algorithm: CORAL
[37m[36mINFO[0m[0m 02/10 21:58:05 | Dataset: OfficeHome
