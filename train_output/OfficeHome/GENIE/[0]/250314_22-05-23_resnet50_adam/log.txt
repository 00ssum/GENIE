[37m[36mINFO[0m[0m 03/14 22:05:23 | Command :: /jsm0707/GENIE/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm GENIE --test_envs 0 --dataset OfficeHome
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: GENIE
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_adam.yaml']
	data_dir: data
	dataset: OfficeHome
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_adam
	out_dir: train_output/OfficeHome/GENIE/[0]/250314_22-05-23_resnet50_adam
	out_root: train_output/OfficeHome/GENIE/[0]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0]
	trial_seed: 0
	unique_name: 250314_22-05-23_resnet50_adam
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: adam
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	momentum: 0.9
	convergence_rate: 0.015
	moving_avg: 0.95
	p: 0.4
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[OfficeHome] #envs=4, #classes=65
	env0: A (#2427)
	env1: C (#4365)
	env2: P (#4439)
	env3: R (#4357)

[37m[36mINFO[0m[0m 03/14 22:05:23 | n_steps = 5001
[37m[36mINFO[0m[0m 03/14 22:05:23 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/14 22:05:23 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/14 22:05:23 | 
[37m[36mINFO[0m[0m 03/14 22:05:23 | Testenv name escaping te_A -> te_A
[37m[36mINFO[0m[0m 03/14 22:05:23 | Test envs = [0], name = te_A
[37m[36mINFO[0m[0m 03/14 22:05:23 | Train environments: [1, 2, 3], Test environments: [0]
[37m[36mINFO[0m[0m 03/14 22:05:23 | Batch sizes for each domain: [0, 32, 32, 32] (total=96)
[37m[36mINFO[0m[0m 03/14 22:05:23 | steps-per-epoch for each domain: 109.12, 111.00, 108.94 -> min = 108.94
[37m[36mINFO[0m[0m 03/14 22:05:24 | # of params = 23641217
[37m[36mINFO[0m[0m 03/14 22:07:20 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/14 22:07:20 | 0.019053    0.018557    0.010364    0.010281    4.225991    0.019053    0.018557    0.008591    0.004582    0.008446    0.007892    0.014056    0.018370    0           0.000000    4.273489    1.342533    114.779274 
[37m[36mINFO[0m[0m 03/14 22:11:05 | 0.576210    0.612371    0.816964    0.765486    0.868625    0.576210    0.612371    0.746850    0.673540    0.859234    0.839910    0.844808    0.783008    200         1.835915    1.439195    0.532675    118.425230 
[37m[36mINFO[0m[0m 03/14 22:14:51 | 0.579815    0.614433    0.875701    0.778047    0.861669    0.579815    0.614433    0.832188    0.689576    0.907939    0.848929    0.886976    0.795637    400         3.671830    0.536665    0.514462    123.286960 
[37m[36mINFO[0m[0m 03/14 22:18:41 | 0.568486    0.581443    0.902350    0.792851    0.817065    0.568486    0.581443    0.883162    0.722795    0.923142    0.864713    0.900746    0.791045    600         5.507745    0.340024    0.550204    119.864020 
[37m[36mINFO[0m[0m 03/14 22:22:32 | 0.610711    0.610309    0.923760    0.789899    0.865466    0.610711    0.610309    0.904353    0.714777    0.937782    0.847802    0.929145    0.807118    800         7.343660    0.262065    0.538031    122.892323 
[37m[36mINFO[0m[0m 03/14 22:26:23 | 0.607621    0.630928    0.947311    0.811181    0.865064    0.607621    0.630928    0.930699    0.746850    0.961149    0.868095    0.950086    0.818599    1000        9.179575    0.192431    0.555622    119.597893 
[37m[36mINFO[0m[0m 03/14 22:30:06 | 0.627703    0.622680    0.962708    0.815663    0.875191    0.627703    0.622680    0.945017    0.746850    0.974662    0.886133    0.968445    0.814007    1200        11.015491   0.159599    0.531968    117.554638 
[37m[36mINFO[0m[0m 03/14 22:33:52 | 0.616375    0.606186    0.969467    0.820962    0.869420    0.616375    0.606186    0.957904    0.760596    0.978322    0.894025    0.972174    0.808266    1400        12.851406   0.122790    0.524146    120.427571 
[37m[36mINFO[0m[0m 03/14 22:37:36 | 0.623584    0.643299    0.972793    0.822903    0.858141    0.623584    0.643299    0.959908    0.760596    0.981419    0.889515    0.977051    0.818599    1600        14.687321   0.114885    0.522719    119.570979 
[37m[36mINFO[0m[0m 03/14 22:41:18 | 0.619979    0.610309    0.973394    0.821399    0.879529    0.619979    0.610309    0.959049    0.752577    0.977196    0.886133    0.983936    0.825488    1800        16.523236   0.091356    0.514926    119.227411 
[37m[36mINFO[0m[0m 03/14 22:45:07 | 0.609166    0.628866    0.974587    0.818276    0.903568    0.609166    0.628866    0.959336    0.760596    0.985079    0.895152    0.979346    0.799082    2000        18.359151   0.088397    0.533795    121.716689 
[37m[36mINFO[0m[0m 03/14 22:48:48 | 0.584449    0.604124    0.978034    0.812981    0.959094    0.584449    0.604124    0.969645    0.751432    0.983390    0.886133    0.981067    0.801378    2200        20.195066   0.079528    0.536095    114.331448 
[37m[36mINFO[0m[0m 03/14 22:52:29 | 0.607106    0.632990    0.983151    0.820206    0.924293    0.607106    0.632990    0.973368    0.749141    0.990428    0.894025    0.985657    0.817451    2400        22.030981   0.071684    0.511453    118.390800 
[37m[36mINFO[0m[0m 03/14 22:56:14 | 0.608136    0.612371    0.980232    0.827484    0.911321    0.608136    0.612371    0.974513    0.767468    0.983108    0.890643    0.983075    0.824340    2600        23.866896   0.057581    0.519099    121.445179 
[37m[36mINFO[0m[0m 03/14 23:00:03 | 0.617920    0.608247    0.982201    0.817952    0.968864    0.617920    0.608247    0.971363    0.747995    0.989583    0.887260    0.985657    0.818599    2800        25.702811   0.054730    0.520663    124.575131 
[37m[36mINFO[0m[0m 03/14 23:03:49 | 0.607106    0.602062    0.985828    0.831263    0.980453    0.607106    0.602062    0.977090    0.766323    0.990146    0.898534    0.990247    0.828932    3000        27.538726   0.053032    0.535800    119.268962 
[37m[36mINFO[0m[0m 03/14 23:07:32 | 0.617405    0.630928    0.987822    0.826657    0.939640    0.617405    0.630928    0.979095    0.766323    0.992117    0.900789    0.992255    0.812859    3200        29.374641   0.049491    0.507980    121.111604 
[37m[36mINFO[0m[0m 03/14 23:11:19 | 0.626159    0.637113    0.988393    0.816723    1.073937    0.626159    0.637113    0.980813    0.744559    0.992399    0.900789    0.991968    0.804822    3400        31.210557   0.041737    0.527935    121.570274 
[37m[36mINFO[0m[0m 03/14 23:15:06 | 0.628733    0.620619    0.988666    0.826684    1.008226    0.628733    0.620619    0.979954    0.767468    0.994651    0.896280    0.991394    0.816303    3600        33.046472   0.047711    0.536894    119.092800 
[37m[36mINFO[0m[0m 03/14 23:18:52 | 0.611226    0.612371    0.986196    0.824372    0.924210    0.611226    0.612371    0.975086    0.751432    0.992680    0.900789    0.990820    0.820896    3800        34.882387   0.042343    0.529269    120.845064 
[37m[36mINFO[0m[0m 03/14 23:22:35 | 0.620494    0.608247    0.988585    0.829325    1.049495    0.620494    0.608247    0.980813    0.762887    0.992399    0.903044    0.992542    0.822044    4000        36.718302   0.037021    0.525289    117.369557 
[37m[36mINFO[0m[0m 03/14 23:26:24 | 0.614315    0.612371    0.987255    0.821754    1.082191    0.614315    0.612371    0.977950    0.761741    0.991273    0.889515    0.992542    0.814007    4200        38.554217   0.036279    0.556449    117.979760 
[37m[36mINFO[0m[0m 03/14 23:30:03 | 0.626159    0.618557    0.987728    0.820944    1.040770    0.626159    0.618557    0.979095    0.747995    0.991836    0.898534    0.992255    0.816303    4400        40.390132   0.033274    0.506270    117.551084 
[37m[36mINFO[0m[0m 03/14 23:33:51 | 0.605561    0.626804    0.989155    0.829738    1.125924    0.605561    0.626804    0.982532    0.759450    0.992680    0.898534    0.992255    0.831228    4600        42.226047   0.029191    0.540921    119.930299 
[37m[36mINFO[0m[0m 03/14 23:37:36 | 0.627703    0.630928    0.989333    0.827429    1.078853    0.627703    0.630928    0.979381    0.749141    0.995214    0.901917    0.993402    0.831228    4800        44.061962   0.032943    0.530867    119.116050 
[37m[36mINFO[0m[0m 03/14 23:41:20 | 0.615345    0.624742    0.990384    0.826729    1.066214    0.615345    0.624742    0.982532    0.762887    0.994932    0.889515    0.993689    0.827784    5000        45.897877   0.029188    0.527037    118.277078 
[37m[36mINFO[0m[0m 03/14 23:41:20 | Cumulative gradient change saved at train_output/OfficeHome/GENIE/[0]/250314_22-05-23_resnet50_adam/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/14 23:41:21 | ---
[37m[36mINFO[0m[0m 03/14 23:41:21 | test-domain validation(oracle) = 62.358%
[37m[36mINFO[0m[0m 03/14 23:41:21 | training-domain validation(iid) = 60.711%
[37m[36mINFO[0m[0m 03/14 23:41:21 | last = 61.535%
[37m[36mINFO[0m[0m 03/14 23:41:21 | last (inD) = 82.673%
[37m[36mINFO[0m[0m 03/14 23:41:21 | training-domain validation (iid, inD) = 83.126%
[37m[36mINFO[0m[0m 03/14 23:41:21 | === Summary ===
[37m[36mINFO[0m[0m 03/14 23:41:21 | Command: /jsm0707/GENIE/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm GENIE --test_envs 0 --dataset OfficeHome
[37m[36mINFO[0m[0m 03/14 23:41:21 | Unique name: 250314_22-05-23_resnet50_adam
[37m[36mINFO[0m[0m 03/14 23:41:21 | Out path: train_output/OfficeHome/GENIE/[0]/250314_22-05-23_resnet50_adam
[37m[36mINFO[0m[0m 03/14 23:41:21 | Algorithm: GENIE
[37m[36mINFO[0m[0m 03/14 23:41:21 | Dataset: OfficeHome
