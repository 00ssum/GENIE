[37m[36mINFO[0m[0m 03/15 00:26:03 | Command :: /jsm0707/GENIE/train_all.py B_OfficeHome0_adam config/resnet50_adam.yaml --trial_seed 2 --hparams_seed 10 --algorithm GENIE --test_envs 0 --dataset OfficeHome
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: GENIE
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_adam.yaml']
	data_dir: data
	dataset: OfficeHome
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 10
	in_domain: False
	model_save: None
	mpa: False
	name: B_OfficeHome0_adam
	out_dir: train_output/OfficeHome/GENIE/[0]/250315_00-26-03_B_OfficeHome0_adam
	out_root: train_output/OfficeHome/GENIE/[0]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0]
	trial_seed: 2
	unique_name: 250315_00-26-03_B_OfficeHome0_adam
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.5
	class_balanced: False
	optimizer: adam
	freeze_bn: False
	pretrained: True
	lr: 7.494887873901297e-05
	batch_size: 23
	weight_decay: 0.000495139494108363
	momentum: 0.9161886820913123
	convergence_rate: 0.003714112431183281
	moving_avg: 0.9624846363789884
	p: 0.14674963900384252
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[OfficeHome] #envs=4, #classes=65
	env0: A (#2427)
	env1: C (#4365)
	env2: P (#4439)
	env3: R (#4357)

[37m[36mINFO[0m[0m 03/15 00:26:03 | n_steps = 5001
[37m[36mINFO[0m[0m 03/15 00:26:03 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/15 00:26:03 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/15 00:26:03 | 
[37m[36mINFO[0m[0m 03/15 00:26:03 | Testenv name escaping te_A -> te_A
[37m[36mINFO[0m[0m 03/15 00:26:03 | Test envs = [0], name = te_A
[37m[36mINFO[0m[0m 03/15 00:26:03 | Train environments: [1, 2, 3], Test environments: [0]
[37m[36mINFO[0m[0m 03/15 00:26:03 | Batch sizes for each domain: [0, 23, 23, 23] (total=69)
[37m[36mINFO[0m[0m 03/15 00:26:03 | steps-per-epoch for each domain: 151.83, 154.43, 151.57 -> min = 151.57
[37m[36mINFO[0m[0m 03/15 00:26:04 | # of params = 23641217
[37m[36mINFO[0m[0m 03/15 00:28:09 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/15 00:28:09 | 0.016478    0.020619    0.010003    0.013362    4.243890    0.016478    0.020619    0.009450    0.016037    0.005068    0.003382    0.015491    0.020666    0           0.000000    4.278715    0.971377    123.898402 
[37m[36mINFO[0m[0m 03/15 00:31:32 | 0.515448    0.478351    0.627445    0.624162    1.456130    0.515448    0.478351    0.510023    0.512027    0.698761    0.689966    0.673551    0.670494    200         1.319564    3.445457    0.391700    124.656754 
[37m[36mINFO[0m[0m 03/15 00:34:43 | 0.616375    0.606186    0.781363    0.763672    0.856991    0.616375    0.606186    0.688717    0.670103    0.838964    0.824126    0.816408    0.796785    400         2.639128    1.298394    0.372466    116.408360 
[37m[36mINFO[0m[0m 03/15 00:37:56 | 0.627188    0.626804    0.824537    0.795636    0.761248    0.627188    0.626804    0.751145    0.710195    0.871059    0.848929    0.851406    0.827784    600         3.958692    0.883139    0.378722    117.389602 
[37m[36mINFO[0m[0m 03/15 00:41:15 | 0.641092    0.643299    0.853260    0.795572    0.730555    0.641092    0.643299    0.787801    0.712486    0.892173    0.859076    0.879805    0.815155    800         5.278256    0.729355    0.385016    121.419742 
[37m[36mINFO[0m[0m 03/15 00:44:29 | 0.645726    0.641237    0.870862    0.810837    0.697298    0.645726    0.641237    0.822451    0.742268    0.902872    0.862458    0.887263    0.827784    1000        6.597820    0.624596    0.389573    116.334579 
[37m[36mINFO[0m[0m 03/15 00:47:44 | 0.651905    0.672165    0.893318    0.809251    0.690928    0.651905    0.672165    0.848511    0.742268    0.918074    0.871477    0.913368    0.814007    1200        7.917384    0.524363    0.374247    120.579327 
[37m[36mINFO[0m[0m 03/15 00:51:03 | 0.652420    0.651546    0.906209    0.819203    0.653986    0.652420    0.651546    0.869129    0.757159    0.934122    0.869222    0.915376    0.831228    1400        9.236948    0.447036    0.376756    123.612798 
[37m[36mINFO[0m[0m 03/15 00:54:26 | 0.636972    0.645361    0.916518    0.827532    0.651606    0.636972    0.645361    0.881730    0.758305    0.935811    0.883878    0.932014    0.840413    1600        10.556512   0.414690    0.397741    123.246115 
[37m[36mINFO[0m[0m 03/15 00:57:39 | 0.645726    0.661856    0.932261    0.823334    0.674899    0.645726    0.661856    0.897766    0.760596    0.954955    0.881623    0.944062    0.827784    1800        11.876076   0.368479    0.369831    118.808107 
[37m[36mINFO[0m[0m 03/15 01:00:56 | 0.645726    0.628866    0.928863    0.818031    0.686839    0.645726    0.628866    0.897480    0.761741    0.947917    0.872604    0.941193    0.819747    2000        13.195640   0.314106    0.389797    119.080868 
[37m[36mINFO[0m[0m 03/15 01:04:10 | 0.646756    0.688660    0.940262    0.836267    0.667692    0.646756    0.688660    0.908362    0.782360    0.958896    0.891770    0.953528    0.834673    2200        14.515204   0.292255    0.378827    117.911294 
[37m[36mINFO[0m[0m 03/15 01:07:23 | 0.652935    0.661856    0.945587    0.834323    0.690434    0.652935    0.661856    0.920676    0.777778    0.962556    0.897407    0.953528    0.827784    2400        15.834768   0.253335    0.386421    116.072451 
[37m[36mINFO[0m[0m 03/15 01:10:38 | 0.657570    0.678351    0.958617    0.833595    0.673658    0.657570    0.678351    0.937858    0.774341    0.972128    0.891770    0.965863    0.834673    2600        17.154332   0.243689    0.387683    117.160361 
[37m[36mINFO[0m[0m 03/15 01:13:52 | 0.636457    0.641237    0.957485    0.830160    0.709258    0.636457    0.641237    0.935281    0.761741    0.969876    0.891770    0.967298    0.836969    2800        18.473896   0.216322    0.381736    118.155597 
[37m[36mINFO[0m[0m 03/15 01:17:09 | 0.650875    0.659794    0.958609    0.839355    0.687920    0.650875    0.659794    0.935853    0.784651    0.973536    0.887260    0.966437    0.846154    3000        19.793460   0.205521    0.387532    119.085140 
[37m[36mINFO[0m[0m 03/15 01:20:30 | 0.644696    0.657732    0.961565    0.832099    0.735441    0.644696    0.657732    0.941008    0.773196    0.974381    0.886133    0.969306    0.836969    3200        21.113024   0.187118    0.391448    122.802366 
[37m[36mINFO[0m[0m 03/15 01:23:50 | 0.659629    0.680412    0.965191    0.834027    0.740007    0.659629    0.680412    0.947881    0.773196    0.974944    0.883878    0.972748    0.845006    3400        22.432587   0.172893    0.394179    121.036160 
[37m[36mINFO[0m[0m 03/15 01:27:07 | 0.630278    0.651546    0.968133    0.835513    0.740983    0.630278    0.651546    0.949885    0.777778    0.978322    0.890643    0.976190    0.838117    3600        23.752151   0.162097    0.385304    120.234222 
[37m[36mINFO[0m[0m 03/15 01:30:22 | 0.665294    0.665979    0.974600    0.848090    0.671046    0.665294    0.665979    0.958763    0.799542    0.983108    0.896280    0.981928    0.848450    3800        25.071715   0.153490    0.386305    117.945441 
[37m[36mINFO[0m[0m 03/15 01:33:37 | 0.647271    0.670103    0.972599    0.840079    0.722505    0.647271    0.670103    0.954754    0.784651    0.982264    0.894025    0.980780    0.841561    4000        26.391279   0.129041    0.398611    115.434263 
[37m[36mINFO[0m[0m 03/15 01:36:56 | 0.648301    0.665979    0.976492    0.846513    0.744615    0.648301    0.665979    0.963058    0.797251    0.985923    0.904171    0.980493    0.838117    4200        27.710843   0.133197    0.397353    119.606260 
[37m[36mINFO[0m[0m 03/15 01:40:15 | 0.642636    0.641237    0.978398    0.840057    0.729492    0.642636    0.641237    0.964490    0.785796    0.986768    0.897407    0.983936    0.836969    4400        29.030407   0.122642    0.407449    116.848835 
[37m[36mINFO[0m[0m 03/15 01:43:31 | 0.651390    0.659794    0.978319    0.837809    0.736484    0.651390    0.659794    0.964204    0.786942    0.984234    0.889515    0.986517    0.836969    4600        30.349971   0.104773    0.384613    119.155990 
[37m[36mINFO[0m[0m 03/15 01:46:50 | 0.650360    0.655670    0.981449    0.840441    0.729278    0.650360    0.655670    0.966781    0.793814    0.987894    0.896280    0.989673    0.831228    4800        31.669535   0.115467    0.384764    122.018688 
[37m[36mINFO[0m[0m 03/15 01:50:06 | 0.656025    0.665979    0.980497    0.838936    0.783534    0.656025    0.665979    0.969072    0.786942    0.987050    0.892897    0.985370    0.836969    5000        32.989099   0.102658    0.390510    118.246755 
[37m[36mINFO[0m[0m 03/15 01:50:06 | Cumulative gradient change saved at train_output/OfficeHome/GENIE/[0]/250315_00-26-03_B_OfficeHome0_adam/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/15 01:50:08 | ---
[37m[36mINFO[0m[0m 03/15 01:50:08 | test-domain validation(oracle) = 64.676%
[37m[36mINFO[0m[0m 03/15 01:50:08 | training-domain validation(iid) = 66.529%
[37m[36mINFO[0m[0m 03/15 01:50:08 | last = 65.602%
[37m[36mINFO[0m[0m 03/15 01:50:08 | last (inD) = 83.894%
[37m[36mINFO[0m[0m 03/15 01:50:08 | training-domain validation (iid, inD) = 84.809%
[37m[36mINFO[0m[0m 03/15 01:50:08 | === Summary ===
[37m[36mINFO[0m[0m 03/15 01:50:08 | Command: /jsm0707/GENIE/train_all.py B_OfficeHome0_adam config/resnet50_adam.yaml --trial_seed 2 --hparams_seed 10 --algorithm GENIE --test_envs 0 --dataset OfficeHome
[37m[36mINFO[0m[0m 03/15 01:50:08 | Unique name: 250315_00-26-03_B_OfficeHome0_adam
[37m[36mINFO[0m[0m 03/15 01:50:08 | Out path: train_output/OfficeHome/GENIE/[0]/250315_00-26-03_B_OfficeHome0_adam
[37m[36mINFO[0m[0m 03/15 01:50:08 | Algorithm: GENIE
[37m[36mINFO[0m[0m 03/15 01:50:08 | Dataset: OfficeHome
