[37m[36mINFO[0m[0m 01/22 16:37:56 | Command :: /jsm0707/DomainBed/Large-scale/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm gsnr1224 --test_envs 0 1 3 --dataset OfficeHome --trial_seed 0 --hparams_seed 15
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: gsnr1224
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_sgd.yaml']
	data_dir: data
	dataset: OfficeHome
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 15
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_sgd
	out_dir: train_output/OfficeHome/gsnr1224/[0, 1, 3]/250122_16-37-56_resnet50_sgd
	out_root: train_output/OfficeHome/gsnr1224/[0, 1, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 1, 3]
	trial_seed: 0
	unique_name: 250122_16-37-56_resnet50_sgd
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.5
	class_balanced: False
	optimizer: sgd
	freeze_bn: False
	pretrained: True
	lr: 0.00010661763546249327
	batch_size: 14
	weight_decay: 9.086452814323981e-06
	momentum: 0.846320346520143
	convergence_rate: 0.001625681705546367
	moving_avg: 0.9229441284737897
	p: 0.5950371143099659
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[OfficeHome] #envs=4, #classes=65
	env0: A (#2427)
	env1: C (#4365)
	env2: P (#4439)
	env3: R (#4357)

[37m[36mINFO[0m[0m 01/22 16:37:56 | n_steps = 5001
[37m[36mINFO[0m[0m 01/22 16:37:56 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 01/22 16:37:56 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 01/22 16:37:56 | 
[37m[36mINFO[0m[0m 01/22 16:37:56 | Testenv name escaping te_A_C_R -> te_A_C_R
[37m[36mINFO[0m[0m 01/22 16:37:56 | Test envs = [0, 1, 3], name = te_A_C_R
[37m[36mINFO[0m[0m 01/22 16:37:56 | Train environments: [2], Test environments: [0, 1, 3]
[37m[36mINFO[0m[0m 01/22 16:37:56 | Batch sizes for each domain: [0, 0, 14, 0] (total=14)
[37m[36mINFO[0m[0m 01/22 16:37:56 | steps-per-epoch for each domain: 253.71 -> min = 253.71
[37m[36mINFO[0m[0m 01/22 16:37:58 | # of params = 23641217
[37m[36mINFO[0m[0m 01/22 16:40:02 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 01/22 16:40:02 | 0.018004    0.016961    0.013795    0.014656    4.253435    0.021627    0.026804    0.017468    0.013746    0.013795    0.014656    0.014917    0.010333    0           0.000000    4.345976    2.808669    121.025834 
[37m[36mINFO[0m[0m 01/22 16:42:32 | 0.172825    0.160322    0.386543    0.376550    3.021988    0.132338    0.088660    0.153780    0.151203    0.386543    0.376550    0.232358    0.241102    200         0.788288    3.905227    0.140516    121.869446 
[37m[36mINFO[0m[0m 01/22 16:45:04 | 0.467449    0.456976    0.784347    0.773393    0.845027    0.420185    0.406186    0.363402    0.355097    0.784347    0.773393    0.618761    0.609644    400         1.576577    2.000137    0.130362    124.927513 
[37m[36mINFO[0m[0m 01/22 16:47:31 | 0.499602    0.505874    0.849944    0.798196    0.645258    0.464470    0.478351    0.384593    0.397480    0.849944    0.798196    0.649742    0.641791    600         2.364865    0.952793    0.130664    120.918720 
[37m[36mINFO[0m[0m 01/22 16:50:00 | 0.514974    0.511833    0.894144    0.836528    0.522736    0.472194    0.492784    0.412085    0.397480    0.894144    0.836528    0.660643    0.645235    800         3.153153    0.705215    0.129973    122.662159 
[37m[36mINFO[0m[0m 01/22 16:52:35 | 0.526102    0.525916    0.920327    0.863585    0.446927    0.476313    0.484536    0.409507    0.406644    0.920327    0.863585    0.692484    0.686567    1000        3.941441    0.506773    0.188899    117.103336 
[37m[36mINFO[0m[0m 01/22 16:55:01 | 0.519398    0.533858    0.914414    0.859076    0.479086    0.471679    0.517526    0.400916    0.397480    0.914414    0.859076    0.685600    0.686567    1200        4.729730    0.418029    0.145964    116.860035 
[37m[36mINFO[0m[0m 01/22 16:57:26 | 0.530967    0.541272    0.941160    0.868095    0.424765    0.494336    0.523711    0.399485    0.404353    0.941160    0.868095    0.699082    0.695752    1400        5.518018    0.387326    0.146350    115.214369 
[37m[36mINFO[0m[0m 01/22 16:59:52 | 0.543250    0.547851    0.945383    0.888388    0.379169    0.505664    0.531959    0.406644    0.400916    0.945383    0.888388    0.717441    0.710677    1600        6.306306    0.345701    0.138444    118.283555 
[37m[36mINFO[0m[0m 01/22 17:02:22 | 0.534269    0.540516    0.958896    0.877114    0.375198    0.497940    0.523711    0.406357    0.391753    0.958896    0.877114    0.698508    0.706085    1800        7.094595    0.282888    0.145345    120.979797 
[37m[36mINFO[0m[0m 01/22 17:05:16 | 0.533191    0.537217    0.948761    0.875986    0.436075    0.506179    0.529897    0.405498    0.396334    0.948761    0.875986    0.687894    0.685419    2000        7.882883    0.254145    0.173738    138.446122 
[37m[36mINFO[0m[0m 01/22 17:07:49 | 0.532218    0.538077    0.971002    0.875986    0.391479    0.486612    0.517526    0.399198    0.384880    0.971002    0.875986    0.710843    0.711825    2200        8.671171    0.218512    0.215805    110.645814 
[37m[36mINFO[0m[0m 01/22 17:10:23 | 0.543660    0.537675    0.973818    0.897407    0.379101    0.502060    0.507216    0.429840    0.420389    0.973818    0.897407    0.699082    0.685419    2400        9.459459    0.198129    0.183395    117.262418 
[37m[36mINFO[0m[0m 01/22 17:12:55 | 0.530244    0.548082    0.972128    0.891770    0.398603    0.483007    0.515464    0.411512    0.415808    0.972128    0.891770    0.696213    0.712974    2600        10.247748   0.176824    0.171571    117.082754 
[37m[36mINFO[0m[0m 01/22 17:15:28 | 0.526299    0.526319    0.974381    0.883878    0.438985    0.478888    0.484536    0.394616    0.379152    0.974381    0.883878    0.705393    0.715270    2800        11.036036   0.155703    0.174856    117.982683 
[37m[36mINFO[0m[0m 01/22 17:17:56 | 0.543196    0.547482    0.976914    0.901917    0.383212    0.496910    0.511340    0.414089    0.403207    0.976914    0.901917    0.718589    0.727899    3000        11.824324   0.140808    0.135036    121.058713 
[37m[36mINFO[0m[0m 01/22 17:20:28 | 0.539491    0.546708    0.982545    0.905299    0.390887    0.488671    0.521649    0.418671    0.404353    0.982545    0.905299    0.711130    0.714122    3200        12.612613   0.121152    0.153738    120.752610 
[37m[36mINFO[0m[0m 01/22 17:23:04 | 0.524485    0.534476    0.980011    0.896280    0.391563    0.468589    0.501031    0.406071    0.406644    0.980011    0.896280    0.698795    0.695752    3400        13.400901   0.115693    0.160482    123.913624 
[37m[36mINFO[0m[0m 01/22 17:25:44 | 0.531987    0.538231    0.985360    0.899662    0.381293    0.474768    0.503093    0.419817    0.397480    0.985360    0.899662    0.701377    0.714122    3600        14.189189   0.112046    0.191965    121.531996 
[37m[36mINFO[0m[0m 01/22 17:28:34 | 0.535436    0.530350    0.984516    0.898534    0.407657    0.481977    0.488660    0.429840    0.408935    0.984516    0.898534    0.694492    0.693456    3800        14.977477   0.088829    0.221241    125.980702 
[37m[36mINFO[0m[0m 01/22 17:31:15 | 0.544471    0.555567    0.985642    0.908681    0.349377    0.490731    0.529897    0.434422    0.421535    0.985642    0.908681    0.708262    0.715270    4000        15.765766   0.099859    0.208708    119.139011 
[37m[36mINFO[0m[0m 01/22 17:33:46 | 0.543498    0.550678    0.989020    0.905299    0.374178    0.491246    0.507216    0.429553    0.431844    0.989020    0.905299    0.709696    0.712974    4200        16.554054   0.087437    0.161986    118.183903 
[37m[36mINFO[0m[0m 01/22 17:36:22 | 0.547678    0.549823    0.983671    0.900789    0.363123    0.496910    0.529897    0.435567    0.426117    0.983671    0.900789    0.710557    0.693456    4400        17.342342   0.083050    0.189069    117.830638 
[37m[36mINFO[0m[0m 01/22 17:39:04 | 0.536746    0.545482    0.988739    0.904171    0.391319    0.467559    0.503093    0.436426    0.424971    0.988739    0.904171    0.706254    0.708381    4600        18.130631   0.086441    0.168466    127.811833 
[37m[36mINFO[0m[0m 01/22 17:41:31 | 0.536627    0.535539    0.984516    0.904171    0.428358    0.475798    0.503093    0.430412    0.414662    0.984516    0.904171    0.703672    0.688863    4800        18.918919   0.066654    0.171664    112.993585 
[37m[36mINFO[0m[0m 01/22 17:44:03 | 0.541666    0.542352    0.989302    0.901917    0.400360    0.489186    0.505155    0.426117    0.412371    0.989302    0.901917    0.709696    0.709529    5000        19.707207   0.063614    0.171638    117.785197 
[37m[36mINFO[0m[0m 01/22 17:44:03 | Cumulative gradient change saved at train_output/OfficeHome/gsnr1224/[0, 1, 3]/250122_16-37-56_resnet50_sgd/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 01/22 17:44:04 | ---
[37m[36mINFO[0m[0m 01/22 17:44:04 | test-domain validation(oracle) = 54.447%
[37m[36mINFO[0m[0m 01/22 17:44:04 | training-domain validation(iid) = 54.447%
[37m[36mINFO[0m[0m 01/22 17:44:04 | last = 54.167%
[37m[36mINFO[0m[0m 01/22 17:44:04 | last (inD) = 90.192%
[37m[36mINFO[0m[0m 01/22 17:44:04 | training-domain validation (iid, inD) = 90.868%
[37m[36mINFO[0m[0m 01/22 17:44:04 | === Summary ===
[37m[36mINFO[0m[0m 01/22 17:44:04 | Command: /jsm0707/DomainBed/Large-scale/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm gsnr1224 --test_envs 0 1 3 --dataset OfficeHome --trial_seed 0 --hparams_seed 15
[37m[36mINFO[0m[0m 01/22 17:44:04 | Unique name: 250122_16-37-56_resnet50_sgd
[37m[36mINFO[0m[0m 01/22 17:44:04 | Out path: train_output/OfficeHome/gsnr1224/[0, 1, 3]/250122_16-37-56_resnet50_sgd
[37m[36mINFO[0m[0m 01/22 17:44:04 | Algorithm: gsnr1224
[37m[36mINFO[0m[0m 01/22 17:44:04 | Dataset: OfficeHome
