[37m[36mINFO[0m[0m 03/15 06:04:31 | Command :: /jsm0707/GENIE/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm GENIE --test_envs 1 2 3 --dataset OfficeHome
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: GENIE
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_adam.yaml']
	data_dir: data
	dataset: OfficeHome
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_adam
	out_dir: train_output/OfficeHome/GENIE/[1, 2, 3]/250315_06-04-31_resnet50_adam
	out_root: train_output/OfficeHome/GENIE/[1, 2, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [1, 2, 3]
	trial_seed: 0
	unique_name: 250315_06-04-31_resnet50_adam
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: adam
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	momentum: 0.9
	convergence_rate: 0.015
	moving_avg: 0.95
	p: 0.4
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[OfficeHome] #envs=4, #classes=65
	env0: A (#2427)
	env1: C (#4365)
	env2: P (#4439)
	env3: R (#4357)

[37m[36mINFO[0m[0m 03/15 06:04:31 | n_steps = 5001
[37m[36mINFO[0m[0m 03/15 06:04:31 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/15 06:04:31 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/15 06:04:31 | 
[37m[36mINFO[0m[0m 03/15 06:04:31 | Testenv name escaping te_C_P_R -> te_C_P_R
[37m[36mINFO[0m[0m 03/15 06:04:31 | Test envs = [1, 2, 3], name = te_C_P_R
[37m[36mINFO[0m[0m 03/15 06:04:31 | Train environments: [0], Test environments: [1, 2, 3]
[37m[36mINFO[0m[0m 03/15 06:04:31 | Batch sizes for each domain: [32, 0, 0, 0] (total=32)
[37m[36mINFO[0m[0m 03/15 06:04:31 | steps-per-epoch for each domain: 60.69 -> min = 60.69
[37m[36mINFO[0m[0m 03/15 06:04:32 | # of params = 23641217
[37m[36mINFO[0m[0m 03/15 06:06:16 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/15 06:06:16 | 0.025878    0.023585    0.044284    0.037113    4.198364    0.044284    0.037113    0.026060    0.024055    0.018300    0.020293    0.033276    0.026406    0           0.000000    4.231345    1.040084    102.621543 
[37m[36mINFO[0m[0m 03/15 06:08:44 | 0.498923    0.493818    0.820803    0.645361    1.501662    0.820803    0.645361    0.376575    0.386025    0.500000    0.492672    0.620195    0.602755    200         3.295572    1.724292    0.237028    100.632285 
[37m[36mINFO[0m[0m 03/15 06:11:10 | 0.519458    0.495644    0.877961    0.680412    1.388193    0.877961    0.680412    0.410939    0.391753    0.530968    0.506201    0.616466    0.588978    400         6.591143    0.436110    0.223008    101.335049 
[37m[36mINFO[0m[0m 03/15 06:13:36 | 0.507607    0.498365    0.930484    0.723711    1.577007    0.930484    0.723711    0.371993    0.381443    0.533502    0.500564    0.617326    0.613088    600         9.886715    0.301099    0.220743    102.086879 
[37m[36mINFO[0m[0m 03/15 06:16:04 | 0.534970    0.518892    0.966529    0.678351    1.364259    0.966529    0.678351    0.399198    0.400916    0.558840    0.520857    0.646873    0.634902    800         13.182286   0.183249    0.228988    101.540752 
[37m[36mINFO[0m[0m 03/15 06:18:31 | 0.538214    0.519251    0.972709    0.723711    1.503371    0.972709    0.723711    0.418671    0.413517    0.558277    0.523112    0.637694    0.621125    1000        16.477858   0.098808    0.226885    101.430650 
[37m[36mINFO[0m[0m 03/15 06:20:59 | 0.537568    0.528373    0.973223    0.678351    1.619502    0.973223    0.678351    0.405212    0.405498    0.555743    0.534386    0.651750    0.645235    1200        19.773429   0.072145    0.225170    103.237645 
[37m[36mINFO[0m[0m 03/15 06:23:29 | 0.563932    0.540806    0.986612    0.703093    1.689454    0.986612    0.703093    0.433562    0.427262    0.587838    0.563698    0.670396    0.631458    1400        23.069001   0.063902    0.223136    105.114553 
[37m[36mINFO[0m[0m 03/15 06:25:56 | 0.547068    0.528806    0.977858    0.715464    1.604690    0.977858    0.715464    0.429553    0.421535    0.563345    0.524239    0.648308    0.640643    1600        26.364573   0.047545    0.227028    101.585330 
[37m[36mINFO[0m[0m 03/15 06:28:21 | 0.545234    0.521889    0.992791    0.734021    1.409692    0.992791    0.734021    0.405212    0.395189    0.568412    0.532131    0.662077    0.638347    1800        29.660144   0.047925    0.226252    100.117584 
[37m[36mINFO[0m[0m 03/15 06:30:51 | 0.570114    0.552421    0.995881    0.752577    1.466267    0.995881    0.752577    0.451604    0.451317    0.576295    0.538895    0.682444    0.667049    2000        32.955716   0.031617    0.231606    103.732445 
[37m[36mINFO[0m[0m 03/15 06:33:18 | 0.543135    0.531416    0.992276    0.734021    1.387576    0.992276    0.734021    0.434708    0.421535    0.549831    0.535513    0.644865    0.637199    2200        36.251287   0.020787    0.226102    101.603185 
[37m[36mINFO[0m[0m 03/15 06:35:45 | 0.557093    0.541746    0.975283    0.690722    1.766629    0.975283    0.690722    0.444731    0.460481    0.564471    0.531003    0.662077    0.633754    2400        39.546859   0.033077    0.228436    101.255853 
[37m[36mINFO[0m[0m 03/15 06:38:14 | 0.551717    0.530381    0.990216    0.725773    1.513259    0.990216    0.725773    0.441008    0.426117    0.552928    0.516347    0.661216    0.648680    2600        42.842430   0.046355    0.235164    101.850396 
[37m[36mINFO[0m[0m 03/15 06:40:44 | 0.559503    0.546574    0.994336    0.731959    1.407803    0.994336    0.731959    0.434708    0.418099    0.577421    0.560316    0.666380    0.661309    2800        46.138002   0.021902    0.228282    104.863657 
[37m[36mINFO[0m[0m 03/15 06:43:14 | 0.562441    0.550090    0.993821    0.721649    1.665168    0.993821    0.721649    0.440149    0.442153    0.581081    0.545660    0.666093    0.662457    3000        49.433574   0.019487    0.228190    103.745673 
[37m[36mINFO[0m[0m 03/15 06:45:42 | 0.551268    0.534078    0.988671    0.721649    1.852967    0.988671    0.721649    0.439863    0.415808    0.563626    0.538895    0.650316    0.647532    3200        52.729145   0.012164    0.230432    102.498707 
[37m[36mINFO[0m[0m 03/15 06:48:13 | 0.543972    0.524206    0.986097    0.707216    1.543448    0.986097    0.707216    0.421821    0.413517    0.554617    0.526494    0.655479    0.632606    3400        56.024717   0.031634    0.229939    104.498729 
[37m[36mINFO[0m[0m 03/15 06:50:37 | 0.565031    0.552345    0.994336    0.734021    1.464494    0.994336    0.734021    0.441867    0.460481    0.579673    0.550169    0.673551    0.646383    3600        59.320288   0.027373    0.225598    99.279783  
[37m[36mINFO[0m[0m 03/15 06:53:06 | 0.577898    0.556491    0.995881    0.744330    1.631739    0.995881    0.744330    0.461054    0.452463    0.584459    0.561443    0.688181    0.655568    3800        62.615860   0.010246    0.229918    102.883467 
[37m[36mINFO[0m[0m 03/15 06:55:34 | 0.569456    0.553500    0.995366    0.744330    1.784289    0.995366    0.744330    0.451604    0.442153    0.574606    0.551297    0.682157    0.667049    4000        65.911432   0.006157    0.228618    102.396130 
[37m[36mINFO[0m[0m 03/15 06:57:59 | 0.564688    0.554275    0.995881    0.734021    1.759400    0.995881    0.734021    0.446449    0.457045    0.572917    0.547914    0.674699    0.657865    4200        69.207003   0.006658    0.222756    100.092785 
[37m[36mINFO[0m[0m 03/15 07:00:25 | 0.578816    0.567174    0.995881    0.754639    1.711747    0.995881    0.754639    0.451031    0.450172    0.591498    0.567080    0.693919    0.684271    4400        72.502575   0.007957    0.225948    101.272127 
[37m[36mINFO[0m[0m 03/15 07:02:51 | 0.567428    0.564105    0.995366    0.758763    1.659894    0.995366    0.758763    0.439576    0.451317    0.578829    0.568207    0.683878    0.672790    4600        75.798146   0.007756    0.223566    100.959671 
[37m[36mINFO[0m[0m 03/15 07:05:19 | 0.551487    0.532500    0.985582    0.719588    1.855527    0.985582    0.719588    0.444158    0.431844    0.574043    0.544532    0.636259    0.621125    4800        79.093718   0.011526    0.226791    102.612020 
[37m[36mINFO[0m[0m 03/15 07:07:49 | 0.548519    0.526865    0.994851    0.725773    1.683383    0.994851    0.725773    0.425258    0.420389    0.561092    0.528749    0.659208    0.631458    5000        82.389289   0.026572    0.234743    102.965919 
[37m[36mINFO[0m[0m 03/15 07:07:49 | Cumulative gradient change saved at train_output/OfficeHome/GENIE/[1, 2, 3]/250315_06-04-31_resnet50_adam/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/15 07:07:50 | ---
[37m[36mINFO[0m[0m 03/15 07:07:50 | test-domain validation(oracle) = 57.882%
[37m[36mINFO[0m[0m 03/15 07:07:50 | training-domain validation(iid) = 56.743%
[37m[36mINFO[0m[0m 03/15 07:07:50 | last = 54.852%
[37m[36mINFO[0m[0m 03/15 07:07:50 | last (inD) = 72.577%
[37m[36mINFO[0m[0m 03/15 07:07:50 | training-domain validation (iid, inD) = 75.876%
[37m[36mINFO[0m[0m 03/15 07:07:50 | === Summary ===
[37m[36mINFO[0m[0m 03/15 07:07:50 | Command: /jsm0707/GENIE/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm GENIE --test_envs 1 2 3 --dataset OfficeHome
[37m[36mINFO[0m[0m 03/15 07:07:50 | Unique name: 250315_06-04-31_resnet50_adam
[37m[36mINFO[0m[0m 03/15 07:07:50 | Out path: train_output/OfficeHome/GENIE/[1, 2, 3]/250315_06-04-31_resnet50_adam
[37m[36mINFO[0m[0m 03/15 07:07:50 | Algorithm: GENIE
[37m[36mINFO[0m[0m 03/15 07:07:50 | Dataset: OfficeHome
