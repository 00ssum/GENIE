[37m[36mINFO[0m[0m 03/15 01:50:12 | Command :: /jsm0707/GENIE/train_all.py B_OfficeHome1_adam config/resnet50_adam.yaml --trial_seed 1 --hparams_seed 9 --algorithm GENIE --test_envs 1 --dataset OfficeHome
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: GENIE
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_adam.yaml']
	data_dir: data
	dataset: OfficeHome
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 9
	in_domain: False
	model_save: None
	mpa: False
	name: B_OfficeHome1_adam
	out_dir: train_output/OfficeHome/GENIE/[1]/250315_01-50-12_B_OfficeHome1_adam
	out_root: train_output/OfficeHome/GENIE/[1]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [1]
	trial_seed: 1
	unique_name: 250315_01-50-12_B_OfficeHome1_adam
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.5
	class_balanced: False
	optimizer: adam
	freeze_bn: False
	pretrained: True
	lr: 2.7532223448653515e-05
	batch_size: 36
	weight_decay: 0.007511403320794324
	momentum: 0.9872565509707083
	convergence_rate: 0.019543659090931836
	moving_avg: 0.900758517723229
	p: 0.5423165174183379
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[OfficeHome] #envs=4, #classes=65
	env0: A (#2427)
	env1: C (#4365)
	env2: P (#4439)
	env3: R (#4357)

[37m[36mINFO[0m[0m 03/15 01:50:12 | n_steps = 5001
[37m[36mINFO[0m[0m 03/15 01:50:12 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/15 01:50:12 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/15 01:50:12 | 
[37m[36mINFO[0m[0m 03/15 01:50:12 | Testenv name escaping te_C -> te_C
[37m[36mINFO[0m[0m 03/15 01:50:12 | Test envs = [1], name = te_C
[37m[36mINFO[0m[0m 03/15 01:50:12 | Train environments: [0, 2, 3], Test environments: [1]
[37m[36mINFO[0m[0m 03/15 01:50:12 | Batch sizes for each domain: [36, 0, 36, 36] (total=108)
[37m[36mINFO[0m[0m 03/15 01:50:12 | steps-per-epoch for each domain: 53.94, 98.67, 96.83 -> min = 53.94
[37m[36mINFO[0m[0m 03/15 01:50:13 | # of params = 23641217
[37m[36mINFO[0m[0m 03/15 01:52:15 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/15 01:52:15 | 0.013173    0.017182    0.019166    0.015336    4.195669    0.024717    0.018557    0.013173    0.017182    0.010980    0.005637    0.021801    0.021814    0           0.000000    4.376812    1.202999    121.494044 
[37m[36mINFO[0m[0m 03/15 01:56:22 | 0.489691    0.500573    0.821539    0.773466    0.794047    0.795572    0.717526    0.489691    0.500573    0.844032    0.806088    0.825014    0.796785    200         3.707518    1.559767    0.624862    121.240914 
[37m[36mINFO[0m[0m 03/15 02:00:27 | 0.534651    0.544101    0.895164    0.822612    0.658633    0.887745    0.775258    0.534651    0.544101    0.909910    0.860203    0.887837    0.832377    400         7.415036    0.573595    0.640335    117.681605 
[37m[36mINFO[0m[0m 03/15 02:04:32 | 0.530641    0.544101    0.930066    0.822708    0.664862    0.922245    0.779381    0.530641    0.544101    0.944257    0.881623    0.923695    0.807118    600         11.122554   0.365348    0.628891    119.099013 
[37m[36mINFO[0m[0m 03/15 02:08:36 | 0.540378    0.540664    0.938219    0.809540    0.714575    0.940268    0.754639    0.540378    0.540664    0.952703    0.872604    0.921687    0.801378    800         14.830072   0.267506    0.613952    120.594653 
[37m[36mINFO[0m[0m 03/15 02:12:43 | 0.528351    0.531501    0.961067    0.848981    0.634174    0.968589    0.800000    0.528351    0.531501    0.964527    0.900789    0.950086    0.846154    1000        18.537590   0.202759    0.628109    121.751216 
[37m[36mINFO[0m[0m 03/15 02:16:50 | 0.533792    0.534937    0.968494    0.830720    0.689831    0.976313    0.767010    0.533792    0.534937    0.968468    0.899662    0.960700    0.825488    1200        22.245108   0.153037    0.627091    121.288027 
[37m[36mINFO[0m[0m 03/15 02:20:53 | 0.546964    0.542955    0.974200    0.848357    0.669424    0.981977    0.806186    0.546964    0.542955    0.969595    0.901917    0.971027    0.836969    1400        25.952626   0.137734    0.619241    119.610650 
[37m[36mINFO[0m[0m 03/15 02:24:52 | 0.553265    0.555556    0.979073    0.847762    0.719929    0.985582    0.802062    0.553265    0.555556    0.978604    0.899662    0.973035    0.841561    1600        29.660144   0.114310    0.613399    116.233490 
[37m[36mINFO[0m[0m 03/15 02:28:48 | 0.553551    0.554410    0.987959    0.854154    0.656528    0.991761    0.814433    0.553551    0.554410    0.987894    0.904171    0.984223    0.843858    1800        33.367662   0.089967    0.580059    119.517349 
[37m[36mINFO[0m[0m 03/15 02:32:50 | 0.527491    0.530355    0.988618    0.853349    0.675121    0.991761    0.793814    0.527491    0.530355    0.989583    0.913191    0.984509    0.853042    2000        37.075180   0.071809    0.607054    121.015392 
[37m[36mINFO[0m[0m 03/15 02:36:52 | 0.537801    0.539519    0.981534    0.843646    0.748926    0.982492    0.797938    0.537801    0.539519    0.986205    0.909808    0.975904    0.823192    2200        40.782698   0.070854    0.609777    119.930922 
[37m[36mINFO[0m[0m 03/15 02:41:07 | 0.530355    0.520046    0.988590    0.848252    0.773347    0.990216    0.797938    0.530355    0.520046    0.988176    0.907554    0.987378    0.839265    2400        44.490216   0.060417    0.640503    126.652338 
[37m[36mINFO[0m[0m 03/15 02:45:14 | 0.530928    0.536082    0.987273    0.839436    0.791383    0.987127    0.779381    0.530928    0.536082    0.988176    0.899662    0.986517    0.839265    2600        48.197734   0.057008    0.638793    119.284347 
[37m[36mINFO[0m[0m 03/15 02:49:19 | 0.542955    0.528064    0.992045    0.849604    0.732254    0.994336    0.804124    0.542955    0.528064    0.991554    0.898534    0.990247    0.846154    2800        51.905252   0.054488    0.634540    118.673922 
[37m[36mINFO[0m[0m 03/15 02:53:29 | 0.551833    0.538373    0.988268    0.843624    0.738662    0.991246    0.789691    0.551833    0.538373    0.987613    0.901917    0.985944    0.839265    3000        55.612770   0.046857    0.623208    124.620356 
[37m[36mINFO[0m[0m 03/15 02:57:29 | 0.518328    0.521191    0.990560    0.839513    0.851793    0.993306    0.787629    0.518328    0.521191    0.990709    0.898534    0.987665    0.832377    3200        59.320288   0.047693    0.620626    116.267724 
[37m[36mINFO[0m[0m 03/15 03:01:38 | 0.532932    0.548683    0.993023    0.848826    0.706699    0.993306    0.793814    0.532932    0.548683    0.994369    0.901917    0.991394    0.850746    3400        63.027806   0.039682    0.643855    120.286310 
[37m[36mINFO[0m[0m 03/15 03:05:41 | 0.545246    0.545246    0.992114    0.851980    0.736572    0.994851    0.800000    0.545246    0.545246    0.992680    0.910936    0.988812    0.845006    3600        66.735324   0.037447    0.617415    119.724326 
[37m[36mINFO[0m[0m 03/15 03:09:38 | 0.558992    0.537228    0.992692    0.843340    0.835767    0.992276    0.787629    0.558992    0.537228    0.992399    0.898534    0.993402    0.843858    3800        70.442842   0.036016    0.603973    115.721868 
[37m[36mINFO[0m[0m 03/15 03:13:38 | 0.528923    0.517755    0.993707    0.847305    0.794381    0.992791    0.781443    0.528923    0.517755    0.995214    0.914318    0.993115    0.846154    4000        74.150360   0.035990    0.609802    117.699902 
[37m[36mINFO[0m[0m 03/15 03:17:41 | 0.537228    0.546392    0.993473    0.847409    0.694367    0.994336    0.800000    0.537228    0.546392    0.992680    0.907554    0.993402    0.834673    4200        77.857878   0.040250    0.626002    118.011095 
[37m[36mINFO[0m[0m 03/15 03:21:47 | 0.546678    0.554410    0.993770    0.846935    0.893232    0.993821    0.791753    0.546678    0.554410    0.994088    0.910936    0.993402    0.838117    4400        81.565396   0.023515    0.620517    121.927505 
[37m[36mINFO[0m[0m 03/15 03:25:42 | 0.552405    0.554410    0.995140    0.852299    0.755966    0.995366    0.802062    0.552405    0.554410    0.994932    0.908681    0.995123    0.846154    4600        85.272915   0.031282    0.589660    116.962998 
[37m[36mINFO[0m[0m 03/15 03:29:50 | 0.558419    0.549828    0.994776    0.853945    0.739755    0.994851    0.797938    0.558419    0.549828    0.995214    0.915445    0.994263    0.848450    4800        88.980433   0.025318    0.624562    123.131459 
[37m[36mINFO[0m[0m 03/15 03:33:52 | 0.546392    0.541810    0.994038    0.849734    0.855047    0.994336    0.789691    0.546392    0.541810    0.994088    0.904171    0.993689    0.855339    5000        92.687951   0.026186    0.607435    120.282426 
[37m[36mINFO[0m[0m 03/15 03:33:52 | Cumulative gradient change saved at train_output/OfficeHome/GENIE/[1]/250315_01-50-12_B_OfficeHome1_adam/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/15 03:33:53 | ---
[37m[36mINFO[0m[0m 03/15 03:33:53 | test-domain validation(oracle) = 55.326%
[37m[36mINFO[0m[0m 03/15 03:33:53 | training-domain validation(iid) = 55.355%
[37m[36mINFO[0m[0m 03/15 03:33:53 | last = 54.639%
[37m[36mINFO[0m[0m 03/15 03:33:53 | last (inD) = 84.973%
[37m[36mINFO[0m[0m 03/15 03:33:53 | training-domain validation (iid, inD) = 85.415%
[37m[36mINFO[0m[0m 03/15 03:33:53 | === Summary ===
[37m[36mINFO[0m[0m 03/15 03:33:53 | Command: /jsm0707/GENIE/train_all.py B_OfficeHome1_adam config/resnet50_adam.yaml --trial_seed 1 --hparams_seed 9 --algorithm GENIE --test_envs 1 --dataset OfficeHome
[37m[36mINFO[0m[0m 03/15 03:33:53 | Unique name: 250315_01-50-12_B_OfficeHome1_adam
[37m[36mINFO[0m[0m 03/15 03:33:53 | Out path: train_output/OfficeHome/GENIE/[1]/250315_01-50-12_B_OfficeHome1_adam
[37m[36mINFO[0m[0m 03/15 03:33:53 | Algorithm: GENIE
[37m[36mINFO[0m[0m 03/15 03:33:53 | Dataset: OfficeHome
