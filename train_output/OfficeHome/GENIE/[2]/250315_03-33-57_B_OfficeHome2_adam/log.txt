[37m[36mINFO[0m[0m 03/15 03:33:57 | Command :: /jsm0707/GENIE/train_all.py B_OfficeHome2_adam config/resnet50_adam.yaml --trial_seed 0 --hparams_seed 15 --algorithm GENIE --test_envs 2 --dataset OfficeHome
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: GENIE
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_adam.yaml']
	data_dir: data
	dataset: OfficeHome
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 15
	in_domain: False
	model_save: None
	mpa: False
	name: B_OfficeHome2_adam
	out_dir: train_output/OfficeHome/GENIE/[2]/250315_03-33-57_B_OfficeHome2_adam
	out_root: train_output/OfficeHome/GENIE/[2]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [2]
	trial_seed: 0
	unique_name: 250315_03-33-57_B_OfficeHome2_adam
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.5
	class_balanced: False
	optimizer: adam
	freeze_bn: False
	pretrained: True
	lr: 0.00010661763546249327
	batch_size: 14
	weight_decay: 9.086452814323981e-06
	momentum: 0.846320346520143
	convergence_rate: 0.001625681705546367
	moving_avg: 0.9229441284737897
	p: 0.5950371143099659
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[OfficeHome] #envs=4, #classes=65
	env0: A (#2427)
	env1: C (#4365)
	env2: P (#4439)
	env3: R (#4357)

[37m[36mINFO[0m[0m 03/15 03:33:57 | n_steps = 5001
[37m[36mINFO[0m[0m 03/15 03:33:57 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/15 03:33:57 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/15 03:33:57 | 
[37m[36mINFO[0m[0m 03/15 03:33:57 | Testenv name escaping te_P -> te_P
[37m[36mINFO[0m[0m 03/15 03:33:57 | Test envs = [2], name = te_P
[37m[36mINFO[0m[0m 03/15 03:33:57 | Train environments: [0, 1, 3], Test environments: [2]
[37m[36mINFO[0m[0m 03/15 03:33:57 | Batch sizes for each domain: [14, 14, 0, 14] (total=42)
[37m[36mINFO[0m[0m 03/15 03:33:57 | steps-per-epoch for each domain: 138.71, 249.43, 249.00 -> min = 138.71
[37m[36mINFO[0m[0m 03/15 03:33:58 | # of params = 23641217
[37m[36mINFO[0m[0m 03/15 03:35:58 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/15 03:35:58 | 0.003378    0.004510    0.015257    0.013912    4.263314    0.018538    0.016495    0.011168    0.006873    0.003378    0.004510    0.016064    0.018370    0           0.000000    4.396195    1.046043    118.562136 
[37m[36mINFO[0m[0m 03/15 03:38:47 | 0.146959    0.151071    0.186036    0.181731    3.750423    0.227600    0.220619    0.141753    0.147766    0.146959    0.151071    0.188755    0.176808    200         1.441813    4.069183    0.250914    119.147263 
[37m[36mINFO[0m[0m 03/15 03:41:37 | 0.562218    0.568207    0.585886    0.576340    1.730078    0.587024    0.595876    0.527491    0.515464    0.562218    0.568207    0.643144    0.617681    400         2.883625    2.958248    0.252779    119.778106 
[37m[36mINFO[0m[0m 03/15 03:44:30 | 0.673423    0.662909    0.708828    0.677832    1.230038    0.701339    0.692784    0.657216    0.619702    0.673423    0.662909    0.767929    0.721010    600         4.325438    1.742904    0.254463    121.588769 
[37m[36mINFO[0m[0m 03/15 03:47:16 | 0.701014    0.698985    0.756346    0.714219    1.070872    0.761071    0.721649    0.705326    0.651775    0.701014    0.698985    0.802639    0.769231    800         5.767250    1.272081    0.246803    117.046755 
[37m[36mINFO[0m[0m 03/15 03:50:03 | 0.733390    0.715896    0.781128    0.728443    0.994287    0.795572    0.740206    0.721649    0.649485    0.733390    0.715896    0.826162    0.795637    1000        7.209063    1.104263    0.244316    117.694847 
[37m[36mINFO[0m[0m 03/15 03:52:56 | 0.744088    0.745209    0.807624    0.741279    0.929736    0.827497    0.734021    0.753723    0.684994    0.744088    0.745209    0.841652    0.804822    1200        8.650875    0.993207    0.251623    122.861777 
[37m[36mINFO[0m[0m 03/15 03:55:48 | 0.733390    0.719278    0.824753    0.742263    0.918580    0.844490    0.738144    0.770332    0.695304    0.733390    0.719278    0.859438    0.793341    1400        10.092688   0.819880    0.247680    122.136162 
[37m[36mINFO[0m[0m 03/15 03:58:37 | 0.750845    0.740699    0.843344    0.761299    0.888686    0.865602    0.740206    0.798969    0.722795    0.750845    0.740699    0.865462    0.820896    1600        11.534501   0.779154    0.254020    118.665406 
[37m[36mINFO[0m[0m 03/15 04:01:30 | 0.751126    0.723788    0.850376    0.756101    0.882522    0.866632    0.746392    0.808133    0.707904    0.751126    0.723788    0.876363    0.814007    1800        12.976313   0.705809    0.267869    119.441402 
[37m[36mINFO[0m[0m 03/15 04:04:18 | 0.747748    0.724915    0.867557    0.766878    0.837334    0.892379    0.764948    0.821019    0.709049    0.747748    0.724915    0.889271    0.826636    2000        14.418126   0.651628    0.248349    118.377312 
[37m[36mINFO[0m[0m 03/15 04:07:11 | 0.759572    0.742954    0.878857    0.773294    0.835111    0.901648    0.767010    0.842497    0.723940    0.759572    0.742954    0.892427    0.828932    2200        15.859938   0.575873    0.254082    122.126583 
[37m[36mINFO[0m[0m 03/15 04:10:03 | 0.756194    0.742954    0.886321    0.765115    0.866512    0.914006    0.750515    0.846220    0.727377    0.756194    0.742954    0.898738    0.817451    2400        17.301751   0.561511    0.252224    121.236082 
[37m[36mINFO[0m[0m 03/15 04:12:54 | 0.759291    0.754228    0.894264    0.781321    0.838692    0.921215    0.756701    0.857675    0.746850    0.759291    0.754228    0.903901    0.840413    2600        18.743563   0.521524    0.248065    122.036675 
[37m[36mINFO[0m[0m 03/15 04:15:47 | 0.757320    0.758737    0.905625    0.763353    0.854315    0.934089    0.746392    0.867698    0.733104    0.757320    0.758737    0.915089    0.810563    2800        20.185376   0.481997    0.251782    121.888682 
[37m[36mINFO[0m[0m 03/15 04:18:34 | 0.766610    0.753100    0.910512    0.780699    0.843796    0.941298    0.773196    0.871134    0.743414    0.766610    0.753100    0.919105    0.825488    3000        21.627188   0.432387    0.249756    116.990243 
[37m[36mINFO[0m[0m 03/15 04:21:24 | 0.763232    0.740699    0.914872    0.777112    0.875752    0.937178    0.756701    0.878580    0.746850    0.763232    0.740699    0.928858    0.827784    3200        23.069001   0.422594    0.245000    121.587293 
[37m[36mINFO[0m[0m 03/15 04:24:11 | 0.768863    0.747463    0.919049    0.773826    0.882407    0.942842    0.752577    0.889462    0.743414    0.768863    0.747463    0.924842    0.825488    3400        24.510814   0.400254    0.232979    120.611678 
[37m[36mINFO[0m[0m 03/15 04:27:00 | 0.770833    0.748591    0.932049    0.786664    0.832475    0.960350    0.767010    0.902635    0.756014    0.770833    0.748591    0.933161    0.836969    3600        25.952626   0.373191    0.250718    118.801944 
[37m[36mINFO[0m[0m 03/15 04:29:46 | 0.766329    0.751973    0.935868    0.784827    0.846803    0.965499    0.764948    0.904066    0.758305    0.766329    0.751973    0.938038    0.831228    3800        27.394439   0.327185    0.244384    116.834627 
[37m[36mINFO[0m[0m 03/15 04:32:37 | 0.760417    0.737317    0.934624    0.784149    0.902162    0.968074    0.762887    0.901775    0.746850    0.760417    0.737317    0.934022    0.842710    4000        28.836251   0.324841    0.243750    122.106836 
[37m[36mINFO[0m[0m 03/15 04:35:21 | 0.766610    0.747463    0.941942    0.787502    0.900476    0.963955    0.764948    0.919817    0.764032    0.766610    0.747463    0.942054    0.833525    4200        30.278064   0.301952    0.230313    117.940927 
[37m[36mINFO[0m[0m 03/15 04:38:08 | 0.775338    0.744081    0.941025    0.786349    0.904809    0.965499    0.775258    0.914662    0.759450    0.775338    0.744081    0.942915    0.824340    4400        31.719876   0.283589    0.238023    119.010893 
[37m[36mINFO[0m[0m 03/15 04:40:51 | 0.773367    0.756483    0.944847    0.787730    0.852966    0.965499    0.769072    0.919817    0.761741    0.773367    0.756483    0.949225    0.832377    4600        33.161689   0.271758    0.234109    116.885912 
[37m[36mINFO[0m[0m 03/15 04:43:36 | 0.778435    0.744081    0.952636    0.789108    0.921828    0.976828    0.773196    0.926403    0.757159    0.778435    0.744081    0.954676    0.836969    4800        34.603502   0.247610    0.230564    118.284389 
[37m[36mINFO[0m[0m 03/15 04:46:20 | 0.778435    0.746336    0.956244    0.793462    0.862712    0.982492    0.769072    0.927835    0.773196    0.778435    0.746336    0.958405    0.838117    5000        36.045314   0.259467    0.230219    117.949700 
[37m[36mINFO[0m[0m 03/15 04:46:20 | Cumulative gradient change saved at train_output/OfficeHome/GENIE/[2]/250315_03-33-57_B_OfficeHome2_adam/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/15 04:46:21 | ---
[37m[36mINFO[0m[0m 03/15 04:46:21 | test-domain validation(oracle) = 75.732%
[37m[36mINFO[0m[0m 03/15 04:46:21 | training-domain validation(iid) = 77.843%
[37m[36mINFO[0m[0m 03/15 04:46:21 | last = 77.843%
[37m[36mINFO[0m[0m 03/15 04:46:21 | last (inD) = 79.346%
[37m[36mINFO[0m[0m 03/15 04:46:21 | training-domain validation (iid, inD) = 79.346%
[37m[36mINFO[0m[0m 03/15 04:46:21 | === Summary ===
[37m[36mINFO[0m[0m 03/15 04:46:21 | Command: /jsm0707/GENIE/train_all.py B_OfficeHome2_adam config/resnet50_adam.yaml --trial_seed 0 --hparams_seed 15 --algorithm GENIE --test_envs 2 --dataset OfficeHome
[37m[36mINFO[0m[0m 03/15 04:46:21 | Unique name: 250315_03-33-57_B_OfficeHome2_adam
[37m[36mINFO[0m[0m 03/15 04:46:21 | Out path: train_output/OfficeHome/GENIE/[2]/250315_03-33-57_B_OfficeHome2_adam
[37m[36mINFO[0m[0m 03/15 04:46:21 | Algorithm: GENIE
[37m[36mINFO[0m[0m 03/15 04:46:21 | Dataset: OfficeHome
