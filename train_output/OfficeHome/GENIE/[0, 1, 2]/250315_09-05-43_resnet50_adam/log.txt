[37m[36mINFO[0m[0m 03/15 09:05:43 | Command :: /jsm0707/GENIE/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm GENIE --test_envs 0 1 2 --dataset OfficeHome
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: GENIE
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_adam.yaml']
	data_dir: data
	dataset: OfficeHome
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_adam
	out_dir: train_output/OfficeHome/GENIE/[0, 1, 2]/250315_09-05-43_resnet50_adam
	out_root: train_output/OfficeHome/GENIE/[0, 1, 2]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 1, 2]
	trial_seed: 0
	unique_name: 250315_09-05-43_resnet50_adam
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: adam
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	momentum: 0.9
	convergence_rate: 0.015
	moving_avg: 0.95
	p: 0.4
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[OfficeHome] #envs=4, #classes=65
	env0: A (#2427)
	env1: C (#4365)
	env2: P (#4439)
	env3: R (#4357)

[37m[36mINFO[0m[0m 03/15 09:05:43 | n_steps = 5001
[37m[36mINFO[0m[0m 03/15 09:05:43 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/15 09:05:43 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/15 09:05:43 | 
[37m[36mINFO[0m[0m 03/15 09:05:43 | Testenv name escaping te_A_C_P -> te_A_C_P
[37m[36mINFO[0m[0m 03/15 09:05:43 | Test envs = [0, 1, 2], name = te_A_C_P
[37m[36mINFO[0m[0m 03/15 09:05:43 | Train environments: [3], Test environments: [0, 1, 2]
[37m[36mINFO[0m[0m 03/15 09:05:43 | Batch sizes for each domain: [0, 0, 0, 32] (total=32)
[37m[36mINFO[0m[0m 03/15 09:05:43 | steps-per-epoch for each domain: 108.94 -> min = 108.94
[37m[36mINFO[0m[0m 03/15 09:05:45 | # of params = 23641217
[37m[36mINFO[0m[0m 03/15 09:07:31 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/15 09:07:31 | 0.026590    0.027307    0.026104    0.022962    4.195257    0.031411    0.032990    0.029496    0.028637    0.018863    0.020293    0.026104    0.022962    0           0.000000    4.254128    2.356954    104.271004 
[37m[36mINFO[0m[0m 03/15 09:11:02 | 0.519430    0.502503    0.819564    0.742824    0.920143    0.501545    0.507216    0.392612    0.375716    0.664133    0.624577    0.819564    0.742824    200         1.835915    1.479208    0.530678    105.006621 
[37m[36mINFO[0m[0m 03/15 09:14:27 | 0.544564    0.530441    0.884395    0.774971    0.877556    0.537590    0.546392    0.439290    0.418099    0.656813    0.626832    0.884395    0.774971    400         3.671830    0.477280    0.514802    101.485331 
[37m[36mINFO[0m[0m 03/15 09:17:59 | 0.545426    0.534850    0.912507    0.777268    0.953456    0.517508    0.521649    0.431271    0.395189    0.687500    0.687711    0.912507    0.777268    600         5.507745    0.331254    0.543129    103.549158 
[37m[36mINFO[0m[0m 03/15 09:21:27 | 0.565347    0.556441    0.936604    0.796785    0.889842    0.543769    0.534021    0.447881    0.429553    0.704392    0.705750    0.936604    0.796785    800         7.343660    0.232840    0.515404    104.334136 
[37m[36mINFO[0m[0m 03/15 09:24:53 | 0.575032    0.557991    0.954389    0.774971    0.906164    0.553038    0.542268    0.452463    0.415808    0.719595    0.715896    0.954389    0.774971    1000        9.179575    0.188397    0.508506    105.233953 
[37m[36mINFO[0m[0m 03/15 09:28:24 | 0.588512    0.576453    0.971314    0.805970    0.736543    0.571061    0.548454    0.479668    0.461627    0.714809    0.719278    0.971314    0.805970    1200        11.015491   0.162352    0.523427    106.147238 
[37m[36mINFO[0m[0m 03/15 09:31:57 | 0.564933    0.546098    0.973609    0.776119    0.926926    0.530896    0.525773    0.453036    0.414662    0.710867    0.697858    0.973609    0.776119    1400        12.851406   0.091958    0.532673    106.525322 
[37m[36mINFO[0m[0m 03/15 09:35:28 | 0.590858    0.568332    0.976190    0.777268    0.969120    0.554068    0.544330    0.502291    0.465063    0.716216    0.695603    0.976190    0.777268    1600        14.687321   0.083997    0.516312    106.892546 
[37m[36mINFO[0m[0m 03/15 09:38:57 | 0.572827    0.560836    0.969880    0.788749    1.017855    0.550463    0.560825    0.463345    0.423826    0.704673    0.697858    0.969880    0.788749    1800        16.523236   0.095540    0.523214    105.311297 
[37m[36mINFO[0m[0m 03/15 09:42:21 | 0.596289    0.578635    0.985944    0.814007    0.952738    0.572091    0.558763    0.483104    0.437572    0.733671    0.739572    0.985944    0.814007    2000        18.359151   0.058587    0.495393    104.164441 
[37m[36mINFO[0m[0m 03/15 09:45:42 | 0.569204    0.550991    0.983362    0.804822    0.968988    0.546344    0.538144    0.447022    0.418099    0.714245    0.696731    0.983362    0.804822    2200        20.195066   0.050288    0.486983    103.380846 
[37m[36mINFO[0m[0m 03/15 09:49:05 | 0.577244    0.583334    0.975330    0.808266    1.015281    0.559217    0.564948    0.446163    0.438717    0.726351    0.746336    0.975330    0.808266    2400        22.030981   0.056472    0.502095    103.438404 
[37m[36mINFO[0m[0m 03/15 09:52:31 | 0.598050    0.597692    0.988812    0.816303    0.911233    0.588054    0.612371    0.467640    0.449026    0.738457    0.731680    0.988812    0.816303    2600        23.866896   0.053569    0.518414    101.567728 
[37m[36mINFO[0m[0m 03/15 09:55:56 | 0.592633    0.570147    0.984223    0.804822    1.068825    0.567456    0.540206    0.474800    0.428408    0.735642    0.741826    0.984223    0.804822    2800        25.702811   0.033377    0.513816    102.687996 
[37m[36mINFO[0m[0m 03/15 09:59:25 | 0.607121    0.603854    0.989960    0.822044    1.044778    0.557673    0.569072    0.527205    0.506300    0.736486    0.736189    0.989960    0.822044    3000        27.538726   0.026522    0.532739    102.811572 
[37m[36mINFO[0m[0m 03/15 10:02:54 | 0.566892    0.558563    0.988239    0.804822    1.028020    0.544799    0.544330    0.427835    0.394044    0.728041    0.737317    0.988239    0.804822    3200        29.374641   0.035368    0.524028    103.847550 
[37m[36mINFO[0m[0m 03/15 10:06:24 | 0.595046    0.582196    0.987378    0.804822    1.038307    0.555613    0.546392    0.504582    0.469645    0.724944    0.730552    0.987378    0.804822    3400        31.210557   0.032565    0.530290    103.973936 
[37m[36mINFO[0m[0m 03/15 10:09:54 | 0.581280    0.574654    0.993689    0.810563    0.944471    0.569516    0.564948    0.453322    0.431844    0.721002    0.727170    0.993689    0.810563    3600        33.046472   0.037772    0.527889    104.729467 
[37m[36mINFO[0m[0m 03/15 10:13:19 | 0.602713    0.586366    0.994263    0.817451    1.069991    0.577240    0.556701    0.502577    0.466208    0.728322    0.736189    0.994263    0.817451    3800        34.882387   0.030344    0.500504    104.167878 
[37m[36mINFO[0m[0m 03/15 10:16:42 | 0.565161    0.551214    0.979633    0.785304    1.054997    0.548404    0.542268    0.440435    0.413517    0.706644    0.697858    0.979633    0.785304    4000        36.718302   0.035804    0.506442    102.167988 
[37m[36mINFO[0m[0m 03/15 10:20:05 | 0.591158    0.578999    0.992828    0.830080    0.816566    0.585994    0.579381    0.448740    0.414662    0.738739    0.742954    0.992828    0.830080    4200        38.554217   0.029691    0.513718    99.670083  
[37m[36mINFO[0m[0m 03/15 10:23:30 | 0.583814    0.563278    0.993402    0.823192    1.052564    0.570546    0.554639    0.459049    0.422680    0.721847    0.712514    0.993402    0.823192    4400        40.390132   0.015680    0.504988    104.435960 
[37m[36mINFO[0m[0m 03/15 10:26:54 | 0.610465    0.593273    0.995697    0.828932    0.952096    0.579815    0.564948    0.510309    0.470790    0.741273    0.744081    0.995697    0.828932    4600        42.226047   0.012160    0.512605    101.477529 
[37m[36mINFO[0m[0m 03/15 10:30:19 | 0.573427    0.561337    0.991107    0.805970    1.115245    0.554583    0.558763    0.475945    0.435281    0.689752    0.689966    0.991107    0.805970    4800        44.061962   0.016573    0.510899    102.366402 
[37m[36mINFO[0m[0m 03/15 10:33:40 | 0.577625    0.574005    0.991968    0.808266    1.113682    0.552523    0.575258    0.460195    0.441008    0.720158    0.705750    0.991968    0.808266    5000        45.897877   0.020284    0.500215    101.516351 
[37m[36mINFO[0m[0m 03/15 10:33:40 | Cumulative gradient change saved at train_output/OfficeHome/GENIE/[0, 1, 2]/250315_09-05-43_resnet50_adam/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/15 10:33:42 | ---
[37m[36mINFO[0m[0m 03/15 10:33:42 | test-domain validation(oracle) = 60.712%
[37m[36mINFO[0m[0m 03/15 10:33:42 | training-domain validation(iid) = 59.116%
[37m[36mINFO[0m[0m 03/15 10:33:42 | last = 57.763%
[37m[36mINFO[0m[0m 03/15 10:33:42 | last (inD) = 80.827%
[37m[36mINFO[0m[0m 03/15 10:33:42 | training-domain validation (iid, inD) = 83.008%
[37m[36mINFO[0m[0m 03/15 10:33:42 | === Summary ===
[37m[36mINFO[0m[0m 03/15 10:33:42 | Command: /jsm0707/GENIE/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm GENIE --test_envs 0 1 2 --dataset OfficeHome
[37m[36mINFO[0m[0m 03/15 10:33:42 | Unique name: 250315_09-05-43_resnet50_adam
[37m[36mINFO[0m[0m 03/15 10:33:42 | Out path: train_output/OfficeHome/GENIE/[0, 1, 2]/250315_09-05-43_resnet50_adam
[37m[36mINFO[0m[0m 03/15 10:33:42 | Algorithm: GENIE
[37m[36mINFO[0m[0m 03/15 10:33:42 | Dataset: OfficeHome
