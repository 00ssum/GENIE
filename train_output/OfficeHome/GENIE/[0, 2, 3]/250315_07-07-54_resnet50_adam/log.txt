[37m[36mINFO[0m[0m 03/15 07:07:54 | Command :: /jsm0707/GENIE/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm GENIE --test_envs 0 2 3 --dataset OfficeHome
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: GENIE
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_adam.yaml']
	data_dir: data
	dataset: OfficeHome
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_adam
	out_dir: train_output/OfficeHome/GENIE/[0, 2, 3]/250315_07-07-54_resnet50_adam
	out_root: train_output/OfficeHome/GENIE/[0, 2, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 2, 3]
	trial_seed: 0
	unique_name: 250315_07-07-54_resnet50_adam
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: adam
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	momentum: 0.9
	convergence_rate: 0.015
	moving_avg: 0.95
	p: 0.4
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[OfficeHome] #envs=4, #classes=65
	env0: A (#2427)
	env1: C (#4365)
	env2: P (#4439)
	env3: R (#4357)

[37m[36mINFO[0m[0m 03/15 07:07:54 | n_steps = 5001
[37m[36mINFO[0m[0m 03/15 07:07:54 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/15 07:07:54 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/15 07:07:54 | 
[37m[36mINFO[0m[0m 03/15 07:07:54 | Testenv name escaping te_A_P_R -> te_A_P_R
[37m[36mINFO[0m[0m 03/15 07:07:54 | Test envs = [0, 2, 3], name = te_A_P_R
[37m[36mINFO[0m[0m 03/15 07:07:54 | Train environments: [1], Test environments: [0, 2, 3]
[37m[36mINFO[0m[0m 03/15 07:07:54 | Batch sizes for each domain: [0, 32, 0, 0] (total=32)
[37m[36mINFO[0m[0m 03/15 07:07:54 | steps-per-epoch for each domain: 109.12 -> min = 109.12
[37m[36mINFO[0m[0m 03/15 07:07:56 | # of params = 23641217
[37m[36mINFO[0m[0m 03/15 07:09:41 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/15 07:09:41 | 0.014409    0.011326    0.024341    0.021764    4.204776    0.019567    0.012371    0.024341    0.021764    0.007883    0.011274    0.015777    0.010333    0           0.000000    4.196661    1.352251    104.371100 
[37m[36mINFO[0m[0m 03/15 07:11:57 | 0.480036    0.494211    0.741123    0.603666    1.423923    0.394439    0.418557    0.741123    0.603666    0.512106    0.511838    0.533563    0.552239    200         1.832761    2.001382    0.154851    104.431888 
[37m[36mINFO[0m[0m 03/15 07:14:10 | 0.452355    0.439296    0.824170    0.649485    1.487171    0.377961    0.371134    0.824170    0.649485    0.482545    0.461105    0.496558    0.485649    400         3.665521    0.768975    0.138792    105.684901 
[37m[36mINFO[0m[0m 03/15 07:16:26 | 0.494608    0.499586    0.859966    0.659794    1.491047    0.421215    0.459794    0.859966    0.659794    0.511261    0.503946    0.551348    0.535017    600         5.498282    0.443950    0.165500    102.751358 
[37m[36mINFO[0m[0m 03/15 07:18:42 | 0.504701    0.522184    0.928981    0.737686    1.261263    0.406282    0.463918    0.928981    0.737686    0.547579    0.537768    0.560241    0.564868    800         7.331042    0.348880    0.152239    105.051114 
[37m[36mINFO[0m[0m 03/15 07:20:53 | 0.504296    0.520454    0.943013    0.729668    1.182326    0.409372    0.435052    0.943013    0.729668    0.547579    0.561443    0.555938    0.564868    1000        9.163803    0.232561    0.136746    104.536563 
[37m[36mINFO[0m[0m 03/15 07:23:07 | 0.509567    0.501468    0.936999    0.734250    1.315129    0.420185    0.447423    0.936999    0.734250    0.541104    0.523112    0.567413    0.533869    1200        10.996564   0.187954    0.154420    102.577371 
[37m[36mINFO[0m[0m 03/15 07:25:20 | 0.486489    0.491106    0.952176    0.737686    1.461967    0.384655    0.420619    0.952176    0.737686    0.518300    0.506201    0.556512    0.546498    1400        12.829324   0.170396    0.148366    103.452251 
[37m[36mINFO[0m[0m 03/15 07:27:37 | 0.512084    0.521062    0.951890    0.726231    1.596842    0.418641    0.484536    0.951890    0.726231    0.545608    0.531003    0.572002    0.547646    1600        14.662085   0.143824    0.158707    105.593814 
[37m[36mINFO[0m[0m 03/15 07:29:54 | 0.508459    0.516553    0.961340    0.727377    1.500036    0.410402    0.430928    0.961340    0.727377    0.548423    0.536640    0.566552    0.582090    1800        16.494845   0.129449    0.158597    105.084519 
[37m[36mINFO[0m[0m 03/15 07:32:07 | 0.518672    0.527817    0.964490    0.758305    1.273801    0.412976    0.461856    0.964490    0.758305    0.566160    0.568207    0.576879    0.553387    2000        18.327606   0.123916    0.134114    105.836867 
[37m[36mINFO[0m[0m 03/15 07:34:22 | 0.495321    0.487892    0.955899    0.729668    1.348046    0.410402    0.437113    0.955899    0.729668    0.524212    0.491545    0.551348    0.535017    2200        20.160367   0.112810    0.162708    102.857839 
[37m[36mINFO[0m[0m 03/15 07:36:36 | 0.513049    0.526402    0.975659    0.757159    1.391573    0.418126    0.472165    0.975659    0.757159    0.547297    0.547914    0.573723    0.559127    2400        21.993127   0.096605    0.157467    102.025741 
[37m[36mINFO[0m[0m 03/15 07:38:50 | 0.531480    0.531915    0.977950    0.769759    1.488993    0.432029    0.478351    0.977950    0.769759    0.573198    0.546787    0.589214    0.570608    2600        23.825888   0.071163    0.149190    104.772115 
[37m[36mINFO[0m[0m 03/15 07:41:05 | 0.513032    0.509606    0.975945    0.768614    1.342811    0.430484    0.443299    0.975945    0.768614    0.551239    0.532131    0.557372    0.553387    2800        25.658648   0.077616    0.156647    103.177442 
[37m[36mINFO[0m[0m 03/15 07:43:18 | 0.522150    0.529044    0.973654    0.746850    1.641889    0.434089    0.474227    0.973654    0.746850    0.569538    0.541150    0.562823    0.571757    3000        27.491409   0.065775    0.139871    105.042135 
[37m[36mINFO[0m[0m 03/15 07:45:32 | 0.529046    0.529378    0.978236    0.766323    1.494517    0.430999    0.430928    0.978236    0.766323    0.571227    0.567080    0.584911    0.590126    3200        29.324170   0.079175    0.156563    102.856043 
[37m[36mINFO[0m[0m 03/15 07:47:50 | 0.535645    0.532985    0.981386    0.758305    1.488381    0.440268    0.480412    0.981386    0.758305    0.575732    0.546787    0.590935    0.571757    3400        31.156930   0.057192    0.162606    105.343452 
[37m[36mINFO[0m[0m 03/15 07:50:03 | 0.522050    0.523586    0.978236    0.751432    1.388518    0.439753    0.478351    0.978236    0.751432    0.551239    0.532131    0.575158    0.560276    3600        32.989691   0.051695    0.146165    103.886299 
[37m[36mINFO[0m[0m 03/15 07:52:21 | 0.535132    0.524687    0.980813    0.772050    1.389834    0.443357    0.457732    0.980813    0.772050    0.577703    0.542277    0.584337    0.574053    3800        34.822451   0.050881    0.162066    105.837873 
[37m[36mINFO[0m[0m 03/15 07:54:37 | 0.528689    0.537336    0.982245    0.756014    1.480079    0.443357    0.486598    0.982245    0.756014    0.568412    0.547914    0.574297    0.577497    4000        36.655212   0.046696    0.157213    103.814982 
[37m[36mINFO[0m[0m 03/15 07:56:49 | 0.527661    0.519881    0.978522    0.767468    1.729513    0.445417    0.463918    0.978522    0.767468    0.567286    0.538895    0.570281    0.556831    4200        38.487973   0.043964    0.145470    103.117536 
[37m[36mINFO[0m[0m 03/15 07:59:05 | 0.521663    0.517101    0.980241    0.769759    1.377285    0.437693    0.468041    0.980241    0.769759    0.549268    0.529876    0.578026    0.553387    4400        40.320733   0.061334    0.156203    105.225871 
[37m[36mINFO[0m[0m 03/15 08:01:14 | 0.513327    0.505056    0.976804    0.757159    1.536222    0.423790    0.432990    0.976804    0.757159    0.559966    0.526494    0.556225    0.555683    4600        42.153494   0.053236    0.138768    101.125153 
[37m[36mINFO[0m[0m 03/15 08:03:30 | 0.543702    0.547520    0.979954    0.764032    1.581669    0.457261    0.509278    0.979954    0.764032    0.575450    0.556933    0.598394    0.576349    4800        43.986254   0.057340    0.158812    104.183343 
[37m[36mINFO[0m[0m 03/15 08:05:48 | 0.537381    0.545219    0.979954    0.777778    1.351033    0.444387    0.488660    0.979954    0.777778    0.578829    0.560316    0.588927    0.586682    5000        45.819015   0.049042    0.160099    105.945964 
[37m[36mINFO[0m[0m 03/15 08:05:48 | Cumulative gradient change saved at train_output/OfficeHome/GENIE/[0, 2, 3]/250315_07-07-54_resnet50_adam/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/15 08:05:50 | ---
[37m[36mINFO[0m[0m 03/15 08:05:50 | test-domain validation(oracle) = 54.370%
[37m[36mINFO[0m[0m 03/15 08:05:50 | training-domain validation(iid) = 53.738%
[37m[36mINFO[0m[0m 03/15 08:05:50 | last = 53.738%
[37m[36mINFO[0m[0m 03/15 08:05:50 | last (inD) = 77.778%
[37m[36mINFO[0m[0m 03/15 08:05:50 | training-domain validation (iid, inD) = 77.778%
[37m[36mINFO[0m[0m 03/15 08:05:50 | === Summary ===
[37m[36mINFO[0m[0m 03/15 08:05:50 | Command: /jsm0707/GENIE/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm GENIE --test_envs 0 2 3 --dataset OfficeHome
[37m[36mINFO[0m[0m 03/15 08:05:50 | Unique name: 250315_07-07-54_resnet50_adam
[37m[36mINFO[0m[0m 03/15 08:05:50 | Out path: train_output/OfficeHome/GENIE/[0, 2, 3]/250315_07-07-54_resnet50_adam
[37m[36mINFO[0m[0m 03/15 08:05:50 | Algorithm: GENIE
[37m[36mINFO[0m[0m 03/15 08:05:50 | Dataset: OfficeHome
