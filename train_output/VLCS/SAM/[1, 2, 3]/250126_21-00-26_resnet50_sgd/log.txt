[37m[36mINFO[0m[0m 01/26 21:00:26 | Command :: /jsm0707/Large-scale/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm SAM --test_envs 1 2 3 --dataset VLCS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: SAM
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_sgd.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_sgd
	out_dir: train_output/VLCS/SAM/[1, 2, 3]/250126_21-00-26_resnet50_sgd
	out_root: train_output/VLCS/SAM/[1, 2, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [1, 2, 3]
	trial_seed: 0
	unique_name: 250126_21-00-26_resnet50_sgd
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: sgd
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	rho: 0.05
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 01/26 21:00:26 | n_steps = 5001
[37m[36mINFO[0m[0m 01/26 21:00:26 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 01/26 21:00:26 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 01/26 21:00:26 | 
[37m[36mINFO[0m[0m 01/26 21:00:26 | Testenv name escaping te_L_S_V -> te_L_S_V
[37m[36mINFO[0m[0m 01/26 21:00:26 | Test envs = [1, 2, 3], name = te_L_S_V
[37m[36mINFO[0m[0m 01/26 21:00:26 | Train environments: [0], Test environments: [1, 2, 3]
[37m[36mINFO[0m[0m 01/26 21:00:26 | Batch sizes for each domain: [32, 0, 0, 0] (total=32)
[37m[36mINFO[0m[0m 01/26 21:00:26 | steps-per-epoch for each domain: 35.38 -> min = 35.38
[37m[36mINFO[0m[0m 01/26 21:00:27 | # of params = 23518277
[37m[36mINFO[0m[0m 01/26 21:02:32 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 01/26 21:02:32 | 0.172083    0.145696    0.088339    0.081272    1.894596    0.088339    0.081272    0.188235    0.160075    0.186215    0.157012    0.141799    0.120000    0           0.000000    2.658965    1.137025    123.281609 
[37m[36mINFO[0m[0m 01/26 21:05:11 | 0.512223    0.485908    0.967314    0.954064    0.246689    0.967314    0.954064    0.508706    0.502825    0.540366    0.503049    0.487597    0.451852    200         5.653710    0.917773    0.188277    121.226561 
[37m[36mINFO[0m[0m 01/26 21:07:50 | 0.543828    0.527328    1.000000    1.000000    0.018801    1.000000    1.000000    0.495529    0.480226    0.576161    0.562500    0.559793    0.539259    400         11.307420   0.230961    0.160711    126.508817 
[37m[36mINFO[0m[0m 01/26 21:10:29 | 0.544546    0.523440    1.000000    1.000000    0.005384    1.000000    1.000000    0.493176    0.482109    0.578446    0.554878    0.562014    0.533333    600         16.961131   0.096067    0.162524    126.771857 
[37m[36mINFO[0m[0m 01/26 21:13:07 | 0.552611    0.537151    1.000000    1.000000    0.002610    1.000000    1.000000    0.495529    0.483992    0.591775    0.580793    0.570529    0.546667    800         22.614841   0.071859    0.169041    124.132309 
[37m[36mINFO[0m[0m 01/26 21:15:41 | 0.554118    0.537151    1.000000    1.000000    0.001730    1.000000    1.000000    0.496000    0.483992    0.591013    0.580793    0.575342    0.546667    1000        28.268551   0.060872    0.162552    120.886543 
[37m[36mINFO[0m[0m 01/26 21:18:20 | 0.554492    0.538661    1.000000    1.000000    0.001211    1.000000    1.000000    0.494118    0.483992    0.592536    0.583841    0.576823    0.548148    1200        33.922261   0.044014    0.174183    123.928601 
[37m[36mINFO[0m[0m 01/26 21:20:59 | 0.559425    0.541130    1.000000    1.000000    0.000835    1.000000    1.000000    0.495059    0.483992    0.598248    0.583841    0.584969    0.555556    1400        39.575972   0.041368    0.160762    126.564956 
[37m[36mINFO[0m[0m 01/26 21:23:42 | 0.555199    0.538033    1.000000    1.000000    0.000727    1.000000    1.000000    0.493647    0.482109    0.592536    0.583841    0.579415    0.548148    1600        45.229682   0.037398    0.160144    130.443829 
[37m[36mINFO[0m[0m 01/26 21:26:22 | 0.557061    0.542358    1.000000    1.000000    0.000474    1.000000    1.000000    0.493647    0.480226    0.593679    0.585366    0.583858    0.561481    1800        50.883392   0.029395    0.160717    127.973360 
[37m[36mINFO[0m[0m 01/26 21:29:00 | 0.562525    0.544453    1.000000    1.000000    0.000360    1.000000    1.000000    0.495059    0.482109    0.599772    0.583841    0.592743    0.567407    2000        56.537102   0.027612    0.163620    124.730108 
[37m[36mINFO[0m[0m 01/26 21:31:38 | 0.557611    0.536241    1.000000    1.000000    0.000320    1.000000    1.000000    0.494588    0.478343    0.592536    0.579268    0.585709    0.551111    2200        62.190813   0.025270    0.175670    123.474353 
[37m[36mINFO[0m[0m 01/26 21:34:11 | 0.556090    0.536629    1.000000    1.000000    0.000278    1.000000    1.000000    0.494118    0.476460    0.591775    0.582317    0.582377    0.551111    2400        67.844523   0.025914    0.160497    120.867809 
[37m[36mINFO[0m[0m 01/26 21:36:45 | 0.553588    0.536629    1.000000    1.000000    0.000246    1.000000    1.000000    0.494588    0.476460    0.584539    0.582317    0.581636    0.551111    2600        73.498233   0.023381    0.160045    121.502780 
[37m[36mINFO[0m[0m 01/26 21:39:19 | 0.558972    0.543691    1.000000    1.000000    0.000190    1.000000    1.000000    0.494588    0.478343    0.592917    0.583841    0.589411    0.568889    2800        79.151943   0.020698    0.162166    121.250034 
[37m[36mINFO[0m[0m 01/26 21:41:55 | 0.557851    0.542210    1.000000    1.000000    0.000163    1.000000    1.000000    0.494588    0.478343    0.591775    0.583841    0.587190    0.564444    3000        84.805654   0.017958    0.164024    122.984323 
[37m[36mINFO[0m[0m 01/26 21:44:30 | 0.552306    0.536567    1.000000    1.000000    0.000146    1.000000    1.000000    0.492235    0.474576    0.584158    0.589939    0.580526    0.545185    3200        90.459364   0.018006    0.160715    123.161342 
[37m[36mINFO[0m[0m 01/26 21:47:04 | 0.557141    0.543283    1.000000    1.000000    0.000125    1.000000    1.000000    0.493176    0.478343    0.592536    0.592988    0.585709    0.558519    3400        96.113074   0.016954    0.156468    122.630098 
[37m[36mINFO[0m[0m 01/26 21:49:37 | 0.559801    0.544137    1.000000    1.000000    0.000109    1.000000    1.000000    0.493647    0.476460    0.596344    0.592988    0.589411    0.562963    3600        101.766784  0.011621    0.156594    121.333651 
[37m[36mINFO[0m[0m 01/26 21:52:15 | 0.556058    0.541759    1.000000    1.000000    0.000075    1.000000    1.000000    0.492235    0.478343    0.589490    0.588415    0.586449    0.558519    3800        107.420495  0.011393    0.157671    126.682377 
[37m[36mINFO[0m[0m 01/26 21:54:54 | 0.557070    0.542119    1.000000    1.000000    0.000058    1.000000    1.000000    0.492235    0.476460    0.592155    0.588415    0.586820    0.561481    4000        113.074205  0.011823    0.157916    127.531824 
[37m[36mINFO[0m[0m 01/26 21:57:38 | 0.557855    0.542612    1.000000    1.000000    0.000054    1.000000    1.000000    0.492706    0.476460    0.593298    0.588415    0.587560    0.562963    4200        118.727915  0.013776    0.169247    130.288005 
[37m[36mINFO[0m[0m 01/26 22:00:20 | 0.561710    0.545752    1.000000    1.000000    0.000063    1.000000    1.000000    0.492235    0.478343    0.600152    0.592988    0.592743    0.565926    4400        124.381625  0.014270    0.163055    128.880013 
[37m[36mINFO[0m[0m 01/26 22:02:58 | 0.556666    0.544165    1.000000    1.000000    0.000061    1.000000    1.000000    0.491765    0.476460    0.592155    0.596037    0.586079    0.560000    4600        130.035336  0.010220    0.170211    123.813695 
[37m[36mINFO[0m[0m 01/26 22:05:37 | 0.556804    0.541202    1.000000    1.000000    0.000094    1.000000    1.000000    0.491765    0.476460    0.593679    0.596037    0.584969    0.551111    4800        135.689046  0.014910    0.179346    123.509073 
[37m[36mINFO[0m[0m 01/26 22:08:23 | 0.556294    0.544122    1.000000    1.000000    0.000055    1.000000    1.000000    0.492235    0.476460    0.588347    0.591463    0.588301    0.564444    5000        141.342756  0.009808    0.201201    125.764382 
[37m[36mINFO[0m[0m 01/26 22:08:23 | Cumulative gradient change saved at train_output/VLCS/SAM/[1, 2, 3]/250126_21-00-26_resnet50_sgd/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 01/26 22:08:25 | ---
[37m[36mINFO[0m[0m 01/26 22:08:25 | test-domain validation(oracle) = 56.171%
[37m[36mINFO[0m[0m 01/26 22:08:25 | training-domain validation(iid) = 54.383%
[37m[36mINFO[0m[0m 01/26 22:08:25 | last = 55.629%
[37m[36mINFO[0m[0m 01/26 22:08:25 | last (inD) = 100.000%
[37m[36mINFO[0m[0m 01/26 22:08:25 | training-domain validation (iid, inD) = 100.000%
[37m[36mINFO[0m[0m 01/26 22:08:25 | === Summary ===
[37m[36mINFO[0m[0m 01/26 22:08:25 | Command: /jsm0707/Large-scale/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm SAM --test_envs 1 2 3 --dataset VLCS
[37m[36mINFO[0m[0m 01/26 22:08:25 | Unique name: 250126_21-00-26_resnet50_sgd
[37m[36mINFO[0m[0m 01/26 22:08:25 | Out path: train_output/VLCS/SAM/[1, 2, 3]/250126_21-00-26_resnet50_sgd
[37m[36mINFO[0m[0m 01/26 22:08:25 | Algorithm: SAM
[37m[36mINFO[0m[0m 01/26 22:08:25 | Dataset: VLCS
