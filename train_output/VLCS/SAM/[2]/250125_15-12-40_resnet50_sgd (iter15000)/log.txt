[37m[36mINFO[0m[0m 01/25 15:12:40 | Command :: /jsm0707/Large-scale/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm SAM --test_envs 2 --dataset VLCS --steps 15000
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: SAM
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_sgd.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_sgd
	out_dir: train_output/VLCS/SAM/[2]/250125_15-12-40_resnet50_sgd
	out_root: train_output/VLCS/SAM/[2]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: 15000
	tb_freq: 10
	test_envs: [2]
	trial_seed: 0
	unique_name: 250125_15-12-40_resnet50_sgd
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: sgd
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	rho: 0.05
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 01/25 15:12:40 | n_steps = 15000
[37m[36mINFO[0m[0m 01/25 15:12:40 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 01/25 15:12:40 | n_steps is updated to 15000 => 15001 for checkpointing
[37m[36mINFO[0m[0m 01/25 15:12:40 | 
[37m[36mINFO[0m[0m 01/25 15:12:40 | Testenv name escaping te_S -> te_S
[37m[36mINFO[0m[0m 01/25 15:12:40 | Test envs = [2], name = te_S
[37m[36mINFO[0m[0m 01/25 15:12:40 | Train environments: [0, 1, 3], Test environments: [2]
[37m[36mINFO[0m[0m 01/25 15:12:40 | Batch sizes for each domain: [32, 32, 0, 32] (total=96)
[37m[36mINFO[0m[0m 01/25 15:12:40 | steps-per-epoch for each domain: 35.38, 66.41, 84.41 -> min = 35.38
[37m[36mINFO[0m[0m 01/25 15:12:41 | # of params = 23518277
[37m[36mINFO[0m[0m 01/25 15:14:59 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 01/25 15:14:59 | 0.269992    0.243902    0.128558    0.122538    1.854658    0.142226    0.137809    0.073882    0.077213    0.269992    0.243902    0.169567    0.152593    0           0.000000    2.555151    2.055616    135.920604 
[37m[36mINFO[0m[0m 01/25 15:21:12 | 0.570069    0.548780    0.658080    0.666179    0.844289    0.754417    0.759717    0.636706    0.640301    0.570069    0.548780    0.583117    0.598519    200         5.653710    1.324961    1.165743    139.573858 
[37m[36mINFO[0m[0m 01/25 15:27:19 | 0.760853    0.725610    0.817184    0.817262    0.582070    0.992933    0.982332    0.692235    0.700565    0.760853    0.725610    0.766383    0.768889    400         11.307420   0.894483    1.147522    136.921133 
[37m[36mINFO[0m[0m 01/25 15:33:28 | 0.731150    0.714939    0.845534    0.853026    0.457676    0.996466    0.996466    0.718588    0.734463    0.731150    0.714939    0.821548    0.828148    600         16.961131   0.723802    1.142838    140.227313 
[37m[36mINFO[0m[0m 01/25 15:39:42 | 0.733054    0.722561    0.856690    0.857301    0.410472    0.999117    1.000000    0.729412    0.736347    0.733054    0.722561    0.841540    0.835556    800         22.614841   0.617402    1.164390    140.758817 
[37m[36mINFO[0m[0m 01/25 15:45:55 | 0.722772    0.707317    0.861167    0.861427    0.394254    1.000000    1.000000    0.732706    0.745763    0.722772    0.707317    0.850796    0.838519    1000        28.268551   0.582438    1.162997    140.303372 
[37m[36mINFO[0m[0m 01/25 15:52:14 | 0.733435    0.722561    0.856626    0.863135    0.386799    1.000000    1.000000    0.726118    0.741996    0.733435    0.722561    0.843762    0.847407    1200        33.922261   0.569398    1.164863    145.656024 
[37m[36mINFO[0m[0m 01/25 15:58:20 | 0.722772    0.702744    0.864731    0.861879    0.378318    1.000000    1.000000    0.741176    0.738230    0.722772    0.702744    0.853017    0.847407    1400        39.575972   0.542735    1.131077    139.220684 
[37m[36mINFO[0m[0m 01/25 16:04:35 | 0.735339    0.716463    0.864516    0.866005    0.371240    0.999117    1.000000    0.738824    0.747646    0.735339    0.716463    0.855609    0.850370    1600        45.229682   0.531371    1.169571    141.406080 
[37m[36mINFO[0m[0m 01/25 16:10:53 | 0.734958    0.708841    0.863175    0.863896    0.366886    1.000000    1.000000    0.733176    0.745763    0.734958    0.708841    0.856350    0.845926    1800        50.883392   0.515437    1.164771    144.140804 
[37m[36mINFO[0m[0m 01/25 16:17:16 | 0.719726    0.705793    0.864397    0.866407    0.360960    1.000000    1.000000    0.736471    0.753296    0.719726    0.705793    0.856720    0.845926    2000        56.537102   0.505847    1.196729    144.316056 
[37m[36mINFO[0m[0m 01/25 16:23:34 | 0.743336    0.722561    0.865754    0.869236    0.357698    1.000000    1.000000    0.736471    0.751412    0.743336    0.722561    0.860792    0.856296    2200        62.190813   0.499115    1.185895    140.530200 
[37m[36mINFO[0m[0m 01/25 16:29:56 | 0.745240    0.728659    0.866338    0.871881    0.358301    1.000000    1.000000    0.736000    0.760829    0.745240    0.728659    0.863014    0.854815    2400        67.844523   0.495939    1.180843    144.889747 
[37m[36mINFO[0m[0m 01/25 16:36:25 | 0.734196    0.719512    0.871360    0.868876    0.354520    1.000000    1.000000    0.745882    0.753296    0.734196    0.719512    0.868197    0.853333    2600        73.498233   0.485511    1.217645    145.728212 
[37m[36mINFO[0m[0m 01/25 16:42:49 | 0.731912    0.713415    0.871594    0.870760    0.354494    1.000000    1.000000    0.749176    0.758945    0.731912    0.713415    0.865605    0.853333    2800        79.151943   0.492930    1.182780    147.153849 
[37m[36mINFO[0m[0m 01/25 16:49:23 | 0.742193    0.722561    0.873345    0.872509    0.352694    1.000000    1.000000    0.747765    0.762712    0.742193    0.722561    0.872270    0.854815    3000        84.805654   0.489432    1.228557    147.820876 
[37m[36mINFO[0m[0m 01/25 16:55:38 | 0.739909    0.727134    0.874667    0.869144    0.350443    1.000000    1.000000    0.752471    0.757062    0.739909    0.727134    0.871529    0.850370    3200        90.459364   0.485566    1.171334    140.483084 
[37m[36mINFO[0m[0m 01/25 17:02:08 | 0.725057    0.708841    0.874029    0.868023    0.351881    1.000000    1.000000    0.748706    0.755179    0.725057    0.708841    0.873380    0.848889    3400        96.113074   0.480776    1.224421    145.700229 
[37m[36mINFO[0m[0m 01/25 17:09:17 | 0.738005    0.717988    0.874882    0.871521    0.345336    1.000000    1.000000    0.746824    0.762712    0.738005    0.717988    0.877823    0.851852    3600        101.766784  0.471566    1.365939    155.286350 
[37m[36mINFO[0m[0m 01/25 17:15:44 | 0.746382    0.730183    0.875980    0.871881    0.348245    1.000000    1.000000    0.750118    0.760829    0.746382    0.730183    0.877823    0.854815    3800        107.420495  0.463524    1.230511    141.052046 
[37m[36mINFO[0m[0m 01/25 17:22:05 | 0.745621    0.721037    0.875461    0.874124    0.342003    1.000000    1.000000    0.756706    0.764595    0.745621    0.721037    0.869678    0.857778    4000        113.074205  0.460493    1.182499    144.930489 
[37m[36mINFO[0m[0m 01/25 17:28:28 | 0.739528    0.725610    0.876371    0.870266    0.343394    1.000000    1.000000    0.753882    0.758945    0.739528    0.725610    0.875231    0.851852    4200        118.727915  0.455315    1.170751    147.811106 
[37m[36mINFO[0m[0m 01/25 17:34:53 | 0.739909    0.719512    0.874823    0.869144    0.339023    1.000000    1.000000    0.752941    0.757062    0.739909    0.719512    0.871529    0.850370    4400        124.381625  0.451991    1.200557    144.770603 
[37m[36mINFO[0m[0m 01/25 17:41:16 | 0.733816    0.719512    0.877793    0.873630    0.339711    1.000000    1.000000    0.760000    0.764595    0.733816    0.719512    0.873380    0.856296    4600        130.035336  0.450592    1.191417    145.312603 
[37m[36mINFO[0m[0m 01/25 17:47:33 | 0.749048    0.724085    0.879678    0.873271    0.339004    1.000000    1.000000    0.760471    0.766478    0.749048    0.724085    0.878563    0.853333    4800        135.689046  0.454642    1.178660    140.984022 
[37m[36mINFO[0m[0m 01/25 17:53:42 | 0.748286    0.727134    0.878693    0.873271    0.340095    1.000000    1.000000    0.755294    0.766478    0.748286    0.727134    0.880785    0.853333    5000        141.342756  0.457861    1.125920    143.466221 
[37m[36mINFO[0m[0m 01/25 17:59:49 | 0.748286    0.727134    0.881517    0.871521    0.334578    1.000000    1.000000    0.763765    0.762712    0.748286    0.727134    0.880785    0.851852    5200        146.996466  0.435150    1.130017    141.590234 
[37m[36mINFO[0m[0m 01/25 18:05:59 | 0.745240    0.724085    0.880588    0.872643    0.334739    1.000000    1.000000    0.757647    0.764595    0.745240    0.724085    0.884117    0.853333    5400        152.650177  0.438789    1.138218    141.754804 
[37m[36mINFO[0m[0m 01/25 18:12:02 | 0.750952    0.722561    0.882650    0.873271    0.336637    1.000000    1.000000    0.762353    0.766478    0.750952    0.722561    0.885598    0.853333    5600        158.303887  0.447579    1.122627    138.819654 
[37m[36mINFO[0m[0m 01/25 18:18:12 | 0.733435    0.710366    0.880519    0.872509    0.334353    1.000000    1.000000    0.761882    0.762712    0.733435    0.710366    0.879674    0.854815    5800        163.957597  0.433397    1.117210    146.958122 
[37m[36mINFO[0m[0m 01/25 18:24:37 | 0.739147    0.721037    0.882010    0.875514    0.334686    1.000000    1.000000    0.763765    0.770245    0.739147    0.721037    0.882266    0.856296    6000        169.611307  0.436120    1.187899    147.013640 
[37m[36mINFO[0m[0m 01/25 18:30:46 | 0.752094    0.725610    0.884679    0.874886    0.333212    1.000000    1.000000    0.766588    0.768362    0.752094    0.725610    0.887449    0.856296    6200        175.265018  0.437096    1.136949    141.069527 
[37m[36mINFO[0m[0m 01/25 18:36:52 | 0.748286    0.727134    0.883242    0.874752    0.333698    1.000000    1.000000    0.768941    0.766478    0.748286    0.727134    0.880785    0.857778    6400        180.918728  0.441906    1.137380    138.474143 
[37m[36mINFO[0m[0m 01/25 18:43:01 | 0.743336    0.727134    0.883602    0.870492    0.332561    1.000000    1.000000    0.767059    0.755179    0.743336    0.727134    0.883747    0.856296    6600        186.572438  0.433088    1.132977    142.330874 
[37m[36mINFO[0m[0m 01/25 18:49:10 | 0.753618    0.731707    0.884142    0.875514    0.331096    1.000000    1.000000    0.764235    0.770245    0.753618    0.731707    0.888190    0.856296    6800        192.226148  0.442238    1.124704    144.121802 
[37m[36mINFO[0m[0m 01/25 18:55:19 | 0.743336    0.727134    0.882000    0.873497    0.330901    1.000000    1.000000    0.761882    0.762712    0.743336    0.727134    0.884117    0.857778    7000        197.879859  0.428148    1.140312    140.844200 
[37m[36mINFO[0m[0m 01/25 19:01:37 | 0.755903    0.739329    0.885162    0.874978    0.328516    1.000000    1.000000    0.764706    0.762712    0.755903    0.739329    0.890781    0.862222    7200        203.533569  0.426969    1.146372    149.039237 
[37m[36mINFO[0m[0m 01/25 19:07:50 | 0.755522    0.736280    0.887425    0.875874    0.328333    1.000000    1.000000    0.772235    0.768362    0.755522    0.736280    0.890041    0.859259    7400        209.187279  0.424824    1.144010    144.623592 
[37m[36mINFO[0m[0m 01/25 19:14:02 | 0.759711    0.730183    0.888894    0.876635    0.328211    1.000000    1.000000    0.775529    0.772128    0.759711    0.730183    0.891151    0.857778    7600        214.840989  0.425562    1.173547    136.647127 
[37m[36mINFO[0m[0m 01/25 19:20:13 | 0.754760    0.736280    0.886664    0.876367    0.326048    1.000000    1.000000    0.768471    0.768362    0.754760    0.736280    0.891522    0.860741    7800        220.494700  0.406465    1.165665    137.405839 
[37m[36mINFO[0m[0m 01/25 19:26:24 | 0.761234    0.746951    0.887495    0.880360    0.325756    1.000000    1.000000    0.768000    0.775895    0.761234    0.746951    0.894484    0.865185    8000        226.148410  0.413732    1.150292    140.818650 
[37m[36mINFO[0m[0m 01/25 19:32:39 | 0.754379    0.728659    0.887909    0.876234    0.326106    1.000000    1.000000    0.770353    0.766478    0.754379    0.728659    0.893373    0.862222    8200        231.802120  0.421116    1.174507    140.303377 
[37m[36mINFO[0m[0m 01/25 19:38:56 | 0.755141    0.731707    0.889007    0.875740    0.323926    1.000000    1.000000    0.773647    0.766478    0.755141    0.731707    0.893373    0.860741    8400        237.455830  0.404608    1.167806    142.969683 
[37m[36mINFO[0m[0m 01/25 19:45:24 | 0.755522    0.733232    0.889230    0.875740    0.324722    1.000000    1.000000    0.775059    0.766478    0.755522    0.733232    0.892632    0.860741    8600        243.109541  0.407899    1.208672    146.652596 
[37m[36mINFO[0m[0m 01/25 19:51:47 | 0.755141    0.731707    0.890059    0.874752    0.324172    1.000000    1.000000    0.779765    0.766478    0.755141    0.731707    0.890411    0.857778    8800        248.763251  0.403288    1.185795    145.403179 
[37m[36mINFO[0m[0m 01/25 19:58:17 | 0.756664    0.734756    0.890632    0.876367    0.323641    1.000000    1.000000    0.777412    0.768362    0.756664    0.734756    0.894484    0.860741    9000        254.416961  0.405875    1.190204    151.909020 
[37m[36mINFO[0m[0m 01/25 20:04:48 | 0.761234    0.743902    0.891259    0.879238    0.322811    1.000000    1.000000    0.779294    0.774011    0.761234    0.743902    0.894484    0.863704    9200        260.070671  0.416548    1.218163    147.903149 
[37m[36mINFO[0m[0m 01/25 20:11:22 | 0.754379    0.734756    0.889847    0.877849    0.321815    1.000000    1.000000    0.775059    0.768362    0.754379    0.734756    0.894484    0.865185    9400        265.724382  0.400604    1.236404    146.661322 
[37m[36mINFO[0m[0m 01/25 20:18:04 | 0.765042    0.736280    0.887942    0.876635    0.322102    1.000000    1.000000    0.770824    0.772128    0.765042    0.736280    0.893003    0.857778    9600        271.378092  0.396840    1.239534    153.642548 
[37m[36mINFO[0m[0m 01/25 20:24:42 | 0.745621    0.721037    0.892748    0.876635    0.324304    1.000000    1.000000    0.786353    0.772128    0.745621    0.721037    0.891892    0.857778    9800        277.031802  0.407269    1.253124    148.200783 
[37m[36mINFO[0m[0m 01/25 20:31:23 | 0.752856    0.731707    0.890270    0.876141    0.321858    0.999117    1.000000    0.776471    0.772128    0.752856    0.731707    0.895224    0.856296    10000       282.685512  0.396655    1.251712    149.899825 
[37m[36mINFO[0m[0m 01/25 20:38:03 | 0.758949    0.740854    0.891606    0.876995    0.323143    1.000000    1.000000    0.780706    0.770245    0.758949    0.740854    0.894113    0.860741    10200       288.339223  0.404462    1.243496    151.336766 
[37m[36mINFO[0m[0m 01/25 20:44:39 | 0.754379    0.734756    0.892257    0.878117    0.320288    1.000000    1.000000    0.781176    0.772128    0.754379    0.734756    0.895594    0.862222    10400       293.992933  0.403970    1.253581    145.469872 
[37m[36mINFO[0m[0m 01/25 20:51:02 | 0.752475    0.731707    0.889981    0.876501    0.320635    1.000000    1.000000    0.776941    0.770245    0.752475    0.731707    0.893003    0.859259    10600       299.646643  0.403587    1.208054    141.270156 
[37m[36mINFO[0m[0m 01/25 20:57:38 | 0.752094    0.731707    0.892426    0.876501    0.319693    1.000000    1.000000    0.778353    0.770245    0.752094    0.731707    0.898926    0.859259    10800       305.300353  0.395146    1.203698    155.853120 
[37m[36mINFO[0m[0m 01/25 21:04:00 | 0.753618    0.736280    0.894221    0.877623    0.320630    1.000000    1.000000    0.779294    0.772128    0.753618    0.736280    0.903369    0.860741    11000       310.954064  0.407650    1.193041    142.730776 
[37m[36mINFO[0m[0m 01/25 21:10:35 | 0.751714    0.736280    0.893939    0.877489    0.319185    1.000000    1.000000    0.784000    0.770245    0.751714    0.736280    0.897816    0.862222    11200       316.607774  0.400732    1.232507    148.823367 
[37m[36mINFO[0m[0m 01/25 21:17:04 | 0.747525    0.733232    0.894252    0.879506    0.319743    1.000000    1.000000    0.784941    0.777778    0.747525    0.733232    0.897816    0.860741    11400       322.261484  0.391098    1.231693    142.534504 
[37m[36mINFO[0m[0m 01/25 21:23:41 | 0.742193    0.717988    0.893298    0.878519    0.317892    1.000000    1.000000    0.785412    0.777778    0.742193    0.717988    0.894484    0.857778    11600       327.915194  0.389605    1.245486    147.700871 
[37m[36mINFO[0m[0m 01/25 21:30:22 | 0.750571    0.733232    0.895103    0.877263    0.318244    1.000000    1.000000    0.788235    0.774011    0.750571    0.733232    0.897075    0.857778    11800       333.568905  0.393518    1.254889    150.002975 
[37m[36mINFO[0m[0m 01/25 21:37:02 | 0.747906    0.727134    0.894913    0.877623    0.317680    1.000000    1.000000    0.787294    0.772128    0.747906    0.727134    0.897445    0.860741    12000       339.222615  0.388096    1.240828    152.303732 
[37m[36mINFO[0m[0m 01/25 21:43:31 | 0.749810    0.731707    0.895173    0.878385    0.316757    1.000000    1.000000    0.784000    0.775895    0.749810    0.731707    0.901518    0.859259    12200       344.876325  0.389982    1.226412    143.134775 
[37m[36mINFO[0m[0m 01/25 21:49:51 | 0.753237    0.731707    0.893357    0.877623    0.316421    1.000000    1.000000    0.779294    0.772128    0.753237    0.731707    0.900777    0.860741    12400       350.530035  0.396683    1.186979    142.874635 
[37m[36mINFO[0m[0m 01/25 21:56:20 | 0.747144    0.721037    0.895240    0.877623    0.316075    1.000000    1.000000    0.784941    0.772128    0.747144    0.721037    0.900777    0.860741    12600       356.183746  0.386742    1.217097    145.360390 
[37m[36mINFO[0m[0m 01/25 22:02:56 | 0.753237    0.739329    0.896654    0.878251    0.315532    1.000000    1.000000    0.784000    0.774011    0.753237    0.739329    0.905961    0.860741    12800       361.837456  0.381471    1.231003    150.061987 
[37m[36mINFO[0m[0m 01/25 22:09:26 | 0.756283    0.737805    0.897371    0.879866    0.315756    1.000000    1.000000    0.785412    0.775895    0.756283    0.737805    0.906701    0.863704    13000       367.491166  0.386655    1.229954    144.479315 
[37m[36mINFO[0m[0m 01/25 22:15:55 | 0.764661    0.746951    0.899323    0.879104    0.314979    1.000000    1.000000    0.786824    0.772128    0.764661    0.746951    0.911144    0.865185    13200       373.144876  0.383825    1.220287    144.288015 
[37m[36mINFO[0m[0m 01/25 22:22:16 | 0.752475    0.736280    0.897291    0.878878    0.314265    1.000000    1.000000    0.787765    0.775895    0.752475    0.736280    0.904110    0.860741    13400       378.798587  0.379384    1.179742    145.446357 
[37m[36mINFO[0m[0m 01/25 22:29:04 | 0.753237    0.733232    0.895947    0.883005    0.313373    1.000000    1.000000    0.784471    0.785311    0.753237    0.733232    0.903369    0.863704    13600       384.452297  0.378849    1.284084    151.167063 
[37m[36mINFO[0m[0m 01/25 22:35:44 | 0.774562    0.739329    0.900040    0.875472    0.315104    1.000000    1.000000    0.788235    0.762712    0.774562    0.739329    0.911884    0.863704    13800       390.106007  0.376258    1.237036    152.341172 
[37m[36mINFO[0m[0m 01/25 22:42:24 | 0.753998    0.737805    0.897772    0.880000    0.312984    1.000000    1.000000    0.791059    0.777778    0.753998    0.737805    0.902258    0.862222    14000       395.759717  0.376666    1.252083    149.855898 
[37m[36mINFO[0m[0m 01/25 22:48:55 | 0.755903    0.739329    0.898436    0.882603    0.314158    1.000000    1.000000    0.788235    0.779661    0.755903    0.739329    0.907071    0.868148    14200       401.413428  0.382903    1.218612    146.860226 
[37m[36mINFO[0m[0m 01/25 22:55:17 | 0.750952    0.730183    0.898346    0.881481    0.313072    1.000000    1.000000    0.788706    0.777778    0.750952    0.730183    0.906331    0.866667    14400       407.067138  0.375915    1.169102    147.815602 
[37m[36mINFO[0m[0m 01/25 23:01:44 | 0.757426    0.739329    0.900161    0.879238    0.312511    1.000000    1.000000    0.793412    0.774011    0.757426    0.739329    0.907071    0.863704    14600       412.720848  0.378466    1.210731    145.334607 
[37m[36mINFO[0m[0m 01/25 23:08:07 | 0.751714    0.731707    0.896731    0.881615    0.310479    1.000000    1.000000    0.786824    0.779661    0.751714    0.731707    0.903369    0.865185    14800       418.374558  0.368237    1.175884    147.421059 
[37m[36mINFO[0m[0m 01/25 23:14:31 | 0.752856    0.733232    0.902136    0.883992    0.311739    1.000000    1.000000    0.793412    0.785311    0.752856    0.733232    0.912995    0.866667    15000       424.028269  0.375692    1.179345    148.737012 
[37m[36mINFO[0m[0m 01/25 23:14:32 | Cumulative gradient change saved at train_output/VLCS/SAM/[2]/250125_15-12-40_resnet50_sgd/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 01/25 23:14:33 | ---
[37m[36mINFO[0m[0m 01/25 23:14:33 | test-domain validation(oracle) = 76.123%
[37m[36mINFO[0m[0m 01/25 23:14:33 | training-domain validation(iid) = 75.286%
[37m[36mINFO[0m[0m 01/25 23:14:33 | last = 75.286%
[37m[36mINFO[0m[0m 01/25 23:14:33 | last (inD) = 88.399%
[37m[36mINFO[0m[0m 01/25 23:14:33 | training-domain validation (iid, inD) = 88.399%
[37m[36mINFO[0m[0m 01/25 23:14:33 | === Summary ===
[37m[36mINFO[0m[0m 01/25 23:14:33 | Command: /jsm0707/Large-scale/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm SAM --test_envs 2 --dataset VLCS --steps 15000
[37m[36mINFO[0m[0m 01/25 23:14:33 | Unique name: 250125_15-12-40_resnet50_sgd
[37m[36mINFO[0m[0m 01/25 23:14:33 | Out path: train_output/VLCS/SAM/[2]/250125_15-12-40_resnet50_sgd
[37m[36mINFO[0m[0m 01/25 23:14:33 | Algorithm: SAM
[37m[36mINFO[0m[0m 01/25 23:14:33 | Dataset: VLCS
