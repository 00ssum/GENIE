[37m[36mINFO[0m[0m 02/19 12:02:05 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 0 2 3 --dataset VLCS --trial_seed 2 --hparams_seed 10
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 10
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/VLCS/CORAL/[0, 2, 3]/250219_12-02-05_resnet50_GENIE
	out_root: train_output/VLCS/CORAL/[0, 2, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 2, 3]
	trial_seed: 2
	unique_name: 250219_12-02-05_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.5
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 7.494887873901297e-05
	batch_size: 23
	weight_decay: 0.000495139494108363
	mmd_gamma: 1.4713820315478223
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 02/19 12:02:05 | n_steps = 5001
[37m[36mINFO[0m[0m 02/19 12:02:05 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/19 12:02:05 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/19 12:02:05 | 
[37m[36mINFO[0m[0m 02/19 12:02:05 | Testenv name escaping te_C_S_V -> te_C_S_V
[37m[36mINFO[0m[0m 02/19 12:02:05 | Test envs = [0, 2, 3], name = te_C_S_V
[37m[36mINFO[0m[0m 02/19 12:02:05 | Train environments: [1], Test environments: [0, 2, 3]
[37m[36mINFO[0m[0m 02/19 12:02:05 | Batch sizes for each domain: [0, 23, 0, 0] (total=23)
[37m[36mINFO[0m[0m 02/19 12:02:05 | steps-per-epoch for each domain: 92.39 -> min = 92.39
[37m[36mINFO[0m[0m 02/19 12:02:06 | # of params = 23518277
[37m[36mINFO[0m[0m 02/19 12:04:11 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 02/19 12:04:11 | 0.358272    0.361835    0.467294    0.459510    1.045776    0.274735    0.293286    0.467294    0.459510    0.386900    0.355183    0.413180    0.437037    0           0.000000    1.769198    0.000000    1.198653    123.937496 
[37m[36mINFO[0m[0m 02/19 12:08:58 | 0.640346    0.610962    0.732706    0.755179    0.679350    0.830389    0.798587    0.732706    0.755179    0.504570    0.481707    0.586079    0.552593    200         2.164706    0.791320    0.000000    0.825620    121.814239 
[37m[36mINFO[0m[0m 02/19 12:13:58 | 0.666859    0.626125    0.760471    0.755179    0.670313    0.848057    0.802120    0.760471    0.755179    0.532749    0.498476    0.619770    0.577778    400         4.329412    0.674280    0.000000    0.860494    128.086889 
[37m[36mINFO[0m[0m 02/19 12:18:53 | 0.695609    0.666655    0.791529    0.770245    0.618195    0.856007    0.833922    0.791529    0.770245    0.552551    0.530488    0.678267    0.635556    600         6.494118    0.597437    0.000000    0.859663    122.867992 
[37m[36mINFO[0m[0m 02/19 12:24:01 | 0.679121    0.653301    0.811765    0.741996    0.619462    0.856007    0.816254    0.811765    0.741996    0.544554    0.524390    0.636801    0.619259    800         8.658824    0.509428    0.000000    0.865456    134.350221 
[37m[36mINFO[0m[0m 02/19 12:28:59 | 0.603402    0.595818    0.862588    0.772128    0.617164    0.503534    0.505300    0.862588    0.772128    0.644326    0.655488    0.662347    0.626667    1000        10.823529   0.458299    0.000000    0.865097    124.914369 
[37m[36mINFO[0m[0m 02/19 12:33:55 | 0.702091    0.665319    0.844706    0.760829    0.697835    0.900177    0.848057    0.844706    0.760829    0.582254    0.570122    0.623843    0.577778    1200        12.988235   0.423652    0.000000    0.854113    126.056944 
[37m[36mINFO[0m[0m 02/19 12:38:50 | 0.708060    0.691321    0.802824    0.738230    0.851621    0.887809    0.879859    0.802824    0.738230    0.552551    0.527439    0.683821    0.666667    1400        15.152941   0.420161    0.000000    0.844843    125.376784 
[37m[36mINFO[0m[0m 02/19 12:43:40 | 0.687386    0.652817    0.905412    0.755179    0.696053    0.856007    0.805654    0.905412    0.755179    0.557502    0.533537    0.648649    0.619259    1600        17.317647   0.354844    0.000000    0.834978    123.487378 
[37m[36mINFO[0m[0m 02/19 12:48:31 | 0.711012    0.705569    0.908706    0.747646    0.915688    0.925795    0.915194    0.908706    0.747646    0.543412    0.527439    0.663828    0.674074    1800        19.482353   0.299474    0.000000    0.848109    121.543605 
[37m[36mINFO[0m[0m 02/19 12:53:33 | 0.562253    0.551841    0.873412    0.728814    0.773230    0.454947    0.445230    0.873412    0.728814    0.588347    0.576220    0.643465    0.634074    2000        21.647059   0.275033    0.000000    0.851289    131.041089 
[37m[36mINFO[0m[0m 02/19 12:58:26 | 0.604639    0.598397    0.931765    0.747646    0.800186    0.598057    0.611307    0.931765    0.747646    0.600533    0.585366    0.615328    0.598519    2200        23.811765   0.328439    0.000000    0.838511    125.101592 
[37m[36mINFO[0m[0m 02/19 13:03:26 | 0.699052    0.670854    0.944471    0.753296    0.844433    0.871025    0.844523    0.944471    0.753296    0.583778    0.548780    0.642355    0.619259    2400        25.976471   0.239452    0.000000    0.839411    132.542076 
[37m[36mINFO[0m[0m 02/19 13:08:19 | 0.702338    0.691838    0.947765    0.751412    1.080847    0.858657    0.862191    0.947765    0.751412    0.557502    0.525915    0.690855    0.687407    2600        28.141176   0.225823    0.000000    0.821606    128.825586 
[37m[36mINFO[0m[0m 02/19 13:13:15 | 0.501148    0.475305    0.938353    0.758945    0.895527    0.393110    0.371025    0.938353    0.758945    0.560168    0.528963    0.550167    0.525926    2800        30.305882   0.176522    0.000000    0.850122    125.327998 
[37m[36mINFO[0m[0m 02/19 13:18:12 | 0.489232    0.477594    0.936941    0.740113    0.967757    0.325088    0.346290    0.936941    0.740113    0.615765    0.599085    0.526842    0.487407    3000        32.470588   0.177566    0.000000    0.857702    125.879454 
[37m[36mINFO[0m[0m 02/19 13:23:06 | 0.552862    0.544376    0.972706    0.745763    1.056674    0.423145    0.445230    0.972706    0.745763    0.599010    0.570122    0.636431    0.617778    3200        34.635294   0.151494    0.000000    0.852350    123.841705 
[37m[36mINFO[0m[0m 02/19 13:28:00 | 0.637526    0.630869    0.968941    0.745763    1.365903    0.699647    0.727915    0.968941    0.745763    0.575019    0.535061    0.637912    0.629630    3400        36.800000   0.141368    0.000000    0.841236    125.644384 
[37m[36mINFO[0m[0m 02/19 13:32:53 | 0.567338    0.540835    0.976000    0.749529    1.142011    0.458481    0.452297    0.976000    0.749529    0.610434    0.573171    0.633099    0.597037    3600        38.964706   0.146838    0.000000    0.848023    123.682613 
[37m[36mINFO[0m[0m 02/19 13:38:00 | 0.622386    0.603635    0.967059    0.743879    1.407687    0.710247    0.713781    0.967059    0.743879    0.544174    0.503049    0.612736    0.594074    3800        41.129412   0.101929    0.000000    0.864633    133.257237 
[37m[36mINFO[0m[0m 02/19 13:42:52 | 0.582135    0.554865    0.952471    0.751412    1.057288    0.609541    0.583039    0.952471    0.751412    0.555598    0.528963    0.581266    0.552593    4000        43.294118   0.114148    0.000000    0.848991    122.977220 
[37m[36mINFO[0m[0m 02/19 13:47:53 | 0.548578    0.522151    0.953412    0.741996    0.914936    0.509717    0.515901    0.953412    0.741996    0.525133    0.480183    0.610885    0.570370    4200        45.458824   0.139806    0.000000    0.833816    133.843879 
[37m[36mINFO[0m[0m 02/19 13:52:43 | 0.526118    0.513182    0.939765    0.728814    1.185881    0.377208    0.392226    0.939765    0.728814    0.630617    0.602134    0.570529    0.545185    4400        47.623529   0.109394    0.000000    0.829672    123.987139 
[37m[36mINFO[0m[0m 02/19 13:57:40 | 0.549385    0.554328    0.983059    0.768362    1.028298    0.462898    0.491166    0.983059    0.768362    0.578446    0.577744    0.606812    0.594074    4600        49.788235   0.078131    0.000000    0.848327    127.844687 
[37m[36mINFO[0m[0m 02/19 14:02:33 | 0.600200    0.570055    0.983059    0.753296    1.394596    0.599823    0.579505    0.983059    0.753296    0.577304    0.536585    0.623473    0.594074    4800        51.952941   0.075839    0.000000    0.851258    121.912023 
[37m[36mINFO[0m[0m 02/19 14:07:29 | 0.587611    0.570847    0.985882    0.753296    1.120650    0.656360    0.657244    0.985882    0.753296    0.514471    0.490854    0.592003    0.564444    5000        54.117647   0.089693    0.000000    0.844459    127.369055 
[37m[36mINFO[0m[0m 02/19 14:07:29 | Cumulative gradient change saved at train_output/VLCS/CORAL/[0, 2, 3]/250219_12-02-05_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/19 14:07:30 | ---
[37m[36mINFO[0m[0m 02/19 14:07:30 | test-domain validation(oracle) = 71.101%
[37m[36mINFO[0m[0m 02/19 14:07:30 | training-domain validation(iid) = 60.340%
[37m[36mINFO[0m[0m 02/19 14:07:30 | last = 58.761%
[37m[36mINFO[0m[0m 02/19 14:07:30 | last (inD) = 75.330%
[37m[36mINFO[0m[0m 02/19 14:07:30 | training-domain validation (iid, inD) = 77.213%
[37m[36mINFO[0m[0m 02/19 14:07:31 | === Summary ===
[37m[36mINFO[0m[0m 02/19 14:07:31 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 0 2 3 --dataset VLCS --trial_seed 2 --hparams_seed 10
[37m[36mINFO[0m[0m 02/19 14:07:31 | Unique name: 250219_12-02-05_resnet50_GENIE
[37m[36mINFO[0m[0m 02/19 14:07:31 | Out path: train_output/VLCS/CORAL/[0, 2, 3]/250219_12-02-05_resnet50_GENIE
[37m[36mINFO[0m[0m 02/19 14:07:31 | Algorithm: CORAL
[37m[36mINFO[0m[0m 02/19 14:07:31 | Dataset: VLCS
