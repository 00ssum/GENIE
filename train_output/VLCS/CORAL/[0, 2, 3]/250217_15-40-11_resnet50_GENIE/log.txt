[37m[36mINFO[0m[0m 02/17 15:40:11 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 0 2 3 --dataset VLCS --trial_seed 1 --hparams_seed 8
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 8
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/VLCS/CORAL/[0, 2, 3]/250217_15-40-11_resnet50_GENIE
	out_root: train_output/VLCS/CORAL/[0, 2, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 2, 3]
	trial_seed: 1
	unique_name: 250217_15-40-11_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 3.335053008064847e-05
	batch_size: 18
	weight_decay: 0.00011109601170966198
	mmd_gamma: 0.5310831856660853
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 02/17 15:40:11 | n_steps = 5001
[37m[36mINFO[0m[0m 02/17 15:40:11 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/17 15:40:11 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/17 15:40:11 | 
[37m[36mINFO[0m[0m 02/17 15:40:11 | Testenv name escaping te_C_S_V -> te_C_S_V
[37m[36mINFO[0m[0m 02/17 15:40:11 | Test envs = [0, 2, 3], name = te_C_S_V
[37m[36mINFO[0m[0m 02/17 15:40:11 | Train environments: [1], Test environments: [0, 2, 3]
[37m[36mINFO[0m[0m 02/17 15:40:11 | Batch sizes for each domain: [0, 18, 0, 0] (total=18)
[37m[36mINFO[0m[0m 02/17 15:40:11 | steps-per-epoch for each domain: 118.06 -> min = 118.06
[37m[36mINFO[0m[0m 02/17 15:40:13 | # of params = 23518277
[37m[36mINFO[0m[0m 02/17 15:42:31 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 02/17 15:42:31 | 0.469039    0.472113    0.466824    0.461394    1.257837    0.582155    0.597173    0.466824    0.461394    0.376238    0.417683    0.448723    0.401481    0           0.000000    1.729287    0.000000    1.106603    137.178971 
[37m[36mINFO[0m[0m 02/17 15:47:04 | 0.618455    0.622634    0.736941    0.709981    0.742523    0.802120    0.791519    0.736941    0.709981    0.464204    0.503049    0.589041    0.573333    200         1.694118    0.759415    0.000000    0.685028    135.185668 
[37m[36mINFO[0m[0m 02/17 15:51:38 | 0.664601    0.658840    0.791059    0.751412    0.642609    0.852473    0.833922    0.791059    0.751412    0.503046    0.539634    0.638282    0.602963    400         3.388235    0.603479    0.000000    0.709607    132.519789 
[37m[36mINFO[0m[0m 02/17 15:56:06 | 0.658837    0.665915    0.728000    0.715631    0.726484    0.840989    0.837456    0.728000    0.715631    0.507235    0.536585    0.628286    0.623704    600         5.082353    0.563731    0.000000    0.698834    128.067491 
[37m[36mINFO[0m[0m 02/17 16:00:39 | 0.692723    0.696945    0.805176    0.755179    0.631889    0.876325    0.872792    0.805176    0.755179    0.562452    0.588415    0.639393    0.629630    800         6.776471    0.551997    0.000000    0.736833    126.223503 
[37m[36mINFO[0m[0m 02/17 16:05:19 | 0.722633    0.722939    0.832000    0.783427    0.657851    0.908127    0.897527    0.832000    0.783427    0.555217    0.585366    0.704554    0.685926    1000        8.470588    0.479398    0.000000    0.696480    140.790035 
[37m[36mINFO[0m[0m 02/17 16:09:47 | 0.697293    0.680280    0.802353    0.751412    0.702811    0.798587    0.752650    0.802353    0.751412    0.589109    0.606707    0.704184    0.681481    1200        10.164706   0.470641    0.000000    0.706094    126.462335 
[37m[36mINFO[0m[0m 02/17 16:14:18 | 0.675172    0.676313    0.867765    0.743879    0.747359    0.821555    0.812721    0.867765    0.743879    0.545316    0.576220    0.658645    0.640000    1400        11.858824   0.387742    0.000000    0.732700    124.115283 
[37m[36mINFO[0m[0m 02/17 16:19:06 | 0.641042    0.639782    0.868235    0.743879    0.759084    0.751767    0.749117    0.868235    0.743879    0.491241    0.521341    0.680118    0.648889    1600        13.552941   0.349380    0.000000    0.715453    145.490425 
[37m[36mINFO[0m[0m 02/17 16:23:39 | 0.601196    0.602242    0.900235    0.760829    0.662546    0.495583    0.508834    0.900235    0.760829    0.638995    0.635671    0.669011    0.662222    1800        15.247059   0.346033    0.000000    0.679461    136.846831 
[37m[36mINFO[0m[0m 02/17 16:28:13 | 0.663278    0.642946    0.895059    0.777778    0.670867    0.691696    0.664311    0.895059    0.777778    0.630236    0.608232    0.667901    0.656296    2000        16.941176   0.329449    0.000000    0.681842    136.966870 
[37m[36mINFO[0m[0m 02/17 16:32:47 | 0.656470    0.641000    0.909647    0.755179    0.907592    0.704064    0.664311    0.909647    0.755179    0.595963    0.611280    0.669382    0.647407    2200        18.635294   0.308698    0.000000    0.710842    132.207309 
[37m[36mINFO[0m[0m 02/17 16:37:32 | 0.612910    0.633758    0.854588    0.723164    0.827831    0.728799    0.763251    0.854588    0.723164    0.492384    0.535061    0.617549    0.602963    2400        20.329412   0.269844    0.000000    0.712193    142.823713 
[37m[36mINFO[0m[0m 02/17 16:42:11 | 0.614989    0.613983    0.919059    0.741996    1.160868    0.717314    0.731449    0.919059    0.741996    0.490480    0.504573    0.637171    0.605926    2600        22.023529   0.230708    0.000000    0.680438    143.085692 
[37m[36mINFO[0m[0m 02/17 16:46:46 | 0.641450    0.634648    0.930353    0.734463    0.900100    0.732332    0.685512    0.930353    0.734463    0.555217    0.602134    0.636801    0.616296    2800        23.717647   0.236996    0.000000    0.716173    131.667705 
[37m[36mINFO[0m[0m 02/17 16:51:19 | 0.659910    0.664461    0.946353    0.743879    0.944302    0.784452    0.805654    0.946353    0.743879    0.539223    0.564024    0.656053    0.623704    3000        25.411765   0.191395    0.000000    0.716477    128.999448 
[37m[36mINFO[0m[0m 02/17 16:56:04 | 0.611907    0.604408    0.928941    0.743879    1.161490    0.717314    0.696113    0.928941    0.743879    0.490861    0.528963    0.627545    0.588148    3200        27.105882   0.178408    0.000000    0.711184    142.753560 
[37m[36mINFO[0m[0m 02/17 17:00:33 | 0.632249    0.636758    0.902118    0.753296    1.222019    0.831272    0.812721    0.902118    0.753296    0.464585    0.518293    0.600889    0.579259    3400        28.800000   0.163398    0.000000    0.673237    134.723979 
[37m[36mINFO[0m[0m 02/17 17:05:10 | 0.655675    0.670802    0.969412    0.743879    1.134204    0.825972    0.830389    0.969412    0.743879    0.506474    0.571646    0.634580    0.610370    3600        30.494118   0.150088    0.000000    0.712509    134.755576 
[37m[36mINFO[0m[0m 02/17 17:09:42 | 0.665479    0.657159    0.909647    0.738230    1.648299    0.854240    0.840989    0.909647    0.738230    0.507616    0.530488    0.634580    0.600000    3800        32.188235   0.126492    0.000000    0.726473    126.479191 
[37m[36mINFO[0m[0m 02/17 17:14:08 | 0.570579    0.543171    0.946824    0.772128    1.171632    0.507067    0.448763    0.946824    0.772128    0.557502    0.579268    0.647168    0.601481    4000        33.882353   0.123938    0.000000    0.699348    126.055382 
[37m[36mINFO[0m[0m 02/17 17:18:46 | 0.534981    0.514560    0.969412    0.751412    1.226987    0.407244    0.371025    0.969412    0.751412    0.546458    0.554878    0.651240    0.617778    4200        35.576471   0.131063    0.000000    0.729593    132.172080 
[37m[36mINFO[0m[0m 02/17 17:23:15 | 0.636600    0.622752    0.955294    0.757062    1.162427    0.736749    0.703180    0.955294    0.757062    0.525514    0.548780    0.647538    0.616296    4400        37.270588   0.138381    0.000000    0.690298    131.143906 
[37m[36mINFO[0m[0m 02/17 17:27:47 | 0.675121    0.668366    0.942588    0.730697    1.451027    0.889576    0.858657    0.942588    0.730697    0.476771    0.518293    0.659015    0.628148    4600        38.964706   0.117833    0.000000    0.707203    130.030341 
[37m[36mINFO[0m[0m 02/17 17:32:15 | 0.498613    0.501353    0.945412    0.728814    1.063572    0.363958    0.349823    0.945412    0.728814    0.482864    0.532012    0.649019    0.622222    4800        40.658824   0.127022    0.000000    0.674908    133.117740 
[37m[36mINFO[0m[0m 02/17 17:36:47 | 0.494408    0.487147    0.976000    0.728814    1.342154    0.395760    0.356890    0.976000    0.728814    0.509901    0.556402    0.577564    0.548148    5000        42.352941   0.093953    0.000000    0.709329    130.109992 
[37m[36mINFO[0m[0m 02/17 17:36:47 | Cumulative gradient change saved at train_output/VLCS/CORAL/[0, 2, 3]/250217_15-40-11_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/17 17:36:48 | ---
[37m[36mINFO[0m[0m 02/17 17:36:48 | test-domain validation(oracle) = 72.263%
[37m[36mINFO[0m[0m 02/17 17:36:48 | training-domain validation(iid) = 72.263%
[37m[36mINFO[0m[0m 02/17 17:36:48 | last = 49.441%
[37m[36mINFO[0m[0m 02/17 17:36:48 | last (inD) = 72.881%
[37m[36mINFO[0m[0m 02/17 17:36:48 | training-domain validation (iid, inD) = 78.343%
[37m[36mINFO[0m[0m 02/17 17:36:49 | === Summary ===
[37m[36mINFO[0m[0m 02/17 17:36:49 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 0 2 3 --dataset VLCS --trial_seed 1 --hparams_seed 8
[37m[36mINFO[0m[0m 02/17 17:36:49 | Unique name: 250217_15-40-11_resnet50_GENIE
[37m[36mINFO[0m[0m 02/17 17:36:49 | Out path: train_output/VLCS/CORAL/[0, 2, 3]/250217_15-40-11_resnet50_GENIE
[37m[36mINFO[0m[0m 02/17 17:36:49 | Algorithm: CORAL
[37m[36mINFO[0m[0m 02/17 17:36:49 | Dataset: VLCS
