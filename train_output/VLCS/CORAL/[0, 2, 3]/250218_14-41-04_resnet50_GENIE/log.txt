[37m[36mINFO[0m[0m 02/18 14:41:04 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 0 2 3 --dataset VLCS --trial_seed 1 --hparams_seed 20
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 20
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/VLCS/CORAL/[0, 2, 3]/250218_14-41-04_resnet50_GENIE
	out_root: train_output/VLCS/CORAL/[0, 2, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 2, 3]
	trial_seed: 1
	unique_name: 250218_14-41-04_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.1
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 1.6701621650738547e-05
	batch_size: 28
	weight_decay: 2.09977539257237e-05
	mmd_gamma: 2.1411578651095096
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 02/18 14:41:04 | n_steps = 5001
[37m[36mINFO[0m[0m 02/18 14:41:04 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/18 14:41:04 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/18 14:41:04 | 
[37m[36mINFO[0m[0m 02/18 14:41:04 | Testenv name escaping te_C_S_V -> te_C_S_V
[37m[36mINFO[0m[0m 02/18 14:41:04 | Test envs = [0, 2, 3], name = te_C_S_V
[37m[36mINFO[0m[0m 02/18 14:41:04 | Train environments: [1], Test environments: [0, 2, 3]
[37m[36mINFO[0m[0m 02/18 14:41:04 | Batch sizes for each domain: [0, 28, 0, 0] (total=28)
[37m[36mINFO[0m[0m 02/18 14:41:04 | steps-per-epoch for each domain: 75.89 -> min = 75.89
[37m[36mINFO[0m[0m 02/18 14:41:06 | # of params = 23518277
[37m[36mINFO[0m[0m 02/18 14:43:39 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 02/18 14:43:39 | 0.481247    0.481169    0.466824    0.461394    1.323761    0.613958    0.618375    0.466824    0.461394    0.376618    0.419207    0.453165    0.405926    0           0.000000    1.757869    0.000000    1.502412    152.150543 
[37m[36mINFO[0m[0m 02/18 14:49:59 | 0.671817    0.666509    0.770353    0.738230    0.686132    0.855124    0.837456    0.770353    0.738230    0.507235    0.547256    0.653091    0.614815    200         2.635294    0.736788    0.000000    1.200258    139.449187 
[37m[36mINFO[0m[0m 02/18 14:56:05 | 0.716369    0.712725    0.784000    0.760829    0.705991    0.869258    0.865724    0.784000    0.760829    0.598248    0.626524    0.681599    0.645926    400         5.270588    0.576644    0.000000    1.134409    139.243115 
[37m[36mINFO[0m[0m 02/18 15:02:10 | 0.684489    0.680860    0.782588    0.757062    0.644785    0.853357    0.844523    0.782588    0.757062    0.539985    0.562500    0.660126    0.635556    600         7.905882    0.559041    0.000000    1.097225    145.788709 
[37m[36mINFO[0m[0m 02/18 15:08:02 | 0.695174    0.676414    0.845176    0.757062    0.641960    0.865724    0.837456    0.845176    0.757062    0.528941    0.550305    0.690855    0.641481    800         10.541176   0.455598    0.000000    1.101620    131.463615 
[37m[36mINFO[0m[0m 02/18 15:14:12 | 0.708959    0.707184    0.875765    0.758945    0.682020    0.877208    0.876325    0.875765    0.758945    0.564737    0.606707    0.684932    0.638519    1000        13.176471   0.415662    0.000000    1.098060    150.651612 
[37m[36mINFO[0m[0m 02/18 15:20:08 | 0.650421    0.654515    0.890353    0.760829    0.705544    0.742933    0.752650    0.890353    0.760829    0.555979    0.597561    0.652351    0.613333    1200        15.811765   0.360357    0.000000    1.123745    131.352777 
[37m[36mINFO[0m[0m 02/18 15:26:11 | 0.644494    0.645349    0.895529    0.740113    0.887483    0.681095    0.674912    0.895529    0.740113    0.555979    0.592988    0.696409    0.668148    1400        18.447059   0.285818    0.000000    1.127120    137.272686 
[37m[36mINFO[0m[0m 02/18 15:32:10 | 0.567852    0.557132    0.936941    0.762712    0.803887    0.413428    0.367491    0.936941    0.762712    0.595202    0.638720    0.694928    0.665185    1600        21.082353   0.326286    0.000000    1.116186    135.607772 
[37m[36mINFO[0m[0m 02/18 15:38:09 | 0.589223    0.561090    0.903059    0.743879    0.964491    0.522085    0.484099    0.903059    0.743879    0.604341    0.602134    0.641244    0.597037    1800        23.717647   0.194507    0.000000    1.098677    139.658896 
[37m[36mINFO[0m[0m 02/18 15:44:10 | 0.601284    0.603447    0.937882    0.740113    1.137094    0.588339    0.572438    0.937882    0.740113    0.561310    0.609756    0.654202    0.628148    2000        26.352941   0.179780    0.000000    1.100687    140.167108 
[37m[36mINFO[0m[0m 02/18 15:50:21 | 0.518181    0.539083    0.957647    0.749529    1.161212    0.413428    0.459364    0.957647    0.749529    0.522087    0.556402    0.619030    0.601481    2200        28.988235   0.167342    0.000000    1.128687    146.020040 
[37m[36mINFO[0m[0m 02/18 15:56:17 | 0.622582    0.602234    0.966118    0.760829    1.149974    0.685512    0.636042    0.966118    0.760829    0.496192    0.536585    0.686042    0.634074    2400        31.623529   0.199871    0.000000    1.123508    131.094723 
[37m[36mINFO[0m[0m 02/18 16:02:24 | 0.550888    0.541375    0.953412    0.734463    0.952425    0.477032    0.448763    0.953412    0.734463    0.525133    0.545732    0.650500    0.629630    2600        34.258824   0.105367    0.000000    1.112670    144.417850 
[37m[36mINFO[0m[0m 02/18 16:08:13 | 0.551073    0.535204    0.944000    0.760829    1.607794    0.503534    0.484099    0.944000    0.760829    0.497334    0.527439    0.652351    0.594074    2800        36.894118   0.091779    0.000000    1.052565    137.932484 
[37m[36mINFO[0m[0m 02/18 16:14:23 | 0.546808    0.535080    0.980235    0.743879    0.971046    0.395760    0.378092    0.980235    0.743879    0.584539    0.596037    0.660126    0.631111    3000        39.529412   0.107431    0.000000    1.113846    147.516281 
[37m[36mINFO[0m[0m 02/18 16:20:11 | 0.528540    0.524941    0.984471    0.757062    1.302907    0.385159    0.367491    0.984471    0.757062    0.539223    0.576220    0.661237    0.631111    3200        42.164706   0.074024    0.000000    1.107165    126.818298 
[37m[36mINFO[0m[0m 02/18 16:26:23 | 0.527309    0.522765    0.983059    0.741996    1.584788    0.381625    0.367491    0.983059    0.741996    0.520183    0.554878    0.680118    0.645926    3400        44.800000   0.076582    0.000000    1.135153    144.960577 
[37m[36mINFO[0m[0m 02/18 16:32:19 | 0.593080    0.589263    0.988235    0.736347    1.277316    0.585689    0.572438    0.988235    0.736347    0.543793    0.571646    0.649759    0.623704    3600        47.435294   0.073675    0.000000    1.084307    138.896369 
[37m[36mINFO[0m[0m 02/18 16:38:31 | 0.531642    0.520602    0.974118    0.738230    1.664791    0.414311    0.402827    0.974118    0.738230    0.544554    0.542683    0.636061    0.616296    3800        50.070588   0.062388    0.000000    1.128191    146.636210 
[37m[36mINFO[0m[0m 02/18 16:44:32 | 0.595823    0.603800    0.969882    0.721281    1.524084    0.607774    0.604240    0.969882    0.721281    0.524752    0.570122    0.654943    0.637037    4000        52.705882   0.086053    0.000000    1.102800    139.786827 
[37m[36mINFO[0m[0m 02/18 16:50:27 | 0.555246    0.528708    0.981176    0.758945    1.948114    0.533569    0.480565    0.981176    0.758945    0.506474    0.539634    0.625694    0.565926    4200        55.341176   0.048426    0.000000    1.091696    137.446967 
[37m[36mINFO[0m[0m 02/18 16:56:23 | 0.549391    0.529120    0.988235    0.738230    1.525399    0.505300    0.459364    0.988235    0.738230    0.531988    0.547256    0.610885    0.580741    4400        57.976471   0.048998    0.000000    1.135414    128.370404 
[37m[36mINFO[0m[0m 02/18 17:02:37 | 0.544647    0.518982    0.967059    0.751412    1.307120    0.576855    0.522968    0.967059    0.751412    0.495811    0.522866    0.561274    0.511111    4600        60.611765   0.046821    0.000000    1.111164    151.950943 
[37m[36mINFO[0m[0m 02/18 17:08:28 | 0.545197    0.537717    0.986353    0.758945    1.718964    0.440813    0.424028    0.986353    0.758945    0.534653    0.560976    0.660126    0.628148    4800        63.247059   0.054551    0.000000    1.109124    129.167339 
[37m[36mINFO[0m[0m 02/18 17:14:32 | 0.601861    0.592468    0.995765    0.758945    1.915827    0.603357    0.565371    0.995765    0.758945    0.536177    0.585366    0.666050    0.626667    5000        65.882353   0.035576    0.000000    1.115867    140.432940 
[37m[36mINFO[0m[0m 02/18 17:14:32 | Cumulative gradient change saved at train_output/VLCS/CORAL/[0, 2, 3]/250218_14-41-04_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/18 17:14:33 | ---
[37m[36mINFO[0m[0m 02/18 17:14:33 | test-domain validation(oracle) = 71.637%
[37m[36mINFO[0m[0m 02/18 17:14:33 | training-domain validation(iid) = 56.785%
[37m[36mINFO[0m[0m 02/18 17:14:33 | last = 60.186%
[37m[36mINFO[0m[0m 02/18 17:14:33 | last (inD) = 75.895%
[37m[36mINFO[0m[0m 02/18 17:14:33 | training-domain validation (iid, inD) = 76.271%
[37m[36mINFO[0m[0m 02/18 17:14:33 | === Summary ===
[37m[36mINFO[0m[0m 02/18 17:14:33 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 0 2 3 --dataset VLCS --trial_seed 1 --hparams_seed 20
[37m[36mINFO[0m[0m 02/18 17:14:33 | Unique name: 250218_14-41-04_resnet50_GENIE
[37m[36mINFO[0m[0m 02/18 17:14:33 | Out path: train_output/VLCS/CORAL/[0, 2, 3]/250218_14-41-04_resnet50_GENIE
[37m[36mINFO[0m[0m 02/18 17:14:33 | Algorithm: CORAL
[37m[36mINFO[0m[0m 02/18 17:14:33 | Dataset: VLCS
