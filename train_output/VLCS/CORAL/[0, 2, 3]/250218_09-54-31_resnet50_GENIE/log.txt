[37m[36mINFO[0m[0m 02/18 09:54:31 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 0 2 3 --dataset VLCS --trial_seed 1 --hparams_seed 18
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 18
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/VLCS/CORAL/[0, 2, 3]/250218_09-54-31_resnet50_GENIE
	out_root: train_output/VLCS/CORAL/[0, 2, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 2, 3]
	trial_seed: 1
	unique_name: 250218_09-54-31_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.1
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 0.0002805925701721472
	batch_size: 39
	weight_decay: 1.5909976529017505e-06
	mmd_gamma: 0.7378941383723668
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 02/18 09:54:31 | n_steps = 5001
[37m[36mINFO[0m[0m 02/18 09:54:31 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/18 09:54:31 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/18 09:54:31 | 
[37m[36mINFO[0m[0m 02/18 09:54:32 | Testenv name escaping te_C_S_V -> te_C_S_V
[37m[36mINFO[0m[0m 02/18 09:54:32 | Test envs = [0, 2, 3], name = te_C_S_V
[37m[36mINFO[0m[0m 02/18 09:54:32 | Train environments: [1], Test environments: [0, 2, 3]
[37m[36mINFO[0m[0m 02/18 09:54:32 | Batch sizes for each domain: [0, 39, 0, 0] (total=39)
[37m[36mINFO[0m[0m 02/18 09:54:32 | steps-per-epoch for each domain: 54.49 -> min = 54.49
[37m[36mINFO[0m[0m 02/18 09:54:33 | # of params = 23518277
[37m[36mINFO[0m[0m 02/18 09:56:48 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 02/18 09:56:48 | 0.365191    0.364346    0.467294    0.461394    1.093432    0.304770    0.310954    0.467294    0.461394    0.372810    0.416159    0.417993    0.365926    0           0.000000    1.704444    0.000000    1.699447    133.694539 
[37m[36mINFO[0m[0m 02/18 10:03:58 | 0.650806    0.645091    0.783529    0.743879    0.672119    0.827739    0.809187    0.783529    0.743879    0.503427    0.532012    0.621251    0.594074    200         3.670588    0.707313    0.000000    1.495428    130.649094 
[37m[36mINFO[0m[0m 02/18 10:11:14 | 0.694502    0.687332    0.814588    0.749529    0.625405    0.866608    0.840989    0.814588    0.749529    0.544554    0.588415    0.672344    0.632593    400         7.341176    0.527504    0.000000    1.520289    131.583661 
[37m[36mINFO[0m[0m 02/18 10:18:20 | 0.684616    0.679255    0.857412    0.757062    0.671977    0.786219    0.745583    0.857412    0.757062    0.598248    0.643293    0.669382    0.648889    600         11.011765   0.455486    0.000000    1.479261    130.899862 
[37m[36mINFO[0m[0m 02/18 10:25:31 | 0.634665    0.630146    0.894588    0.768362    0.707992    0.595406    0.593640    0.894588    0.768362    0.633283    0.649390    0.675305    0.647407    800         14.682353   0.374947    0.000000    1.477674    135.141616 
[37m[36mINFO[0m[0m 02/18 10:32:52 | 0.625262    0.623182    0.919059    0.755179    0.892957    0.614841    0.593640    0.919059    0.755179    0.570830    0.591463    0.690115    0.684444    1000        18.352941   0.282889    0.000000    1.522335    136.328190 
[37m[36mINFO[0m[0m 02/18 10:40:06 | 0.586654    0.577828    0.938353    0.762712    0.811018    0.512367    0.494700    0.938353    0.762712    0.570069    0.588415    0.677527    0.650370    1200        22.023529   0.239639    0.000000    1.497341    134.153382 
[37m[36mINFO[0m[0m 02/18 10:47:22 | 0.564467    0.548686    0.953412    0.775895    0.945060    0.433746    0.409894    0.953412    0.775895    0.591013    0.600610    0.668641    0.635556    1400        25.694118   0.198482    0.000000    1.506713    134.961212 
[37m[36mINFO[0m[0m 02/18 10:54:36 | 0.546428    0.540466    0.948235    0.760829    1.215345    0.409894    0.406360    0.948235    0.760829    0.581112    0.586890    0.648278    0.628148    1600        29.364706   0.186501    0.000000    1.486969    136.490170 
[37m[36mINFO[0m[0m 02/18 11:01:46 | 0.566339    0.544196    0.969412    0.758945    1.229138    0.515018    0.438163    0.969412    0.758945    0.559787    0.591463    0.624213    0.602963    1800        33.035294   0.116989    0.000000    1.497102    131.050794 
[37m[36mINFO[0m[0m 02/18 11:09:02 | 0.561960    0.557224    0.973647    0.753296    1.118251    0.406360    0.402827    0.973647    0.753296    0.599772    0.603659    0.679748    0.665185    2000        36.705882   0.092417    0.000000    1.512243    133.796267 
[37m[36mINFO[0m[0m 02/18 11:16:30 | 0.596206    0.588095    0.980235    0.755179    1.749509    0.617491    0.590106    0.980235    0.755179    0.509520    0.556402    0.661607    0.617778    2200        40.376471   0.094774    0.000000    1.563081    134.936228 
[37m[36mINFO[0m[0m 02/18 11:23:39 | 0.540114    0.536035    0.979294    0.770245    1.163550    0.393110    0.399293    0.979294    0.770245    0.596725    0.576220    0.630507    0.632593    2400        44.047059   0.074020    0.000000    1.501584    128.754109 
[37m[36mINFO[0m[0m 02/18 11:30:59 | 0.566364    0.545248    0.988706    0.751412    1.624961    0.437279    0.413428    0.988706    0.751412    0.588728    0.582317    0.673084    0.640000    2600        47.717647   0.061196    0.000000    1.570569    125.591062 
[37m[36mINFO[0m[0m 02/18 11:38:25 | 0.614622    0.598721    0.968471    0.726930    1.110662    0.681095    0.643110    0.968471    0.726930    0.501904    0.542683    0.660866    0.610370    2800        51.388235   0.075817    0.000000    1.619647    122.189782 
[37m[36mINFO[0m[0m 02/18 11:45:48 | 0.595643    0.577321    0.993412    0.757062    1.217513    0.526502    0.501767    0.993412    0.757062    0.592155    0.599085    0.668271    0.631111    3000        55.058824   0.058924    0.000000    1.562634    130.514162 
[37m[36mINFO[0m[0m 02/18 11:53:23 | 0.566958    0.547019    0.991529    0.758945    1.702123    0.438163    0.385159    0.991529    0.758945    0.621097    0.617378    0.641614    0.638519    3200        58.729412   0.053756    0.000000    1.564369    142.607550 
[37m[36mINFO[0m[0m 02/18 12:00:51 | 0.550622    0.531277    0.995294    0.753296    1.647808    0.436396    0.381625    0.995294    0.753296    0.586443    0.591463    0.629026    0.620741    3400        62.400000   0.034590    0.000000    1.528826    141.828151 
[37m[36mINFO[0m[0m 02/18 12:08:25 | 0.551901    0.543641    0.985882    0.740113    1.589406    0.487633    0.459364    0.985882    0.740113    0.546078    0.568598    0.621992    0.602963    3600        66.070588   0.034800    0.000000    1.530477    148.155713 
[37m[36mINFO[0m[0m 02/18 12:15:42 | 0.603482    0.594133    0.996706    0.747646    1.688652    0.666961    0.618375    0.996706    0.747646    0.527418    0.564024    0.616068    0.600000    3800        69.741176   0.024646    0.000000    1.527548    131.157275 
[37m[36mINFO[0m[0m 02/18 12:23:13 | 0.575770    0.553223    0.986824    0.743879    1.378401    0.493816    0.452297    0.986824    0.743879    0.568926    0.577744    0.664569    0.629630    4000        73.411765   0.065098    0.000000    1.592322    132.515958 
[37m[36mINFO[0m[0m 02/18 12:30:48 | 0.578986    0.553101    0.999059    0.743879    1.863512    0.526502    0.469965    0.999059    0.743879    0.539223    0.568598    0.671233    0.620741    4200        77.082353   0.017979    0.000000    1.612920    132.222878 
[37m[36mINFO[0m[0m 02/18 12:38:10 | 0.599890    0.588676    0.975529    0.719397    2.022379    0.641343    0.614841    0.975529    0.719397    0.488576    0.528963    0.669752    0.622222    4400        80.752941   0.014258    0.000000    1.523776    137.255191 
[37m[36mINFO[0m[0m 02/18 12:45:23 | 0.528716    0.516607    0.990588    0.753296    2.017748    0.466431    0.438163    0.990588    0.753296    0.551409    0.545732    0.568308    0.565926    4600        84.423529   0.021307    0.000000    1.464768    139.961038 
[37m[36mINFO[0m[0m 02/18 12:53:03 | 0.571466    0.554556    0.991059    0.753296    1.493247    0.522085    0.484099    0.991059    0.753296    0.579208    0.589939    0.613106    0.589630    4800        88.094118   0.030266    0.000000    1.565905    146.667087 
[37m[36mINFO[0m[0m 02/18 13:00:50 | 0.560633    0.545552    0.990118    0.738230    2.173569    0.537102    0.477032    0.990118    0.738230    0.521325    0.565549    0.623473    0.594074    5000        91.764706   0.013982    0.000000    1.598042    148.173919 
[37m[36mINFO[0m[0m 02/18 13:00:50 | Cumulative gradient change saved at train_output/VLCS/CORAL/[0, 2, 3]/250218_09-54-31_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/18 13:00:52 | ---
[37m[36mINFO[0m[0m 02/18 13:00:52 | test-domain validation(oracle) = 69.450%
[37m[36mINFO[0m[0m 02/18 13:00:52 | training-domain validation(iid) = 56.447%
[37m[36mINFO[0m[0m 02/18 13:00:52 | last = 56.063%
[37m[36mINFO[0m[0m 02/18 13:00:52 | last (inD) = 73.823%
[37m[36mINFO[0m[0m 02/18 13:00:52 | training-domain validation (iid, inD) = 77.589%
[37m[36mINFO[0m[0m 02/18 13:00:52 | === Summary ===
[37m[36mINFO[0m[0m 02/18 13:00:52 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 0 2 3 --dataset VLCS --trial_seed 1 --hparams_seed 18
[37m[36mINFO[0m[0m 02/18 13:00:52 | Unique name: 250218_09-54-31_resnet50_GENIE
[37m[36mINFO[0m[0m 02/18 13:00:52 | Out path: train_output/VLCS/CORAL/[0, 2, 3]/250218_09-54-31_resnet50_GENIE
[37m[36mINFO[0m[0m 02/18 13:00:52 | Algorithm: CORAL
[37m[36mINFO[0m[0m 02/18 13:00:52 | Dataset: VLCS
