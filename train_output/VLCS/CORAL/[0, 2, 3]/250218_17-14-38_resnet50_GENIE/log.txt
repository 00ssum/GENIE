[37m[36mINFO[0m[0m 02/18 17:14:38 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 0 2 3 --dataset VLCS --trial_seed 2 --hparams_seed 0
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/VLCS/CORAL/[0, 2, 3]/250218_17-14-38_resnet50_GENIE
	out_root: train_output/VLCS/CORAL/[0, 2, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 2, 3]
	trial_seed: 2
	unique_name: 250218_17-14-38_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	mmd_gamma: 1.0
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 02/18 17:14:38 | n_steps = 5001
[37m[36mINFO[0m[0m 02/18 17:14:38 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/18 17:14:38 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/18 17:14:38 | 
[37m[36mINFO[0m[0m 02/18 17:14:38 | Testenv name escaping te_C_S_V -> te_C_S_V
[37m[36mINFO[0m[0m 02/18 17:14:38 | Test envs = [0, 2, 3], name = te_C_S_V
[37m[36mINFO[0m[0m 02/18 17:14:38 | Train environments: [1], Test environments: [0, 2, 3]
[37m[36mINFO[0m[0m 02/18 17:14:38 | Batch sizes for each domain: [0, 32, 0, 0] (total=32)
[37m[36mINFO[0m[0m 02/18 17:14:38 | steps-per-epoch for each domain: 66.41 -> min = 66.41
[37m[36mINFO[0m[0m 02/18 17:14:39 | # of params = 23518277
[37m[36mINFO[0m[0m 02/18 17:16:57 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 02/18 17:16:57 | 0.483943    0.470377    0.467294    0.459510    1.292389    0.620141    0.593640    0.467294    0.459510    0.391851    0.358232    0.439837    0.459259    0           0.000000    1.736678    0.000000    1.022141    136.354716 
[37m[36mINFO[0m[0m 02/18 17:23:29 | 0.555736    0.527285    0.779294    0.757062    0.620899    0.620141    0.597173    0.779294    0.757062    0.481721    0.455793    0.565346    0.528889    200         3.011765    0.742118    0.000000    1.275005    137.629123 
[37m[36mINFO[0m[0m 02/18 17:30:14 | 0.699160    0.680047    0.813176    0.777778    0.640559    0.868375    0.865724    0.813176    0.777778    0.544174    0.512195    0.684932    0.662222    400         6.023529    0.564663    0.000000    1.341622    136.617385 
[37m[36mINFO[0m[0m 02/18 17:36:47 | 0.689610    0.654112    0.720471    0.664783    0.765083    0.869258    0.805654    0.720471    0.664783    0.547220    0.513720    0.652351    0.642963    600         9.035294    0.494332    0.000000    1.298293    133.413652 
[37m[36mINFO[0m[0m 02/18 17:43:30 | 0.726191    0.697980    0.875294    0.779661    0.699161    0.929329    0.893993    0.875294    0.779661    0.549505    0.524390    0.699741    0.675556    800         12.047059   0.419661    0.000000    1.304931    142.025082 
[37m[36mINFO[0m[0m 02/18 17:50:15 | 0.689912    0.660939    0.910588    0.757062    0.782346    0.786219    0.756184    0.910588    0.757062    0.610434    0.577744    0.673084    0.648889    1000        15.058824   0.338756    0.000000    1.301569    143.841073 
[37m[36mINFO[0m[0m 02/18 17:56:42 | 0.731416    0.711094    0.906824    0.768362    0.634792    0.864841    0.848057    0.906824    0.768362    0.623001    0.606707    0.706405    0.678519    1200        18.070588   0.298390    0.000000    1.271202    132.712873 
[37m[36mINFO[0m[0m 02/18 18:03:13 | 0.543671    0.538837    0.921882    0.760829    0.934077    0.413428    0.445230    0.921882    0.760829    0.622620    0.611280    0.594965    0.560000    1400        21.082353   0.250476    0.000000    1.242917    143.289895 
[37m[36mINFO[0m[0m 02/18 18:09:56 | 0.590635    0.566553    0.947294    0.770245    1.153345    0.505300    0.498233    0.947294    0.770245    0.654608    0.629573    0.611996    0.571852    1600        24.094118   0.217788    0.000000    1.274328    148.107050 
[37m[36mINFO[0m[0m 02/18 18:16:07 | 0.606625    0.587588    0.958588    0.749529    0.927358    0.577739    0.597173    0.958588    0.749529    0.613481    0.567073    0.628656    0.598519    1800        27.105882   0.162558    0.000000    1.247808    121.213545 
[37m[36mINFO[0m[0m 02/18 18:22:45 | 0.548698    0.540750    0.965647    0.764595    0.987674    0.504417    0.551237    0.965647    0.764595    0.582254    0.522866    0.559422    0.548148    2000        30.117647   0.131259    0.000000    1.343699    129.378038 
[37m[36mINFO[0m[0m 02/18 18:29:15 | 0.650102    0.662395    0.932235    0.740113    1.154710    0.649293    0.685512    0.932235    0.740113    0.653846    0.664634    0.647168    0.637037    2200        33.129412   0.172970    0.000000    1.254206    138.675335 
[37m[36mINFO[0m[0m 02/18 18:35:53 | 0.668402    0.639819    0.917647    0.740113    1.141120    0.745583    0.713781    0.917647    0.740113    0.603199    0.570122    0.656424    0.635556    2400        36.141176   0.127751    0.000000    1.231441    151.578476 
[37m[36mINFO[0m[0m 02/18 18:42:25 | 0.612533    0.599409    0.963294    0.755179    1.167758    0.618375    0.625442    0.963294    0.755179    0.588347    0.559451    0.630877    0.613333    2600        39.152941   0.118060    0.000000    1.269011    138.176774 
[37m[36mINFO[0m[0m 02/18 18:48:54 | 0.688869    0.676582    0.988706    0.758945    1.520159    0.858657    0.858657    0.988706    0.758945    0.582254    0.551829    0.625694    0.619259    2800        42.164706   0.072908    0.000000    1.260483    136.934855 
[37m[36mINFO[0m[0m 02/18 18:55:23 | 0.585941    0.583042    0.973176    0.751412    1.277300    0.563604    0.583039    0.973176    0.751412    0.554455    0.532012    0.639763    0.634074    3000        45.176471   0.065859    0.000000    1.293207    131.132653 
[37m[36mINFO[0m[0m 02/18 19:02:04 | 0.625773    0.601274    0.982118    0.755179    1.460929    0.687279    0.678445    0.982118    0.755179    0.590632    0.559451    0.599408    0.565926    3200        48.188235   0.055863    0.000000    1.305491    139.192949 
[37m[36mINFO[0m[0m 02/18 19:08:43 | 0.597596    0.567274    0.989647    0.758945    1.252135    0.633392    0.618375    0.989647    0.758945    0.540366    0.490854    0.619030    0.592593    3400        51.200000   0.069159    0.000000    1.297843    139.956274 
[37m[36mINFO[0m[0m 02/18 19:15:15 | 0.622224    0.601174    0.993882    0.768362    1.326059    0.719081    0.703180    0.993882    0.768362    0.541889    0.512195    0.605702    0.588148    3600        54.211765   0.039214    0.000000    1.204402    150.563638 
[37m[36mINFO[0m[0m 02/18 19:21:41 | 0.613079    0.617336    0.995765    0.768362    1.431564    0.578622    0.625442    0.995765    0.768362    0.638995    0.628049    0.621622    0.598519    3800        57.223529   0.049018    0.000000    1.287156    129.049002 
[37m[36mINFO[0m[0m 02/18 19:28:25 | 0.506208    0.496968    0.982118    0.726930    1.118313    0.353357    0.371025    0.982118    0.726930    0.591775    0.574695    0.573491    0.545185    4000        60.235294   0.050167    0.000000    1.299072    143.918762 
[37m[36mINFO[0m[0m 02/18 19:34:57 | 0.661953    0.654638    0.989176    0.757062    1.336907    0.750883    0.759717    0.989176    0.757062    0.582254    0.570122    0.652721    0.634074    4200        63.247059   0.054013    0.000000    1.279629    135.707202 
[37m[36mINFO[0m[0m 02/18 19:41:16 | 0.525972    0.520032    0.995294    0.753296    1.264405    0.423145    0.441696    0.995294    0.753296    0.587205    0.574695    0.567568    0.543704    4400        66.258824   0.034579    0.000000    1.220282    135.272434 
[37m[36mINFO[0m[0m 02/18 19:47:49 | 0.620382    0.612276    0.986353    0.772128    1.289698    0.652827    0.667845    0.986353    0.772128    0.595583    0.582317    0.612736    0.586667    4600        69.270588   0.032492    0.000000    1.297073    134.007254 
[37m[36mINFO[0m[0m 02/18 19:54:44 | 0.652725    0.626312    0.957647    0.736347    1.605213    0.819788    0.766784    0.957647    0.736347    0.530465    0.510671    0.607923    0.601481    4800        72.282353   0.027538    0.000000    1.325277    149.384477 
[37m[36mINFO[0m[0m 02/18 20:01:33 | 0.701147    0.682598    0.988235    0.768362    1.494013    0.909011    0.886926    0.988235    0.768362    0.535415    0.504573    0.659015    0.656296    5000        75.294118   0.032237    0.000000    1.333373    142.357567 
[37m[36mINFO[0m[0m 02/18 20:01:33 | Cumulative gradient change saved at train_output/VLCS/CORAL/[0, 2, 3]/250218_17-14-38_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/18 20:01:34 | ---
[37m[36mINFO[0m[0m 02/18 20:01:34 | test-domain validation(oracle) = 73.142%
[37m[36mINFO[0m[0m 02/18 20:01:34 | training-domain validation(iid) = 72.619%
[37m[36mINFO[0m[0m 02/18 20:01:34 | last = 70.115%
[37m[36mINFO[0m[0m 02/18 20:01:34 | last (inD) = 76.836%
[37m[36mINFO[0m[0m 02/18 20:01:34 | training-domain validation (iid, inD) = 77.966%
[37m[36mINFO[0m[0m 02/18 20:01:34 | === Summary ===
[37m[36mINFO[0m[0m 02/18 20:01:34 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 0 2 3 --dataset VLCS --trial_seed 2 --hparams_seed 0
[37m[36mINFO[0m[0m 02/18 20:01:34 | Unique name: 250218_17-14-38_resnet50_GENIE
[37m[36mINFO[0m[0m 02/18 20:01:34 | Out path: train_output/VLCS/CORAL/[0, 2, 3]/250218_17-14-38_resnet50_GENIE
[37m[36mINFO[0m[0m 02/18 20:01:34 | Algorithm: CORAL
[37m[36mINFO[0m[0m 02/18 20:01:34 | Dataset: VLCS
