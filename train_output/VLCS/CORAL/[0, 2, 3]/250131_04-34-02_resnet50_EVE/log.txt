[37m[36mINFO[0m[0m 01/31 04:34:02 | Command :: /jsm0707/Large-scale/train_all.py resnet50_EVE config/resnet50_EVE.yaml --algorithm CORAL --test_envs 0 2 3 --dataset VLCS --trial_seed 0 --hparams_seed 13
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_EVE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 13
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_EVE
	out_dir: train_output/VLCS/CORAL/[0, 2, 3]/250131_04-34-02_resnet50_EVE
	out_root: train_output/VLCS/CORAL/[0, 2, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 2, 3]
	trial_seed: 0
	unique_name: 250131_04-34-02_resnet50_EVE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: GENIE
	freeze_bn: False
	pretrained: True
	lr: 0.00014596629881421895
	batch_size: 9
	weight_decay: 0.0009399117661702502
	mmd_gamma: 0.20722924582334493
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 01/31 04:34:02 | n_steps = 5001
[37m[36mINFO[0m[0m 01/31 04:34:02 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 01/31 04:34:02 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 01/31 04:34:02 | 
[37m[36mINFO[0m[0m 01/31 04:34:02 | Testenv name escaping te_C_S_V -> te_C_S_V
[37m[36mINFO[0m[0m 01/31 04:34:02 | Test envs = [0, 2, 3], name = te_C_S_V
[37m[36mINFO[0m[0m 01/31 04:34:02 | Train environments: [1], Test environments: [0, 2, 3]
[37m[36mINFO[0m[0m 01/31 04:34:02 | Batch sizes for each domain: [0, 9, 0, 0] (total=9)
[37m[36mINFO[0m[0m 01/31 04:34:02 | steps-per-epoch for each domain: 236.11 -> min = 236.11
[37m[36mINFO[0m[0m 01/31 04:34:04 | # of params = 23518277
[37m[36mINFO[0m[0m 01/31 04:36:25 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 01/31 04:36:25 | 0.319042    0.324472    0.462118    0.487759    0.984085    0.171378    0.173145    0.462118    0.487759    0.377380    0.378049    0.408367    0.422222    0           0.000000    1.709675    0.000000    1.810370    139.500162 
[37m[36mINFO[0m[0m 01/31 04:40:09 | 0.602614    0.591128    0.723294    0.723164    0.702686    0.749117    0.734982    0.723294    0.723164    0.474867    0.469512    0.583858    0.568889    200         0.847059    0.835801    0.000000    0.397999    144.264834 
[37m[36mINFO[0m[0m 01/31 04:43:56 | 0.549600    0.545927    0.672941    0.679849    1.006292    0.643993    0.674912    0.672941    0.679849    0.426504    0.417683    0.578304    0.545185    400         1.694118    0.709356    0.000000    0.367514    152.628412 
[37m[36mINFO[0m[0m 01/31 04:47:34 | 0.669701    0.653266    0.739294    0.700565    0.730907    0.891343    0.865724    0.739294    0.700565    0.507616    0.500000    0.610144    0.594074    600         2.541176    0.691156    0.000000    0.351251    147.683377 
[37m[36mINFO[0m[0m 01/31 04:51:13 | 0.664069    0.659478    0.688000    0.691149    0.722202    0.902827    0.908127    0.688000    0.691149    0.445545    0.445122    0.643836    0.625185    800         3.388235    0.619222    0.000000    0.342351    150.062565 
[37m[36mINFO[0m[0m 01/31 04:54:48 | 0.673631    0.665346    0.775529    0.749529    0.636291    0.893993    0.883392    0.775529    0.749529    0.463442    0.475610    0.663458    0.637037    1000        4.235294    0.638257    0.000000    0.350118    144.533599 
[37m[36mINFO[0m[0m 01/31 04:58:38 | 0.644141    0.625739    0.762353    0.730697    0.654796    0.717314    0.692580    0.762353    0.730697    0.586824    0.559451    0.628286    0.625185    1200        5.082353    0.581270    0.000000    0.367578    156.256665 
[37m[36mINFO[0m[0m 01/31 05:02:23 | 0.702789    0.688299    0.795765    0.774011    0.617388    0.920495    0.908127    0.795765    0.774011    0.525895    0.516768    0.661977    0.640000    1400        5.929412    0.558532    0.000000    0.360868    153.218715 
[37m[36mINFO[0m[0m 01/31 05:05:57 | 0.707321    0.680240    0.761882    0.709981    0.718897    0.921378    0.890459    0.761882    0.709981    0.570449    0.548780    0.630137    0.601481    1600        6.776471    0.675035    0.000000    0.351636    142.911194 
[37m[36mINFO[0m[0m 01/31 05:09:37 | 0.721697    0.698453    0.812706    0.758945    0.615469    0.930212    0.925795    0.812706    0.758945    0.578827    0.550305    0.656053    0.619259    1800        7.623529    0.542816    0.000000    0.348612    149.766413 
[37m[36mINFO[0m[0m 01/31 05:13:14 | 0.713933    0.700181    0.784471    0.766478    0.665690    0.957597    0.946996    0.784471    0.766478    0.527037    0.507622    0.657164    0.645926    2000        8.470588    0.574070    0.000000    0.377831    141.514783 
[37m[36mINFO[0m[0m 01/31 05:16:56 | 0.704006    0.697573    0.814588    0.762712    0.682197    0.932862    0.925795    0.814588    0.762712    0.518660    0.509146    0.660496    0.657778    2200        9.317647    0.492620    0.000000    0.371128    148.394021 
[37m[36mINFO[0m[0m 01/31 05:20:44 | 0.704428    0.697611    0.832941    0.781544    0.588176    0.909894    0.915194    0.832941    0.781544    0.538081    0.521341    0.665309    0.656296    2400        10.164706   0.519378    0.000000    0.401234    147.059046 
[37m[36mINFO[0m[0m 01/31 05:24:27 | 0.574557    0.553053    0.823059    0.741996    0.643648    0.564488    0.526502    0.823059    0.741996    0.572734    0.554878    0.586449    0.577778    2600        11.011765   0.480753    0.000000    0.410165    140.465128 
[37m[36mINFO[0m[0m 01/31 05:28:14 | 0.678211    0.653280    0.824471    0.757062    0.694644    0.814488    0.773852    0.824471    0.757062    0.568165    0.554878    0.651981    0.631111    2800        11.858824   0.462599    0.000000    0.415598    144.473624 
[37m[36mINFO[0m[0m 01/31 05:32:03 | 0.666959    0.650395    0.803765    0.730697    0.704601    0.836572    0.809187    0.803765    0.730697    0.530465    0.518293    0.633839    0.623704    3000        12.705882   0.459338    0.000000    0.391496    150.589204 
[37m[36mINFO[0m[0m 01/31 05:35:55 | 0.724902    0.713080    0.836235    0.755179    0.630195    0.914311    0.893993    0.836235    0.755179    0.564356    0.554878    0.696039    0.690370    3200        13.552941   0.421831    0.000000    0.381563    155.720376 
[37m[36mINFO[0m[0m 01/31 05:39:35 | 0.672736    0.664651    0.854588    0.751412    0.639483    0.830389    0.833922    0.854588    0.751412    0.550647    0.527439    0.637171    0.632593    3400        14.400000   0.422753    0.000000    0.357966    147.761515 
[37m[36mINFO[0m[0m 01/31 05:43:26 | 0.488362    0.473180    0.856941    0.768362    0.653623    0.353357    0.328622    0.856941    0.768362    0.570449    0.545732    0.541281    0.545185    3600        15.247059   0.451769    0.000000    0.383952    154.679522 
[37m[36mINFO[0m[0m 01/31 05:47:03 | 0.479455    0.443864    0.811765    0.700565    0.814041    0.330389    0.279152    0.811765    0.700565    0.595202    0.547256    0.512773    0.505185    3800        16.094118   0.382596    0.000000    0.362317    144.166871 
[37m[36mINFO[0m[0m 01/31 05:50:44 | 0.559195    0.566455    0.812235    0.725047    0.780056    0.649293    0.671378    0.812235    0.725047    0.472201    0.467988    0.556090    0.560000    4000        16.941176   0.375721    0.000000    0.366089    147.428084 
[37m[36mINFO[0m[0m 01/31 05:54:27 | 0.589013    0.575274    0.873412    0.758945    0.736934    0.615724    0.611307    0.873412    0.758945    0.529322    0.489329    0.621992    0.625185    4200        17.788235   0.345363    0.000000    0.395920    143.714832 
[37m[36mINFO[0m[0m 01/31 05:58:08 | 0.449134    0.439176    0.775059    0.694915    0.943761    0.348940    0.363958    0.775059    0.694915    0.477913    0.455793    0.520548    0.497778    4400        18.635294   0.330853    0.000000    0.399068    141.475242 
[37m[36mINFO[0m[0m 01/31 06:01:48 | 0.466811    0.439824    0.870118    0.762712    0.752440    0.332155    0.318021    0.870118    0.762712    0.525514    0.472561    0.542762    0.528889    4600        19.482353   0.353646    0.000000    0.411464    138.117648 
[37m[36mINFO[0m[0m 01/31 06:05:36 | 0.490803    0.469161    0.874824    0.741996    0.794424    0.331272    0.307420    0.874824    0.741996    0.562833    0.554878    0.578304    0.545185    4800        20.329412   0.322361    0.000000    0.420683    143.678015 
[37m[36mINFO[0m[0m 01/31 06:09:25 | 0.645686    0.622444    0.856941    0.730697    0.847658    0.831272    0.812721    0.856941    0.730697    0.489718    0.466463    0.616068    0.588148    5000        21.176471   0.367623    0.000000    0.399108    148.668145 
[37m[36mINFO[0m[0m 01/31 06:09:25 | Cumulative gradient change saved at train_output/VLCS/CORAL/[0, 2, 3]/250131_04-34-02_resnet50_EVE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 01/31 06:09:26 | ---
[37m[36mINFO[0m[0m 01/31 06:09:26 | test-domain validation(oracle) = 72.490%
[37m[36mINFO[0m[0m 01/31 06:09:26 | training-domain validation(iid) = 70.443%
[37m[36mINFO[0m[0m 01/31 06:09:26 | last = 64.569%
[37m[36mINFO[0m[0m 01/31 06:09:26 | last (inD) = 73.070%
[37m[36mINFO[0m[0m 01/31 06:09:26 | training-domain validation (iid, inD) = 78.154%
[37m[36mINFO[0m[0m 01/31 06:09:26 | === Summary ===
[37m[36mINFO[0m[0m 01/31 06:09:26 | Command: /jsm0707/Large-scale/train_all.py resnet50_EVE config/resnet50_EVE.yaml --algorithm CORAL --test_envs 0 2 3 --dataset VLCS --trial_seed 0 --hparams_seed 13
[37m[36mINFO[0m[0m 01/31 06:09:26 | Unique name: 250131_04-34-02_resnet50_EVE
[37m[36mINFO[0m[0m 01/31 06:09:26 | Out path: train_output/VLCS/CORAL/[0, 2, 3]/250131_04-34-02_resnet50_EVE
[37m[36mINFO[0m[0m 01/31 06:09:26 | Algorithm: CORAL
[37m[36mINFO[0m[0m 01/31 06:09:26 | Dataset: VLCS
