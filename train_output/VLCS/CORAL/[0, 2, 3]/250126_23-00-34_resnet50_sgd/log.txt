[37m[36mINFO[0m[0m 01/26 23:00:34 | Command :: /jsm0707/Large-scale/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm CORAL --test_envs 0 2 3 --dataset VLCS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_sgd.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_sgd
	out_dir: train_output/VLCS/CORAL/[0, 2, 3]/250126_23-00-34_resnet50_sgd
	out_root: train_output/VLCS/CORAL/[0, 2, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 2, 3]
	trial_seed: 0
	unique_name: 250126_23-00-34_resnet50_sgd
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: sgd
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	mmd_gamma: 1.0
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 01/26 23:00:34 | n_steps = 5001
[37m[36mINFO[0m[0m 01/26 23:00:34 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 01/26 23:00:34 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 01/26 23:00:34 | 
[37m[36mINFO[0m[0m 01/26 23:00:34 | Testenv name escaping te_C_S_V -> te_C_S_V
[37m[36mINFO[0m[0m 01/26 23:00:34 | Test envs = [0, 2, 3], name = te_C_S_V
[37m[36mINFO[0m[0m 01/26 23:00:34 | Train environments: [1], Test environments: [0, 2, 3]
[37m[36mINFO[0m[0m 01/26 23:00:34 | Batch sizes for each domain: [0, 32, 0, 0] (total=32)
[37m[36mINFO[0m[0m 01/26 23:00:34 | steps-per-epoch for each domain: 66.41 -> min = 66.41
[37m[36mINFO[0m[0m 01/26 23:00:35 | # of params = 23518277
[37m[36mINFO[0m[0m 01/26 23:02:44 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 01/26 23:02:44 | 0.142825    0.121299    0.147294    0.169492    1.662063    0.093640    0.077739    0.147294    0.169492    0.191927    0.166159    0.142910    0.120000    0           0.000000    1.627299    0.000000    1.495368    127.246706 
[37m[36mINFO[0m[0m 01/26 23:08:44 | 0.208213    0.200507    0.571294    0.585687    0.997479    0.080389    0.074205    0.571294    0.585687    0.333587    0.312500    0.210663    0.214815    200         3.011765    1.222604    0.000000    1.170893    126.397955 
[37m[36mINFO[0m[0m 01/26 23:14:49 | 0.250740    0.239500    0.652235    0.655367    0.867276    0.123675    0.113074    0.652235    0.655367    0.382711    0.350610    0.245835    0.254815    400         6.023529    0.930064    0.000000    1.175430    129.636178 
[37m[36mINFO[0m[0m 01/26 23:21:00 | 0.278199    0.279114    0.672471    0.689266    0.804573    0.150177    0.144876    0.672471    0.689266    0.408225    0.390244    0.276194    0.302222    600         9.035294    0.852897    0.000000    1.184360    133.334278 
[37m[36mINFO[0m[0m 01/26 23:27:05 | 0.295998    0.295046    0.680941    0.689266    0.763485    0.159011    0.151943    0.680941    0.689266    0.426504    0.416159    0.302481    0.317037    800         12.047059   0.815233    0.000000    1.164271    131.905576 
[37m[36mINFO[0m[0m 01/26 23:33:11 | 0.310650    0.314426    0.687059    0.694915    0.736529    0.174912    0.169611    0.687059    0.694915    0.436786    0.432927    0.320252    0.340741    1000        15.058824   0.788845    0.000000    1.176112    130.257741 
[37m[36mINFO[0m[0m 01/26 23:39:16 | 0.339800    0.341662    0.697882    0.698682    0.716668    0.214664    0.215548    0.697882    0.698682    0.447829    0.440549    0.356905    0.368889    1200        18.070588   0.778775    0.000000    1.186425    127.630266 
[37m[36mINFO[0m[0m 01/26 23:45:20 | 0.330208    0.332923    0.708706    0.713748    0.701334    0.196996    0.190813    0.708706    0.713748    0.447829    0.440549    0.345798    0.367407    1400        21.082353   0.741928    0.000000    1.154941    133.092062 
[37m[36mINFO[0m[0m 01/26 23:51:21 | 0.338718    0.350261    0.700235    0.719397    0.688495    0.204947    0.219081    0.700235    0.719397    0.454303    0.442073    0.356905    0.389630    1600        24.094118   0.737810    0.000000    1.159494    129.023962 
[37m[36mINFO[0m[0m 01/26 23:57:33 | 0.366304    0.365838    0.717176    0.715631    0.673982    0.238516    0.240283    0.717176    0.715631    0.465727    0.454268    0.394669    0.402963    1800        27.105882   0.716115    0.000000    1.182472    134.602666 
[37m[36mINFO[0m[0m 01/27 00:03:39 | 0.390908    0.387488    0.722353    0.725047    0.664035    0.267668    0.265018    0.722353    0.725047    0.474105    0.461890    0.430951    0.435556    2000        30.117647   0.709995    0.000000    1.183407    129.467575 
[37m[36mINFO[0m[0m 01/27 00:09:47 | 0.391071    0.388950    0.722353    0.730697    0.654229    0.252650    0.254417    0.722353    0.730697    0.485910    0.467988    0.434654    0.444444    2200        33.129412   0.699515    0.000000    1.167699    134.066032 
[37m[36mINFO[0m[0m 01/27 00:15:46 | 0.423221    0.423190    0.726588    0.732580    0.646741    0.305654    0.310954    0.726588    0.732580    0.490480    0.477134    0.473528    0.481481    2400        36.141176   0.684304    0.000000    1.150634    128.606163 
[37m[36mINFO[0m[0m 01/27 00:21:50 | 0.436541    0.430385    0.737412    0.749529    0.637879    0.327739    0.325088    0.737412    0.749529    0.494288    0.478659    0.487597    0.487407    2600        39.152941   0.671808    0.000000    1.147183    133.748357 
[37m[36mINFO[0m[0m 01/27 00:27:58 | 0.471578    0.469963    0.751059    0.758945    0.631538    0.382509    0.399293    0.751059    0.758945    0.507235    0.481707    0.524991    0.528889    2800        42.164706   0.682190    0.000000    1.176867    132.430168 
[37m[36mINFO[0m[0m 01/27 00:33:59 | 0.498174    0.493467    0.748235    0.760829    0.627252    0.430212    0.448763    0.748235    0.760829    0.515994    0.492378    0.548315    0.539259    3000        45.176471   0.658392    0.000000    1.153727    130.026330 
[37m[36mINFO[0m[0m 01/27 00:40:02 | 0.490177    0.481512    0.759059    0.772128    0.618421    0.395760    0.409894    0.759059    0.772128    0.532749    0.493902    0.542021    0.540741    3200        48.188235   0.645692    0.000000    1.149097    133.392035 
[37m[36mINFO[0m[0m 01/27 00:45:59 | 0.501131    0.490887    0.752471    0.775895    0.612764    0.412544    0.427562    0.752471    0.775895    0.538462    0.496951    0.552388    0.548148    3400        51.200000   0.645739    0.000000    1.151855    126.524129 
[37m[36mINFO[0m[0m 01/27 00:51:59 | 0.500156    0.487795    0.764235    0.772128    0.607373    0.401060    0.402827    0.764235    0.772128    0.553313    0.519817    0.546094    0.540741    3600        54.211765   0.633198    0.000000    1.160020    127.366955 
[37m[36mINFO[0m[0m 01/27 00:57:54 | 0.498452    0.488459    0.760471    0.770245    0.604853    0.393993    0.395760    0.760471    0.770245    0.557121    0.525915    0.544243    0.543704    3800        57.223529   0.639026    0.000000    1.143279    126.179789 
[37m[36mINFO[0m[0m 01/27 01:03:53 | 0.537428    0.531957    0.773176    0.781544    0.604168    0.483216    0.498233    0.773176    0.781544    0.554836    0.521341    0.574232    0.576296    4000        60.235294   0.606357    0.000000    1.157846    126.902314 
[37m[36mINFO[0m[0m 01/27 01:09:55 | 0.548232    0.540007    0.774588    0.779661    0.597914    0.495583    0.508834    0.774588    0.779661    0.570069    0.528963    0.579045    0.582222    4200        63.247059   0.611943    0.000000    1.151868    131.528186 
[37m[36mINFO[0m[0m 01/27 01:15:56 | 0.514600    0.500597    0.772706    0.783427    0.591691    0.400177    0.395760    0.772706    0.783427    0.585682    0.556402    0.557942    0.549630    4400        66.258824   0.592780    0.000000    1.141231    132.490314 
[37m[36mINFO[0m[0m 01/27 01:21:54 | 0.534046    0.522534    0.773176    0.775895    0.586890    0.436396    0.445230    0.773176    0.775895    0.595583    0.557927    0.570159    0.564444    4600        69.270588   0.602072    0.000000    1.148547    128.611362 
[37m[36mINFO[0m[0m 01/27 01:27:56 | 0.523497    0.517822    0.775529    0.787194    0.586650    0.417845    0.431095    0.775529    0.787194    0.590632    0.557927    0.562014    0.564444    4800        72.282353   0.602722    0.000000    1.153964    130.128646 
[37m[36mINFO[0m[0m 01/27 01:33:54 | 0.543094    0.530488    0.779294    0.766478    0.586380    0.470848    0.466431    0.779294    0.766478    0.585682    0.547256    0.572751    0.577778    5000        75.294118   0.572577    0.000000    1.152858    127.505342 
[37m[36mINFO[0m[0m 01/27 01:33:54 | Cumulative gradient change saved at train_output/VLCS/CORAL/[0, 2, 3]/250126_23-00-34_resnet50_sgd/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 01/27 01:33:55 | ---
[37m[36mINFO[0m[0m 01/27 01:33:55 | test-domain validation(oracle) = 54.823%
[37m[36mINFO[0m[0m 01/27 01:33:55 | training-domain validation(iid) = 52.350%
[37m[36mINFO[0m[0m 01/27 01:33:55 | last = 54.309%
[37m[36mINFO[0m[0m 01/27 01:33:55 | last (inD) = 76.648%
[37m[36mINFO[0m[0m 01/27 01:33:55 | training-domain validation (iid, inD) = 78.719%
[37m[36mINFO[0m[0m 01/27 01:33:55 | === Summary ===
[37m[36mINFO[0m[0m 01/27 01:33:55 | Command: /jsm0707/Large-scale/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm CORAL --test_envs 0 2 3 --dataset VLCS
[37m[36mINFO[0m[0m 01/27 01:33:55 | Unique name: 250126_23-00-34_resnet50_sgd
[37m[36mINFO[0m[0m 01/27 01:33:55 | Out path: train_output/VLCS/CORAL/[0, 2, 3]/250126_23-00-34_resnet50_sgd
[37m[36mINFO[0m[0m 01/27 01:33:55 | Algorithm: CORAL
[37m[36mINFO[0m[0m 01/27 01:33:55 | Dataset: VLCS
