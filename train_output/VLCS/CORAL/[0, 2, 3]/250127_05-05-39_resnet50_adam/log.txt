[37m[36mINFO[0m[0m 01/27 05:05:39 | Command :: /jsm0707/Large-scale/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm CORAL --test_envs 0 2 3 --dataset VLCS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_adam.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_adam
	out_dir: train_output/VLCS/CORAL/[0, 2, 3]/250127_05-05-39_resnet50_adam
	out_root: train_output/VLCS/CORAL/[0, 2, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 2, 3]
	trial_seed: 0
	unique_name: 250127_05-05-39_resnet50_adam
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: adam
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	mmd_gamma: 1.0
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 01/27 05:05:39 | n_steps = 5001
[37m[36mINFO[0m[0m 01/27 05:05:39 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 01/27 05:05:39 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 01/27 05:05:39 | 
[37m[36mINFO[0m[0m 01/27 05:05:39 | Testenv name escaping te_C_S_V -> te_C_S_V
[37m[36mINFO[0m[0m 01/27 05:05:39 | Test envs = [0, 2, 3], name = te_C_S_V
[37m[36mINFO[0m[0m 01/27 05:05:39 | Train environments: [1], Test environments: [0, 2, 3]
[37m[36mINFO[0m[0m 01/27 05:05:39 | Batch sizes for each domain: [0, 32, 0, 0] (total=32)
[37m[36mINFO[0m[0m 01/27 05:05:39 | steps-per-epoch for each domain: 66.41 -> min = 66.41
[37m[36mINFO[0m[0m 01/27 05:05:40 | # of params = 23518277
[37m[36mINFO[0m[0m 01/27 05:07:46 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 01/27 05:07:46 | 0.206158    0.195549    0.482353    0.459510    1.281990    0.089223    0.063604    0.482353    0.459510    0.313404    0.318598    0.215846    0.204444    0           0.000000    1.627299    0.000000    1.500057    124.081388 
[37m[36mINFO[0m[0m 01/27 05:13:42 | 0.740486    0.730601    0.755765    0.768362    0.638717    0.934629    0.918728    0.755765    0.768362    0.609673    0.596037    0.677157    0.677037    200         3.011765    0.697925    0.000000    1.147615    126.516315 
[37m[36mINFO[0m[0m 01/27 05:19:34 | 0.647316    0.629492    0.852235    0.772128    0.603182    0.711131    0.689046    0.852235    0.772128    0.632521    0.611280    0.598297    0.588148    400         6.023529    0.486239    0.000000    1.120738    127.250948 
[37m[36mINFO[0m[0m 01/27 05:25:29 | 0.744231    0.745487    0.889412    0.785311    0.600361    0.900177    0.943463    0.889412    0.785311    0.601676    0.567073    0.730840    0.725926    600         9.035294    0.394003    0.000000    1.149079    125.028267 
[37m[36mINFO[0m[0m 01/27 05:31:23 | 0.587043    0.555138    0.920000    0.787194    0.619038    0.521201    0.473498    0.920000    0.787194    0.587205    0.554878    0.652721    0.637037    800         12.047059   0.285629    0.000000    1.129315    128.117581 
[37m[36mINFO[0m[0m 01/27 05:37:21 | 0.529377    0.494154    0.937882    0.770245    0.673224    0.460247    0.424028    0.937882    0.770245    0.552171    0.496951    0.575713    0.561481    1000        15.058824   0.263244    0.000000    1.145989    128.639811 
[37m[36mINFO[0m[0m 01/27 05:43:18 | 0.631346    0.628522    0.953412    0.760829    0.966018    0.684629    0.710247    0.953412    0.760829    0.568165    0.544207    0.641244    0.631111    1200        18.070588   0.181544    0.000000    1.147249    127.973498 
[37m[36mINFO[0m[0m 01/27 05:49:09 | 0.526343    0.528015    0.938824    0.758945    0.838564    0.416078    0.413428    0.938824    0.758945    0.535034    0.535061    0.627916    0.635556    1400        21.082353   0.145368    0.000000    1.127441    125.634274 
[37m[36mINFO[0m[0m 01/27 05:55:05 | 0.659676    0.664891    0.962353    0.762712    1.153540    0.806537    0.812721    0.962353    0.762712    0.518660    0.516768    0.653832    0.665185    1600        24.094118   0.101034    0.000000    1.146663    126.414673 
[37m[36mINFO[0m[0m 01/27 06:01:00 | 0.529747    0.500406    0.954824    0.762712    1.271356    0.382509    0.385159    0.954824    0.762712    0.591775    0.544207    0.614957    0.571852    1800        27.105882   0.106180    0.000000    1.129889    128.586031 
[37m[36mINFO[0m[0m 01/27 06:06:59 | 0.500346    0.491379    0.976941    0.785311    0.904815    0.330389    0.321555    0.976941    0.785311    0.545697    0.525915    0.624954    0.626667    2000        30.117647   0.089012    0.000000    1.147619    129.648817 
[37m[36mINFO[0m[0m 01/27 06:12:55 | 0.534683    0.523800    0.980235    0.800377    1.096698    0.440813    0.438163    0.980235    0.800377    0.545316    0.522866    0.617919    0.610370    2200        33.129412   0.069966    0.000000    1.133610    128.886659 
[37m[36mINFO[0m[0m 01/27 06:18:51 | 0.652049    0.655323    0.971765    0.785311    1.294154    0.804770    0.812721    0.971765    0.785311    0.491622    0.496951    0.659756    0.656296    2400        36.141176   0.061086    0.000000    1.144921    127.788980 
[37m[36mINFO[0m[0m 01/27 06:24:46 | 0.531496    0.524731    0.976000    0.772128    1.385245    0.460247    0.445230    0.976000    0.772128    0.541127    0.528963    0.593114    0.600000    2600        39.152941   0.073710    0.000000    1.134474    128.018975 
[37m[36mINFO[0m[0m 01/27 06:30:40 | 0.605089    0.585938    0.983059    0.757062    1.216072    0.647527    0.660777    0.983059    0.757062    0.534273    0.500000    0.633469    0.597037    2800        42.164706   0.052412    0.000000    1.141864    125.744497 
[37m[36mINFO[0m[0m 01/27 06:36:40 | 0.488801    0.484086    0.982588    0.762712    1.013560    0.300353    0.303887    0.982588    0.762712    0.606626    0.586890    0.559422    0.561481    3000        45.176471   0.076539    0.000000    1.150544    129.898496 
[37m[36mINFO[0m[0m 01/27 06:42:37 | 0.598907    0.579993    0.991059    0.785311    1.302931    0.628092    0.607774    0.991059    0.785311    0.512947    0.486280    0.655683    0.645926    3200        48.188235   0.048189    0.000000    1.131280    130.018020 
[37m[36mINFO[0m[0m 01/27 06:48:30 | 0.608877    0.604505    0.989176    0.751412    1.126711    0.658127    0.674912    0.989176    0.751412    0.535034    0.503049    0.633469    0.635556    3400        51.200000   0.044008    0.000000    1.134063    126.583520 
[37m[36mINFO[0m[0m 01/27 06:54:27 | 0.564829    0.553423    0.987294    0.787194    1.009565    0.571555    0.561837    0.987294    0.787194    0.507235    0.496951    0.615698    0.601481    3600        54.211765   0.055600    0.000000    1.148012    127.801951 
[37m[36mINFO[0m[0m 01/27 07:00:22 | 0.514439    0.488881    0.993882    0.758945    1.240871    0.350707    0.321555    0.993882    0.758945    0.549886    0.522866    0.642725    0.622222    3800        57.223529   0.033284    0.000000    1.133940    127.386829 
[37m[36mINFO[0m[0m 01/27 07:06:18 | 0.521611    0.516058    0.992471    0.792844    1.186067    0.343640    0.335689    0.992471    0.792844    0.565880    0.548780    0.655313    0.663704    4000        60.235294   0.056290    0.000000    1.141995    128.243540 
[37m[36mINFO[0m[0m 01/27 07:12:12 | 0.518706    0.518276    0.986353    0.783427    1.464568    0.321555    0.335689    0.986353    0.783427    0.580731    0.574695    0.653832    0.644444    4200        63.247059   0.044958    0.000000    1.144524    124.537676 
[37m[36mINFO[0m[0m 01/27 07:18:13 | 0.453184    0.454289    0.989647    0.764595    1.285094    0.296820    0.282686    0.989647    0.764595    0.472582    0.480183    0.590152    0.600000    4400        66.258824   0.049573    0.000000    1.156695    130.332848 
[37m[36mINFO[0m[0m 01/27 07:24:07 | 0.514983    0.522049    0.979294    0.772128    1.351660    0.401060    0.409894    0.979294    0.772128    0.488576    0.498476    0.655313    0.657778    4600        69.270588   0.027780    0.000000    1.130962    127.184284 
[37m[36mINFO[0m[0m 01/27 07:29:57 | 0.488451    0.473030    0.998118    0.785311    1.115631    0.324205    0.286219    0.998118    0.785311    0.576542    0.562500    0.564606    0.570370    4800        72.282353   0.044596    0.000000    1.116498    126.808006 
[37m[36mINFO[0m[0m 01/27 07:35:57 | 0.520216    0.516518    0.989647    0.764595    1.181861    0.422261    0.416961    0.989647    0.764595    0.503808    0.500000    0.634580    0.632593    5000        75.294118   0.027961    0.000000    1.158959    128.394468 
[37m[36mINFO[0m[0m 01/27 07:35:57 | Cumulative gradient change saved at train_output/VLCS/CORAL/[0, 2, 3]/250127_05-05-39_resnet50_adam/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 01/27 07:35:59 | ---
[37m[36mINFO[0m[0m 01/27 07:35:59 | test-domain validation(oracle) = 74.423%
[37m[36mINFO[0m[0m 01/27 07:35:59 | training-domain validation(iid) = 53.468%
[37m[36mINFO[0m[0m 01/27 07:35:59 | last = 52.022%
[37m[36mINFO[0m[0m 01/27 07:35:59 | last (inD) = 76.460%
[37m[36mINFO[0m[0m 01/27 07:35:59 | training-domain validation (iid, inD) = 80.038%
[37m[36mINFO[0m[0m 01/27 07:35:59 | === Summary ===
[37m[36mINFO[0m[0m 01/27 07:35:59 | Command: /jsm0707/Large-scale/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm CORAL --test_envs 0 2 3 --dataset VLCS
[37m[36mINFO[0m[0m 01/27 07:35:59 | Unique name: 250127_05-05-39_resnet50_adam
[37m[36mINFO[0m[0m 01/27 07:35:59 | Out path: train_output/VLCS/CORAL/[0, 2, 3]/250127_05-05-39_resnet50_adam
[37m[36mINFO[0m[0m 01/27 07:35:59 | Algorithm: CORAL
[37m[36mINFO[0m[0m 01/27 07:35:59 | Dataset: VLCS
