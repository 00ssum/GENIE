[37m[36mINFO[0m[0m 02/18 13:00:58 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 0 2 3 --dataset VLCS --trial_seed 1 --hparams_seed 19
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 19
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/VLCS/CORAL/[0, 2, 3]/250218_13-00-57_resnet50_GENIE
	out_root: train_output/VLCS/CORAL/[0, 2, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 2, 3]
	trial_seed: 1
	unique_name: 250218_13-00-57_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.5
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 3.7692486045276154e-05
	batch_size: 10
	weight_decay: 0.0003178970604685295
	mmd_gamma: 1.483929697730203
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 02/18 13:00:58 | n_steps = 5001
[37m[36mINFO[0m[0m 02/18 13:00:58 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/18 13:00:58 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/18 13:00:58 | 
[37m[36mINFO[0m[0m 02/18 13:00:58 | Testenv name escaping te_C_S_V -> te_C_S_V
[37m[36mINFO[0m[0m 02/18 13:00:58 | Test envs = [0, 2, 3], name = te_C_S_V
[37m[36mINFO[0m[0m 02/18 13:00:58 | Train environments: [1], Test environments: [0, 2, 3]
[37m[36mINFO[0m[0m 02/18 13:00:58 | Batch sizes for each domain: [0, 10, 0, 0] (total=10)
[37m[36mINFO[0m[0m 02/18 13:00:58 | steps-per-epoch for each domain: 212.50 -> min = 212.50
[37m[36mINFO[0m[0m 02/18 13:00:59 | # of params = 23518277
[37m[36mINFO[0m[0m 02/18 13:03:13 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 02/18 13:03:13 | 0.180398    0.185878    0.501647    0.495292    1.026468    0.037986    0.031802    0.501647    0.495292    0.295506    0.312500    0.207701    0.213333    0           0.000000    1.613834    0.000000    2.084204    131.804246 
[37m[36mINFO[0m[0m 02/18 13:07:09 | 0.437760    0.447067    0.622588    0.600753    0.973757    0.478799    0.484099    0.622588    0.600753    0.412414    0.449695    0.422066    0.407407    200         0.941176    0.989275    0.000000    0.451229    145.900450 
[37m[36mINFO[0m[0m 02/18 13:10:51 | 0.550844    0.552131    0.689882    0.685499    0.792467    0.693463    0.674912    0.689882    0.685499    0.445925    0.500000    0.513143    0.481481    400         1.882353    0.900901    0.000000    0.404402    140.332767 
[37m[36mINFO[0m[0m 02/18 13:14:37 | 0.612866    0.607024    0.727059    0.728814    0.752726    0.798587    0.766784    0.727059    0.728814    0.467631    0.507622    0.572381    0.546667    600         2.823529    0.728817    0.000000    0.441653    138.179849 
[37m[36mINFO[0m[0m 02/18 13:18:33 | 0.640452    0.643586    0.748706    0.715631    0.716044    0.837456    0.819788    0.748706    0.715631    0.474867    0.521341    0.609034    0.589630    800         3.764706    0.794105    0.000000    0.458065    144.606370 
[37m[36mINFO[0m[0m 02/18 13:22:30 | 0.646624    0.641991    0.757647    0.751412    0.676697    0.840106    0.826855    0.757647    0.751412    0.486291    0.521341    0.613476    0.577778    1000        4.705882    0.682650    0.000000    0.420021    152.762023 
[37m[36mINFO[0m[0m 02/18 13:26:41 | 0.612557    0.609059    0.726118    0.723164    0.739157    0.825088    0.805654    0.726118    0.723164    0.453161    0.501524    0.559422    0.520000    1200        5.647059    0.678349    0.000000    0.479617    154.453339 
[37m[36mINFO[0m[0m 02/18 13:30:35 | 0.639369    0.636249    0.767059    0.755179    0.654982    0.828622    0.812721    0.767059    0.755179    0.476009    0.516768    0.613476    0.579259    1400        6.588235    0.689335    0.000000    0.441998    146.019137 
[37m[36mINFO[0m[0m 02/18 13:34:25 | 0.637035    0.624586    0.785412    0.762712    0.636066    0.826855    0.802120    0.785412    0.762712    0.474105    0.492378    0.610144    0.579259    1600        7.529412    0.637043    0.000000    0.441491    141.364195 
[37m[36mINFO[0m[0m 02/18 13:38:21 | 0.625119    0.620602    0.787765    0.747646    0.677588    0.802120    0.798587    0.787765    0.747646    0.464204    0.509146    0.609034    0.554074    1800        8.470588    0.591496    0.000000    0.474610    141.848866 
[37m[36mINFO[0m[0m 02/18 13:42:14 | 0.638999    0.634824    0.803294    0.717514    0.658610    0.830389    0.805654    0.803294    0.717514    0.465727    0.510671    0.620881    0.588148    2000        9.411765    0.597910    0.000000    0.427185    146.762420 
[37m[36mINFO[0m[0m 02/18 13:46:09 | 0.629637    0.626921    0.812706    0.734463    0.704374    0.780035    0.773852    0.812706    0.734463    0.507616    0.535061    0.601259    0.571852    2200        10.352941   0.522664    0.000000    0.478817    139.746893 
[37m[36mINFO[0m[0m 02/18 13:50:10 | 0.641701    0.646229    0.767529    0.708098    0.730490    0.858657    0.876325    0.767529    0.708098    0.432978    0.478659    0.633469    0.583704    2400        11.294118   0.545709    0.000000    0.456082    149.921951 
[37m[36mINFO[0m[0m 02/18 13:54:02 | 0.641770    0.652239    0.823529    0.740113    0.675517    0.823322    0.844523    0.823529    0.740113    0.472963    0.512195    0.629026    0.600000    2600        12.235294   0.537020    0.000000    0.393218    153.313853 
[37m[36mINFO[0m[0m 02/18 13:57:58 | 0.646355    0.639493    0.792000    0.728814    0.866362    0.839223    0.819788    0.792000    0.728814    0.462300    0.506098    0.637542    0.592593    2800        13.176471   0.484741    0.000000    0.408698    153.557270 
[37m[36mINFO[0m[0m 02/18 14:02:01 | 0.680597    0.675221    0.830118    0.728814    0.703281    0.860424    0.876325    0.830118    0.728814    0.544935    0.568598    0.636431    0.580741    3000        14.117647   0.462614    0.000000    0.419718    159.228701 
[37m[36mINFO[0m[0m 02/18 14:05:58 | 0.660296    0.655460    0.844235    0.749529    0.794611    0.859541    0.844523    0.844235    0.749529    0.490099    0.539634    0.631248    0.582222    3200        15.058824   0.463324    0.000000    0.374088    162.876173 
[37m[36mINFO[0m[0m 02/18 14:09:47 | 0.659287    0.645083    0.842353    0.741996    0.764004    0.859541    0.826855    0.842353    0.741996    0.501142    0.535061    0.617179    0.573333    3400        16.000000   0.465233    0.000000    0.377021    152.972158 
[37m[36mINFO[0m[0m 02/18 14:14:01 | 0.670379    0.668121    0.836235    0.704331    0.800900    0.869258    0.869258    0.836235    0.704331    0.496192    0.536585    0.645687    0.598519    3600        16.941176   0.517496    0.000000    0.433433    167.555450 
[37m[36mINFO[0m[0m 02/18 14:17:44 | 0.657914    0.655258    0.851765    0.749529    0.835948    0.829505    0.812721    0.851765    0.749529    0.501142    0.542683    0.643095    0.610370    3800        17.882353   0.413287    0.000000    0.396909    143.504672 
[37m[36mINFO[0m[0m 02/18 14:21:34 | 0.532286    0.528582    0.801412    0.706215    0.905777    0.501767    0.494700    0.801412    0.706215    0.557883    0.550305    0.537208    0.540741    4000        18.823529   0.404303    0.000000    0.403915    149.597436 
[37m[36mINFO[0m[0m 02/18 14:25:39 | 0.465888    0.455024    0.809882    0.741996    0.891865    0.324205    0.293286    0.809882    0.741996    0.552171    0.550305    0.521288    0.521481    4200        19.764706   0.493626    0.000000    0.475163    149.797362 
[37m[36mINFO[0m[0m 02/18 14:29:25 | 0.607648    0.594296    0.853176    0.741996    1.016411    0.760601    0.720848    0.853176    0.741996    0.511805    0.519817    0.550537    0.542222    4400        20.705882   0.401985    0.000000    0.399460    145.841956 
[37m[36mINFO[0m[0m 02/18 14:33:08 | 0.617738    0.601069    0.892235    0.749529    0.897752    0.692580    0.667845    0.892235    0.749529    0.518279    0.545732    0.642355    0.589630    4600        21.647059   0.425361    0.000000    0.433573    136.094830 
[37m[36mINFO[0m[0m 02/18 14:37:02 | 0.673502    0.667194    0.881882    0.749529    0.677169    0.858657    0.848057    0.881882    0.749529    0.548743    0.559451    0.613106    0.594074    4800        22.588235   0.442734    0.000000    0.516006    131.396345 
[37m[36mINFO[0m[0m 02/18 14:40:58 | 0.650191    0.646962    0.873882    0.732580    0.852557    0.795936    0.780919    0.873882    0.732580    0.542270    0.577744    0.612366    0.582222    5000        23.529412   0.421096    0.000000    0.493979    137.198261 
[37m[36mINFO[0m[0m 02/18 14:40:59 | Cumulative gradient change saved at train_output/VLCS/CORAL/[0, 2, 3]/250218_13-00-57_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/18 14:41:00 | ---
[37m[36mINFO[0m[0m 02/18 14:41:00 | test-domain validation(oracle) = 68.060%
[37m[36mINFO[0m[0m 02/18 14:41:00 | training-domain validation(iid) = 63.703%
[37m[36mINFO[0m[0m 02/18 14:41:00 | last = 65.019%
[37m[36mINFO[0m[0m 02/18 14:41:00 | last (inD) = 73.258%
[37m[36mINFO[0m[0m 02/18 14:41:00 | training-domain validation (iid, inD) = 76.271%
[37m[36mINFO[0m[0m 02/18 14:41:00 | === Summary ===
[37m[36mINFO[0m[0m 02/18 14:41:00 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 0 2 3 --dataset VLCS --trial_seed 1 --hparams_seed 19
[37m[36mINFO[0m[0m 02/18 14:41:00 | Unique name: 250218_13-00-57_resnet50_GENIE
[37m[36mINFO[0m[0m 02/18 14:41:00 | Out path: train_output/VLCS/CORAL/[0, 2, 3]/250218_13-00-57_resnet50_GENIE
[37m[36mINFO[0m[0m 02/18 14:41:00 | Algorithm: CORAL
[37m[36mINFO[0m[0m 02/18 14:41:00 | Dataset: VLCS
