[37m[36mINFO[0m[0m 02/20 17:49:30 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 0 2 3 --dataset VLCS --trial_seed 1 --hparams_seed 9
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 9
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/VLCS/CORAL/[0, 2, 3]/250220_17-49-30_resnet50_GENIE
	out_root: train_output/VLCS/CORAL/[0, 2, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 2, 3]
	trial_seed: 1
	unique_name: 250220_17-49-30_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.5
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 2.7532223448653515e-05
	batch_size: 36
	weight_decay: 0.007511403320794324
	mmd_gamma: 7.620358209128009
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 02/20 17:49:30 | n_steps = 5001
[37m[36mINFO[0m[0m 02/20 17:49:30 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/20 17:49:30 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/20 17:49:30 | 
[37m[36mINFO[0m[0m 02/20 17:49:30 | Testenv name escaping te_C_S_V -> te_C_S_V
[37m[36mINFO[0m[0m 02/20 17:49:30 | Test envs = [0, 2, 3], name = te_C_S_V
[37m[36mINFO[0m[0m 02/20 17:49:30 | Train environments: [1], Test environments: [0, 2, 3]
[37m[36mINFO[0m[0m 02/20 17:49:30 | Batch sizes for each domain: [0, 36, 0, 0] (total=36)
[37m[36mINFO[0m[0m 02/20 17:49:30 | steps-per-epoch for each domain: 59.03 -> min = 59.03
[37m[36mINFO[0m[0m 02/20 17:49:31 | # of params = 23518277
[37m[36mINFO[0m[0m 02/20 17:52:03 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 02/20 17:52:03 | 0.424415    0.429483    0.466824    0.461394    1.142051    0.462014    0.484099    0.466824    0.461394    0.375095    0.417683    0.436135    0.386667    0           0.000000    1.704425    0.000000    1.574830    150.292723 
[37m[36mINFO[0m[0m 02/20 17:59:42 | 0.655172    0.655283    0.764235    0.736347    0.703845    0.840106    0.833922    0.764235    0.736347    0.489718    0.528963    0.635690    0.602963    200         3.388235    0.733614    0.000000    1.627101    133.771231 
[37m[36mINFO[0m[0m 02/20 18:07:34 | 0.667005    0.657206    0.804706    0.770245    0.689418    0.850707    0.819788    0.804706    0.770245    0.519802    0.551829    0.630507    0.600000    400         6.776471    0.581481    0.000000    1.680633    136.072011 
[37m[36mINFO[0m[0m 02/20 18:14:59 | 0.670246    0.669283    0.830118    0.764595    0.620339    0.856007    0.840989    0.830118    0.764595    0.505712    0.559451    0.649019    0.607407    600         10.164706   0.540880    0.000000    1.512917    142.423835 
[37m[36mINFO[0m[0m 02/20 18:22:28 | 0.711333    0.689217    0.880941    0.774011    0.598165    0.858657    0.812721    0.880941    0.774011    0.595963    0.635671    0.679378    0.619259    800         13.552941   0.451372    0.000000    1.517479    145.135613 
[37m[36mINFO[0m[0m 02/20 18:29:53 | 0.728143    0.706195    0.890824    0.775895    0.730918    0.885159    0.851590    0.890824    0.775895    0.617669    0.643293    0.681599    0.623704    1000        16.941176   0.367607    0.000000    1.515544    141.845507 
[37m[36mINFO[0m[0m 02/20 18:37:24 | 0.625385    0.631791    0.855529    0.749529    1.025307    0.823322    0.795053    0.855529    0.749529    0.502666    0.564024    0.550167    0.536296    1200        20.329412   0.306086    0.000000    1.550544    141.000158 
[37m[36mINFO[0m[0m 02/20 18:44:58 | 0.502756    0.501429    0.882353    0.757062    0.842049    0.325972    0.318021    0.882353    0.757062    0.631759    0.617378    0.550537    0.568889    1400        23.717647   0.278356    0.000000    1.513651    151.434433 
[37m[36mINFO[0m[0m 02/20 18:52:38 | 0.562199    0.570756    0.935529    0.753296    0.733979    0.431979    0.445230    0.935529    0.753296    0.623001    0.644817    0.631618    0.622222    1600        27.105882   0.283375    0.000000    1.532247    153.825267 
[37m[36mINFO[0m[0m 02/20 19:00:00 | 0.545471    0.548381    0.914353    0.753296    0.705644    0.441696    0.448763    0.914353    0.753296    0.572353    0.608232    0.622362    0.588148    1800        30.494118   0.259530    0.000000    1.510805    139.324799 
[37m[36mINFO[0m[0m 02/20 19:07:31 | 0.648416    0.646000    0.962353    0.751412    0.861511    0.631625    0.650177    0.962353    0.751412    0.641280    0.646341    0.672344    0.641481    2000        33.882353   0.224214    0.000000    1.497985    151.607873 
[37m[36mINFO[0m[0m 02/20 19:15:04 | 0.656222    0.636594    0.935059    0.755179    0.922983    0.805654    0.770318    0.935059    0.755179    0.523991    0.533537    0.639023    0.605926    2200        37.270588   0.201474    0.000000    1.507545    151.354185 
[37m[36mINFO[0m[0m 02/20 19:22:36 | 0.631006    0.611747    0.946353    0.747646    0.989057    0.768551    0.734982    0.946353    0.747646    0.482483    0.509146    0.641984    0.591111    2400        40.658824   0.188851    0.000000    1.477868    156.708954 
[37m[36mINFO[0m[0m 02/20 19:30:09 | 0.624090    0.618153    0.918588    0.762712    0.800066    0.742049    0.717314    0.918588    0.762712    0.543031    0.556402    0.587190    0.580741    2600        44.047059   0.215719    0.000000    1.519616    149.242707 
[37m[36mINFO[0m[0m 02/20 19:37:20 | 0.585885    0.595062    0.931765    0.743879    1.043612    0.568905    0.586572    0.931765    0.743879    0.557502    0.582317    0.631248    0.616296    2800        47.435294   0.172934    0.000000    1.445884    141.168595 
[37m[36mINFO[0m[0m 02/20 19:44:42 | 0.554514    0.543240    0.969412    0.745763    1.191109    0.494700    0.477032    0.969412    0.745763    0.573877    0.582317    0.594965    0.570370    3000        50.823529   0.151280    0.000000    1.440354    154.495132 
[37m[36mINFO[0m[0m 02/20 19:52:07 | 0.561882    0.551462    0.952471    0.709981    0.985920    0.544170    0.537102    0.952471    0.709981    0.535034    0.535061    0.606442    0.582222    3200        54.211765   0.139552    0.000000    1.450319    154.886333 
[37m[36mINFO[0m[0m 02/20 19:59:32 | 0.620065    0.591598    0.945412    0.732580    1.090649    0.689046    0.611307    0.945412    0.732580    0.563595    0.597561    0.607553    0.565926    3400        57.600000   0.162650    0.000000    1.491070    146.675457 
[37m[36mINFO[0m[0m 02/20 20:06:50 | 0.652890    0.632898    0.958588    0.738230    1.412160    0.762367    0.731449    0.958588    0.738230    0.562833    0.573171    0.633469    0.594074    3600        60.988235   0.145251    0.000000    1.472005    143.460824 
[37m[36mINFO[0m[0m 02/20 20:14:21 | 0.599665    0.580788    0.968471    0.740113    1.285975    0.660777    0.590106    0.968471    0.740113    0.524372    0.567073    0.613847    0.585185    3800        64.376471   0.155493    0.000000    1.470942    156.472052 
[37m[36mINFO[0m[0m 02/20 20:21:44 | 0.634124    0.612697    0.954824    0.717514    1.089878    0.784452    0.727915    0.954824    0.717514    0.513328    0.545732    0.604591    0.564444    4000        67.764706   0.162849    0.000000    1.444658    154.259662 
[37m[36mINFO[0m[0m 02/20 20:28:55 | 0.599313    0.598092    0.949176    0.747646    0.930881    0.709364    0.674912    0.949176    0.747646    0.509901    0.556402    0.578675    0.562963    4200        71.152941   0.127636    0.000000    1.449324    141.078408 
[37m[36mINFO[0m[0m 02/20 20:36:22 | 0.592377    0.581811    0.975059    0.740113    1.120008    0.657244    0.632509    0.975059    0.740113    0.544174    0.538110    0.575713    0.574815    4400        74.541176   0.128050    0.000000    1.445578    158.475209 
[37m[36mINFO[0m[0m 02/20 20:43:59 | 0.587382    0.579748    0.969412    0.738230    1.156530    0.663428    0.667845    0.969412    0.738230    0.515232    0.536585    0.583488    0.534815    4600        77.929412   0.245566    0.000000    1.514094    153.348061 
[37m[36mINFO[0m[0m 02/20 20:51:39 | 0.595842    0.563677    0.953412    0.743879    1.267574    0.720848    0.639576    0.953412    0.743879    0.494669    0.512195    0.572010    0.539259    4800        81.317647   0.158950    0.000000    1.609453    138.171453 
[37m[36mINFO[0m[0m 02/20 20:59:04 | 0.587953    0.575536    0.984000    0.741996    1.176227    0.728799    0.664311    0.984000    0.741996    0.502666    0.528963    0.532395    0.533333    5000        84.705882   0.135717    0.000000    1.503780    144.159702 
[37m[36mINFO[0m[0m 02/20 20:59:04 | Cumulative gradient change saved at train_output/VLCS/CORAL/[0, 2, 3]/250220_17-49-30_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/20 20:59:05 | ---
[37m[36mINFO[0m[0m 02/20 20:59:05 | test-domain validation(oracle) = 72.814%
[37m[36mINFO[0m[0m 02/20 20:59:05 | training-domain validation(iid) = 72.814%
[37m[36mINFO[0m[0m 02/20 20:59:05 | last = 58.795%
[37m[36mINFO[0m[0m 02/20 20:59:05 | last (inD) = 74.200%
[37m[36mINFO[0m[0m 02/20 20:59:05 | training-domain validation (iid, inD) = 77.589%
[37m[36mINFO[0m[0m 02/20 20:59:05 | === Summary ===
[37m[36mINFO[0m[0m 02/20 20:59:05 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 0 2 3 --dataset VLCS --trial_seed 1 --hparams_seed 9
[37m[36mINFO[0m[0m 02/20 20:59:05 | Unique name: 250220_17-49-30_resnet50_GENIE
[37m[36mINFO[0m[0m 02/20 20:59:05 | Out path: train_output/VLCS/CORAL/[0, 2, 3]/250220_17-49-30_resnet50_GENIE
[37m[36mINFO[0m[0m 02/20 20:59:05 | Algorithm: CORAL
[37m[36mINFO[0m[0m 02/20 20:59:05 | Dataset: VLCS
