[37m[36mINFO[0m[0m 02/18 18:03:43 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 0 1 3 --dataset VLCS --trial_seed 0 --hparams_seed 20
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 20
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/VLCS/CORAL/[0, 1, 3]/250218_18-03-43_resnet50_GENIE
	out_root: train_output/VLCS/CORAL/[0, 1, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 1, 3]
	trial_seed: 0
	unique_name: 250218_18-03-43_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.5
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 2.6157673767852512e-05
	batch_size: 32
	weight_decay: 1.110622050999988e-05
	mmd_gamma: 0.11123344099864356
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 02/18 18:03:43 | n_steps = 5001
[37m[36mINFO[0m[0m 02/18 18:03:43 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/18 18:03:43 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/18 18:03:43 | 
[37m[36mINFO[0m[0m 02/18 18:03:43 | Testenv name escaping te_C_L_V -> te_C_L_V
[37m[36mINFO[0m[0m 02/18 18:03:43 | Test envs = [0, 1, 3], name = te_C_L_V
[37m[36mINFO[0m[0m 02/18 18:03:43 | Train environments: [2], Test environments: [0, 1, 3]
[37m[36mINFO[0m[0m 02/18 18:03:43 | Batch sizes for each domain: [0, 0, 32, 0] (total=32)
[37m[36mINFO[0m[0m 02/18 18:03:43 | steps-per-epoch for each domain: 82.06 -> min = 82.06
[37m[36mINFO[0m[0m 02/18 18:03:45 | # of params = 23518277
[37m[36mINFO[0m[0m 02/18 18:06:19 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 02/18 18:06:19 | 0.337979    0.347977    0.487433    0.501524    1.179016    0.124558    0.134276    0.529882    0.534840    0.487433    0.501524    0.359496    0.374815    0           0.000000    1.800473    0.000000    1.770069    152.609558 
[37m[36mINFO[0m[0m 02/18 18:09:31 | 0.636813    0.640438    0.856055    0.804878    0.545395    0.704064    0.713781    0.573647    0.563089    0.856055    0.804878    0.632729    0.644444    200         2.437167    0.567461    0.000000    0.250299    141.707728 
[37m[36mINFO[0m[0m 02/18 18:12:33 | 0.594604    0.618772    0.883854    0.807927    0.525393    0.569788    0.618375    0.593882    0.587571    0.883854    0.807927    0.620141    0.650370    400         4.874334    0.404447    0.000000    0.287914    124.595834 
[37m[36mINFO[0m[0m 02/18 18:15:40 | 0.519444    0.528637    0.906321    0.815549    0.516377    0.379859    0.399293    0.599059    0.596987    0.906321    0.815549    0.579415    0.589630    600         7.311500    0.348115    0.000000    0.306097    126.091885 
[37m[36mINFO[0m[0m 02/18 18:19:02 | 0.652365    0.658735    0.924600    0.812500    0.620953    0.709364    0.713781    0.606118    0.612053    0.924600    0.812500    0.641614    0.650370    800         9.748667    0.290290    0.000000    0.317933    138.030460 
[37m[36mINFO[0m[0m 02/18 18:22:17 | 0.613925    0.629530    0.924981    0.798780    0.696687    0.595406    0.639576    0.568471    0.563089    0.924981    0.798780    0.677897    0.685926    1000        12.185834   0.216701    0.000000    0.249821    144.657378 
[37m[36mINFO[0m[0m 02/18 18:25:24 | 0.623631    0.623364    0.931835    0.789634    0.672103    0.652827    0.660777    0.564235    0.536723    0.931835    0.789634    0.653832    0.672593    1200        14.623001   0.185609    0.000000    0.231625    140.837176 
[37m[36mINFO[0m[0m 02/18 18:28:40 | 0.527039    0.534719    0.952399    0.795732    0.638388    0.359541    0.363958    0.608471    0.612053    0.952399    0.795732    0.613106    0.628148    1400        17.060168   0.160457    0.000000    0.277216    140.727226 
[37m[36mINFO[0m[0m 02/18 18:31:57 | 0.605123    0.619036    0.960777    0.775915    0.783362    0.526502    0.572438    0.602824    0.591337    0.960777    0.775915    0.686042    0.693333    1600        19.497334   0.163875    0.000000    0.248882    146.912215 
[37m[36mINFO[0m[0m 02/18 18:35:18 | 0.666615    0.675742    0.963062    0.788110    0.833824    0.747350    0.752650    0.592000    0.585687    0.963062    0.788110    0.660496    0.688889    1800        21.934501   0.109611    0.000000    0.244308    152.185963 
[37m[36mINFO[0m[0m 02/18 18:38:27 | 0.492111    0.493733    0.958873    0.763720    0.950600    0.299470    0.310954    0.568941    0.548023    0.958873    0.763720    0.607923    0.622222    2000        24.371668   0.086108    0.000000    0.242111    140.856180 
[37m[36mINFO[0m[0m 02/18 18:41:30 | 0.651707    0.673020    0.961538    0.789634    1.041480    0.642226    0.678445    0.656471    0.659134    0.961538    0.789634    0.656424    0.681481    2200        26.808835   0.106236    0.000000    0.271588    128.247963 
[37m[36mINFO[0m[0m 02/18 18:44:38 | 0.587794    0.614697    0.983244    0.800305    0.949780    0.503534    0.565371    0.605647    0.612053    0.983244    0.800305    0.654202    0.666667    2400        29.246002   0.082137    0.000000    0.289086    130.429811 
[37m[36mINFO[0m[0m 02/18 18:47:54 | 0.642788    0.657750    0.989718    0.794207    0.811193    0.627208    0.657244    0.624000    0.627119    0.989718    0.794207    0.677157    0.688889    2600        31.683168   0.064795    0.000000    0.275867    141.069605 
[37m[36mINFO[0m[0m 02/18 18:51:02 | 0.705283    0.708936    0.981721    0.792683    0.958126    0.800353    0.780919    0.623529    0.642185    0.981721    0.792683    0.691966    0.703704    2800        34.120335   0.071151    0.000000    0.273418    132.722523 
[37m[36mINFO[0m[0m 02/18 18:54:16 | 0.618697    0.632865    0.985149    0.794207    1.115599    0.584806    0.621908    0.636706    0.623352    0.985149    0.794207    0.634580    0.653333    3000        36.557502   0.049660    0.000000    0.292229    136.324655 
[37m[36mINFO[0m[0m 02/18 18:57:36 | 0.625047    0.644978    0.978675    0.777439    1.274604    0.561837    0.593640    0.653176    0.655367    0.978675    0.777439    0.660126    0.685926    3200        38.994669   0.042189    0.000000    0.244839    150.631512 
[37m[36mINFO[0m[0m 02/18 19:00:52 | 0.585267    0.610324    0.993526    0.798780    1.248102    0.492049    0.558304    0.606588    0.604520    0.993526    0.798780    0.657164    0.668148    3400        41.431835   0.053074    0.000000    0.238921    148.049554 
[37m[36mINFO[0m[0m 02/18 19:04:06 | 0.631844    0.647696    0.990480    0.795732    1.027100    0.661661    0.685512    0.601882    0.610169    0.990480    0.795732    0.631988    0.647407    3600        43.869002   0.055095    0.000000    0.263660    141.192863 
[37m[36mINFO[0m[0m 02/18 19:07:21 | 0.568040    0.591746    0.996192    0.801829    1.194409    0.447880    0.501767    0.611294    0.608286    0.996192    0.801829    0.644946    0.665185    3800        46.306169   0.037862    0.000000    0.283057    138.323084 
[37m[36mINFO[0m[0m 02/18 19:10:29 | 0.562917    0.574989    0.960015    0.750000    1.854260    0.535336    0.579505    0.561412    0.549906    0.960015    0.750000    0.592003    0.595556    4000        48.743336   0.023384    0.000000    0.279530    132.571661 
[37m[36mINFO[0m[0m 02/18 19:13:45 | 0.628620    0.634936    0.990480    0.794207    1.192539    0.641343    0.653710    0.618824    0.621469    0.990480    0.794207    0.625694    0.629630    4200        51.180503   0.043856    0.000000    0.261862    143.412709 
[37m[36mINFO[0m[0m 02/18 19:16:50 | 0.649775    0.667132    0.991241    0.795732    1.029912    0.626325    0.671378    0.624000    0.623352    0.991241    0.795732    0.699000    0.706667    4400        53.617669   0.046125    0.000000    0.263262    132.648741 
[37m[36mINFO[0m[0m 02/18 19:20:08 | 0.598867    0.608075    0.996192    0.794207    1.303199    0.506184    0.554770    0.601412    0.589454    0.996192    0.794207    0.689004    0.680000    4600        56.054836   0.027536    0.000000    0.287808    139.858248 
[37m[36mINFO[0m[0m 02/18 19:23:24 | 0.557400    0.580049    0.992384    0.789634    1.496165    0.473498    0.533569    0.574118    0.572505    0.992384    0.789634    0.624583    0.634074    4800        58.492003   0.019944    0.000000    0.231445    149.794324 
[37m[36mINFO[0m[0m 02/18 19:26:48 | 0.657166    0.658127    0.968774    0.788110    1.065269    0.712898    0.720848    0.608471    0.612053    0.968774    0.788110    0.650130    0.641481    5000        60.929170   0.028288    0.000000    0.252672    154.004555 
[37m[36mINFO[0m[0m 02/18 19:26:48 | Cumulative gradient change saved at train_output/VLCS/CORAL/[0, 1, 3]/250218_18-03-43_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/18 19:26:50 | ---
[37m[36mINFO[0m[0m 02/18 19:26:50 | test-domain validation(oracle) = 70.528%
[37m[36mINFO[0m[0m 02/18 19:26:50 | training-domain validation(iid) = 51.944%
[37m[36mINFO[0m[0m 02/18 19:26:50 | last = 65.717%
[37m[36mINFO[0m[0m 02/18 19:26:50 | last (inD) = 78.811%
[37m[36mINFO[0m[0m 02/18 19:26:50 | training-domain validation (iid, inD) = 81.555%
[37m[36mINFO[0m[0m 02/18 19:26:50 | === Summary ===
[37m[36mINFO[0m[0m 02/18 19:26:50 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 0 1 3 --dataset VLCS --trial_seed 0 --hparams_seed 20
[37m[36mINFO[0m[0m 02/18 19:26:50 | Unique name: 250218_18-03-43_resnet50_GENIE
[37m[36mINFO[0m[0m 02/18 19:26:50 | Out path: train_output/VLCS/CORAL/[0, 1, 3]/250218_18-03-43_resnet50_GENIE
[37m[36mINFO[0m[0m 02/18 19:26:50 | Algorithm: CORAL
[37m[36mINFO[0m[0m 02/18 19:26:50 | Dataset: VLCS
