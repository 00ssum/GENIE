[37m[36mINFO[0m[0m 02/18 16:44:00 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 0 1 3 --dataset VLCS --trial_seed 0 --hparams_seed 19
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 19
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/VLCS/CORAL/[0, 1, 3]/250218_16-44-00_resnet50_GENIE
	out_root: train_output/VLCS/CORAL/[0, 1, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 1, 3]
	trial_seed: 0
	unique_name: 250218_16-44-00_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 5.513854977685438e-05
	batch_size: 27
	weight_decay: 0.0014556716107047517
	mmd_gamma: 6.828665286703169
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 02/18 16:44:00 | n_steps = 5001
[37m[36mINFO[0m[0m 02/18 16:44:00 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/18 16:44:00 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/18 16:44:00 | 
[37m[36mINFO[0m[0m 02/18 16:44:00 | Testenv name escaping te_C_L_V -> te_C_L_V
[37m[36mINFO[0m[0m 02/18 16:44:00 | Test envs = [0, 1, 3], name = te_C_L_V
[37m[36mINFO[0m[0m 02/18 16:44:00 | Train environments: [2], Test environments: [0, 1, 3]
[37m[36mINFO[0m[0m 02/18 16:44:00 | Batch sizes for each domain: [0, 0, 27, 0] (total=27)
[37m[36mINFO[0m[0m 02/18 16:44:00 | steps-per-epoch for each domain: 97.26 -> min = 97.26
[37m[36mINFO[0m[0m 02/18 16:44:01 | # of params = 23518277
[37m[36mINFO[0m[0m 02/18 16:46:25 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 02/18 16:46:25 | 0.454554    0.478927    0.399086    0.428354    1.131623    0.460247    0.501767    0.477647    0.500942    0.399086    0.428354    0.425768    0.434074    0           0.000000    1.687580    0.000000    1.991142    141.787333 
[37m[36mINFO[0m[0m 02/18 16:49:35 | 0.630757    0.632411    0.851104    0.794207    0.580752    0.677562    0.674912    0.584941    0.583804    0.851104    0.794207    0.629767    0.638519    200         2.056359    0.547767    0.000000    0.204439    149.088801 
[37m[36mINFO[0m[0m 02/18 16:52:31 | 0.661753    0.658036    0.846154    0.792683    0.701380    0.753534    0.745583    0.595294    0.578154    0.846154    0.792683    0.636431    0.650370    400         4.112719    0.442404    0.000000    0.198328    136.470446 
[37m[36mINFO[0m[0m 02/18 16:55:35 | 0.651588    0.656210    0.874714    0.800305    0.627192    0.690813    0.671378    0.635294    0.657250    0.874714    0.800305    0.628656    0.640000    600         6.169078    0.339459    0.000000    0.250767    133.536503 
[37m[36mINFO[0m[0m 02/18 16:58:42 | 0.664460    0.668062    0.926504    0.785061    0.649570    0.725265    0.734982    0.590588    0.574388    0.926504    0.785061    0.677527    0.694815    800         8.225438    0.283303    0.000000    0.209746    145.665406 
[37m[36mINFO[0m[0m 02/18 17:01:55 | 0.681118    0.668837    0.921935    0.800305    0.617063    0.741166    0.713781    0.608000    0.608286    0.921935    0.800305    0.694187    0.684444    1000        10.281797   0.241940    0.000000    0.209102    150.852830 
[37m[36mINFO[0m[0m 02/18 17:04:50 | 0.514313    0.519017    0.896801    0.785061    0.785241    0.331272    0.339223    0.619294    0.625235    0.896801    0.785061    0.592373    0.592593    1200        12.338157   0.181602    0.000000    0.241133    126.511337 
[37m[36mINFO[0m[0m 02/18 17:08:00 | 0.683768    0.698151    0.929931    0.803354    0.832676    0.734982    0.749117    0.634353    0.653484    0.929931    0.803354    0.681970    0.691852    1400        14.394516   0.186645    0.000000    0.245861    141.193608 
[37m[36mINFO[0m[0m 02/18 17:11:15 | 0.589772    0.615697    0.927266    0.807927    0.643371    0.511484    0.558304    0.629176    0.638418    0.927266    0.807927    0.628656    0.650370    1600        16.450876   0.154074    0.000000    0.213352    151.735978 
[37m[36mINFO[0m[0m 02/18 17:14:16 | 0.686423    0.694880    0.969155    0.795732    0.858314    0.723498    0.745583    0.612706    0.610169    0.969155    0.795732    0.723066    0.728889    1800        18.507235   0.130493    0.000000    0.197400    142.057005 
[37m[36mINFO[0m[0m 02/18 17:17:27 | 0.689081    0.686825    0.956969    0.797256    0.854854    0.750000    0.738516    0.600471    0.606403    0.956969    0.797256    0.716772    0.715556    2000        20.563595   0.118605    0.000000    0.221830    146.346425 
[37m[36mINFO[0m[0m 02/18 17:20:27 | 0.529203    0.545045    0.973343    0.797256    0.823650    0.378975    0.420495    0.598118    0.589454    0.973343    0.797256    0.610515    0.625185    2200        22.619954   0.106037    0.000000    0.216552    137.195406 
[37m[36mINFO[0m[0m 02/18 17:23:30 | 0.651750    0.671520    0.988195    0.794207    0.979820    0.644876    0.667845    0.627294    0.625235    0.988195    0.794207    0.683080    0.721481    2400        24.676314   0.070072    0.000000    0.224490    137.841583 
[37m[36mINFO[0m[0m 02/18 17:26:35 | 0.527671    0.545023    0.973343    0.772866    1.163495    0.354240    0.388693    0.640471    0.627119    0.973343    0.772866    0.588301    0.619259    2600        26.732673   0.056746    0.000000    0.261003    133.138367 
[37m[36mINFO[0m[0m 02/18 17:29:45 | 0.571843    0.581852    0.984387    0.777439    0.819893    0.541519    0.579505    0.564235    0.563089    0.984387    0.777439    0.609774    0.602963    2800        28.789033   0.091434    0.000000    0.242921    140.931826 
[37m[36mINFO[0m[0m 02/18 17:32:46 | 0.633065    0.651911    0.975248    0.792683    1.036993    0.614841    0.653710    0.604235    0.610169    0.975248    0.792683    0.680118    0.691852    3000        30.845392   0.055100    0.000000    0.200657    140.829613 
[37m[36mINFO[0m[0m 02/18 17:35:44 | 0.616596    0.635809    0.987433    0.782012    1.038693    0.560954    0.611307    0.600941    0.589454    0.987433    0.782012    0.687893    0.706667    3200        32.901752   0.047966    0.000000    0.226354    132.709783 
[37m[36mINFO[0m[0m 02/18 17:38:46 | 0.666865    0.681437    0.979056    0.786585    1.147952    0.655477    0.671378    0.646118    0.664783    0.979056    0.786585    0.699000    0.708148    3400        34.958111   0.055918    0.000000    0.211450    139.502105 
[37m[36mINFO[0m[0m 02/18 17:42:03 | 0.670740    0.690301    0.980198    0.798780    0.705711    0.685512    0.734982    0.646588    0.644068    0.980198    0.798780    0.680118    0.691852    3600        37.014471   0.091679    0.000000    0.208341    155.998119 
[37m[36mINFO[0m[0m 02/18 17:45:02 | 0.604209    0.624686    0.990861    0.797256    1.030032    0.487633    0.533569    0.643765    0.651601    0.990861    0.797256    0.681229    0.688889    3800        39.070830   0.039668    0.000000    0.199610    138.499337 
[37m[36mINFO[0m[0m 02/18 17:48:08 | 0.643322    0.661169    0.991241    0.797256    0.891818    0.674912    0.703180    0.617882    0.619586    0.991241    0.797256    0.637171    0.660741    4000        41.127190   0.063236    0.000000    0.275629    131.411673 
[37m[36mINFO[0m[0m 02/18 17:51:16 | 0.663515    0.681153    0.994288    0.809451    1.163248    0.683746    0.720848    0.607059    0.623352    0.994288    0.809451    0.699741    0.699259    4200        43.183549   0.038567    0.000000    0.232504    141.134132 
[37m[36mINFO[0m[0m 02/18 17:54:27 | 0.591920    0.619676    0.993145    0.815549    1.036555    0.504417    0.579505    0.617882    0.615819    0.993145    0.815549    0.653462    0.663704    4400        45.239909   0.050120    0.000000    0.229697    144.715293 
[37m[36mINFO[0m[0m 02/18 17:57:29 | 0.648411    0.657474    0.972963    0.763720    1.343145    0.663428    0.657244    0.623529    0.644068    0.972963    0.763720    0.658275    0.671111    4600        47.296268   0.041881    0.000000    0.226432    136.800354 
[37m[36mINFO[0m[0m 02/18 18:00:31 | 0.617804    0.643981    0.995430    0.791159    1.343316    0.566254    0.632509    0.622588    0.632768    0.995430    0.791159    0.664569    0.666667    4800        49.352628   0.015819    0.000000    0.243051    133.236207 
[37m[36mINFO[0m[0m 02/18 18:03:38 | 0.588402    0.617366    0.978294    0.775915    1.125502    0.431979    0.477032    0.654588    0.681733    0.978294    0.775915    0.678638    0.693333    5000        51.408987   0.028924    0.000000    0.209437    144.998936 
[37m[36mINFO[0m[0m 02/18 18:03:38 | Cumulative gradient change saved at train_output/VLCS/CORAL/[0, 1, 3]/250218_16-44-00_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/18 18:03:39 | ---
[37m[36mINFO[0m[0m 02/18 18:03:39 | test-domain validation(oracle) = 68.377%
[37m[36mINFO[0m[0m 02/18 18:03:39 | training-domain validation(iid) = 59.192%
[37m[36mINFO[0m[0m 02/18 18:03:39 | last = 58.840%
[37m[36mINFO[0m[0m 02/18 18:03:39 | last (inD) = 77.591%
[37m[36mINFO[0m[0m 02/18 18:03:39 | training-domain validation (iid, inD) = 81.555%
[37m[36mINFO[0m[0m 02/18 18:03:39 | === Summary ===
[37m[36mINFO[0m[0m 02/18 18:03:39 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 0 1 3 --dataset VLCS --trial_seed 0 --hparams_seed 19
[37m[36mINFO[0m[0m 02/18 18:03:39 | Unique name: 250218_16-44-00_resnet50_GENIE
[37m[36mINFO[0m[0m 02/18 18:03:39 | Out path: train_output/VLCS/CORAL/[0, 1, 3]/250218_16-44-00_resnet50_GENIE
[37m[36mINFO[0m[0m 02/18 18:03:39 | Algorithm: CORAL
[37m[36mINFO[0m[0m 02/18 18:03:39 | Dataset: VLCS
