[37m[36mINFO[0m[0m 02/18 05:41:45 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 0 1 3 --dataset VLCS --trial_seed 0 --hparams_seed 10
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 10
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/VLCS/CORAL/[0, 1, 3]/250218_05-41-45_resnet50_GENIE
	out_root: train_output/VLCS/CORAL/[0, 1, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 1, 3]
	trial_seed: 0
	unique_name: 250218_05-41-45_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.5
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 2.5980189819232268e-05
	batch_size: 22
	weight_decay: 1.2831747186887755e-05
	mmd_gamma: 9.16203772838486
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 02/18 05:41:45 | n_steps = 5001
[37m[36mINFO[0m[0m 02/18 05:41:45 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/18 05:41:45 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/18 05:41:45 | 
[37m[36mINFO[0m[0m 02/18 05:41:45 | Testenv name escaping te_C_L_V -> te_C_L_V
[37m[36mINFO[0m[0m 02/18 05:41:45 | Test envs = [0, 1, 3], name = te_C_L_V
[37m[36mINFO[0m[0m 02/18 05:41:45 | Train environments: [2], Test environments: [0, 1, 3]
[37m[36mINFO[0m[0m 02/18 05:41:45 | Batch sizes for each domain: [0, 0, 22, 0] (total=22)
[37m[36mINFO[0m[0m 02/18 05:41:45 | steps-per-epoch for each domain: 119.36 -> min = 119.36
[37m[36mINFO[0m[0m 02/18 05:41:47 | # of params = 23518277
[37m[36mINFO[0m[0m 02/18 05:44:24 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 02/18 05:44:24 | 0.504467    0.522142    0.384996    0.396341    1.324049    0.611307    0.628975    0.459294    0.491525    0.384996    0.396341    0.442799    0.445926    0           0.000000    1.887361    0.000000    1.411466    155.927462 
[37m[36mINFO[0m[0m 02/18 05:47:31 | 0.645208    0.645158    0.808073    0.760671    0.583868    0.738516    0.727915    0.556235    0.542373    0.808073    0.760671    0.640874    0.665185    200         1.675552    0.646752    0.000000    0.167305    153.239189 
[37m[36mINFO[0m[0m 02/18 05:50:29 | 0.691093    0.692853    0.829779    0.775915    0.577229    0.762367    0.749117    0.654118    0.655367    0.829779    0.775915    0.656794    0.674074    400         3.351104    0.485810    0.000000    0.186505    141.011374 
[37m[36mINFO[0m[0m 02/18 05:53:21 | 0.681341    0.671755    0.845011    0.765244    0.641827    0.751767    0.731449    0.634353    0.629002    0.845011    0.765244    0.657904    0.654815    600         5.026657    0.435434    0.000000    0.175798    136.241261 
[37m[36mINFO[0m[0m 02/18 05:56:17 | 0.671410    0.678146    0.872049    0.795732    0.605982    0.761484    0.763251    0.607059    0.604520    0.872049    0.795732    0.645687    0.666667    800         6.702209    0.387888    0.000000    0.231196    129.643036 
[37m[36mINFO[0m[0m 02/18 05:59:21 | 0.683532    0.691216    0.878142    0.794207    0.667964    0.750000    0.756184    0.640471    0.647834    0.878142    0.794207    0.660126    0.669630    1000        8.377761    0.370068    0.000000    0.206178    142.752797 
[37m[36mINFO[0m[0m 02/18 06:02:26 | 0.675405    0.672651    0.896040    0.783537    0.684754    0.740283    0.731449    0.632471    0.634652    0.896040    0.783537    0.653462    0.651852    1200        10.053313   0.287618    0.000000    0.169464    151.333171 
[37m[36mINFO[0m[0m 02/18 06:05:32 | 0.653054    0.656201    0.940594    0.782012    0.634108    0.741166    0.734982    0.593412    0.595104    0.940594    0.782012    0.624583    0.638519    1400        11.728865   0.247200    0.000000    0.167579    152.459416 
[37m[36mINFO[0m[0m 02/18 06:08:21 | 0.633764    0.653079    0.943641    0.786585    0.731097    0.659011    0.710247    0.578824    0.583804    0.943641    0.786585    0.663458    0.665185    1600        13.404417   0.230064    0.000000    0.180833    133.024145 
[37m[36mINFO[0m[0m 02/18 06:11:24 | 0.657580    0.670501    0.923077    0.778963    0.764089    0.679329    0.678445    0.653647    0.672316    0.923077    0.778963    0.639763    0.660741    1800        15.079970   0.177523    0.000000    0.209119    141.220738 
[37m[36mINFO[0m[0m 02/18 06:14:27 | 0.614871    0.625162    0.961919    0.771341    0.882956    0.598940    0.625442    0.610353    0.602637    0.961919    0.771341    0.635320    0.647407    2000        16.755522   0.158113    0.000000    0.224336    138.299670 
[37m[36mINFO[0m[0m 02/18 06:17:40 | 0.601856    0.619868    0.952018    0.766768    0.699535    0.545936    0.593640    0.592471    0.580038    0.952018    0.766768    0.667160    0.685926    2200        18.431074   0.167987    0.000000    0.202144    152.193365 
[37m[36mINFO[0m[0m 02/18 06:20:55 | 0.665338    0.667962    0.979436    0.786585    0.981112    0.736749    0.720848    0.615059    0.604520    0.979436    0.786585    0.644206    0.678519    2400        20.106626   0.152418    0.000000    0.170189    161.494505 
[37m[36mINFO[0m[0m 02/18 06:24:10 | 0.657749    0.682212    0.952780    0.778963    0.883036    0.656360    0.689046    0.640471    0.655367    0.952780    0.778963    0.676416    0.702222    2600        21.782178   0.141072    0.000000    0.160899    161.891002 
[37m[36mINFO[0m[0m 02/18 06:27:00 | 0.688422    0.701388    0.964966    0.786585    0.862607    0.802120    0.816254    0.581176    0.585687    0.964966    0.786585    0.681970    0.702222    2800        23.457730   0.130047    0.000000    0.213032    127.586777 
[37m[36mINFO[0m[0m 02/18 06:30:16 | 0.677032    0.682377    0.951637    0.778963    0.874232    0.736749    0.756184    0.632000    0.634652    0.951637    0.778963    0.662347    0.656296    3000        25.133283   0.131075    0.000000    0.230294    150.365525 
[37m[36mINFO[0m[0m 02/18 06:33:27 | 0.588244    0.600940    0.958111    0.780488    0.956900    0.555654    0.586572    0.591529    0.596987    0.958111    0.780488    0.617549    0.619259    3200        26.808835   0.088467    0.000000    0.199163    151.264135 
[37m[36mINFO[0m[0m 02/18 06:36:27 | 0.516655    0.527256    0.958492    0.771341    0.959304    0.386042    0.399293    0.581176    0.570621    0.958492    0.771341    0.582747    0.611852    3400        28.484387   0.084098    0.000000    0.188868    142.239685 
[37m[36mINFO[0m[0m 02/18 06:39:36 | 0.581480    0.590188    0.966489    0.763720    1.082061    0.595406    0.618375    0.565176    0.553672    0.966489    0.763720    0.583858    0.598519    3600        30.159939   0.102827    0.000000    0.183726    152.200305 
[37m[36mINFO[0m[0m 02/18 06:42:48 | 0.598903    0.624578    0.974867    0.786585    0.797946    0.568021    0.597173    0.601882    0.615819    0.974867    0.786585    0.626805    0.660741    3800        31.835491   0.137922    0.000000    0.178040    155.690446 
[37m[36mINFO[0m[0m 02/18 06:45:49 | 0.666059    0.667065    0.980960    0.783537    1.183887    0.729682    0.749117    0.608000    0.591337    0.980960    0.783537    0.660496    0.660741    4000        33.511043   0.071567    0.000000    0.220271    137.543437 
[37m[36mINFO[0m[0m 02/18 06:48:57 | 0.532962    0.531132    0.968393    0.743902    1.011057    0.348057    0.346290    0.580706    0.581921    0.968393    0.743902    0.670122    0.665185    4200        35.186596   0.074562    0.000000    0.276053    132.818513 
[37m[36mINFO[0m[0m 02/18 06:52:09 | 0.660600    0.657690    0.983625    0.763720    1.506581    0.748233    0.749117    0.577882    0.570621    0.983625    0.763720    0.655683    0.653333    4400        36.862148   0.044095    0.000000    0.184923    154.421156 
[37m[36mINFO[0m[0m 02/18 06:55:11 | 0.621045    0.634497    0.990480    0.783537    1.192359    0.559187    0.583039    0.624941    0.627119    0.990480    0.783537    0.679008    0.693333    4600        38.537700   0.057152    0.000000    0.172342    148.203461 
[37m[36mINFO[0m[0m 02/18 06:58:15 | 0.545608    0.549756    0.972582    0.756098    1.201485    0.439929    0.473498    0.565647    0.546139    0.972582    0.756098    0.631248    0.629630    4800        40.213252   0.056919    0.000000    0.193511    144.795637 
[37m[36mINFO[0m[0m 02/18 07:01:33 | 0.566281    0.571924    0.984768    0.788110    1.252753    0.500000    0.505300    0.593882    0.583804    0.984768    0.788110    0.604961    0.626667    5000        41.888804   0.059693    0.000000    0.201424    157.513834 
[37m[36mINFO[0m[0m 02/18 07:01:33 | Cumulative gradient change saved at train_output/VLCS/CORAL/[0, 1, 3]/250218_05-41-45_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/18 07:01:34 | ---
[37m[36mINFO[0m[0m 02/18 07:01:34 | test-domain validation(oracle) = 68.842%
[37m[36mINFO[0m[0m 02/18 07:01:34 | training-domain validation(iid) = 67.141%
[37m[36mINFO[0m[0m 02/18 07:01:34 | last = 56.628%
[37m[36mINFO[0m[0m 02/18 07:01:34 | last (inD) = 78.811%
[37m[36mINFO[0m[0m 02/18 07:01:34 | training-domain validation (iid, inD) = 79.573%
[37m[36mINFO[0m[0m 02/18 07:01:34 | === Summary ===
[37m[36mINFO[0m[0m 02/18 07:01:34 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 0 1 3 --dataset VLCS --trial_seed 0 --hparams_seed 10
[37m[36mINFO[0m[0m 02/18 07:01:34 | Unique name: 250218_05-41-45_resnet50_GENIE
[37m[36mINFO[0m[0m 02/18 07:01:34 | Out path: train_output/VLCS/CORAL/[0, 1, 3]/250218_05-41-45_resnet50_GENIE
[37m[36mINFO[0m[0m 02/18 07:01:34 | Algorithm: CORAL
[37m[36mINFO[0m[0m 02/18 07:01:34 | Dataset: VLCS
