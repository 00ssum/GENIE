[37m[36mINFO[0m[0m 02/18 13:00:37 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 0 1 3 --dataset VLCS --trial_seed 0 --hparams_seed 16
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 16
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/VLCS/CORAL/[0, 1, 3]/250218_13-00-37_resnet50_GENIE
	out_root: train_output/VLCS/CORAL/[0, 1, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 1, 3]
	trial_seed: 0
	unique_name: 250218_13-00-37_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 4.249952708249365e-05
	batch_size: 17
	weight_decay: 9.786966598736845e-06
	mmd_gamma: 1.0088701382180452
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 02/18 13:00:37 | n_steps = 5001
[37m[36mINFO[0m[0m 02/18 13:00:37 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/18 13:00:37 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/18 13:00:37 | 
[37m[36mINFO[0m[0m 02/18 13:00:37 | Testenv name escaping te_C_L_V -> te_C_L_V
[37m[36mINFO[0m[0m 02/18 13:00:37 | Test envs = [0, 1, 3], name = te_C_L_V
[37m[36mINFO[0m[0m 02/18 13:00:37 | Train environments: [2], Test environments: [0, 1, 3]
[37m[36mINFO[0m[0m 02/18 13:00:37 | Batch sizes for each domain: [0, 0, 17, 0] (total=17)
[37m[36mINFO[0m[0m 02/18 13:00:37 | steps-per-epoch for each domain: 154.47 -> min = 154.47
[37m[36mINFO[0m[0m 02/18 13:00:39 | # of params = 23518277
[37m[36mINFO[0m[0m 02/18 13:02:56 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 02/18 13:02:56 | 0.504343    0.521514    0.384996    0.390244    1.544493    0.611307    0.628975    0.459294    0.489642    0.384996    0.390244    0.442429    0.445926    0           0.000000    1.769683    0.000000    1.430730    135.720244 
[37m[36mINFO[0m[0m 02/18 13:06:03 | 0.654301    0.657089    0.811500    0.801829    0.536347    0.757067    0.759717    0.574588    0.581921    0.811500    0.801829    0.631248    0.629630    200         1.294745    0.698273    0.000000    0.262254    134.209279 
[37m[36mINFO[0m[0m 02/18 13:08:58 | 0.683676    0.694263    0.803884    0.751524    0.604070    0.766784    0.756184    0.636706    0.662900    0.803884    0.751524    0.647538    0.663704    400         2.589490    0.499589    0.000000    0.167979    141.616076 
[37m[36mINFO[0m[0m 02/18 13:12:02 | 0.662699    0.649917    0.853389    0.800305    0.536213    0.760601    0.745583    0.585882    0.561205    0.853389    0.800305    0.641614    0.642963    600         3.884235    0.435890    0.000000    0.165256    150.987813 
[37m[36mINFO[0m[0m 02/18 13:15:07 | 0.657184    0.673665    0.846915    0.778963    0.656859    0.690813    0.703180    0.665412    0.691149    0.846915    0.778963    0.615328    0.626667    800         5.178979    0.435691    0.000000    0.160929    153.008568 
[37m[36mINFO[0m[0m 02/18 13:18:10 | 0.646604    0.651164    0.810358    0.743902    0.787871    0.740283    0.745583    0.584941    0.585687    0.810358    0.743902    0.614587    0.622222    1000        6.473724    0.386256    0.000000    0.169310    149.128121 
[37m[36mINFO[0m[0m 02/18 13:21:09 | 0.659286    0.671122    0.873572    0.783537    0.589497    0.685512    0.674912    0.645176    0.662900    0.873572    0.783537    0.647168    0.675556    1200        7.768469    0.368362    0.000000    0.174517    143.506597 
[37m[36mINFO[0m[0m 02/18 13:24:19 | 0.514582    0.526056    0.899086    0.804878    0.546600    0.384276    0.402827    0.563765    0.564972    0.899086    0.804878    0.595705    0.610370    1400        9.063214    0.289560    0.000000    0.147081    160.676268 
[37m[36mINFO[0m[0m 02/18 13:27:28 | 0.574390    0.577610    0.889947    0.771341    0.730417    0.535336    0.565371    0.544000    0.514124    0.889947    0.771341    0.643836    0.653333    1600        10.357959   0.278846    0.000000    0.146301    160.110029 
[37m[36mINFO[0m[0m 02/18 13:30:28 | 0.593744    0.587525    0.911272    0.783537    0.663291    0.596290    0.607774    0.542588    0.510358    0.911272    0.783537    0.642355    0.644444    1800        11.652704   0.259381    0.000000    0.173403    145.103369 
[37m[36mINFO[0m[0m 02/18 13:33:20 | 0.660078    0.664588    0.920411    0.791159    0.684963    0.739399    0.734982    0.603294    0.615819    0.920411    0.791159    0.637542    0.642963    2000        12.947449   0.241767    0.000000    0.199792    132.112665 
[37m[36mINFO[0m[0m 02/18 13:36:27 | 0.571587    0.585536    0.932216    0.791159    0.775882    0.523852    0.565371    0.561882    0.563089    0.932216    0.791159    0.629026    0.628148    2200        14.242193   0.179227    0.000000    0.136223    159.502432 
[37m[36mINFO[0m[0m 02/18 13:39:23 | 0.502532    0.503411    0.890327    0.702744    1.192638    0.416961    0.448763    0.543059    0.510358    0.890327    0.702744    0.547575    0.551111    2400        15.536938   0.195797    0.000000    0.138957    148.000705 
[37m[36mINFO[0m[0m 02/18 13:42:27 | 0.550009    0.562481    0.932216    0.792683    0.632160    0.395760    0.416961    0.626353    0.629002    0.932216    0.792683    0.627916    0.641481    2600        16.831683   0.193514    0.000000    0.168242    150.396326 
[37m[36mINFO[0m[0m 02/18 13:45:29 | 0.590664    0.604032    0.945545    0.791159    1.161331    0.468198    0.491166    0.665882    0.677966    0.945545    0.791159    0.637912    0.642963    2800        18.126428   0.174770    0.000000    0.154477    151.650362 
[37m[36mINFO[0m[0m 02/18 13:48:35 | 0.568027    0.580699    0.964966    0.794207    0.846647    0.463781    0.487633    0.626824    0.623352    0.964966    0.794207    0.613476    0.631111    3000        19.421173   0.132199    0.000000    0.149806    155.723137 
[37m[36mINFO[0m[0m 02/18 13:51:29 | 0.618243    0.633563    0.967631    0.792683    0.923905    0.628092    0.667845    0.573176    0.570621    0.967631    0.792683    0.653462    0.662222    3200        20.715918   0.117090    0.000000    0.159862    142.453820 
[37m[36mINFO[0m[0m 02/18 13:54:36 | 0.596299    0.596580    0.977152    0.815549    0.816375    0.562721    0.572438    0.617882    0.615819    0.977152    0.815549    0.608293    0.601481    3400        22.010663   0.110513    0.000000    0.170927    152.480340 
[37m[36mINFO[0m[0m 02/18 13:57:33 | 0.580468    0.577115    0.976390    0.769817    0.930621    0.524735    0.515901    0.602824    0.593220    0.976390    0.769817    0.613847    0.622222    3600        23.305407   0.110579    0.000000    0.136030    149.865204 
[37m[36mINFO[0m[0m 02/18 14:00:27 | 0.652279    0.674964    0.976771    0.778963    1.019654    0.721731    0.752650    0.609412    0.623352    0.976771    0.778963    0.625694    0.648889    3800        24.600152   0.096818    0.000000    0.161524    141.736488 
[37m[36mINFO[0m[0m 02/18 14:03:33 | 0.630871    0.633533    0.947829    0.786585    0.789161    0.666078    0.674912    0.600471    0.585687    0.947829    0.786585    0.626064    0.640000    4000        25.894897   0.100778    0.000000    0.165361    152.425314 
[37m[36mINFO[0m[0m 02/18 14:06:44 | 0.509953    0.532338    0.966108    0.778963    0.961622    0.327739    0.332155    0.584941    0.602637    0.966108    0.778963    0.617179    0.662222    4200        27.189642   0.079510    0.000000    0.156174    160.359926 
[37m[36mINFO[0m[0m 02/18 14:09:46 | 0.663985    0.672744    0.953922    0.775915    0.995365    0.686396    0.678445    0.655059    0.676083    0.953922    0.775915    0.650500    0.663704    4400        28.484387   0.123252    0.000000    0.164194    149.423382 
[37m[36mINFO[0m[0m 02/18 14:12:42 | 0.498729    0.514304    0.932216    0.748476    0.968989    0.341873    0.378092    0.593412    0.578154    0.932216    0.748476    0.560903    0.586667    4600        29.779132   0.103932    0.000000    0.184636    139.034948 
[37m[36mINFO[0m[0m 02/18 14:15:48 | 0.584840    0.599331    0.975628    0.783537    0.970840    0.539753    0.575972    0.616471    0.610169    0.975628    0.783537    0.598297    0.611852    4800        31.073877   0.104902    0.000000    0.188446    148.266119 
[37m[36mINFO[0m[0m 02/18 14:18:47 | 0.511623    0.514956    0.985910    0.780488    0.946506    0.331272    0.328622    0.612706    0.596987    0.985910    0.780488    0.590892    0.619259    5000        32.368621   0.066014    0.000000    0.150737    148.175163 
[37m[36mINFO[0m[0m 02/18 14:18:47 | Cumulative gradient change saved at train_output/VLCS/CORAL/[0, 1, 3]/250218_13-00-37_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/18 14:18:48 | ---
[37m[36mINFO[0m[0m 02/18 14:18:48 | test-domain validation(oracle) = 68.368%
[37m[36mINFO[0m[0m 02/18 14:18:48 | training-domain validation(iid) = 59.630%
[37m[36mINFO[0m[0m 02/18 14:18:48 | last = 51.162%
[37m[36mINFO[0m[0m 02/18 14:18:48 | last (inD) = 78.049%
[37m[36mINFO[0m[0m 02/18 14:18:48 | training-domain validation (iid, inD) = 81.555%
[37m[36mINFO[0m[0m 02/18 14:18:48 | === Summary ===
[37m[36mINFO[0m[0m 02/18 14:18:48 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 0 1 3 --dataset VLCS --trial_seed 0 --hparams_seed 16
[37m[36mINFO[0m[0m 02/18 14:18:48 | Unique name: 250218_13-00-37_resnet50_GENIE
[37m[36mINFO[0m[0m 02/18 14:18:48 | Out path: train_output/VLCS/CORAL/[0, 1, 3]/250218_13-00-37_resnet50_GENIE
[37m[36mINFO[0m[0m 02/18 14:18:48 | Algorithm: CORAL
[37m[36mINFO[0m[0m 02/18 14:18:48 | Dataset: VLCS
