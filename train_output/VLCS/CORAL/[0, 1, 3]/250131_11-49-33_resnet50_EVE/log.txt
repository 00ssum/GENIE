[37m[36mINFO[0m[0m 01/31 11:49:33 | Command :: /jsm0707/Large-scale/train_all.py resnet50_EVE config/resnet50_EVE.yaml --algorithm CORAL --test_envs 0 1 3 --dataset VLCS --trial_seed 0 --hparams_seed 2
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_EVE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 2
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_EVE
	out_dir: train_output/VLCS/CORAL/[0, 1, 3]/250131_11-49-33_resnet50_EVE
	out_root: train_output/VLCS/CORAL/[0, 1, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 1, 3]
	trial_seed: 0
	unique_name: 250131_11-49-33_resnet50_EVE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: EVE
	freeze_bn: False
	pretrained: True
	lr: 1.9041073434446342e-05
	batch_size: 9
	weight_decay: 0.0006566989842279891
	mmd_gamma: 1.5832433896458313
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 01/31 11:49:33 | n_steps = 5001
[37m[36mINFO[0m[0m 01/31 11:49:33 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 01/31 11:49:33 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 01/31 11:49:33 | 
[37m[36mINFO[0m[0m 01/31 11:49:33 | Testenv name escaping te_C_L_V -> te_C_L_V
[37m[36mINFO[0m[0m 01/31 11:49:33 | Test envs = [0, 1, 3], name = te_C_L_V
[37m[36mINFO[0m[0m 01/31 11:49:33 | Train environments: [2], Test environments: [0, 1, 3]
[37m[36mINFO[0m[0m 01/31 11:49:33 | Batch sizes for each domain: [0, 0, 9, 0] (total=9)
[37m[36mINFO[0m[0m 01/31 11:49:33 | steps-per-epoch for each domain: 291.78 -> min = 291.78
[37m[36mINFO[0m[0m 01/31 11:49:34 | # of params = 23518277
[37m[36mINFO[0m[0m 01/31 11:52:45 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 01/31 11:52:45 | 0.252804    0.237399    0.282940    0.288110    1.835807    0.090106    0.074205    0.460235    0.435028    0.282940    0.288110    0.208071    0.202963    0           0.000000    1.654887    0.000000    1.620416    188.947627 
[37m[36mINFO[0m[0m 01/31 11:56:09 | 0.551993    0.570159    0.737243    0.751524    0.617175    0.454947    0.477032    0.619765    0.629002    0.737243    0.751524    0.581266    0.604444    200         0.685453    0.816963    0.000000    0.140923    175.940251 
[37m[36mINFO[0m[0m 01/31 11:59:40 | 0.636254    0.620743    0.751333    0.736280    0.638097    0.746466    0.713781    0.538824    0.529190    0.751333    0.736280    0.623473    0.619259    400         1.370906    0.659352    0.000000    0.161390    178.264240 
[37m[36mINFO[0m[0m 01/31 12:03:14 | 0.644475    0.641452    0.819497    0.788110    0.561104    0.727032    0.724382    0.585882    0.576271    0.819497    0.788110    0.620511    0.623704    600         2.056359    0.580398    0.000000    0.118679    189.694761 
[37m[36mINFO[0m[0m 01/31 12:06:26 | 0.662077    0.662938    0.837395    0.772866    0.644362    0.757951    0.749117    0.577412    0.581921    0.837395    0.772866    0.650870    0.657778    800         2.741813    0.490103    0.000000    0.138951    163.978665 
[37m[36mINFO[0m[0m 01/31 12:09:54 | 0.611391    0.615996    0.828256    0.791159    0.568145    0.595406    0.600707    0.640471    0.659134    0.828256    0.791159    0.598297    0.588148    1000        3.427266    0.543266    0.000000    0.226850    161.620302 
[37m[36mINFO[0m[0m 01/31 12:13:39 | 0.655001    0.644768    0.829398    0.754573    0.656501    0.747350    0.734982    0.572706    0.559322    0.829398    0.754573    0.644946    0.640000    1200        4.112719    0.491920    0.000000    0.178749    188.118240 
[37m[36mINFO[0m[0m 01/31 12:16:50 | 0.610502    0.618791    0.851104    0.783537    0.580182    0.637809    0.653710    0.590588    0.581921    0.851104    0.783537    0.603110    0.620741    1400        4.798172    0.472548    0.000000    0.165334    158.553831 
[37m[36mINFO[0m[0m 01/31 12:19:52 | 0.652626    0.655962    0.839680    0.772866    0.624326    0.689046    0.678445    0.633882    0.655367    0.839680    0.772866    0.634950    0.634074    1600        5.483625    0.430928    0.000000    0.183964    145.105229 
[37m[36mINFO[0m[0m 01/31 12:23:08 | 0.639999    0.643187    0.847296    0.775915    0.566606    0.727032    0.720848    0.585412    0.589454    0.847296    0.775915    0.607553    0.619259    1800        6.169078    0.411015    0.000000    0.141772    167.126988 
[37m[36mINFO[0m[0m 01/31 12:26:07 | 0.673600    0.669688    0.864433    0.777439    0.780010    0.743816    0.731449    0.628706    0.634652    0.864433    0.777439    0.648278    0.642963    2000        6.854532    0.445163    0.000000    0.111844    156.715888 
[37m[36mINFO[0m[0m 01/31 12:28:55 | 0.512986    0.514374    0.818736    0.740854    0.703013    0.358657    0.360424    0.592000    0.606403    0.818736    0.740854    0.588301    0.576296    2200        7.539985    0.388367    0.000000    0.147563    138.093721 
[37m[36mINFO[0m[0m 01/31 12:31:42 | 0.680520    0.690276    0.814928    0.745427    0.751058    0.744700    0.734982    0.666353    0.706215    0.814928    0.745427    0.630507    0.629630    2400        8.225438    0.388767    0.000000    0.110450    145.368726 
[37m[36mINFO[0m[0m 01/31 12:34:21 | 0.661907    0.660686    0.877761    0.780488    0.581685    0.766784    0.763251    0.594353    0.595104    0.877761    0.780488    0.624583    0.623704    2600        8.910891    0.365598    0.000000    0.125379    133.611651 
[37m[36mINFO[0m[0m 01/31 12:37:04 | 0.646787    0.641777    0.847677    0.763720    0.676889    0.748233    0.752650    0.557176    0.538606    0.847677    0.763720    0.634950    0.634074    2800        9.596344    0.344035    0.000000    0.128212    137.035301 
[37m[36mINFO[0m[0m 01/31 12:39:47 | 0.525025    0.537926    0.854912    0.748476    0.671899    0.404594    0.427562    0.585882    0.595104    0.854912    0.748476    0.584598    0.591111    3000        10.281797   0.330291    0.000000    0.127367    137.303666 
[37m[36mINFO[0m[0m 01/31 12:42:27 | 0.579511    0.573725    0.802361    0.711890    0.892333    0.649293    0.657244    0.503529    0.480226    0.802361    0.711890    0.585709    0.583704    3200        10.967251   0.336816    0.000000    0.125805    135.505205 
[37m[36mINFO[0m[0m 01/31 12:45:07 | 0.640622    0.645266    0.884996    0.780488    0.632738    0.759717    0.766784    0.574588    0.563089    0.884996    0.780488    0.587560    0.605926    3400        11.652704   0.292384    0.000000    0.121985    135.249680 
[37m[36mINFO[0m[0m 01/31 12:47:48 | 0.484962    0.489541    0.859863    0.740854    0.755358    0.298587    0.321555    0.568000    0.557439    0.859863    0.740854    0.588301    0.589630    3600        12.338157   0.308200    0.000000    0.123271    136.116033 
[37m[36mINFO[0m[0m 01/31 12:50:30 | 0.623570    0.652780    0.836634    0.740854    1.028740    0.625442    0.667845    0.636235    0.674200    0.836634    0.740854    0.609034    0.616296    3800        13.023610   0.249290    0.000000    0.127297    136.414980 
[37m[36mINFO[0m[0m 01/31 12:53:11 | 0.542026    0.559824    0.931455    0.777439    0.629786    0.379859    0.424028    0.604235    0.593220    0.931455    0.777439    0.641984    0.662222    4000        13.709063   0.260332    0.000000    0.129321    135.243863 
[37m[36mINFO[0m[0m 01/31 12:55:52 | 0.555266    0.557304    0.904798    0.769817    0.744108    0.512367    0.526502    0.601412    0.591337    0.904798    0.769817    0.552018    0.554074    4200        14.394516   0.252210    0.000000    0.134044    134.675760 
[37m[36mINFO[0m[0m 01/31 12:58:34 | 0.655877    0.656534    0.901371    0.750000    0.830473    0.709364    0.699647    0.605176    0.619586    0.901371    0.750000    0.653091    0.650370    4400        15.079970   0.248401    0.000000    0.127859    135.734289 
[37m[36mINFO[0m[0m 01/31 13:01:15 | 0.558204    0.573446    0.929551    0.771341    0.894774    0.478799    0.519435    0.595294    0.587571    0.929551    0.771341    0.600518    0.613333    4600        15.765423   0.307615    0.000000    0.136035    134.506641 
[37m[36mINFO[0m[0m 01/31 13:04:16 | 0.605305    0.606734    0.899467    0.751524    1.126597    0.638693    0.621908    0.629647    0.630885    0.899467    0.751524    0.547575    0.567407    4800        16.450876   0.229086    0.000000    0.128908    154.742265 
[37m[36mINFO[0m[0m 01/31 13:07:18 | 0.627034    0.637141    0.937167    0.786585    0.666002    0.691696    0.699647    0.605176    0.617702    0.937167    0.786585    0.584228    0.594074    5000        17.136329   0.244615    0.000000    0.135842    154.850579 
[37m[36mINFO[0m[0m 01/31 13:07:18 | Cumulative gradient change saved at train_output/VLCS/CORAL/[0, 1, 3]/250131_11-49-33_resnet50_EVE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 01/31 13:07:20 | ---
[37m[36mINFO[0m[0m 01/31 13:07:20 | test-domain validation(oracle) = 68.052%
[37m[36mINFO[0m[0m 01/31 13:07:20 | training-domain validation(iid) = 61.139%
[37m[36mINFO[0m[0m 01/31 13:07:20 | last = 62.703%
[37m[36mINFO[0m[0m 01/31 13:07:20 | last (inD) = 78.659%
[37m[36mINFO[0m[0m 01/31 13:07:20 | training-domain validation (iid, inD) = 79.116%
[37m[36mINFO[0m[0m 01/31 13:07:20 | === Summary ===
[37m[36mINFO[0m[0m 01/31 13:07:20 | Command: /jsm0707/Large-scale/train_all.py resnet50_EVE config/resnet50_EVE.yaml --algorithm CORAL --test_envs 0 1 3 --dataset VLCS --trial_seed 0 --hparams_seed 2
[37m[36mINFO[0m[0m 01/31 13:07:20 | Unique name: 250131_11-49-33_resnet50_EVE
[37m[36mINFO[0m[0m 01/31 13:07:20 | Out path: train_output/VLCS/CORAL/[0, 1, 3]/250131_11-49-33_resnet50_EVE
[37m[36mINFO[0m[0m 01/31 13:07:20 | Algorithm: CORAL
[37m[36mINFO[0m[0m 01/31 13:07:20 | Dataset: VLCS
