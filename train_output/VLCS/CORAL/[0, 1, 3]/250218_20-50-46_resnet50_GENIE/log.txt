[37m[36mINFO[0m[0m 02/18 20:50:46 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 0 1 3 --dataset VLCS --trial_seed 1 --hparams_seed 1
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 1
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/VLCS/CORAL/[0, 1, 3]/250218_20-50-46_resnet50_GENIE
	out_root: train_output/VLCS/CORAL/[0, 1, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 1, 3]
	trial_seed: 1
	unique_name: 250218_20-50-46_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 1.2332416678311953e-05
	batch_size: 13
	weight_decay: 0.0018634819595667504
	mmd_gamma: 0.42642135699574363
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 02/18 20:50:46 | n_steps = 5001
[37m[36mINFO[0m[0m 02/18 20:50:46 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/18 20:50:46 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/18 20:50:46 | 
[37m[36mINFO[0m[0m 02/18 20:50:46 | Testenv name escaping te_C_L_V -> te_C_L_V
[37m[36mINFO[0m[0m 02/18 20:50:46 | Test envs = [0, 1, 3], name = te_C_L_V
[37m[36mINFO[0m[0m 02/18 20:50:46 | Train environments: [2], Test environments: [0, 1, 3]
[37m[36mINFO[0m[0m 02/18 20:50:46 | Batch sizes for each domain: [0, 0, 13, 0] (total=13)
[37m[36mINFO[0m[0m 02/18 20:50:46 | steps-per-epoch for each domain: 202.00 -> min = 202.00
[37m[36mINFO[0m[0m 02/18 20:50:47 | # of params = 23518277
[37m[36mINFO[0m[0m 02/18 20:53:13 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 02/18 20:53:13 | 0.076897    0.097923    0.322544    0.288110    1.511806    0.083039    0.084806    0.029176    0.048964    0.322544    0.288110    0.118475    0.160000    0           0.000000    1.459601    0.000000    1.016334    144.536825 
[37m[36mINFO[0m[0m 02/18 20:55:53 | 0.566011    0.563426    0.795887    0.797256    0.558028    0.480565    0.469965    0.584000    0.574388    0.795887    0.797256    0.633469    0.645926    200         0.990099    0.731926    0.000000    0.140070    132.404175 
[37m[36mINFO[0m[0m 02/18 20:58:49 | 0.630448    0.616350    0.773039    0.817073    0.529840    0.672261    0.674912    0.586353    0.559322    0.773039    0.817073    0.632729    0.614815    400         1.980198    0.539746    0.000000    0.151270    145.745546 
[37m[36mINFO[0m[0m 02/18 21:01:25 | 0.536926    0.533395    0.807312    0.763720    0.612283    0.504417    0.494700    0.536941    0.529190    0.807312    0.763720    0.569419    0.576296    600         2.970297    0.488029    0.000000    0.129699    129.849887 
[37m[36mINFO[0m[0m 02/18 21:04:27 | 0.501678    0.497966    0.793222    0.730183    0.618737    0.375442    0.378092    0.581647    0.570621    0.793222    0.730183    0.547945    0.545185    800         3.960396    0.496569    0.000000    0.146991    152.238307 
[37m[36mINFO[0m[0m 02/18 21:07:19 | 0.413706    0.411048    0.794364    0.730183    0.630372    0.219081    0.204947    0.520000    0.514124    0.794364    0.730183    0.502036    0.514074    1000        4.950495    0.420744    0.000000    0.120488    148.822543 
[37m[36mINFO[0m[0m 02/18 21:10:08 | 0.430280    0.417408    0.725057    0.663110    0.686816    0.315371    0.272085    0.508235    0.497175    0.725057    0.663110    0.467234    0.482963    1200        5.940594    0.411379    0.000000    0.157551    137.208612 
[37m[36mINFO[0m[0m 02/18 21:13:04 | 0.659756    0.639647    0.829779    0.797256    0.515299    0.715548    0.706714    0.604706    0.578154    0.829779    0.797256    0.659015    0.634074    1400        6.930693    0.445413    0.000000    0.148715    146.213748 
[37m[36mINFO[0m[0m 02/18 21:15:57 | 0.602109    0.588412    0.891851    0.829268    0.509817    0.578622    0.544170    0.632000    0.619586    0.891851    0.829268    0.595705    0.601481    1600        7.920792    0.361884    0.000000    0.160344    140.912291 
[37m[36mINFO[0m[0m 02/18 21:18:47 | 0.699861    0.707880    0.883854    0.844512    0.498462    0.706714    0.731449    0.679059    0.664783    0.883854    0.844512    0.713810    0.727407    1800        8.910891    0.333701    0.000000    0.127444    144.480727 
[37m[36mINFO[0m[0m 02/18 21:21:31 | 0.655193    0.648895    0.890327    0.818598    0.546115    0.706714    0.720848    0.585412    0.572505    0.890327    0.818598    0.673454    0.653333    2000        9.900990    0.313271    0.000000    0.136059    136.359060 
[37m[36mINFO[0m[0m 02/18 21:24:28 | 0.626729    0.622734    0.886519    0.783537    0.567795    0.659894    0.664311    0.586824    0.566855    0.886519    0.783537    0.633469    0.637037    2200        10.891089   0.314321    0.000000    0.194773    138.282945 
[37m[36mINFO[0m[0m 02/18 21:27:17 | 0.665656    0.648204    0.877761    0.801829    0.624706    0.750883    0.742049    0.579294    0.553672    0.877761    0.801829    0.666790    0.648889    2400        11.881188   0.286518    0.000000    0.123505    144.564746 
[37m[36mINFO[0m[0m 02/18 21:30:12 | 0.567924    0.575384    0.897563    0.775915    0.655353    0.533569    0.551237    0.591529    0.583804    0.897563    0.775915    0.578675    0.591111    2600        12.871287   0.261855    0.000000    0.148396    145.413124 
[37m[36mINFO[0m[0m 02/18 21:33:00 | 0.511390    0.513142    0.918126    0.795732    0.621587    0.329505    0.325088    0.621176    0.615819    0.918126    0.795732    0.583488    0.598519    2800        13.861386   0.226455    0.000000    0.135384    140.884238 
[37m[36mINFO[0m[0m 02/18 21:35:51 | 0.593728    0.578418    0.928408    0.797256    0.602636    0.564488    0.558304    0.582118    0.572505    0.928408    0.797256    0.634580    0.604444    3000        14.851485   0.238645    0.000000    0.163949    137.623466 
[37m[36mINFO[0m[0m 02/18 21:38:46 | 0.591619    0.584010    0.938309    0.823171    0.519785    0.557420    0.568905    0.609882    0.587571    0.938309    0.823171    0.607553    0.595556    3200        15.841584   0.258754    0.000000    0.159868    142.891889 
[37m[36mINFO[0m[0m 02/18 21:41:34 | 0.595252    0.575260    0.953161    0.818598    0.581557    0.512367    0.484099    0.624000    0.612053    0.953161    0.818598    0.649389    0.629630    3400        16.831683   0.231090    0.000000    0.161454    135.909943 
[37m[36mINFO[0m[0m 02/18 21:44:18 | 0.695661    0.689523    0.909368    0.821646    0.626926    0.764134    0.759717    0.637176    0.642185    0.909368    0.821646    0.685672    0.666667    3600        17.821782   0.164333    0.000000    0.124231    139.261412 
[37m[36mINFO[0m[0m 02/18 21:47:11 | 0.546266    0.546435    0.950114    0.818598    0.566092    0.396643    0.406360    0.599059    0.598870    0.950114    0.818598    0.643095    0.634074    3800        18.811881   0.235458    0.000000    0.151856    143.250552 
[37m[36mINFO[0m[0m 02/18 21:49:57 | 0.575779    0.575671    0.948210    0.800305    0.549989    0.455830    0.469965    0.622118    0.600753    0.948210    0.800305    0.649389    0.656296    4000        19.801980   0.177756    0.000000    0.128694    139.412244 
[37m[36mINFO[0m[0m 02/18 21:52:47 | 0.642007    0.647611    0.950876    0.821646    0.676314    0.655477    0.674912    0.636706    0.630885    0.950876    0.821646    0.633839    0.637037    4200        20.792079   0.169070    0.000000    0.148294    140.611309 
[37m[36mINFO[0m[0m 02/18 21:55:38 | 0.522352    0.513672    0.949353    0.820122    0.561722    0.322438    0.321555    0.619294    0.612053    0.949353    0.820122    0.625324    0.607407    4400        21.782178   0.154235    0.000000    0.154124    139.922698 
[37m[36mINFO[0m[0m 02/18 21:58:26 | 0.696693    0.694017    0.931835    0.797256    0.723356    0.737633    0.773852    0.652706    0.625235    0.931835    0.797256    0.699741    0.682963    4600        22.772277   0.134216    0.000000    0.137752    141.260460 
[37m[36mINFO[0m[0m 02/18 22:01:20 | 0.477258    0.462131    0.948591    0.806402    0.742351    0.269435    0.229682    0.608471    0.602637    0.948591    0.806402    0.553869    0.554074    4800        23.762376   0.126489    0.000000    0.132388    147.000939 
[37m[36mINFO[0m[0m 02/18 22:04:11 | 0.609765    0.609796    0.951637    0.809451    0.734357    0.618375    0.636042    0.624471    0.600753    0.951637    0.809451    0.586449    0.592593    5000        24.752475   0.149147    0.000000    0.156406    139.428546 
[37m[36mINFO[0m[0m 02/18 22:04:11 | Cumulative gradient change saved at train_output/VLCS/CORAL/[0, 1, 3]/250218_20-50-46_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/18 22:04:12 | ---
[37m[36mINFO[0m[0m 02/18 22:04:12 | test-domain validation(oracle) = 69.986%
[37m[36mINFO[0m[0m 02/18 22:04:12 | training-domain validation(iid) = 69.986%
[37m[36mINFO[0m[0m 02/18 22:04:12 | last = 60.976%
[37m[36mINFO[0m[0m 02/18 22:04:12 | last (inD) = 80.945%
[37m[36mINFO[0m[0m 02/18 22:04:12 | training-domain validation (iid, inD) = 84.451%
[37m[36mINFO[0m[0m 02/18 22:04:12 | === Summary ===
[37m[36mINFO[0m[0m 02/18 22:04:12 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 0 1 3 --dataset VLCS --trial_seed 1 --hparams_seed 1
[37m[36mINFO[0m[0m 02/18 22:04:12 | Unique name: 250218_20-50-46_resnet50_GENIE
[37m[36mINFO[0m[0m 02/18 22:04:12 | Out path: train_output/VLCS/CORAL/[0, 1, 3]/250218_20-50-46_resnet50_GENIE
[37m[36mINFO[0m[0m 02/18 22:04:12 | Algorithm: CORAL
[37m[36mINFO[0m[0m 02/18 22:04:12 | Dataset: VLCS
