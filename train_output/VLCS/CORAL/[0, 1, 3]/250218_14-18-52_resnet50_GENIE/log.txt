[37m[36mINFO[0m[0m 02/18 14:18:52 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 0 1 3 --dataset VLCS --trial_seed 0 --hparams_seed 17
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 17
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/VLCS/CORAL/[0, 1, 3]/250218_14-18-52_resnet50_GENIE
	out_root: train_output/VLCS/CORAL/[0, 1, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 1, 3]
	trial_seed: 0
	unique_name: 250218_14-18-52_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 0.00025159202447589334
	batch_size: 8
	weight_decay: 0.007781932002143384
	mmd_gamma: 0.62835859848447
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 02/18 14:18:52 | n_steps = 5001
[37m[36mINFO[0m[0m 02/18 14:18:52 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/18 14:18:52 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/18 14:18:52 | 
[37m[36mINFO[0m[0m 02/18 14:18:52 | Testenv name escaping te_C_L_V -> te_C_L_V
[37m[36mINFO[0m[0m 02/18 14:18:52 | Test envs = [0, 1, 3], name = te_C_L_V
[37m[36mINFO[0m[0m 02/18 14:18:52 | Train environments: [2], Test environments: [0, 1, 3]
[37m[36mINFO[0m[0m 02/18 14:18:52 | Batch sizes for each domain: [0, 0, 8, 0] (total=8)
[37m[36mINFO[0m[0m 02/18 14:18:52 | steps-per-epoch for each domain: 328.25 -> min = 328.25
[37m[36mINFO[0m[0m 02/18 14:18:53 | # of params = 23518277
[37m[36mINFO[0m[0m 02/18 14:21:26 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 02/18 14:21:26 | 0.252804    0.237399    0.282940    0.288110    2.360859    0.090106    0.074205    0.460235    0.435028    0.282940    0.288110    0.208071    0.202963    0           0.000000    1.668782    0.000000    1.091777    151.631363 
[37m[36mINFO[0m[0m 02/18 14:24:16 | 0.499610    0.492080    0.685834    0.721037    0.701127    0.486749    0.484099    0.488941    0.483992    0.685834    0.721037    0.523140    0.508148    200         0.609292    0.997049    0.000000    0.156036    139.125119 
[37m[36mINFO[0m[0m 02/18 14:27:15 | 0.438816    0.434798    0.682788    0.666159    0.765081    0.372792    0.378092    0.487529    0.467043    0.682788    0.666159    0.456127    0.459259    400         1.218583    0.744616    0.000000    0.118136    154.622338 
[37m[36mINFO[0m[0m 02/18 14:30:17 | 0.655479    0.657402    0.779132    0.746951    0.629245    0.684629    0.678445    0.646118    0.647834    0.779132    0.746951    0.635690    0.645926    600         1.827875    0.628459    0.000000    0.107758    161.189631 
[37m[36mINFO[0m[0m 02/18 14:32:55 | 0.616785    0.606047    0.777989    0.753049    0.612637    0.675795    0.660777    0.631059    0.619586    0.777989    0.753049    0.543502    0.537778    800         2.437167    0.601937    0.000000    0.122331    133.261271 
[37m[36mINFO[0m[0m 02/18 14:36:04 | 0.660039    0.661810    0.813785    0.768293    0.619713    0.712898    0.696113    0.631529    0.647834    0.813785    0.768293    0.635690    0.641481    1000        3.046458    0.577995    0.000000    0.176984    152.950294 
[37m[36mINFO[0m[0m 02/18 14:39:05 | 0.607628    0.597831    0.806550    0.768293    0.577674    0.690813    0.667845    0.563765    0.561205    0.806550    0.768293    0.568308    0.564444    1200        3.655750    0.561337    0.000000    0.106794    160.114770 
[37m[36mINFO[0m[0m 02/18 14:41:57 | 0.570041    0.574113    0.802742    0.754573    0.619419    0.552120    0.537102    0.603765    0.625235    0.802742    0.754573    0.554239    0.560000    1400        4.265042    0.526640    0.000000    0.124919    146.809978 
[37m[36mINFO[0m[0m 02/18 14:44:44 | 0.638441    0.643263    0.749429    0.685976    0.794732    0.711131    0.706714    0.620706    0.629002    0.749429    0.685976    0.583488    0.594074    1600        4.874334    0.518293    0.000000    0.134286    140.776305 
[37m[36mINFO[0m[0m 02/18 14:47:38 | 0.603614    0.608288    0.796649    0.760671    0.599053    0.636042    0.625442    0.578353    0.587571    0.796649    0.760671    0.596446    0.611852    1800        5.483625    0.546740    0.000000    0.109383    151.714243 
[37m[36mINFO[0m[0m 02/18 14:50:19 | 0.644848    0.646065    0.848439    0.763720    0.578991    0.709364    0.710247    0.608000    0.610169    0.848439    0.763720    0.617179    0.617778    2000        6.092917    0.509105    0.000000    0.120167    137.076422 
[37m[36mINFO[0m[0m 02/18 14:52:57 | 0.619693    0.623411    0.828256    0.751524    0.596357    0.676678    0.692580    0.556706    0.548023    0.828256    0.751524    0.625694    0.629630    2200        6.702209    0.548216    0.000000    0.109542    136.370977 
[37m[36mINFO[0m[0m 02/18 14:55:42 | 0.652382    0.649605    0.812643    0.743902    0.654950    0.716431    0.710247    0.618353    0.625235    0.812643    0.743902    0.622362    0.613333    2400        7.311500    0.548639    0.000000    0.149647    134.883076 
[37m[36mINFO[0m[0m 02/18 14:58:28 | 0.567077    0.578194    0.840823    0.756098    0.606726    0.464664    0.491166    0.624941    0.627119    0.840823    0.756098    0.611625    0.616296    2600        7.920792    0.541289    0.000000    0.121783    141.799457 
[37m[36mINFO[0m[0m 02/18 15:01:16 | 0.609409    0.614128    0.811881    0.751524    0.666779    0.585689    0.590106    0.639059    0.647834    0.811881    0.751524    0.603480    0.604444    2800        8.530084    0.562644    0.000000    0.112200    144.703036 
[37m[36mINFO[0m[0m 02/18 15:03:49 | 0.632871    0.640693    0.736481    0.701220    0.675837    0.711131    0.720848    0.634353    0.651601    0.736481    0.701220    0.553128    0.549630    3000        9.139375    0.527055    0.000000    0.138062    125.387189 
[37m[36mINFO[0m[0m 02/18 15:06:35 | 0.638557    0.650628    0.766946    0.740854    0.635371    0.719965    0.720848    0.600000    0.617702    0.766946    0.740854    0.595705    0.613333    3200        9.748667    0.576824    0.000000    0.140770    138.719768 
[37m[36mINFO[0m[0m 02/18 15:09:27 | 0.645572    0.658547    0.770373    0.745427    0.652834    0.731449    0.731449    0.624000    0.651601    0.770373    0.745427    0.581266    0.592593    3400        10.357959   0.533711    0.000000    0.105377    150.032607 
[37m[36mINFO[0m[0m 02/18 15:11:56 | 0.559891    0.554451    0.797411    0.757622    0.651467    0.463781    0.473498    0.606118    0.591337    0.797411    0.757622    0.609774    0.598519    3600        10.967251   0.593370    0.000000    0.109560    127.018529 
[37m[36mINFO[0m[0m 02/18 15:14:48 | 0.498483    0.524211    0.800076    0.766768    0.629082    0.355124    0.395760    0.609412    0.634652    0.800076    0.766768    0.530914    0.542222    3800        11.576542   0.537195    0.000000    0.167551    138.952486 
[37m[36mINFO[0m[0m 02/18 15:17:41 | 0.554817    0.582982    0.705255    0.676829    0.808998    0.646643    0.657244    0.510588    0.568738    0.705255    0.676829    0.507220    0.522963    4000        12.185834   0.496986    0.000000    0.116068    150.097480 
[37m[36mINFO[0m[0m 02/18 15:20:16 | 0.421617    0.408957    0.701066    0.655488    0.781699    0.319788    0.293286    0.494118    0.459510    0.701066    0.655488    0.450944    0.474074    4200        12.795126   0.593216    0.000000    0.110025    132.626858 
[37m[36mINFO[0m[0m 02/18 15:23:02 | 0.634301    0.647439    0.798172    0.739329    0.677392    0.673145    0.681979    0.632941    0.664783    0.798172    0.739329    0.596816    0.595556    4400        13.404417   0.525428    0.000000    0.157787    134.629802 
[37m[36mINFO[0m[0m 02/18 15:25:51 | 0.630104    0.647699    0.718203    0.679878    0.751020    0.665194    0.681979    0.654588    0.689266    0.718203    0.679878    0.570529    0.571852    4600        14.013709   0.547830    0.000000    0.128908    143.166981 
[37m[36mINFO[0m[0m 02/18 15:28:32 | 0.435232    0.426466    0.800457    0.750000    0.628336    0.240283    0.229682    0.551529    0.538606    0.800457    0.750000    0.513884    0.511111    4800        14.623001   0.573879    0.000000    0.112072    138.914944 
[37m[36mINFO[0m[0m 02/18 15:31:19 | 0.535446    0.544768    0.744097    0.724085    0.675305    0.513251    0.498233    0.596235    0.630885    0.744097    0.724085    0.496853    0.505185    5000        15.232292   0.565512    0.000000    0.135525    139.453055 
[37m[36mINFO[0m[0m 02/18 15:31:19 | Cumulative gradient change saved at train_output/VLCS/CORAL/[0, 1, 3]/250218_14-18-52_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/18 15:31:20 | ---
[37m[36mINFO[0m[0m 02/18 15:31:20 | test-domain validation(oracle) = 66.004%
[37m[36mINFO[0m[0m 02/18 15:31:20 | training-domain validation(iid) = 66.004%
[37m[36mINFO[0m[0m 02/18 15:31:20 | last = 53.545%
[37m[36mINFO[0m[0m 02/18 15:31:20 | last (inD) = 72.409%
[37m[36mINFO[0m[0m 02/18 15:31:20 | training-domain validation (iid, inD) = 76.829%
[37m[36mINFO[0m[0m 02/18 15:31:20 | === Summary ===
[37m[36mINFO[0m[0m 02/18 15:31:20 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 0 1 3 --dataset VLCS --trial_seed 0 --hparams_seed 17
[37m[36mINFO[0m[0m 02/18 15:31:20 | Unique name: 250218_14-18-52_resnet50_GENIE
[37m[36mINFO[0m[0m 02/18 15:31:20 | Out path: train_output/VLCS/CORAL/[0, 1, 3]/250218_14-18-52_resnet50_GENIE
[37m[36mINFO[0m[0m 02/18 15:31:20 | Algorithm: CORAL
[37m[36mINFO[0m[0m 02/18 15:31:20 | Dataset: VLCS
