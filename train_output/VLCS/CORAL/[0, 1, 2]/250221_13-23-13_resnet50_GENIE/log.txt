[37m[36mINFO[0m[0m 02/21 13:23:13 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 0 1 2 --dataset VLCS --trial_seed 0 --hparams_seed 15
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 15
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/VLCS/CORAL/[0, 1, 2]/250221_13-23-13_resnet50_GENIE
	out_root: train_output/VLCS/CORAL/[0, 1, 2]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 1, 2]
	trial_seed: 0
	unique_name: 250221_13-23-13_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.5
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 0.00010661763546249327
	batch_size: 14
	weight_decay: 9.086452814323981e-06
	mmd_gamma: 0.2920997066399848
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 02/21 13:23:13 | n_steps = 5001
[37m[36mINFO[0m[0m 02/21 13:23:13 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/21 13:23:13 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/21 13:23:13 | 
[37m[36mINFO[0m[0m 02/21 13:23:13 | Testenv name escaping te_C_L_S -> te_C_L_S
[37m[36mINFO[0m[0m 02/21 13:23:13 | Test envs = [0, 1, 2], name = te_C_L_S
[37m[36mINFO[0m[0m 02/21 13:23:13 | Train environments: [3], Test environments: [0, 1, 2]
[37m[36mINFO[0m[0m 02/21 13:23:13 | Batch sizes for each domain: [0, 0, 0, 14] (total=14)
[37m[36mINFO[0m[0m 02/21 13:23:13 | steps-per-epoch for each domain: 192.93 -> min = 192.93
[37m[36mINFO[0m[0m 02/21 13:23:15 | # of params = 23518277
[37m[36mINFO[0m[0m 02/21 13:25:39 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 02/21 13:25:39 | 0.485483    0.501938    0.443539    0.445926    1.569675    0.611307    0.628975    0.459765    0.489642    0.385377    0.387195    0.443539    0.445926    0           0.000000    1.714383    0.000000    1.655515    142.949614 
[37m[36mINFO[0m[0m 02/21 13:28:22 | 0.702682    0.688517    0.767494    0.789630    0.584665    0.945230    0.925795    0.552000    0.557439    0.610815    0.582317    0.767494    0.789630    200         1.036653    0.758209    0.000000    0.174428    128.108928 
[37m[36mINFO[0m[0m 02/21 13:31:22 | 0.762286    0.757033    0.813773    0.791111    0.638772    0.942580    0.936396    0.600941    0.604520    0.743336    0.730183    0.813773    0.791111    400         2.073306    0.597557    0.000000    0.152526    149.213531 
[37m[36mINFO[0m[0m 02/21 13:34:14 | 0.754891    0.745430    0.858571    0.813333    0.616164    0.962898    0.961131    0.579765    0.580038    0.722011    0.695122    0.858571    0.813333    600         3.109959    0.472407    0.000000    0.125003    146.913995 
[37m[36mINFO[0m[0m 02/21 13:37:06 | 0.770620    0.768370    0.851166    0.816296    0.600372    0.958481    0.964664    0.620706    0.634652    0.732673    0.705793    0.851166    0.816296    800         4.146612    0.464681    0.000000    0.136713    144.890524 
[37m[36mINFO[0m[0m 02/21 13:39:56 | 0.753457    0.734751    0.880785    0.831111    0.504278    0.955830    0.932862    0.546353    0.544256    0.758187    0.727134    0.880785    0.831111    1000        5.183265    0.344499    0.000000    0.167632    135.873789 
[37m[36mINFO[0m[0m 02/21 13:42:49 | 0.767750    0.744605    0.904110    0.837037    0.512099    0.972615    0.946996    0.603294    0.593220    0.727342    0.693598    0.904110    0.837037    1200        6.219919    0.334416    0.000000    0.128646    147.311984 
[37m[36mINFO[0m[0m 02/21 13:45:41 | 0.732439    0.737513    0.878563    0.810370    0.533888    0.919611    0.883392    0.611294    0.655367    0.666413    0.673780    0.878563    0.810370    1400        7.256572    0.342757    0.000000    0.128086    147.055903 
[37m[36mINFO[0m[0m 02/21 13:48:37 | 0.755264    0.739923    0.909293    0.814815    0.572763    0.954947    0.950530    0.569412    0.564972    0.741432    0.704268    0.909293    0.814815    1600        8.293225    0.334340    0.000000    0.131907    149.507277 
[37m[36mINFO[0m[0m 02/21 13:51:28 | 0.762792    0.759736    0.896335    0.831111    0.512198    0.970848    0.957597    0.592471    0.615819    0.725057    0.705793    0.896335    0.831111    1800        9.329878    0.272234    0.000000    0.147293    141.394847 
[37m[36mINFO[0m[0m 02/21 13:54:27 | 0.752118    0.741873    0.908923    0.826667    0.563549    0.972615    0.961131    0.567059    0.580038    0.716679    0.684451    0.908923    0.826667    2000        10.366531   0.305135    0.000000    0.154391    148.184942 
[37m[36mINFO[0m[0m 02/21 13:57:22 | 0.744106    0.737783    0.914846    0.808889    0.750888    0.931979    0.936396    0.572235    0.589454    0.728104    0.687500    0.914846    0.808889    2200        11.403184   0.267601    0.000000    0.129409    149.174495 
[37m[36mINFO[0m[0m 02/21 14:00:18 | 0.748619    0.759211    0.889300    0.788148    0.614301    0.929329    0.961131    0.613176    0.629002    0.703351    0.687500    0.889300    0.788148    2400        12.439837   0.256967    0.000000    0.142041    147.364007 
[37m[36mINFO[0m[0m 02/21 14:03:08 | 0.766690    0.768608    0.900407    0.804444    0.596215    0.949647    0.946996    0.621176    0.659134    0.729246    0.699695    0.900407    0.804444    2600        13.476490   0.283439    0.000000    0.110921    147.644494 
[37m[36mINFO[0m[0m 02/21 14:06:05 | 0.778904    0.766606    0.942244    0.837037    0.790986    0.958481    0.946996    0.645176    0.651601    0.733054    0.701220    0.942244    0.837037    2800        14.513143   0.181117    0.000000    0.142991    148.698700 
[37m[36mINFO[0m[0m 02/21 14:08:52 | 0.743173    0.727385    0.942984    0.808889    0.648839    0.917845    0.893993    0.571765    0.576271    0.739909    0.711890    0.942984    0.808889    3000        15.549796   0.205725    0.000000    0.120315    142.803403 
[37m[36mINFO[0m[0m 02/21 14:11:47 | 0.755681    0.756059    0.946686    0.829630    0.535094    0.958481    0.957597    0.577412    0.581921    0.731150    0.728659    0.946686    0.829630    3200        16.586449   0.271655    0.000000    0.154738    144.188142 
[37m[36mINFO[0m[0m 02/21 14:14:32 | 0.757470    0.764651    0.959645    0.841481    0.599650    0.975265    0.978799    0.593412    0.613936    0.703732    0.701220    0.959645    0.841481    3400        17.623103   0.160558    0.000000    0.123130    140.407075 
[37m[36mINFO[0m[0m 02/21 14:17:22 | 0.758877    0.754391    0.928545    0.819259    0.697787    0.951413    0.932862    0.610824    0.621469    0.714395    0.708841    0.928545    0.819259    3600        18.659756   0.211455    0.000000    0.140899    141.212149 
[37m[36mINFO[0m[0m 02/21 14:20:14 | 0.741426    0.720045    0.952240    0.792593    0.786895    0.969965    0.950530    0.534588    0.516008    0.719726    0.693598    0.952240    0.792593    3800        19.696409   0.160880    0.000000    0.137233    145.193768 
[37m[36mINFO[0m[0m 02/21 14:23:04 | 0.752404    0.743373    0.955202    0.822222    0.748730    0.950530    0.936396    0.583529    0.589454    0.723153    0.704268    0.955202    0.822222    4000        20.733062   0.127478    0.000000    0.133339    143.270972 
[37m[36mINFO[0m[0m 02/21 14:25:58 | 0.734123    0.724942    0.964828    0.814815    0.711245    0.961131    0.957597    0.553882    0.548023    0.687357    0.669207    0.964828    0.814815    4200        21.769715   0.146913    0.000000    0.137138    146.132515 
[37m[36mINFO[0m[0m 02/21 14:28:41 | 0.727356    0.711780    0.942614    0.783704    0.851604    0.888693    0.858657    0.581647    0.580038    0.711729    0.696646    0.942614    0.783704    4400        22.806368   0.113160    0.000000    0.132736    136.774883 
[37m[36mINFO[0m[0m 02/21 14:31:27 | 0.767344    0.752179    0.969641    0.826667    0.810694    0.953180    0.932862    0.616941    0.634652    0.731912    0.689024    0.969641    0.826667    4600        23.843021   0.120401    0.000000    0.127259    140.428514 
[37m[36mINFO[0m[0m 02/21 14:34:11 | 0.769594    0.742954    0.948538    0.817778    0.685842    0.954064    0.936396    0.611765    0.598870    0.742955    0.693598    0.948538    0.817778    4800        24.879674   0.121248    0.000000    0.121768    139.762080 
[37m[36mINFO[0m[0m 02/21 14:36:57 | 0.752778    0.759573    0.960755    0.804444    0.682637    0.907244    0.918728    0.612706    0.625235    0.738385    0.734756    0.960755    0.804444    5000        25.916327   0.169789    0.000000    0.119817    141.750269 
[37m[36mINFO[0m[0m 02/21 14:36:57 | Cumulative gradient change saved at train_output/VLCS/CORAL/[0, 1, 2]/250221_13-23-13_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/21 14:36:59 | ---
[37m[36mINFO[0m[0m 02/21 14:36:59 | test-domain validation(oracle) = 76.669%
[37m[36mINFO[0m[0m 02/21 14:36:59 | training-domain validation(iid) = 75.747%
[37m[36mINFO[0m[0m 02/21 14:36:59 | last = 75.278%
[37m[36mINFO[0m[0m 02/21 14:36:59 | last (inD) = 80.444%
[37m[36mINFO[0m[0m 02/21 14:36:59 | training-domain validation (iid, inD) = 84.148%
[37m[36mINFO[0m[0m 02/21 14:36:59 | === Summary ===
[37m[36mINFO[0m[0m 02/21 14:36:59 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 0 1 2 --dataset VLCS --trial_seed 0 --hparams_seed 15
[37m[36mINFO[0m[0m 02/21 14:36:59 | Unique name: 250221_13-23-13_resnet50_GENIE
[37m[36mINFO[0m[0m 02/21 14:36:59 | Out path: train_output/VLCS/CORAL/[0, 1, 2]/250221_13-23-13_resnet50_GENIE
[37m[36mINFO[0m[0m 02/21 14:36:59 | Algorithm: CORAL
[37m[36mINFO[0m[0m 02/21 14:36:59 | Dataset: VLCS
