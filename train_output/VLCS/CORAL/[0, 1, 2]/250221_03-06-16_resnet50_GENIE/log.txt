[37m[36mINFO[0m[0m 02/21 03:06:16 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 0 1 2 --dataset VLCS --trial_seed 0 --hparams_seed 7
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 7
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/VLCS/CORAL/[0, 1, 2]/250221_03-06-16_resnet50_GENIE
	out_root: train_output/VLCS/CORAL/[0, 1, 2]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 1, 2]
	trial_seed: 0
	unique_name: 250221_03-06-16_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 1.6632780446310692e-05
	batch_size: 24
	weight_decay: 5.717289389191427e-06
	mmd_gamma: 3.812683559377669
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 02/21 03:06:16 | n_steps = 5001
[37m[36mINFO[0m[0m 02/21 03:06:16 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/21 03:06:16 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/21 03:06:16 | 
[37m[36mINFO[0m[0m 02/21 03:06:16 | Testenv name escaping te_C_L_S -> te_C_L_S
[37m[36mINFO[0m[0m 02/21 03:06:16 | Test envs = [0, 1, 2], name = te_C_L_S
[37m[36mINFO[0m[0m 02/21 03:06:16 | Train environments: [3], Test environments: [0, 1, 2]
[37m[36mINFO[0m[0m 02/21 03:06:16 | Batch sizes for each domain: [0, 0, 0, 24] (total=24)
[37m[36mINFO[0m[0m 02/21 03:06:16 | steps-per-epoch for each domain: 112.54 -> min = 112.54
[37m[36mINFO[0m[0m 02/21 03:06:17 | # of params = 23518277
[37m[36mINFO[0m[0m 02/21 03:08:56 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 02/21 03:08:56 | 0.485356    0.501938    0.443539    0.445926    1.495468    0.611307    0.628975    0.459765    0.489642    0.384996    0.387195    0.443539    0.445926    0           0.000000    1.712650    0.000000    1.409614    157.603946 
[37m[36mINFO[0m[0m 02/21 03:11:46 | 0.752870    0.742979    0.831914    0.797037    0.521851    0.983216    0.978799    0.539294    0.536723    0.736101    0.713415    0.831914    0.797037    200         1.777120    0.566159    0.000000    0.155934    138.846837 
[37m[36mINFO[0m[0m 02/21 03:14:42 | 0.758789    0.742590    0.853758    0.789630    0.649654    0.984099    0.978799    0.553882    0.538606    0.738385    0.710366    0.853758    0.789630    400         3.554239    0.357656    0.000000    0.183682    138.958765 
[37m[36mINFO[0m[0m 02/21 03:17:41 | 0.750918    0.728996    0.916698    0.840000    0.475191    0.992933    0.989399    0.527529    0.500942    0.732292    0.696646    0.916698    0.840000    600         5.331359    0.309860    0.000000    0.138484    151.201513 
[37m[36mINFO[0m[0m 02/21 03:20:41 | 0.789127    0.769863    0.944465    0.856296    0.433291    0.988516    0.964664    0.606588    0.610169    0.772277    0.734756    0.944465    0.856296    800         7.108478    0.233248    0.000000    0.165202    147.435448 
[37m[36mINFO[0m[0m 02/21 03:23:43 | 0.778665    0.765704    0.914846    0.832593    0.488751    0.966431    0.954064    0.653647    0.672316    0.715918    0.670732    0.914846    0.832593    1000        8.885598    0.218955    0.000000    0.164884    149.268172 
[37m[36mINFO[0m[0m 02/21 03:26:33 | 0.774830    0.758636    0.957793    0.841481    0.550867    0.979682    0.968198    0.579765    0.566855    0.765042    0.740854    0.957793    0.841481    1200        10.662718   0.188781    0.000000    0.173228    135.114676 
[37m[36mINFO[0m[0m 02/21 03:29:37 | 0.760248    0.751253    0.911514    0.810370    0.622614    0.964664    0.950530    0.610824    0.623352    0.705255    0.679878    0.911514    0.810370    1400        12.439837   0.144695    0.000000    0.187906    146.051244 
[37m[36mINFO[0m[0m 02/21 03:32:38 | 0.765315    0.746254    0.938171    0.816296    0.701614    0.973498    0.957597    0.570353    0.555556    0.752094    0.725610    0.938171    0.816296    1600        14.216957   0.148639    0.000000    0.152731    151.056226 
[37m[36mINFO[0m[0m 02/21 03:35:29 | 0.765475    0.758898    0.969641    0.841481    0.601425    0.965548    0.939929    0.590588    0.591337    0.740289    0.745427    0.969641    0.841481    1800        15.994076   0.106157    0.000000    0.160506    138.183758 
[37m[36mINFO[0m[0m 02/21 03:38:28 | 0.763671    0.753423    0.974824    0.837037    0.709345    0.972615    0.964664    0.583059    0.591337    0.735339    0.704268    0.974824    0.837037    2000        17.771196   0.081657    0.000000    0.157781    147.379421 
[37m[36mINFO[0m[0m 02/21 03:41:18 | 0.733812    0.718837    0.958904    0.816296    0.843407    0.939929    0.929329    0.538353    0.544256    0.723153    0.682927    0.958904    0.816296    2200        19.548315   0.123654    0.000000    0.159831    138.831857 
[37m[36mINFO[0m[0m 02/21 03:44:20 | 0.770548    0.759814    0.970011    0.820741    0.707386    0.970848    0.971731    0.580706    0.598870    0.760091    0.708841    0.970011    0.820741    2400        21.325435   0.083688    0.000000    0.152729    151.288084 
[37m[36mINFO[0m[0m 02/21 03:47:19 | 0.754731    0.735595    0.985561    0.837037    0.711272    0.973498    0.961131    0.541647    0.529190    0.749048    0.716463    0.985561    0.837037    2600        23.102555   0.067650    0.000000    0.147706    149.516177 
[37m[36mINFO[0m[0m 02/21 03:50:19 | 0.757350    0.740935    0.962236    0.817778    0.820605    0.965548    0.957597    0.582588    0.583804    0.723915    0.681402    0.962236    0.817778    2800        24.879674   0.092135    0.000000    0.145627    150.994896 
[37m[36mINFO[0m[0m 02/21 03:53:08 | 0.750810    0.743175    0.992595    0.837037    0.766300    0.955830    0.939929    0.574588    0.583804    0.722011    0.705793    0.992595    0.837037    3000        26.656794   0.047216    0.000000    0.160082    136.485000 
[37m[36mINFO[0m[0m 02/21 03:56:01 | 0.779307    0.765607    0.983340    0.832593    0.746704    0.977915    0.961131    0.607529    0.617702    0.752475    0.717988    0.983340    0.832593    3200        28.433913   0.082757    0.000000    0.177802    137.395867 
[37m[36mINFO[0m[0m 02/21 03:58:56 | 0.746173    0.724935    0.982229    0.811852    0.747755    0.967314    0.946996    0.539294    0.523540    0.731912    0.704268    0.982229    0.811852    3400        30.211033   0.062219    0.000000    0.138754    147.470671 
[37m[36mINFO[0m[0m 02/21 04:01:55 | 0.750322    0.737107    0.977046    0.794074    0.672208    0.974382    0.957597    0.543529    0.523540    0.733054    0.730183    0.977046    0.794074    3600        31.988153   0.086325    0.000000    0.163986    145.997370 
[37m[36mINFO[0m[0m 02/21 04:04:39 | 0.744172    0.726603    0.990744    0.819259    0.794723    0.965548    0.954064    0.527059    0.504708    0.739909    0.721037    0.990744    0.819259    3800        33.765272   0.042469    0.000000    0.169834    129.981725 
[37m[36mINFO[0m[0m 02/21 04:07:28 | 0.755646    0.735571    0.988523    0.814815    1.014618    0.971731    0.954064    0.563294    0.549906    0.731912    0.702744    0.988523    0.814815    4000        35.542392   0.018009    0.000000    0.150438    139.309512 
[37m[36mINFO[0m[0m 02/21 04:10:30 | 0.761179    0.741608    0.993706    0.817778    0.880492    0.962014    0.936396    0.551529    0.553672    0.769992    0.734756    0.993706    0.817778    4200        37.319511   0.054470    0.000000    0.175722    146.177373 
[37m[36mINFO[0m[0m 02/21 04:13:31 | 0.761704    0.750847    0.988893    0.825185    0.736726    0.982332    0.971731    0.567059    0.585687    0.735720    0.695122    0.988893    0.825185    4400        39.096631   0.048712    0.000000    0.147302    152.403043 
[37m[36mINFO[0m[0m 02/21 04:16:30 | 0.722202    0.692796    0.987782    0.789630    0.817338    0.948763    0.936396    0.527059    0.497175    0.690784    0.644817    0.987782    0.789630    4600        40.873750   0.045996    0.000000    0.162609    146.106467 
[37m[36mINFO[0m[0m 02/21 04:19:27 | 0.775000    0.757763    0.980378    0.820741    0.873557    0.972615    0.975265    0.599529    0.580038    0.752856    0.717988    0.980378    0.820741    4800        42.650870   0.036705    0.000000    0.176058    142.000010 
[37m[36mINFO[0m[0m 02/21 04:22:15 | 0.757436    0.739445    0.995557    0.822222    0.950353    0.962898    0.950530    0.569882    0.557439    0.739528    0.710366    0.995557    0.822222    5000        44.427990   0.026439    0.000000    0.141089    139.827179 
[37m[36mINFO[0m[0m 02/21 04:22:15 | Cumulative gradient change saved at train_output/VLCS/CORAL/[0, 1, 2]/250221_03-06-16_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/21 04:22:17 | ---
[37m[36mINFO[0m[0m 02/21 04:22:17 | test-domain validation(oracle) = 78.913%
[37m[36mINFO[0m[0m 02/21 04:22:17 | training-domain validation(iid) = 78.913%
[37m[36mINFO[0m[0m 02/21 04:22:17 | last = 75.744%
[37m[36mINFO[0m[0m 02/21 04:22:17 | last (inD) = 82.222%
[37m[36mINFO[0m[0m 02/21 04:22:17 | training-domain validation (iid, inD) = 85.630%
[37m[36mINFO[0m[0m 02/21 04:22:17 | === Summary ===
[37m[36mINFO[0m[0m 02/21 04:22:17 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 0 1 2 --dataset VLCS --trial_seed 0 --hparams_seed 7
[37m[36mINFO[0m[0m 02/21 04:22:17 | Unique name: 250221_03-06-16_resnet50_GENIE
[37m[36mINFO[0m[0m 02/21 04:22:17 | Out path: train_output/VLCS/CORAL/[0, 1, 2]/250221_03-06-16_resnet50_GENIE
[37m[36mINFO[0m[0m 02/21 04:22:17 | Algorithm: CORAL
[37m[36mINFO[0m[0m 02/21 04:22:17 | Dataset: VLCS
