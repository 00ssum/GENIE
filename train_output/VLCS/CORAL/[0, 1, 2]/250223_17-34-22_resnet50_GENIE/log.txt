[37m[36mINFO[0m[0m 02/23 17:34:22 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 0 1 2 --dataset VLCS --trial_seed 2 --hparams_seed 13
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 13
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/VLCS/CORAL/[0, 1, 2]/250223_17-34-22_resnet50_GENIE
	out_root: train_output/VLCS/CORAL/[0, 1, 2]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 1, 2]
	trial_seed: 2
	unique_name: 250223_17-34-22_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 0.00010514591448387436
	batch_size: 9
	weight_decay: 2.4366015497066046e-05
	mmd_gamma: 0.11427248695687856
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 02/23 17:34:22 | n_steps = 5001
[37m[36mINFO[0m[0m 02/23 17:34:22 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/23 17:34:22 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/23 17:34:22 | 
[37m[36mINFO[0m[0m 02/23 17:34:22 | Testenv name escaping te_C_L_S -> te_C_L_S
[37m[36mINFO[0m[0m 02/23 17:34:22 | Test envs = [0, 1, 2], name = te_C_L_S
[37m[36mINFO[0m[0m 02/23 17:34:22 | Train environments: [3], Test environments: [0, 1, 2]
[37m[36mINFO[0m[0m 02/23 17:34:22 | Batch sizes for each domain: [0, 0, 0, 9] (total=9)
[37m[36mINFO[0m[0m 02/23 17:34:22 | steps-per-epoch for each domain: 300.11 -> min = 300.11
[37m[36mINFO[0m[0m 02/23 17:34:24 | # of params = 23518277
[37m[36mINFO[0m[0m 02/23 17:36:41 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 02/23 17:36:41 | 0.493095    0.470461    0.440207    0.459259    1.800212    0.620141    0.593640    0.467294    0.459510    0.391851    0.358232    0.440207    0.459259    0           0.000000    1.902179    0.000000    1.739455    135.666784 
[37m[36mINFO[0m[0m 02/23 17:39:21 | 0.695840    0.701694    0.702703    0.682963    0.782271    0.863958    0.837456    0.543059    0.572505    0.680503    0.695122    0.702703    0.682963    200         0.666420    0.950299    0.000000    0.120413    135.789477 
[37m[36mINFO[0m[0m 02/23 17:42:11 | 0.707845    0.694477    0.780452    0.785185    0.649026    0.924912    0.893993    0.584000    0.610169    0.614623    0.579268    0.780452    0.785185    400         1.332840    0.700514    0.000000    0.121831    145.239394 
[37m[36mINFO[0m[0m 02/23 17:44:53 | 0.733930    0.725607    0.800444    0.798519    0.611139    0.948763    0.932862    0.621647    0.640301    0.631379    0.603659    0.800444    0.798519    600         1.999260    0.567298    0.000000    0.122180    137.842980 
[37m[36mINFO[0m[0m 02/23 17:47:38 | 0.720669    0.716584    0.783784    0.743704    0.673885    0.958481    0.943463    0.521882    0.538606    0.681645    0.667683    0.783784    0.743704    800         2.665679    0.597337    0.000000    0.117861    141.406867 
[37m[36mINFO[0m[0m 02/23 17:50:25 | 0.753716    0.762953    0.854128    0.825185    0.522390    0.978799    0.971731    0.563765    0.608286    0.718583    0.708841    0.854128    0.825185    1000        3.332099    0.511677    0.000000    0.118215    143.195649 
[37m[36mINFO[0m[0m 02/23 17:53:15 | 0.696858    0.709740    0.834506    0.789630    0.634230    0.969965    0.978799    0.488471    0.493409    0.632140    0.657012    0.834506    0.789630    1200        3.998519    0.431151    0.000000    0.111610    147.825833 
[37m[36mINFO[0m[0m 02/23 17:55:48 | 0.751069    0.755754    0.840059    0.798519    0.561944    0.947880    0.964664    0.552471    0.580038    0.752856    0.722561    0.840059    0.798519    1400        4.664939    0.493059    0.000000    0.111492    130.773874 
[37m[36mINFO[0m[0m 02/23 17:58:26 | 0.766509    0.753884    0.830433    0.782222    0.666688    0.962898    0.932862    0.636706    0.653484    0.699924    0.675305    0.830433    0.782222    1600        5.331359    0.457915    0.000000    0.132294    130.839023 
[37m[36mINFO[0m[0m 02/23 18:01:11 | 0.768789    0.785646    0.885598    0.834074    0.484192    0.975265    0.982332    0.587765    0.613936    0.743336    0.760671    0.885598    0.834074    1800        5.997779    0.439791    0.000000    0.123264    140.653638 
[37m[36mINFO[0m[0m 02/23 18:03:54 | 0.756167    0.766300    0.865605    0.807407    0.574612    0.924912    0.936396    0.619294    0.638418    0.724296    0.724085    0.865605    0.807407    2000        6.664198    0.388186    0.000000    0.103995    142.334383 
[37m[36mINFO[0m[0m 02/23 18:06:42 | 0.758852    0.747737    0.867456    0.804444    0.566094    0.948763    0.918728    0.610353    0.630885    0.717441    0.693598    0.867456    0.804444    2200        7.330618    0.417660    0.000000    0.114003    145.034230 
[37m[36mINFO[0m[0m 02/23 18:09:18 | 0.745967    0.742301    0.868937    0.816296    0.544199    0.886042    0.876325    0.628706    0.647834    0.723153    0.702744    0.868937    0.816296    2400        7.997038    0.383965    0.000000    0.108625    134.734469 
[37m[36mINFO[0m[0m 02/23 18:11:58 | 0.766781    0.764621    0.875972    0.819259    0.529947    0.954064    0.961131    0.625412    0.642185    0.720868    0.690549    0.875972    0.819259    2600        8.663458    0.358259    0.000000    0.110144    137.899738 
[37m[36mINFO[0m[0m 02/23 18:14:41 | 0.743582    0.750893    0.868937    0.782222    0.637038    0.916078    0.915194    0.609412    0.627119    0.705255    0.710366    0.868937    0.782222    2800        9.329878    0.349340    0.000000    0.115620    139.351271 
[37m[36mINFO[0m[0m 02/23 18:17:18 | 0.757957    0.763747    0.904480    0.829630    0.517703    0.955830    0.950530    0.589176    0.612053    0.728865    0.728659    0.904480    0.829630    3000        9.996298    0.304051    0.000000    0.109243    135.326258 
[37m[36mINFO[0m[0m 02/23 18:19:51 | 0.780245    0.772650    0.920400    0.838519    0.544790    0.957597    0.957597    0.648941    0.659134    0.734196    0.701220    0.920400    0.838519    3200        10.662718   0.323650    0.000000    0.124126    128.591571 
[37m[36mINFO[0m[0m 02/23 18:22:29 | 0.783513    0.790580    0.917068    0.826667    0.516903    0.981449    0.982332    0.645176    0.683616    0.723915    0.705793    0.917068    0.826667    3400        11.329137   0.263467    0.000000    0.140974    129.568238 
[37m[36mINFO[0m[0m 02/23 18:25:08 | 0.758352    0.745542    0.869678    0.817778    0.672401    0.927562    0.897527    0.635765    0.651601    0.711729    0.687500    0.869678    0.817778    3600        11.995557   0.353989    0.000000    0.129802    132.872973 
[37m[36mINFO[0m[0m 02/23 18:27:44 | 0.742988    0.755374    0.867456    0.770370    0.729967    0.979682    0.975265    0.616000    0.638418    0.633283    0.652439    0.867456    0.770370    3800        12.661977   0.339862    0.000000    0.102877    135.668351 
[37m[36mINFO[0m[0m 02/23 18:30:37 | 0.767120    0.768285    0.895964    0.825185    0.630026    0.946113    0.939929    0.640471    0.659134    0.714775    0.705793    0.895964    0.825185    4000        13.328397   0.292654    0.000000    0.106296    151.680998 
[37m[36mINFO[0m[0m 02/23 18:33:26 | 0.760593    0.774969    0.911144    0.834074    0.547381    0.956714    0.954064    0.624000    0.642185    0.701066    0.728659    0.911144    0.834074    4200        13.994817   0.314936    0.000000    0.106880    147.898583 
[37m[36mINFO[0m[0m 02/23 18:36:13 | 0.764270    0.768788    0.929656    0.826667    0.569575    0.964664    0.964664    0.596235    0.625235    0.731912    0.716463    0.929656    0.826667    4400        14.661237   0.303183    0.000000    0.114001    143.804129 
[37m[36mINFO[0m[0m 02/23 18:39:04 | 0.755936    0.776494    0.929656    0.826667    0.620262    0.962898    0.971731    0.580235    0.621469    0.724676    0.736280    0.929656    0.826667    4600        15.327656   0.233444    0.000000    0.109792    149.071848 
[37m[36mINFO[0m[0m 02/23 18:41:51 | 0.752777    0.754918    0.932988    0.817778    0.577609    0.972615    0.964664    0.585412    0.598870    0.700305    0.701220    0.932988    0.817778    4800        15.994076   0.233535    0.000000    0.117503    143.216737 
[37m[36mINFO[0m[0m 02/23 18:44:38 | 0.738317    0.746056    0.919289    0.783704    0.612881    0.935512    0.925795    0.568471    0.591337    0.710967    0.721037    0.919289    0.783704    5000        16.660496   0.251332    0.000000    0.141951    139.101954 
[37m[36mINFO[0m[0m 02/23 18:44:38 | Cumulative gradient change saved at train_output/VLCS/CORAL/[0, 1, 2]/250223_17-34-22_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/23 18:44:40 | ---
[37m[36mINFO[0m[0m 02/23 18:44:40 | test-domain validation(oracle) = 78.351%
[37m[36mINFO[0m[0m 02/23 18:44:40 | training-domain validation(iid) = 78.024%
[37m[36mINFO[0m[0m 02/23 18:44:40 | last = 73.832%
[37m[36mINFO[0m[0m 02/23 18:44:40 | last (inD) = 78.370%
[37m[36mINFO[0m[0m 02/23 18:44:40 | training-domain validation (iid, inD) = 83.852%
[37m[36mINFO[0m[0m 02/23 18:44:40 | === Summary ===
[37m[36mINFO[0m[0m 02/23 18:44:40 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 0 1 2 --dataset VLCS --trial_seed 2 --hparams_seed 13
[37m[36mINFO[0m[0m 02/23 18:44:40 | Unique name: 250223_17-34-22_resnet50_GENIE
[37m[36mINFO[0m[0m 02/23 18:44:40 | Out path: train_output/VLCS/CORAL/[0, 1, 2]/250223_17-34-22_resnet50_GENIE
[37m[36mINFO[0m[0m 02/23 18:44:40 | Algorithm: CORAL
[37m[36mINFO[0m[0m 02/23 18:44:40 | Dataset: VLCS
