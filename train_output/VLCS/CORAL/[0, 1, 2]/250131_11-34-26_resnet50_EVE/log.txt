[37m[36mINFO[0m[0m 01/31 11:34:26 | Command :: /jsm0707/Large-scale/train_all.py resnet50_EVE config/resnet50_EVE.yaml --algorithm CORAL --test_envs 0 1 2 --dataset VLCS --trial_seed 0 --hparams_seed 2
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_EVE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 2
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_EVE
	out_dir: train_output/VLCS/CORAL/[0, 1, 2]/250131_11-34-26_resnet50_EVE
	out_root: train_output/VLCS/CORAL/[0, 1, 2]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 1, 2]
	trial_seed: 0
	unique_name: 250131_11-34-26_resnet50_EVE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: EVE
	freeze_bn: False
	pretrained: True
	lr: 1.9041073434446342e-05
	batch_size: 9
	weight_decay: 0.0006566989842279891
	mmd_gamma: 1.5832433896458313
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 01/31 11:34:26 | n_steps = 5001
[37m[36mINFO[0m[0m 01/31 11:34:26 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 01/31 11:34:26 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 01/31 11:34:26 | 
[37m[36mINFO[0m[0m 01/31 11:34:26 | Testenv name escaping te_C_L_S -> te_C_L_S
[37m[36mINFO[0m[0m 01/31 11:34:26 | Test envs = [0, 1, 2], name = te_C_L_S
[37m[36mINFO[0m[0m 01/31 11:34:26 | Train environments: [3], Test environments: [0, 1, 2]
[37m[36mINFO[0m[0m 01/31 11:34:26 | Batch sizes for each domain: [0, 0, 0, 9] (total=9)
[37m[36mINFO[0m[0m 01/31 11:34:26 | steps-per-epoch for each domain: 300.11 -> min = 300.11
[37m[36mINFO[0m[0m 01/31 11:34:28 | # of params = 23518277
[37m[36mINFO[0m[0m 01/31 11:37:43 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 01/31 11:37:43 | 0.485229    0.501938    0.443539    0.445926    1.611874    0.611307    0.628975    0.459765    0.489642    0.384615    0.387195    0.443539    0.445926    0           0.000000    1.789665    0.000000    1.898782    193.008817 
[37m[36mINFO[0m[0m 01/31 11:41:16 | 0.760816    0.739834    0.801925    0.777778    0.696371    0.944346    0.932862    0.616471    0.608286    0.721630    0.678354    0.801925    0.777778    200         0.666420    0.826777    0.000000    0.147598    183.643644 
[37m[36mINFO[0m[0m 01/31 11:44:44 | 0.734451    0.732695    0.735283    0.727407    0.804504    0.909894    0.908127    0.624000    0.617702    0.669459    0.672256    0.735283    0.727407    400         1.332840    0.653821    0.000000    0.186645    170.201000 
[37m[36mINFO[0m[0m 01/31 11:48:32 | 0.701645    0.691105    0.793040    0.749630    0.661443    0.959364    0.957597    0.503529    0.495292    0.642041    0.620427    0.793040    0.749630    600         1.999260    0.686318    0.000000    0.214296    185.331964 
[37m[36mINFO[0m[0m 01/31 11:52:09 | 0.729358    0.729038    0.802295    0.765926    0.659519    0.898410    0.886926    0.656000    0.687382    0.633663    0.612805    0.802295    0.765926    800         2.665679    0.523801    0.000000    0.158946    184.992420 
[37m[36mINFO[0m[0m 01/31 11:55:26 | 0.735945    0.710025    0.822288    0.780741    0.614993    0.930212    0.904594    0.568941    0.559322    0.708682    0.666159    0.822288    0.780741    1000        3.332099    0.558797    0.000000    0.159215    164.862628 
[37m[36mINFO[0m[0m 01/31 11:58:57 | 0.740478    0.720656    0.822658    0.770370    0.674051    0.932862    0.918728    0.610353    0.604520    0.678218    0.638720    0.822658    0.770370    1200        3.998519    0.492021    0.000000    0.167280    177.265659 
[37m[36mINFO[0m[0m 01/31 12:02:39 | 0.787633    0.771431    0.877823    0.832593    0.524054    0.973498    0.968198    0.625882    0.640301    0.763519    0.705793    0.877823    0.832593    1400        4.664939    0.441151    0.000000    0.150464    191.610559 
[37m[36mINFO[0m[0m 01/31 12:05:51 | 0.737924    0.749425    0.839319    0.764444    0.672693    0.939929    0.939929    0.640941    0.674200    0.632902    0.634146    0.839319    0.764444    1600        5.331359    0.476110    0.000000    0.181741    155.350175 
[37m[36mINFO[0m[0m 01/31 12:09:37 | 0.760820    0.757173    0.898926    0.825185    0.544319    0.984982    0.985866    0.589176    0.595104    0.708302    0.690549    0.898926    0.825185    1800        5.997779    0.383951    0.000000    0.190479    187.972020 
[37m[36mINFO[0m[0m 01/31 12:13:21 | 0.764020    0.752090    0.878193    0.819259    0.495997    0.967314    0.950530    0.602353    0.604520    0.722391    0.701220    0.878193    0.819259    2000        6.664198    0.397358    0.000000    0.149182    194.382429 
[37m[36mINFO[0m[0m 01/31 12:16:29 | 0.729979    0.720008    0.867827    0.768889    0.640633    0.902827    0.886926    0.596706    0.593220    0.690404    0.679878    0.867827    0.768889    2200        7.330618    0.344010    0.000000    0.131466    161.910596 
[37m[36mINFO[0m[0m 01/31 12:19:38 | 0.768065    0.755791    0.905961    0.817778    0.496178    0.981449    0.975265    0.593882    0.596987    0.728865    0.695122    0.905961    0.817778    2400        7.997038    0.359296    0.000000    0.196369    148.967520 
[37m[36mINFO[0m[0m 01/31 12:22:56 | 0.751892    0.754403    0.865976    0.786667    0.624211    0.941696    0.936396    0.627765    0.627119    0.686215    0.699695    0.865976    0.786667    2600        8.663458    0.362895    0.000000    0.112736    175.482991 
[37m[36mINFO[0m[0m 01/31 12:25:48 | 0.742972    0.745119    0.908182    0.782222    0.666421    0.962898    0.957597    0.568000    0.585687    0.698020    0.692073    0.908182    0.782222    2800        9.329878    0.303918    0.000000    0.106920    150.567539 
[37m[36mINFO[0m[0m 01/31 12:28:42 | 0.728630    0.705494    0.890041    0.783704    0.708526    0.960247    0.943463    0.536000    0.516008    0.689642    0.657012    0.890041    0.783704    3000        9.996298    0.274290    0.000000    0.151846    143.845431 
[37m[36mINFO[0m[0m 01/31 12:31:32 | 0.764132    0.766863    0.890781    0.786667    0.693060    0.924912    0.925795    0.660706    0.694915    0.706778    0.679878    0.890781    0.786667    3200        10.662718   0.290199    0.000000    0.117609    146.645710 
[37m[36mINFO[0m[0m 01/31 12:34:15 | 0.704968    0.689083    0.794150    0.687407    0.927420    0.930212    0.925795    0.528941    0.510358    0.655750    0.631098    0.794150    0.687407    3400        11.329137   0.288844    0.000000    0.122619    138.132698 
[37m[36mINFO[0m[0m 01/31 12:36:55 | 0.771072    0.758511    0.925213    0.826667    0.608540    0.942580    0.939929    0.643294    0.657250    0.727342    0.678354    0.925213    0.826667    3600        11.995557   0.259089    0.000000    0.122972    136.126553 
[37m[36mINFO[0m[0m 01/31 12:39:41 | 0.739650    0.735751    0.918919    0.814815    0.578879    0.931979    0.936396    0.584000    0.589454    0.702970    0.681402    0.918919    0.814815    3800        12.661977   0.267944    0.000000    0.121671    141.531129 
[37m[36mINFO[0m[0m 01/31 12:42:25 | 0.757859    0.752495    0.905961    0.797037    0.603804    0.894876    0.893993    0.645647    0.651601    0.733054    0.711890    0.905961    0.797037    4000        13.328397   0.245889    0.000000    0.127079    137.957753 
[37m[36mINFO[0m[0m 01/31 12:45:11 | 0.735466    0.724511    0.889300    0.786667    0.673930    0.938163    0.936396    0.565647    0.540490    0.702589    0.696646    0.889300    0.786667    4200        13.994817   0.236383    0.000000    0.122601    141.331475 
[37m[36mINFO[0m[0m 01/31 12:47:53 | 0.738407    0.729514    0.938171    0.807407    0.598358    0.905477    0.922261    0.565647    0.557439    0.744097    0.708841    0.938171    0.807407    4400        14.661237   0.244929    0.000000    0.124369    137.884869 
[37m[36mINFO[0m[0m 01/31 12:50:39 | 0.764079    0.752047    0.918178    0.816296    0.580416    0.944346    0.929329    0.617882    0.627119    0.730008    0.699695    0.918178    0.816296    4600        15.327656   0.261200    0.000000    0.127792    139.911661 
[37m[36mINFO[0m[0m 01/31 12:53:21 | 0.775413    0.767029    0.938541    0.822222    0.612203    0.978799    0.957597    0.615529    0.602637    0.731912    0.740854    0.938541    0.822222    4800        15.994076   0.231346    0.000000    0.127550    136.491194 
[37m[36mINFO[0m[0m 01/31 12:56:04 | 0.718317    0.716705    0.885228    0.771852    0.756032    0.937279    0.925795    0.608000    0.625235    0.609673    0.599085    0.885228    0.771852    5000        16.660496   0.287663    0.000000    0.133092    136.851540 
[37m[36mINFO[0m[0m 01/31 12:56:05 | Cumulative gradient change saved at train_output/VLCS/CORAL/[0, 1, 2]/250131_11-34-26_resnet50_EVE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 01/31 12:56:06 | ---
[37m[36mINFO[0m[0m 01/31 12:56:06 | test-domain validation(oracle) = 78.763%
[37m[36mINFO[0m[0m 01/31 12:56:06 | training-domain validation(iid) = 78.763%
[37m[36mINFO[0m[0m 01/31 12:56:06 | last = 71.832%
[37m[36mINFO[0m[0m 01/31 12:56:06 | last (inD) = 77.185%
[37m[36mINFO[0m[0m 01/31 12:56:06 | training-domain validation (iid, inD) = 83.259%
[37m[36mINFO[0m[0m 01/31 12:56:06 | === Summary ===
[37m[36mINFO[0m[0m 01/31 12:56:06 | Command: /jsm0707/Large-scale/train_all.py resnet50_EVE config/resnet50_EVE.yaml --algorithm CORAL --test_envs 0 1 2 --dataset VLCS --trial_seed 0 --hparams_seed 2
[37m[36mINFO[0m[0m 01/31 12:56:06 | Unique name: 250131_11-34-26_resnet50_EVE
[37m[36mINFO[0m[0m 01/31 12:56:06 | Out path: train_output/VLCS/CORAL/[0, 1, 2]/250131_11-34-26_resnet50_EVE
[37m[36mINFO[0m[0m 01/31 12:56:06 | Algorithm: CORAL
[37m[36mINFO[0m[0m 01/31 12:56:06 | Dataset: VLCS
