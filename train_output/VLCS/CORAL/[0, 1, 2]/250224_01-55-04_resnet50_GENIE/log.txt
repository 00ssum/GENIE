[37m[36mINFO[0m[0m 02/24 01:55:04 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 0 1 2 --dataset VLCS --trial_seed 2 --hparams_seed 20
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 20
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/VLCS/CORAL/[0, 1, 2]/250224_01-55-04_resnet50_GENIE
	out_root: train_output/VLCS/CORAL/[0, 1, 2]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 1, 2]
	trial_seed: 2
	unique_name: 250224_01-55-04_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 3.0575564760860844e-05
	batch_size: 27
	weight_decay: 7.45235722180653e-06
	mmd_gamma: 1.450436842057683
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 02/24 01:55:04 | n_steps = 5001
[37m[36mINFO[0m[0m 02/24 01:55:04 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/24 01:55:04 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/24 01:55:04 | 
[37m[36mINFO[0m[0m 02/24 01:55:04 | Testenv name escaping te_C_L_S -> te_C_L_S
[37m[36mINFO[0m[0m 02/24 01:55:04 | Test envs = [0, 1, 2], name = te_C_L_S
[37m[36mINFO[0m[0m 02/24 01:55:04 | Train environments: [3], Test environments: [0, 1, 2]
[37m[36mINFO[0m[0m 02/24 01:55:04 | Batch sizes for each domain: [0, 0, 0, 27] (total=27)
[37m[36mINFO[0m[0m 02/24 01:55:04 | steps-per-epoch for each domain: 100.04 -> min = 100.04
[37m[36mINFO[0m[0m 02/24 01:55:06 | # of params = 23518277
[37m[36mINFO[0m[0m 02/24 01:57:30 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 02/24 01:57:30 | 0.493095    0.470461    0.440207    0.459259    1.811703    0.620141    0.593640    0.467294    0.459510    0.391851    0.358232    0.440207    0.459259    0           0.000000    1.901143    0.000000    1.238204    143.197488 
[37m[36mINFO[0m[0m 02/24 02:00:23 | 0.785548    0.783596    0.868937    0.871111    0.387183    0.977032    0.968198    0.624471    0.647834    0.755141    0.734756    0.868937    0.871111    200         1.999260    0.573928    0.000000    0.145414    143.463737 
[37m[36mINFO[0m[0m 02/24 02:03:10 | 0.770263    0.759048    0.880785    0.863704    0.410046    0.980565    0.957597    0.581176    0.596987    0.749048    0.722561    0.880785    0.863704    400         3.998519    0.351290    0.000000    0.150619    136.605890 
[37m[36mINFO[0m[0m 02/24 02:05:53 | 0.790975    0.795021    0.940022    0.868148    0.410635    0.986749    0.978799    0.624941    0.644068    0.761234    0.762195    0.940022    0.868148    600         5.997779    0.263695    0.000000    0.145611    133.895131 
[37m[36mINFO[0m[0m 02/24 02:08:44 | 0.775731    0.794733    0.935579    0.862222    0.451686    0.984982    0.982332    0.590118    0.629002    0.752094    0.772866    0.935579    0.862222    800         7.997038    0.217009    0.000000    0.190514    133.379072 
[37m[36mINFO[0m[0m 02/24 02:11:35 | 0.760427    0.768345    0.945205    0.856296    0.534293    0.982332    0.975265    0.568941    0.602637    0.730008    0.727134    0.945205    0.856296    1000        9.996298    0.179570    0.000000    0.159054    139.247948 
[37m[36mINFO[0m[0m 02/24 02:14:24 | 0.782162    0.792073    0.940763    0.871111    0.481162    0.962014    0.964664    0.624000    0.647834    0.760472    0.763720    0.940763    0.871111    1200        11.995557   0.163060    0.000000    0.148097    139.004876 
[37m[36mINFO[0m[0m 02/24 02:17:15 | 0.807422    0.808268    0.966309    0.882963    0.530424    0.986749    0.971731    0.664000    0.681733    0.771516    0.771341    0.966309    0.882963    1400        13.994817   0.126391    0.000000    0.156931    139.407040 
[37m[36mINFO[0m[0m 02/24 02:20:25 | 0.791334    0.789095    0.961126    0.844444    0.640829    0.958481    0.950530    0.631059    0.659134    0.784463    0.757622    0.961126    0.844444    1600        15.994076   0.118860    0.000000    0.159170    158.220329 
[37m[36mINFO[0m[0m 02/24 02:23:36 | 0.745303    0.752727    0.964087    0.838519    0.543077    0.912544    0.901060    0.565176    0.610169    0.758187    0.746951    0.964087    0.838519    1800        17.993336   0.110390    0.000000    0.164761    158.467921 
[37m[36mINFO[0m[0m 02/24 02:26:41 | 0.775740    0.767472    0.979637    0.866667    0.468577    0.976148    0.946996    0.622588    0.625235    0.728484    0.730183    0.979637    0.866667    2000        19.992595   0.100328    0.000000    0.172575    150.359113 
[37m[36mINFO[0m[0m 02/24 02:29:52 | 0.781554    0.768015    0.979637    0.860741    0.596184    0.963781    0.939929    0.605176    0.630885    0.775704    0.733232    0.979637    0.860741    2200        21.991855   0.082816    0.000000    0.183059    154.339600 
[37m[36mINFO[0m[0m 02/24 02:32:55 | 0.766265    0.774575    0.990004    0.869630    0.510813    0.979682    0.978799    0.578824    0.610169    0.740289    0.734756    0.990004    0.869630    2400        23.991114   0.080455    0.000000    0.194722    144.263299 
[37m[36mINFO[0m[0m 02/24 02:36:02 | 0.791068    0.799738    0.987782    0.877037    0.698376    0.987633    0.985866    0.627765    0.657250    0.757807    0.756098    0.987782    0.877037    2600        25.990374   0.047179    0.000000    0.152461    156.330383 
[37m[36mINFO[0m[0m 02/24 02:39:18 | 0.788339    0.802715    0.989263    0.865185    0.662920    0.982332    0.982332    0.638588    0.666667    0.744097    0.759146    0.989263    0.865185    2800        27.989633   0.053998    0.000000    0.148644    166.733845 
[37m[36mINFO[0m[0m 02/24 02:42:26 | 0.771579    0.782841    0.991114    0.850370    0.845431    0.970848    0.957597    0.584941    0.619586    0.758949    0.771341    0.991114    0.850370    3000        29.988893   0.040648    0.000000    0.164350    154.908576 
[37m[36mINFO[0m[0m 02/24 02:45:31 | 0.757137    0.770910    0.984450    0.845926    0.734376    0.983216    0.982332    0.568471    0.581921    0.719726    0.748476    0.984450    0.845926    3200        31.988153   0.056569    0.000000    0.178075    149.534020 
[37m[36mINFO[0m[0m 02/24 02:48:58 | 0.787360    0.788163    0.991855    0.856296    0.650816    0.974382    0.975265    0.624941    0.634652    0.762757    0.754573    0.991855    0.856296    3400        33.987412   0.060043    0.000000    0.214438    164.086468 
[37m[36mINFO[0m[0m 02/24 02:51:59 | 0.755271    0.766128    0.990744    0.842963    0.717565    0.975265    0.982332    0.570824    0.602637    0.719726    0.713415    0.990744    0.842963    3600        35.986672   0.043592    0.000000    0.164568    147.965329 
[37m[36mINFO[0m[0m 02/24 02:55:05 | 0.788071    0.788367    0.992595    0.845926    0.592547    0.983216    0.982332    0.619765    0.632768    0.761234    0.750000    0.992595    0.845926    3800        37.985931   0.055035    0.000000    0.242612    137.447724 
[37m[36mINFO[0m[0m 02/24 02:58:12 | 0.765372    0.771651    0.995927    0.862222    0.791746    0.980565    0.971731    0.574118    0.593220    0.741432    0.750000    0.995927    0.862222    4000        39.985191   0.036879    0.000000    0.170420    152.577793 
[37m[36mINFO[0m[0m 02/24 03:01:24 | 0.787044    0.787357    0.988153    0.840000    0.671883    0.984099    0.992933    0.616941    0.625235    0.760091    0.743902    0.988153    0.840000    4200        41.984450   0.034788    0.000000    0.148783    162.173820 
[37m[36mINFO[0m[0m 02/24 03:04:34 | 0.759847    0.765775    0.972233    0.840000    0.843406    0.984982    0.992933    0.569882    0.589454    0.724676    0.714939    0.972233    0.840000    4400        43.983710   0.026308    0.000000    0.185639    153.132772 
[37m[36mINFO[0m[0m 02/24 03:07:35 | 0.747937    0.756275    0.981118    0.835556    0.914268    0.972615    0.968198    0.573176    0.585687    0.698020    0.714939    0.981118    0.835556    4600        45.982969   0.028618    0.000000    0.228553    135.416795 
[37m[36mINFO[0m[0m 02/24 03:10:52 | 0.775317    0.773642    0.988893    0.845926    0.793301    0.970848    0.950530    0.619765    0.647834    0.735339    0.722561    0.988893    0.845926    4800        47.982229   0.018628    0.000000    0.218549    153.482841 
[37m[36mINFO[0m[0m 02/24 03:14:05 | 0.780877    0.786484    0.997038    0.851852    0.758576    0.974382    0.982332    0.610824    0.627119    0.757426    0.750000    0.997038    0.851852    5000        49.981488   0.051804    0.000000    0.190056    154.474786 
[37m[36mINFO[0m[0m 02/24 03:14:05 | Cumulative gradient change saved at train_output/VLCS/CORAL/[0, 1, 2]/250224_01-55-04_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/24 03:14:08 | ---
[37m[36mINFO[0m[0m 02/24 03:14:08 | test-domain validation(oracle) = 80.742%
[37m[36mINFO[0m[0m 02/24 03:14:08 | training-domain validation(iid) = 80.742%
[37m[36mINFO[0m[0m 02/24 03:14:08 | last = 78.088%
[37m[36mINFO[0m[0m 02/24 03:14:08 | last (inD) = 85.185%
[37m[36mINFO[0m[0m 02/24 03:14:08 | training-domain validation (iid, inD) = 88.296%
[37m[36mINFO[0m[0m 02/24 03:14:08 | === Summary ===
[37m[36mINFO[0m[0m 02/24 03:14:08 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 0 1 2 --dataset VLCS --trial_seed 2 --hparams_seed 20
[37m[36mINFO[0m[0m 02/24 03:14:08 | Unique name: 250224_01-55-04_resnet50_GENIE
[37m[36mINFO[0m[0m 02/24 03:14:08 | Out path: train_output/VLCS/CORAL/[0, 1, 2]/250224_01-55-04_resnet50_GENIE
[37m[36mINFO[0m[0m 02/24 03:14:08 | Algorithm: CORAL
[37m[36mINFO[0m[0m 02/24 03:14:08 | Dataset: VLCS
