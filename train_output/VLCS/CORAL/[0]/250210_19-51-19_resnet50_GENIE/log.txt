[37m[36mINFO[0m[0m 02/10 19:51:19 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 0 --dataset VLCS --trial_seed 1 --hparams_seed 7
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 7
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/VLCS/CORAL/[0]/250210_19-51-19_resnet50_GENIE
	out_root: train_output/VLCS/CORAL/[0]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0]
	trial_seed: 1
	unique_name: 250210_19-51-19_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.5
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 0.00025471109765784857
	batch_size: 39
	weight_decay: 9.10622179414602e-05
	mmd_gamma: 8.495822994867268
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 02/10 19:51:19 | n_steps = 5001
[37m[36mINFO[0m[0m 02/10 19:51:19 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/10 19:51:19 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/10 19:51:19 | 
[37m[36mINFO[0m[0m 02/10 19:51:19 | Testenv name escaping te_C -> te_C
[37m[36mINFO[0m[0m 02/10 19:51:19 | Test envs = [0], name = te_C
[37m[36mINFO[0m[0m 02/10 19:51:19 | Train environments: [1, 2, 3], Test environments: [0]
[37m[36mINFO[0m[0m 02/10 19:51:19 | Batch sizes for each domain: [0, 39, 39, 39] (total=117)
[37m[36mINFO[0m[0m 02/10 19:51:19 | steps-per-epoch for each domain: 54.49, 67.33, 69.26 -> min = 54.49
[37m[36mINFO[0m[0m 02/10 19:51:21 | # of params = 23518277
[37m[36mINFO[0m[0m 02/10 19:54:04 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 02/10 19:54:04 | 0.613958    0.618375    0.432326    0.428842    1.329596    0.613958    0.618375    0.466824    0.461394    0.376618    0.419207    0.453536    0.405926    0           0.000000    1.811964    0.074664    2.026132    161.675690 
[37m[36mINFO[0m[0m 02/10 20:01:28 | 0.926678    0.901060    0.774041    0.772387    0.635196    0.926678    0.901060    0.735059    0.734463    0.795506    0.806402    0.791559    0.776296    200         3.670588    0.860479    0.006847    1.477041    148.050507 
[37m[36mINFO[0m[0m 02/10 20:08:56 | 0.977032    0.968198    0.811299    0.797348    0.567216    0.977032    0.968198    0.758588    0.749529    0.813404    0.826220    0.861903    0.816296    400         7.341176    0.568083    0.006787    1.479264    151.813366 
[37m[36mINFO[0m[0m 02/10 20:16:13 | 0.970848    0.971731    0.829155    0.790473    0.556619    0.970848    0.971731    0.793412    0.760829    0.808454    0.797256    0.885598    0.813333    600         11.011765   0.468095    0.005971    1.453308    146.867794 
[37m[36mINFO[0m[0m 02/10 20:23:39 | 0.983216    0.978799    0.872285    0.818748    0.509493    0.983216    0.978799    0.822588    0.755179    0.884235    0.853659    0.910033    0.847407    800         14.682353   0.405730    0.005380    1.481402    149.053595 
[37m[36mINFO[0m[0m 02/10 20:31:03 | 0.977915    0.975265    0.884146    0.816086    0.531460    0.977915    0.975265    0.851294    0.768362    0.891851    0.838415    0.909293    0.841481    1000        18.352941   0.365593    0.005026    1.491964    146.104203 
[37m[36mINFO[0m[0m 02/10 20:38:27 | 0.975265    0.964664    0.870000    0.803201    0.605642    0.975265    0.964664    0.827294    0.764595    0.854532    0.809451    0.928175    0.835556    1200        22.023529   0.315301    0.004982    1.473544    149.684315 
[37m[36mINFO[0m[0m 02/10 20:45:46 | 0.976148    0.978799    0.918220    0.814173    0.567437    0.976148    0.978799    0.878118    0.770245    0.927266    0.830793    0.949278    0.841481    1400        25.694118   0.289545    0.004651    1.482556    142.462247 
[37m[36mINFO[0m[0m 02/10 20:53:10 | 0.982332    0.982332    0.930918    0.814099    0.645889    0.982332    0.982332    0.907294    0.785311    0.928408    0.814024    0.957053    0.842963    1600        29.364706   0.229257    0.004785    1.486348    146.080774 
[37m[36mINFO[0m[0m 02/10 21:00:29 | 0.985866    0.982332    0.944531    0.812550    0.612713    0.985866    0.982332    0.936000    0.762712    0.938690    0.820122    0.958904    0.854815    1800        33.035294   0.196776    0.004577    1.444920    150.755016 
[37m[36mINFO[0m[0m 02/10 21:07:47 | 0.978799    0.982332    0.959345    0.799807    0.676386    0.978799    0.982332    0.944000    0.758945    0.957730    0.806402    0.976305    0.834074    2000        36.705882   0.171522    0.004506    1.447833    147.770715 
[37m[36mINFO[0m[0m 02/10 21:15:04 | 0.977915    0.971731    0.940558    0.798462    0.725669    0.977915    0.971731    0.890824    0.745763    0.963062    0.815549    0.967790    0.834074    2200        40.376471   0.139361    0.004541    1.469234    143.763021 
[37m[36mINFO[0m[0m 02/10 21:22:29 | 0.977915    0.982332    0.964870    0.793197    0.807587    0.977915    0.982332    0.953412    0.749529    0.962300    0.804878    0.978897    0.825185    2400        44.047059   0.120556    0.004513    1.485512    147.490823 
[37m[36mINFO[0m[0m 02/10 21:29:52 | 0.979682    0.982332    0.960250    0.781784    0.796412    0.979682    0.982332    0.935059    0.715631    0.964204    0.792683    0.981488    0.837037    2600        47.717647   0.099673    0.004341    1.495630    144.046048 
[37m[36mINFO[0m[0m 02/10 21:37:20 | 0.977915    0.968198    0.981646    0.800239    0.707960    0.977915    0.968198    0.972706    0.757062    0.986672    0.814024    0.985561    0.829630    2800        51.388235   0.112659    0.004105    1.490469    150.067730 
[37m[36mINFO[0m[0m 02/10 21:44:37 | 0.980565    0.971731    0.981816    0.794320    0.787299    0.980565    0.971731    0.971765    0.743879    0.985529    0.809451    0.988153    0.829630    3000        55.058824   0.075148    0.003999    1.466251    143.758730 
[37m[36mINFO[0m[0m 02/10 21:52:06 | 0.972615    0.971731    0.986746    0.793764    0.805537    0.972615    0.971731    0.981647    0.741996    0.988957    0.817073    0.989633    0.822222    3200        58.729412   0.064438    0.003854    1.473033    153.850301 
[37m[36mINFO[0m[0m 02/10 21:59:19 | 0.980565    0.975265    0.991109    0.795244    0.808353    0.980565    0.975265    0.986824    0.749529    0.993907    0.812500    0.992595    0.823704    3400        62.400000   0.057294    0.003806    1.473981    138.503979 
[37m[36mINFO[0m[0m 02/10 22:06:36 | 0.984099    0.978799    0.991480    0.805496    0.863354    0.984099    0.978799    0.989176    0.766478    0.989337    0.829268    0.995927    0.820741    3600        66.070588   0.043161    0.003620    1.472439    142.343223 
[37m[36mINFO[0m[0m 02/10 22:13:59 | 0.984982    0.982332    0.993725    0.801466    0.819160    0.984982    0.982332    0.990588    0.760829    0.994288    0.810976    0.996298    0.832593    3800        69.741176   0.040452    0.003484    1.505686    141.351418 
[37m[36mINFO[0m[0m 02/10 22:21:18 | 0.966431    0.957597    0.993735    0.795260    0.798485    0.966431    0.957597    0.990588    0.741996    0.995430    0.818598    0.995187    0.825185    4000        73.411765   0.036884    0.003311    1.471577    145.204416 
[37m[36mINFO[0m[0m 02/10 22:28:30 | 0.984099    0.975265    0.995413    0.806671    0.817537    0.984099    0.975265    0.993412    0.772128    0.995050    0.806402    0.997779    0.841481    4200        77.082353   0.030936    0.003247    1.443141    143.274199 
[37m[36mINFO[0m[0m 02/10 22:35:45 | 0.976148    0.975265    0.997012    0.810752    0.809896    0.976148    0.975265    0.996706    0.757062    0.995811    0.829268    0.998519    0.845926    4400        80.752941   0.032436    0.003134    1.432800    148.142032 
[37m[36mINFO[0m[0m 02/10 22:43:02 | 0.981449    0.978799    0.994879    0.794263    0.848692    0.981449    0.978799    0.994824    0.743879    0.993145    0.803354    0.996668    0.835556    4600        84.423529   0.023685    0.002991    1.468240    143.799580 
[37m[36mINFO[0m[0m 02/10 22:50:16 | 0.982332    0.985866    0.993777    0.792676    0.946934    0.982332    0.985866    0.993412    0.741996    0.991622    0.806402    0.996298    0.829630    4800        88.094118   0.023420    0.002868    1.446087    144.945762 
[37m[36mINFO[0m[0m 02/10 22:57:30 | 0.977032    0.978799    0.992570    0.794793    0.955678    0.977032    0.978799    0.993882    0.749529    0.990861    0.817073    0.992966    0.817778    5000        91.764706   0.032496    0.002846    1.431409    147.054103 
[37m[36mINFO[0m[0m 02/10 22:57:30 | Cumulative gradient change saved at train_output/VLCS/CORAL/[0]/250210_19-51-19_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/10 22:57:31 | ---
[37m[36mINFO[0m[0m 02/10 22:57:31 | test-domain validation(oracle) = 98.233%
[37m[36mINFO[0m[0m 02/10 22:57:31 | training-domain validation(iid) = 98.322%
[37m[36mINFO[0m[0m 02/10 22:57:31 | last = 97.703%
[37m[36mINFO[0m[0m 02/10 22:57:31 | last (inD) = 79.479%
[37m[36mINFO[0m[0m 02/10 22:57:31 | training-domain validation (iid, inD) = 81.875%
[37m[36mINFO[0m[0m 02/10 22:57:31 | === Summary ===
[37m[36mINFO[0m[0m 02/10 22:57:31 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 0 --dataset VLCS --trial_seed 1 --hparams_seed 7
[37m[36mINFO[0m[0m 02/10 22:57:31 | Unique name: 250210_19-51-19_resnet50_GENIE
[37m[36mINFO[0m[0m 02/10 22:57:31 | Out path: train_output/VLCS/CORAL/[0]/250210_19-51-19_resnet50_GENIE
[37m[36mINFO[0m[0m 02/10 22:57:31 | Algorithm: CORAL
[37m[36mINFO[0m[0m 02/10 22:57:31 | Dataset: VLCS
