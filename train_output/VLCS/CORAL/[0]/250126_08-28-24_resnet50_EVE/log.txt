[37m[36mINFO[0m[0m 01/26 08:28:24 | Command :: /jsm0707/DomainBed/Large-scale/train_all.py resnet50_EVE config/resnet50_EVE.yaml --algorithm CORAL --test_envs 0 --dataset VLCS --trial_seed 2 --hparams_seed 14
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 9.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_EVE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 14
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_EVE
	out_dir: train_output/VLCS/CORAL/[0]/250126_08-28-24_resnet50_EVE
	out_root: train_output/VLCS/CORAL/[0]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0]
	trial_seed: 2
	unique_name: 250126_08-28-24_resnet50_EVE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.5
	class_balanced: False
	optimizer: EVE
	freeze_bn: False
	pretrained: True
	lr: 4.223376545632674e-05
	batch_size: 27
	weight_decay: 1.4009530778122364e-05
	mmd_gamma: 5.905916742185723
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 01/26 08:28:24 | n_steps = 5001
[37m[36mINFO[0m[0m 01/26 08:28:24 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 01/26 08:28:24 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 01/26 08:28:24 | Target test envs = [[0]]
[37m[36mINFO[0m[0m 01/26 08:28:24 | 
[37m[36mINFO[0m[0m 01/26 08:28:24 | Testenv name escaping te_C -> te_C
[37m[36mINFO[0m[0m 01/26 08:28:24 | Test envs = [0], name = te_C
[37m[36mINFO[0m[0m 01/26 08:28:24 | Batch sizes for each domain: [0, 27, 27, 27] (total=81)
[37m[36mINFO[0m[0m 01/26 08:28:24 | steps-per-epoch for each domain: 78.70, 97.26, 100.04 -> min = 78.70
[37m[36mINFO[0m[0m 01/26 08:28:25 | # of params = 23518277
[37m[36mINFO[0m[0m 01/26 08:30:40 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 01/26 08:30:40 | 0.620141    0.593640    0.433741    0.432173    1.310076    0.620141    0.593640    0.467294    0.459510    0.392612    0.367378    0.441318    0.469630    0           0.000000    1.920779    0.092344    1.292812    133.697924 
[37m[36mINFO[0m[0m 01/26 08:36:03 | 0.938163    0.911661    0.777080    0.774181    0.630065    0.938163    0.911661    0.726118    0.743879    0.792460    0.768293    0.812662    0.810370    200         2.541176    0.852563    0.010052    0.931958    136.944258 
[37m[36mINFO[0m[0m 01/26 08:41:34 | 0.956714    0.936396    0.794559    0.793417    0.561360    0.956714    0.936396    0.752471    0.764595    0.785225    0.766768    0.845983    0.848889    400         5.082353    0.567515    0.009551    0.960195    137.965604 
[37m[36mINFO[0m[0m 01/26 08:46:59 | 0.966431    0.936396    0.837763    0.814047    0.516435    0.966431    0.936396    0.797647    0.787194    0.839299    0.794207    0.876342    0.860741    600         7.623529    0.492610    0.008064    0.956260    133.815600 
[37m[36mINFO[0m[0m 01/26 08:52:31 | 0.992049    0.985866    0.857399    0.816574    0.519976    0.992049    0.985866    0.817882    0.787194    0.858720    0.800305    0.895594    0.862222    800         10.164706   0.436318    0.007497    0.973015    136.783396 
[37m[36mINFO[0m[0m 01/26 08:57:58 | 0.977915    0.968198    0.876189    0.808815    0.507999    0.977915    0.968198    0.835294    0.768362    0.888423    0.800305    0.904850    0.857778    1000        12.705882   0.384780    0.007160    0.969739    133.607096 
[37m[36mINFO[0m[0m 01/26 09:03:27 | 0.984099    0.968198    0.870829    0.810286    0.566590    0.984099    0.968198    0.828235    0.777778    0.870145    0.780488    0.914106    0.872593    1200        15.247059   0.343265    0.006704    0.974115    133.514827 
[37m[36mINFO[0m[0m 01/26 09:08:54 | 0.983216    0.968198    0.896354    0.811955    0.542331    0.983216    0.968198    0.862118    0.770245    0.900990    0.804878    0.925953    0.860741    1400        17.788235   0.327319    0.006445    0.948418    137.622688 
[37m[36mINFO[0m[0m 01/26 09:14:23 | 0.976148    0.978799    0.901174    0.802541    0.584188    0.976148    0.978799    0.876706    0.758945    0.896420    0.782012    0.930396    0.866667    1600        20.329412   0.285523    0.006378    0.973881    134.003399 
[37m[36mINFO[0m[0m 01/26 09:19:46 | 0.978799    0.971731    0.917437    0.808413    0.599254    0.978799    0.971731    0.886588    0.762712    0.924219    0.800305    0.941503    0.862222    1800        22.870588   0.266092    0.006108    0.949030    133.824121 
[37m[36mINFO[0m[0m 01/26 09:25:11 | 0.966431    0.943463    0.936924    0.795716    0.595990    0.966431    0.943463    0.917176    0.743879    0.941356    0.800305    0.952240    0.842963    2000        25.411765   0.227528    0.006168    0.947203    135.208406 
[37m[36mINFO[0m[0m 01/26 09:30:37 | 0.987633    0.982332    0.926911    0.804230    0.678378    0.987633    0.982332    0.905882    0.745763    0.919650    0.798780    0.955202    0.868148    2200        27.952941   0.190988    0.005899    0.962057    133.765749 
[37m[36mINFO[0m[0m 01/26 09:36:05 | 0.967314    0.957597    0.933767    0.789294    0.742381    0.967314    0.957597    0.912000    0.732580    0.933359    0.780488    0.955942    0.854815    2400        30.494118   0.173271    0.005961    0.963628    135.061456 
[37m[36mINFO[0m[0m 01/26 09:41:29 | 0.964664    0.957597    0.954875    0.807801    0.688291    0.964664    0.957597    0.934588    0.753296    0.960396    0.806402    0.969641    0.863704    2600        33.035294   0.156833    0.005831    0.948724    134.601965 
[37m[36mINFO[0m[0m 01/26 09:46:55 | 0.981449    0.975265    0.959098    0.808354    0.676706    0.981449    0.975265    0.944000    0.738230    0.957730    0.821646    0.975565    0.865185    2800        35.576471   0.134266    0.005660    0.957790    133.835170 
[37m[36mINFO[0m[0m 01/26 09:52:20 | 0.979682    0.968198    0.927421    0.790681    0.779201    0.979682    0.968198    0.845647    0.721281    0.957350    0.803354    0.979267    0.847407    3000        38.117647   0.152671    0.005443    0.959167    133.445784 
[37m[36mINFO[0m[0m 01/26 09:57:48 | 0.985866    0.982332    0.973165    0.805374    0.724811    0.985866    0.982332    0.960941    0.753296    0.974105    0.810976    0.984450    0.851852    3200        40.658824   0.114011    0.005606    0.945990    138.412404 
[37m[36mINFO[0m[0m 01/26 10:03:14 | 0.977915    0.968198    0.972583    0.792322    0.768082    0.977915    0.968198    0.969412    0.738230    0.966108    0.797256    0.982229    0.841481    3400        43.200000   0.098024    0.005520    0.960317    134.274747 
[37m[36mINFO[0m[0m 01/26 10:08:39 | 0.985866    0.971731    0.985647    0.795359    0.762713    0.985866    0.971731    0.981176    0.723164    0.980579    0.814024    0.995187    0.848889    3600        45.741176   0.090344    0.005277    0.948869    134.854967 
[37m[36mINFO[0m[0m 01/26 10:14:06 | 0.970848    0.954064    0.979093    0.808040    0.758154    0.970848    0.954064    0.972706    0.757062    0.977532    0.803354    0.987042    0.863704    3800        48.282353   0.075391    0.005205    0.967419    133.862235 
[37m[36mINFO[0m[0m 01/26 10:19:33 | 0.968198    0.950530    0.984114    0.800884    0.856852    0.968198    0.950530    0.982118    0.749529    0.980960    0.782012    0.989263    0.871111    4000        50.823529   0.066767    0.004949    0.948288    137.184190 
[37m[36mINFO[0m[0m 01/26 10:24:56 | 0.973498    0.968198    0.984050    0.803432    0.821734    0.973498    0.968198    0.981176    0.762712    0.981340    0.795732    0.989633    0.851852    4200        53.364706   0.085134    0.004928    0.946732    134.186659 
[37m[36mINFO[0m[0m 01/26 10:30:26 | 0.977915    0.975265    0.987192    0.796609    0.822459    0.977915    0.975265    0.983059    0.706215    0.986291    0.812500    0.992225    0.871111    4400        55.905882   0.061096    0.004713    0.975675    134.067623 
[37m[36mINFO[0m[0m 01/26 10:35:53 | 0.975265    0.957597    0.990196    0.804555    0.827679    0.975265    0.957597    0.984941    0.749529    0.989718    0.804878    0.995927    0.859259    4600        58.447059   0.051793    0.004622    0.958376    135.318637 
[37m[36mINFO[0m[0m 01/26 10:41:22 | 0.966431    0.961131    0.987804    0.802565    0.803447    0.966431    0.961131    0.980706    0.757062    0.990480    0.798780    0.992225    0.851852    4800        60.988235   0.048129    0.004400    0.956461    137.832608 
[37m[36mINFO[0m[0m 01/26 10:46:48 | 0.977032    0.971731    0.990347    0.790814    0.842056    0.977032    0.971731    0.983059    0.723164    0.993907    0.803354    0.994076    0.845926    5000        63.529412   0.036346    0.004368    0.950329    136.150219 
[37m[36mINFO[0m[0m 01/26 10:46:48 | Cumulative gradient change saved at train_output/VLCS/CORAL/[0]/250126_08-28-24_resnet50_EVE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 01/26 10:46:49 | ---
[37m[36mINFO[0m[0m 01/26 10:46:49 | test-domain validation(oracle) = 99.205%
[37m[36mINFO[0m[0m 01/26 10:46:49 | training-domain validation(iid) = 99.205%
[37m[36mINFO[0m[0m 01/26 10:46:49 | last = 97.703%
[37m[36mINFO[0m[0m 01/26 10:46:49 | last (inD) = 79.081%
[37m[36mINFO[0m[0m 01/26 10:46:49 | training-domain validation (iid, inD) = 81.657%
[37m[36mINFO[0m[0m 01/26 10:46:50 | === Summary ===
[37m[36mINFO[0m[0m 01/26 10:46:50 | Command: /jsm0707/DomainBed/Large-scale/train_all.py resnet50_EVE config/resnet50_EVE.yaml --algorithm CORAL --test_envs 0 --dataset VLCS --trial_seed 2 --hparams_seed 14
[37m[36mINFO[0m[0m 01/26 10:46:50 | Unique name: 250126_08-28-24_resnet50_EVE
[37m[36mINFO[0m[0m 01/26 10:46:50 | Out path: train_output/VLCS/CORAL/[0]/250126_08-28-24_resnet50_EVE
[37m[36mINFO[0m[0m 01/26 10:46:50 | Algorithm: CORAL
[37m[36mINFO[0m[0m 01/26 10:46:50 | Dataset: VLCS
[37m[36mINFO[0m[0m 01/26 10:46:50 | Max test_in: 0.9920
