[37m[36mINFO[0m[0m 02/18 21:45:14 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 3 --dataset VLCS --trial_seed 2 --hparams_seed 12
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 12
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/VLCS/CORAL/[3]/250218_21-45-14_resnet50_GENIE
	out_root: train_output/VLCS/CORAL/[3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [3]
	trial_seed: 2
	unique_name: 250218_21-45-14_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 5.346798771850428e-05
	batch_size: 44
	weight_decay: 1.8352299015720086e-05
	mmd_gamma: 3.310992720685983
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 02/18 21:45:14 | n_steps = 5001
[37m[36mINFO[0m[0m 02/18 21:45:14 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/18 21:45:14 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/18 21:45:14 | 
[37m[36mINFO[0m[0m 02/18 21:45:15 | Testenv name escaping te_V -> te_V
[37m[36mINFO[0m[0m 02/18 21:45:15 | Test envs = [3], name = te_V
[37m[36mINFO[0m[0m 02/18 21:45:15 | Train environments: [0, 1, 2], Test environments: [3]
[37m[36mINFO[0m[0m 02/18 21:45:15 | Batch sizes for each domain: [44, 44, 44, 0] (total=132)
[37m[36mINFO[0m[0m 02/18 21:45:15 | steps-per-epoch for each domain: 25.73, 48.30, 59.68 -> min = 25.73
[37m[36mINFO[0m[0m 02/18 21:45:16 | # of params = 23518277
[37m[36mINFO[0m[0m 02/18 21:47:48 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 02/18 21:47:48 | 0.440207    0.459259    0.493095    0.470461    1.242142    0.620141    0.593640    0.467294    0.459510    0.391851    0.358232    0.440207    0.459259    0           0.000000    1.801625    0.059972    1.899864    150.638207 
[37m[36mINFO[0m[0m 02/18 21:56:12 | 0.739726    0.736296    0.859034    0.835197    0.422222    1.000000    0.996466    0.761412    0.743879    0.815689    0.765244    0.739726    0.736296    200         7.773852    0.492937    0.013616    1.767398    150.522889 
[37m[36mINFO[0m[0m 02/18 22:04:39 | 0.781562    0.780741    0.893820    0.858069    0.392536    1.000000    0.989399    0.809412    0.789077    0.872049    0.795732    0.781562    0.780741    400         15.547703   0.323838    0.009314    1.772657    152.494285 
[37m[36mINFO[0m[0m 02/18 22:13:05 | 0.761940    0.764444    0.890464    0.842418    0.426804    1.000000    0.992933    0.782588    0.740113    0.888804    0.794207    0.761940    0.764444    600         23.321555   0.285994    0.008080    1.767299    151.924278 
[37m[36mINFO[0m[0m 02/18 22:21:32 | 0.746760    0.731852    0.928243    0.852205    0.424259    1.000000    0.996466    0.877647    0.779661    0.907083    0.780488    0.746760    0.731852    800         31.095406   0.231058    0.007702    1.809237    145.046319 
[37m[36mINFO[0m[0m 02/18 22:30:06 | 0.764532    0.768889    0.943190    0.852354    0.421285    0.999117    0.996466    0.891765    0.774011    0.938690    0.786585    0.764532    0.768889    1000        38.869258   0.187152    0.007368    1.846814    144.743634 
[37m[36mINFO[0m[0m 02/18 22:38:38 | 0.748982    0.733333    0.927555    0.827263    0.541401    0.998233    0.992933    0.862118    0.717514    0.922315    0.771341    0.748982    0.733333    1200        46.643110   0.153416    0.007257    1.772131    157.389972 
[37m[36mINFO[0m[0m 02/18 22:47:06 | 0.762310    0.758519    0.968304    0.841270    0.534414    1.000000    0.989399    0.948706    0.764595    0.956207    0.769817    0.762310    0.758519    1400        54.416961   0.112444    0.007019    1.802645    148.315753 
[37m[36mINFO[0m[0m 02/18 22:55:34 | 0.745280    0.748148    0.975159    0.852886    0.582945    1.000000    0.985866    0.948706    0.774011    0.976771    0.798780    0.745280    0.748148    1600        62.190813   0.089588    0.006704    1.825272    142.125658 
[37m[36mINFO[0m[0m 02/18 23:04:06 | 0.746390    0.743704    0.975443    0.850268    0.582938    1.000000    0.989399    0.949176    0.770245    0.977152    0.791159    0.746390    0.743704    1800        69.964664   0.070155    0.006373    1.766056    158.787790 
[37m[36mINFO[0m[0m 02/18 23:12:33 | 0.714550    0.717037    0.983584    0.840906    0.543188    1.000000    0.996466    0.969412    0.745763    0.981340    0.780488    0.714550    0.717037    2000        77.738516   0.068171    0.006166    1.749751    157.430502 
[37m[36mINFO[0m[0m 02/18 23:20:42 | 0.716772    0.709630    0.992815    0.850638    0.587619    1.000000    0.992933    0.986824    0.749529    0.991622    0.809451    0.716772    0.709630    2200        85.512367   0.040424    0.005557    1.743188    140.817014 
[37m[36mINFO[0m[0m 02/18 23:29:18 | 0.733802    0.721481    0.995078    0.850925    0.606820    1.000000    0.989399    0.992471    0.764595    0.992765    0.798780    0.733802    0.721481    2400        93.286219   0.041515    0.005434    1.851817    145.071620 
[37m[36mINFO[0m[0m 02/18 23:38:04 | 0.733432    0.733333    0.995175    0.851403    0.645263    1.000000    0.989399    0.992000    0.772128    0.993526    0.792683    0.733432    0.733333    2600        101.060071  0.031029    0.005053    1.845094    157.496361 
[37m[36mINFO[0m[0m 02/18 23:46:46 | 0.756387    0.758519    0.996938    0.854601    0.664732    1.000000    0.989399    0.995765    0.766478    0.995050    0.807927    0.756387    0.758519    2800        108.833922  0.022542    0.004703    1.802774    161.032928 
[37m[36mINFO[0m[0m 02/18 23:55:23 | 0.751573    0.736296    0.996572    0.848277    0.633965    1.000000    0.992933    0.992000    0.768362    0.997715    0.783537    0.751573    0.736296    3000        116.607774  0.023173    0.004442    1.821352    152.892122 
[37m[36mINFO[0m[0m 02/19 00:03:50 | 0.714920    0.727407    0.995893    0.846155    0.646950    1.000000    0.992933    0.995294    0.758945    0.992384    0.786585    0.714920    0.727407    3200        124.381625  0.027874    0.004336    1.792571    148.271020 
[37m[36mINFO[0m[0m 02/19 00:12:30 | 0.738986    0.745185    0.992912    0.839776    0.778366    1.000000    0.989399    0.986353    0.757062    0.992384    0.772866    0.738986    0.745185    3400        132.155477  0.016300    0.004081    1.794577    160.835980 
[37m[36mINFO[0m[0m 02/19 00:21:33 | 0.705665    0.706667    0.995175    0.844839    0.678292    1.000000    0.992933    0.992000    0.738230    0.993526    0.803354    0.705665    0.706667    3600        139.929329  0.020278    0.003932    1.879486    167.537961 
[37m[36mINFO[0m[0m 02/19 00:30:45 | 0.747871    0.745185    0.998357    0.846980    0.724467    1.000000    0.989399    0.998118    0.766478    0.996954    0.785061    0.747871    0.745185    3800        147.703180  0.015359    0.003736    1.903659    170.786206 
[37m[36mINFO[0m[0m 02/19 00:39:47 | 0.735283    0.743704    0.997857    0.837534    0.727154    1.000000    0.989399    0.996235    0.745763    0.997334    0.777439    0.735283    0.743704    4000        155.477032  0.012958    0.003523    1.893070    163.309945 
[37m[36mINFO[0m[0m 02/19 00:48:47 | 0.732692    0.745185    0.996661    0.837815    0.818438    1.000000    0.992933    0.993412    0.747646    0.996573    0.772866    0.732692    0.745185    4200        163.250883  0.015048    0.003577    1.882300    164.328117 
[37m[36mINFO[0m[0m 02/19 00:57:41 | 0.721214    0.736296    0.999246    0.847637    0.731328    1.000000    0.989399    0.998118    0.760829    0.999619    0.792683    0.721214    0.736296    4400        171.024735  0.006965    0.003163    1.897800    154.051711 
[37m[36mINFO[0m[0m 02/19 01:06:34 | 0.745280    0.760000    0.994623    0.835561    0.874423    1.000000    0.989399    0.995294    0.762712    0.988576    0.754573    0.745280    0.760000    4600        178.798587  0.015172    0.003224    1.847178    163.570869 
[37m[36mINFO[0m[0m 02/19 01:15:15 | 0.735283    0.724444    0.998835    0.849203    0.734432    1.000000    0.992933    0.997647    0.758945    0.998858    0.795732    0.735283    0.724444    4800        186.572438  0.011217    0.003250    1.806645    159.751425 
[37m[36mINFO[0m[0m 02/19 01:23:53 | 0.748241    0.760000    0.997737    0.850058    0.750239    1.000000    0.989399    0.994353    0.758945    0.998858    0.801829    0.748241    0.760000    5000        194.346290  0.008721    0.003074    1.793438    159.497794 
[37m[36mINFO[0m[0m 02/19 01:23:53 | Cumulative gradient change saved at train_output/VLCS/CORAL/[3]/250218_21-45-14_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/19 01:23:55 | ---
[37m[36mINFO[0m[0m 02/19 01:23:55 | test-domain validation(oracle) = 78.156%
[37m[36mINFO[0m[0m 02/19 01:23:55 | training-domain validation(iid) = 78.156%
[37m[36mINFO[0m[0m 02/19 01:23:55 | last = 74.824%
[37m[36mINFO[0m[0m 02/19 01:23:55 | last (inD) = 85.006%
[37m[36mINFO[0m[0m 02/19 01:23:55 | training-domain validation (iid, inD) = 85.807%
[37m[36mINFO[0m[0m 02/19 01:23:55 | === Summary ===
[37m[36mINFO[0m[0m 02/19 01:23:55 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 3 --dataset VLCS --trial_seed 2 --hparams_seed 12
[37m[36mINFO[0m[0m 02/19 01:23:55 | Unique name: 250218_21-45-14_resnet50_GENIE
[37m[36mINFO[0m[0m 02/19 01:23:55 | Out path: train_output/VLCS/CORAL/[3]/250218_21-45-14_resnet50_GENIE
[37m[36mINFO[0m[0m 02/19 01:23:55 | Algorithm: CORAL
[37m[36mINFO[0m[0m 02/19 01:23:55 | Dataset: VLCS
