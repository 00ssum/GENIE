[37m[36mINFO[0m[0m 02/06 16:14:36 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 3 --dataset VLCS --trial_seed 0 --hparams_seed 0
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/VLCS/CORAL/[3]/250206_16-14-36_resnet50_GENIE
	out_root: train_output/VLCS/CORAL/[3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [3]
	trial_seed: 0
	unique_name: 250206_16-14-36_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	mmd_gamma: 1.0
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 02/06 16:14:36 | n_steps = 5001
[37m[36mINFO[0m[0m 02/06 16:14:36 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/06 16:14:36 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/06 16:14:36 | 
[37m[36mINFO[0m[0m 02/06 16:14:36 | Testenv name escaping te_V -> te_V
[37m[36mINFO[0m[0m 02/06 16:14:36 | Test envs = [3], name = te_V
[37m[36mINFO[0m[0m 02/06 16:14:36 | Train environments: [0, 1, 2], Test environments: [3]
[37m[36mINFO[0m[0m 02/06 16:14:36 | Batch sizes for each domain: [32, 32, 32, 0] (total=96)
[37m[36mINFO[0m[0m 02/06 16:14:36 | steps-per-epoch for each domain: 35.38, 66.41, 82.06 -> min = 35.38
[37m[36mINFO[0m[0m 02/06 16:14:37 | # of params = 23518277
[37m[36mINFO[0m[0m 02/06 16:17:07 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 02/06 16:17:07 | 0.445391    0.450370    0.484889    0.502099    1.213849    0.612191    0.632509    0.459765    0.489642    0.382711    0.384146    0.445391    0.450370    0           0.000000    1.809197    0.061167    1.902641    147.258697 
[37m[36mINFO[0m[0m 02/06 16:24:29 | 0.787486    0.797037    0.868410    0.851589    0.390565    0.999117    1.000000    0.771765    0.751412    0.834349    0.803354    0.787486    0.797037    200         5.653710    0.466900    0.030368    1.373606    167.706112 
[37m[36mINFO[0m[0m 02/06 16:31:40 | 0.782303    0.801481    0.884209    0.863157    0.383322    1.000000    1.000000    0.800000    0.781544    0.852628    0.807927    0.782303    0.801481    400         11.307420   0.336261    0.021203    1.325847    165.560632 
[37m[36mINFO[0m[0m 02/06 16:39:02 | 0.768234    0.771852    0.901253    0.858464    0.404612    1.000000    1.000000    0.832471    0.779661    0.871287    0.795732    0.768234    0.771852    600         16.961131   0.298122    0.018398    1.410760    160.508508 
[37m[36mINFO[0m[0m 02/06 16:46:28 | 0.774158    0.789630    0.918713    0.853173    0.425768    1.000000    1.000000    0.855529    0.768362    0.900609    0.791159    0.774158    0.789630    800         22.614841   0.238469    0.016972    1.353519    175.166859 
[37m[36mINFO[0m[0m 02/06 16:53:46 | 0.732321    0.751111    0.933633    0.841067    0.442810    0.999117    1.000000    0.893176    0.745763    0.908606    0.777439    0.732321    0.751111    1000        28.268551   0.209033    0.016549    1.380016    161.845606 
[37m[36mINFO[0m[0m 02/06 17:01:01 | 0.741577    0.758519    0.936379    0.846226    0.434255    0.999117    0.996466    0.880471    0.749529    0.929551    0.792683    0.741577    0.758519    1200        33.922261   0.176174    0.016347    1.353432    164.144963 
[37m[36mINFO[0m[0m 02/06 17:08:19 | 0.750833    0.768889    0.961275    0.856778    0.498198    1.000000    0.996466    0.928000    0.779661    0.955826    0.794207    0.750833    0.768889    1400        39.575972   0.147190    0.016133    1.360522    165.497158 
[37m[36mINFO[0m[0m 02/06 17:15:54 | 0.791559    0.788148    0.940954    0.841845    0.611917    1.000000    1.000000    0.897882    0.774011    0.924981    0.751524    0.791559    0.788148    1600        45.229682   0.114415    0.016586    1.473577    160.405578 
[37m[36mINFO[0m[0m 02/06 17:23:00 | 0.763791    0.758519    0.961063    0.838963    0.564192    0.999117    0.996466    0.923294    0.755179    0.960777    0.765244    0.763791    0.758519    1800        50.883392   0.117903    0.015968    1.336372    159.015261 
[37m[36mINFO[0m[0m 02/06 17:30:04 | 0.780081    0.797037    0.976010    0.850543    0.588443    1.000000    1.000000    0.950118    0.758945    0.977913    0.792683    0.780081    0.797037    2000        56.537102   0.083622    0.015365    1.353327    153.512693 
[37m[36mINFO[0m[0m 02/06 17:37:12 | 0.773417    0.755556    0.970112    0.849557    0.659236    1.000000    1.000000    0.957176    0.783427    0.953161    0.765244    0.773417    0.755556    2200        62.190813   0.058596    0.015466    1.361436    155.903399 
[37m[36mINFO[0m[0m 02/06 17:44:23 | 0.776379    0.794074    0.989552    0.856163    0.633562    1.000000    1.000000    0.985412    0.783427    0.983244    0.785061    0.776379    0.794074    2400        67.844523   0.060446    0.014168    1.351572    159.917951 
[37m[36mINFO[0m[0m 02/06 17:51:41 | 0.760459    0.783704    0.987848    0.852875    0.680936    1.000000    1.000000    0.974588    0.779661    0.988957    0.778963    0.760459    0.783704    2600        73.498233   0.043514    0.013957    1.400115    158.771425 
[37m[36mINFO[0m[0m 02/06 17:58:50 | 0.699741    0.709630    0.990157    0.833284    0.665785    1.000000    0.996466    0.984941    0.745763    0.985529    0.757622    0.699741    0.709630    2800        79.151943   0.041850    0.013151    1.350318    158.676229 
[37m[36mINFO[0m[0m 02/06 18:06:02 | 0.723436    0.743704    0.995265    0.856103    0.660751    1.000000    1.000000    0.993412    0.766478    0.992384    0.801829    0.723436    0.743704    3000        84.805654   0.034879    0.012715    1.361135    160.045966 
[37m[36mINFO[0m[0m 02/06 18:13:28 | 0.744539    0.760000    0.991262    0.844314    0.787642    1.000000    0.996466    0.986353    0.783427    0.987433    0.753049    0.744539    0.760000    3200        90.459364   0.026571    0.012141    1.407529    164.457710 
[37m[36mINFO[0m[0m 02/06 18:20:59 | 0.721955    0.748148    0.996087    0.852486    0.681570    1.000000    1.000000    0.994353    0.781544    0.993907    0.775915    0.721955    0.748148    3400        96.113074   0.024187    0.011148    1.450402    160.209493 
[37m[36mINFO[0m[0m 02/06 18:28:12 | 0.716772    0.736296    0.994585    0.847165    0.663800    1.000000    1.000000    0.988706    0.745763    0.995050    0.795732    0.716772    0.736296    3600        101.766784  0.025679    0.010664    1.354452    162.426708 
[37m[36mINFO[0m[0m 02/06 18:35:34 | 0.740466    0.745185    0.996064    0.846974    0.657133    1.000000    0.996466    0.992000    0.753296    0.996192    0.791159    0.740466    0.745185    3800        107.420495  0.021913    0.010482    1.383196    165.164730 
[37m[36mINFO[0m[0m 02/06 18:43:08 | 0.701222    0.691852    0.995833    0.848420    0.687583    1.000000    1.000000    0.994353    0.749529    0.993145    0.795732    0.701222    0.691852    4000        113.074205  0.020260    0.009877    1.430075    168.542256 
[37m[36mINFO[0m[0m 02/06 18:50:40 | 0.758978    0.758519    0.996998    0.852056    0.708727    1.000000    0.996466    0.996706    0.785311    0.994288    0.774390    0.758978    0.758519    4200        118.727915  0.023308    0.009940    1.410015    169.431445 
[37m[36mINFO[0m[0m 02/06 18:58:07 | 0.745280    0.757037    0.996281    0.861065    0.755897    1.000000    1.000000    0.993412    0.796610    0.995430    0.786585    0.745280    0.757037    4400        124.381625  0.013237    0.008965    1.425783    161.889472 
[37m[36mINFO[0m[0m 02/06 19:05:36 | 0.758608    0.765926    0.997566    0.855684    0.767163    1.000000    1.000000    0.997647    0.775895    0.995050    0.791159    0.758608    0.765926    4600        130.035336  0.010524    0.008844    1.423307    164.392413 
[37m[36mINFO[0m[0m 02/06 19:12:50 | 0.743428    0.737778    0.996841    0.848002    0.783291    1.000000    1.000000    0.996235    0.758945    0.994288    0.785061    0.743428    0.737778    4800        135.689046  0.008918    0.008466    1.356440    162.313681 
[37m[36mINFO[0m[0m 02/06 19:20:12 | 0.733062    0.728889    0.998768    0.853024    0.746115    1.000000    1.000000    0.998588    0.774011    0.997715    0.785061    0.733062    0.728889    5000        141.342756  0.009904    0.007920    1.382253    166.300297 
[37m[36mINFO[0m[0m 02/06 19:20:13 | Cumulative gradient change saved at train_output/VLCS/CORAL/[3]/250206_16-14-36_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/06 19:20:14 | ---
[37m[36mINFO[0m[0m 02/06 19:20:14 | test-domain validation(oracle) = 78.230%
[37m[36mINFO[0m[0m 02/06 19:20:14 | training-domain validation(iid) = 78.230%
[37m[36mINFO[0m[0m 02/06 19:20:14 | last = 73.306%
[37m[36mINFO[0m[0m 02/06 19:20:14 | last (inD) = 85.302%
[37m[36mINFO[0m[0m 02/06 19:20:14 | training-domain validation (iid, inD) = 86.316%
[37m[36mINFO[0m[0m 02/06 19:20:15 | === Summary ===
[37m[36mINFO[0m[0m 02/06 19:20:15 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 3 --dataset VLCS --trial_seed 0 --hparams_seed 0
[37m[36mINFO[0m[0m 02/06 19:20:15 | Unique name: 250206_16-14-36_resnet50_GENIE
[37m[36mINFO[0m[0m 02/06 19:20:15 | Out path: train_output/VLCS/CORAL/[3]/250206_16-14-36_resnet50_GENIE
[37m[36mINFO[0m[0m 02/06 19:20:15 | Algorithm: CORAL
[37m[36mINFO[0m[0m 02/06 19:20:15 | Dataset: VLCS
