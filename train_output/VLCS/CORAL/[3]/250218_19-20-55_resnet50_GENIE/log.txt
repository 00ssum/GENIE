[37m[36mINFO[0m[0m 02/18 19:20:55 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 3 --dataset VLCS --trial_seed 2 --hparams_seed 10
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 10
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/VLCS/CORAL/[3]/250218_19-20-55_resnet50_GENIE
	out_root: train_output/VLCS/CORAL/[3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [3]
	trial_seed: 2
	unique_name: 250218_19-20-55_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.5
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 7.494887873901297e-05
	batch_size: 23
	weight_decay: 0.000495139494108363
	mmd_gamma: 1.4713820315478223
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 02/18 19:20:55 | n_steps = 5001
[37m[36mINFO[0m[0m 02/18 19:20:55 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/18 19:20:55 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/18 19:20:55 | 
[37m[36mINFO[0m[0m 02/18 19:20:55 | Testenv name escaping te_V -> te_V
[37m[36mINFO[0m[0m 02/18 19:20:55 | Test envs = [3], name = te_V
[37m[36mINFO[0m[0m 02/18 19:20:55 | Train environments: [0, 1, 2], Test environments: [3]
[37m[36mINFO[0m[0m 02/18 19:20:55 | Batch sizes for each domain: [23, 23, 23, 0] (total=69)
[37m[36mINFO[0m[0m 02/18 19:20:55 | steps-per-epoch for each domain: 49.22, 92.39, 114.17 -> min = 49.22
[37m[36mINFO[0m[0m 02/18 19:20:56 | # of params = 23518277
[37m[36mINFO[0m[0m 02/18 19:23:35 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 02/18 19:23:35 | 0.440948    0.460741    0.493095    0.469952    1.222578    0.620141    0.593640    0.467294    0.459510    0.391851    0.356707    0.440948    0.460741    0           0.000000    1.791646    0.109096    1.169758    157.277740 
[37m[36mINFO[0m[0m 02/18 19:29:02 | 0.755276    0.749630    0.861550    0.858943    0.391212    1.000000    1.000000    0.759059    0.787194    0.825590    0.789634    0.755276    0.749630    200         4.063604    0.536436    0.032241    0.927966    141.261065 
[37m[36mINFO[0m[0m 02/18 19:34:32 | 0.756387    0.761481    0.867806    0.832937    0.416190    0.999117    1.000000    0.780235    0.745763    0.824067    0.753049    0.756387    0.761481    400         8.127208    0.370280    0.022948    0.946481    140.952363 
[37m[36mINFO[0m[0m 02/18 19:39:57 | 0.782673    0.788148    0.894933    0.860437    0.386529    1.000000    1.000000    0.808941    0.794727    0.875857    0.786585    0.782673    0.788148    600         12.190813   0.327944    0.019387    0.891022    146.622332 
[37m[36mINFO[0m[0m 02/18 19:45:30 | 0.764161    0.782222    0.898011    0.856419    0.384712    1.000000    0.996466    0.825412    0.774011    0.868621    0.798780    0.764161    0.782222    800         16.254417   0.317852    0.017091    0.908749    151.080211 
[37m[36mINFO[0m[0m 02/18 19:51:05 | 0.778971    0.776296    0.907418    0.836112    0.485999    0.999117    0.992933    0.844235    0.760829    0.878903    0.754573    0.778971    0.776296    1000        20.318021   0.266358    0.016927    0.921168    151.262023 
[37m[36mINFO[0m[0m 02/18 19:56:52 | 0.796001    0.791111    0.921726    0.844798    0.428430    0.999117    0.989399    0.853647    0.772128    0.912414    0.772866    0.796001    0.791111    1200        24.381625   0.256151    0.016299    0.984639    149.930860 
[37m[36mINFO[0m[0m 02/18 20:02:49 | 0.778971    0.779259    0.934852    0.853490    0.416066    1.000000    0.996466    0.883765    0.775895    0.920792    0.788110    0.778971    0.779259    1400        28.445230   0.248155    0.015181    0.934517    170.352446 
[37m[36mINFO[0m[0m 02/18 20:08:16 | 0.771936    0.742222    0.925249    0.851756    0.467058    1.000000    0.996466    0.872471    0.764595    0.903275    0.794207    0.771936    0.742222    1600        32.508834   0.205064    0.014700    0.891956    148.886140 
[37m[36mINFO[0m[0m 02/18 20:14:06 | 0.751573    0.736296    0.945069    0.849550    0.455937    1.000000    0.989399    0.900706    0.758945    0.934501    0.800305    0.751573    0.736296    1800        36.572438   0.181625    0.014364    0.977403    154.099140 
[37m[36mINFO[0m[0m 02/18 20:19:49 | 0.757867    0.764444    0.940770    0.840983    0.484682    0.998233    0.992933    0.908235    0.749529    0.915842    0.780488    0.757867    0.764444    2000        40.636042   0.154977    0.014897    0.922693    157.979545 
[37m[36mINFO[0m[0m 02/18 20:25:16 | 0.753795    0.762963    0.953091    0.846765    0.496495    1.000000    0.996466    0.919059    0.774011    0.940213    0.769817    0.753795    0.762963    2200        44.699647   0.159141    0.013753    0.881545    150.817097 
[37m[36mINFO[0m[0m 02/18 20:31:06 | 0.733802    0.734815    0.959683    0.845365    0.488971    1.000000    0.989399    0.912941    0.757062    0.966108    0.789634    0.733802    0.734815    2400        48.763251   0.135220    0.013422    0.977996    154.460389 
[37m[36mINFO[0m[0m 02/18 20:36:48 | 0.754165    0.758519    0.968595    0.848576    0.572680    1.000000    0.992933    0.947294    0.757062    0.958492    0.795732    0.754165    0.758519    2600        52.826855   0.111440    0.013944    0.959292    149.905766 
[37m[36mINFO[0m[0m 02/18 20:42:41 | 0.757867    0.760000    0.975444    0.839142    0.628082    1.000000    0.996466    0.957176    0.741996    0.969155    0.778963    0.757867    0.760000    2800        56.890459   0.094042    0.013432    0.978515    157.391495 
[37m[36mINFO[0m[0m 02/18 20:48:23 | 0.735283    0.725926    0.973673    0.844271    0.579198    1.000000    0.992933    0.947294    0.753296    0.973724    0.786585    0.735283    0.725926    3000        60.954064   0.085513    0.013108    0.944213    153.129875 
[37m[36mINFO[0m[0m 02/18 20:54:05 | 0.707886    0.728889    0.972942    0.842825    0.562610    0.998233    0.989399    0.951059    0.757062    0.969535    0.782012    0.707886    0.728889    3200        65.017668   0.072070    0.012794    0.946384    153.361785 
[37m[36mINFO[0m[0m 02/18 20:59:34 | 0.711959    0.724444    0.966735    0.832602    0.663474    1.000000    0.989399    0.936000    0.740113    0.964204    0.768293    0.711959    0.724444    3400        69.081272   0.071841    0.012435    0.892626    150.557785 
[37m[36mINFO[0m[0m 02/18 21:05:11 | 0.748982    0.731852    0.982934    0.843058    0.612670    1.000000    0.996466    0.965176    0.747646    0.983625    0.785061    0.748982    0.731852    3600        73.144876   0.067382    0.011899    0.969032    143.061334 
[37m[36mINFO[0m[0m 02/18 21:11:03 | 0.743799    0.757037    0.985331    0.851792    0.629684    1.000000    0.989399    0.968941    0.770245    0.987053    0.795732    0.743799    0.757037    3800        77.208481   0.058522    0.011671    0.971397    157.573879 
[37m[36mINFO[0m[0m 02/18 21:16:46 | 0.738245    0.748148    0.986288    0.844582    0.550288    1.000000    0.996466    0.976000    0.747646    0.982864    0.789634    0.738245    0.748148    4000        81.272085   0.063153    0.011535    0.934495    155.561291 
[37m[36mINFO[0m[0m 02/18 21:22:27 | 0.753795    0.767407    0.995168    0.848187    0.679940    1.000000    0.992933    0.993882    0.758945    0.991622    0.792683    0.753795    0.767407    4200        85.335689   0.037254    0.011579    0.914398    158.961969 
[37m[36mINFO[0m[0m 02/18 21:28:12 | 0.731951    0.748148    0.992808    0.843213    0.674155    1.000000    0.989399    0.988706    0.755179    0.989718    0.785061    0.731951    0.748148    4400        89.399293   0.041288    0.011192    0.945982    155.714059 
[37m[36mINFO[0m[0m 02/18 21:33:54 | 0.767123    0.773333    0.985108    0.837516    0.639652    1.000000    0.992933    0.977412    0.758945    0.977913    0.760671    0.767123    0.773333    4600        93.462898   0.052080    0.010610    0.913593    159.336991 
[37m[36mINFO[0m[0m 02/18 21:39:33 | 0.735653    0.752593    0.993816    0.846125    0.687250    1.000000    0.992933    0.990588    0.766478    0.990861    0.778963    0.735653    0.752593    4800        97.526502   0.035288    0.010449    0.917963    155.029839 
[37m[36mINFO[0m[0m 02/18 21:45:09 | 0.680489    0.687407    0.989208    0.842669    0.620709    1.000000    0.996466    0.984000    0.749529    0.983625    0.782012    0.680489    0.687407    5000        101.590106  0.041384    0.010112    0.909473    154.138562 
[37m[36mINFO[0m[0m 02/18 21:45:09 | Cumulative gradient change saved at train_output/VLCS/CORAL/[3]/250218_19-20-55_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/18 21:45:11 | ---
[37m[36mINFO[0m[0m 02/18 21:45:11 | test-domain validation(oracle) = 79.600%
[37m[36mINFO[0m[0m 02/18 21:45:11 | training-domain validation(iid) = 78.267%
[37m[36mINFO[0m[0m 02/18 21:45:11 | last = 68.049%
[37m[36mINFO[0m[0m 02/18 21:45:11 | last (inD) = 84.267%
[37m[36mINFO[0m[0m 02/18 21:45:11 | training-domain validation (iid, inD) = 86.044%
[37m[36mINFO[0m[0m 02/18 21:45:11 | === Summary ===
[37m[36mINFO[0m[0m 02/18 21:45:11 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 3 --dataset VLCS --trial_seed 2 --hparams_seed 10
[37m[36mINFO[0m[0m 02/18 21:45:11 | Unique name: 250218_19-20-55_resnet50_GENIE
[37m[36mINFO[0m[0m 02/18 21:45:11 | Out path: train_output/VLCS/CORAL/[3]/250218_19-20-55_resnet50_GENIE
[37m[36mINFO[0m[0m 02/18 21:45:11 | Algorithm: CORAL
[37m[36mINFO[0m[0m 02/18 21:45:11 | Dataset: VLCS
