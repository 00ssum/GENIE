[37m[36mINFO[0m[0m 02/19 01:24:00 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 3 --dataset VLCS --trial_seed 2 --hparams_seed 14
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 14
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/VLCS/CORAL/[3]/250219_01-24-00_resnet50_GENIE
	out_root: train_output/VLCS/CORAL/[3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [3]
	trial_seed: 2
	unique_name: 250219_01-24-00_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.5
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 4.223376545632674e-05
	batch_size: 27
	weight_decay: 1.4009530778122364e-05
	mmd_gamma: 5.905916742185723
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 02/19 01:24:00 | n_steps = 5001
[37m[36mINFO[0m[0m 02/19 01:24:00 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/19 01:24:00 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/19 01:24:00 | 
[37m[36mINFO[0m[0m 02/19 01:24:00 | Testenv name escaping te_V -> te_V
[37m[36mINFO[0m[0m 02/19 01:24:00 | Test envs = [3], name = te_V
[37m[36mINFO[0m[0m 02/19 01:24:00 | Train environments: [0, 1, 2], Test environments: [3]
[37m[36mINFO[0m[0m 02/19 01:24:00 | Batch sizes for each domain: [27, 27, 27, 0] (total=81)
[37m[36mINFO[0m[0m 02/19 01:24:00 | steps-per-epoch for each domain: 41.93, 78.70, 97.26 -> min = 41.93
[37m[36mINFO[0m[0m 02/19 01:24:01 | # of params = 23518277
[37m[36mINFO[0m[0m 02/19 01:26:44 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 02/19 01:26:44 | 0.442429    0.463704    0.493222    0.470969    1.319548    0.620141    0.593640    0.467294    0.459510    0.392232    0.359756    0.442429    0.463704    0           0.000000    1.811494    0.109912    1.534099    161.173472 
[37m[36mINFO[0m[0m 02/19 01:32:49 | 0.689004    0.691852    0.841137    0.827048    0.476581    0.986749    0.982332    0.743059    0.745763    0.793602    0.753049    0.689004    0.691852    200         4.770318    0.669189    0.011684    1.107160    144.006538 
[37m[36mINFO[0m[0m 02/19 01:39:08 | 0.717142    0.705185    0.862340    0.843363    0.420833    0.999117    0.989399    0.774118    0.781544    0.813785    0.759146    0.717142    0.705185    400         9.540636    0.418022    0.009318    1.105163    157.605292 
[37m[36mINFO[0m[0m 02/19 01:45:18 | 0.737505    0.722963    0.874050    0.843841    0.405025    1.000000    0.989399    0.768000    0.757062    0.854151    0.785061    0.737505    0.722963    600         14.310954   0.377595    0.007852    1.046039    160.706399 
[37m[36mINFO[0m[0m 02/19 01:51:37 | 0.730840    0.724444    0.892123    0.853167    0.404934    0.997350    0.989399    0.806588    0.775895    0.872430    0.794207    0.730840    0.724444    800         19.081272   0.330111    0.007275    1.090678    161.792265 
[37m[36mINFO[0m[0m 02/19 01:57:37 | 0.751944    0.734815    0.908085    0.853520    0.403682    1.000000    0.996466    0.838118    0.768362    0.886139    0.795732    0.751944    0.734815    1000        23.851590   0.289612    0.006793    1.040515    151.004361 
[37m[36mINFO[0m[0m 02/19 02:03:37 | 0.767864    0.760000    0.916555    0.854357    0.412625    1.000000    0.996466    0.855529    0.781544    0.894136    0.785061    0.767864    0.760000    1200        28.621908   0.278941    0.006367    1.052025    149.862908 
[37m[36mINFO[0m[0m 02/19 02:09:46 | 0.741577    0.734815    0.925607    0.847356    0.417071    1.000000    0.985866    0.870118    0.758945    0.906702    0.797256    0.741577    0.734815    1400        33.392226   0.256464    0.005899    1.063733    156.724484 
[37m[36mINFO[0m[0m 02/19 02:15:53 | 0.753425    0.762963    0.921296    0.842705    0.483918    0.998233    0.989399    0.847529    0.755179    0.918126    0.783537    0.753425    0.762963    1600        38.162544   0.207109    0.006000    1.110323    144.832646 
[37m[36mINFO[0m[0m 02/19 02:22:31 | 0.765272    0.765926    0.956182    0.855391    0.442670    1.000000    0.992933    0.915765    0.768362    0.952780    0.804878    0.765272    0.765926    1800        42.932862   0.191516    0.005819    1.147016    167.879411 
[37m[36mINFO[0m[0m 02/19 02:28:41 | 0.756757    0.762963    0.939220    0.845796    0.491352    1.000000    0.992933    0.878588    0.753296    0.939071    0.791159    0.756757    0.762963    2000        47.703180   0.162287    0.005641    1.057335    159.088002 
[37m[36mINFO[0m[0m 02/19 02:34:58 | 0.711218    0.720000    0.955832    0.842615    0.469908    1.000000    0.989399    0.924235    0.745763    0.943260    0.792683    0.711218    0.720000    2200        52.473498   0.161853    0.005374    1.128671    150.748787 
[37m[36mINFO[0m[0m 02/19 02:40:57 | 0.737875    0.752593    0.966354    0.841181    0.537001    1.000000    0.989399    0.936000    0.755179    0.963062    0.778963    0.737875    0.752593    2400        57.243816   0.122808    0.005621    1.067525    145.801535 
[37m[36mINFO[0m[0m 02/19 02:46:58 | 0.748241    0.739259    0.974562    0.844271    0.551601    1.000000    0.992933    0.955294    0.753296    0.968393    0.786585    0.748241    0.739259    2600        62.014134   0.110074    0.005316    1.036721    153.840061 
[37m[36mINFO[0m[0m 02/19 02:52:56 | 0.744539    0.762963    0.979357    0.842436    0.617313    1.000000    0.989399    0.962824    0.758945    0.975248    0.778963    0.744539    0.762963    2800        66.784452   0.082719    0.005198    1.071088    144.041897 
[37m[36mINFO[0m[0m 02/19 02:58:59 | 0.702332    0.699259    0.968744    0.844366    0.690636    1.000000    0.985866    0.941647    0.743879    0.964585    0.803354    0.702332    0.699259    3000        71.554770   0.097515    0.005050    1.065837    149.357714 
[37m[36mINFO[0m[0m 02/19 03:05:20 | 0.750833    0.758519    0.981530    0.837097    0.558698    1.000000    0.992933    0.967059    0.736347    0.977532    0.782012    0.750833    0.758519    3200        76.325088   0.093530    0.004823    1.085032    163.793624 
[37m[36mINFO[0m[0m 02/19 03:11:20 | 0.725657    0.734815    0.981500    0.836667    0.583304    1.000000    0.989399    0.966588    0.740113    0.977913    0.780488    0.725657    0.734815    3400        81.095406   0.067213    0.005001    1.085194    142.988143 
[37m[36mINFO[0m[0m 02/19 03:17:49 | 0.750093    0.758519    0.990635    0.854601    0.603047    1.000000    0.989399    0.984471    0.766478    0.987433    0.807927    0.750093    0.758519    3600        85.865724   0.056303    0.004893    1.117671    165.465601 
[37m[36mINFO[0m[0m 02/19 03:24:03 | 0.751203    0.742222    0.987833    0.850488    0.649097    1.000000    0.992933    0.970353    0.755179    0.993145    0.803354    0.751203    0.742222    3800        90.636042   0.055580    0.004518    1.098247    154.679587 
[37m[36mINFO[0m[0m 02/19 03:29:59 | 0.770826    0.780741    0.989186    0.846812    0.690391    1.000000    0.992933    0.981647    0.753296    0.985910    0.794207    0.770826    0.780741    4000        95.406360   0.048030    0.004464    1.089331    138.379853 
[37m[36mINFO[0m[0m 02/19 03:36:14 | 0.738986    0.739259    0.991837    0.839075    0.682793    1.000000    0.985866    0.985412    0.732580    0.990099    0.798780    0.738986    0.739259    4200        100.176678  0.044602    0.004294    1.082645    158.519258 
[37m[36mINFO[0m[0m 02/19 03:42:41 | 0.731211    0.728889    0.976010    0.832105    0.589232    1.000000    0.992933    0.950118    0.713748    0.977913    0.789634    0.731211    0.728889    4400        104.946996  0.043445    0.004198    1.092642    168.460316 
[37m[36mINFO[0m[0m 02/19 03:48:40 | 0.738615    0.762963    0.994705    0.837013    0.649102    1.000000    0.985866    0.990588    0.740113    0.993526    0.785061    0.738615    0.762963    4600        109.717314  0.045613    0.004144    1.086128    141.862897 
[37m[36mINFO[0m[0m 02/19 03:54:54 | 0.742688    0.746667    0.996661    0.851834    0.641624    1.000000    0.992933    0.993412    0.768362    0.996573    0.794207    0.742688    0.746667    4800        114.487633  0.024547    0.003985    1.087511    155.530708 
[37m[36mINFO[0m[0m 02/19 04:00:58 | 0.733432    0.743704    0.995646    0.851851    0.574698    1.000000    0.989399    0.993412    0.755179    0.993526    0.810976    0.733432    0.743704    5000        119.257951  0.023777    0.003935    1.084959    147.106074 
[37m[36mINFO[0m[0m 02/19 04:00:58 | Cumulative gradient change saved at train_output/VLCS/CORAL/[3]/250219_01-24-00_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/19 04:00:59 | ---
[37m[36mINFO[0m[0m 02/19 04:00:59 | test-domain validation(oracle) = 77.083%
[37m[36mINFO[0m[0m 02/19 04:00:59 | training-domain validation(iid) = 76.527%
[37m[36mINFO[0m[0m 02/19 04:00:59 | last = 73.343%
[37m[36mINFO[0m[0m 02/19 04:00:59 | last (inD) = 85.185%
[37m[36mINFO[0m[0m 02/19 04:00:59 | training-domain validation (iid, inD) = 85.539%
[37m[36mINFO[0m[0m 02/19 04:01:00 | === Summary ===
[37m[36mINFO[0m[0m 02/19 04:01:00 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 3 --dataset VLCS --trial_seed 2 --hparams_seed 14
[37m[36mINFO[0m[0m 02/19 04:01:00 | Unique name: 250219_01-24-00_resnet50_GENIE
[37m[36mINFO[0m[0m 02/19 04:01:00 | Out path: train_output/VLCS/CORAL/[3]/250219_01-24-00_resnet50_GENIE
[37m[36mINFO[0m[0m 02/19 04:01:00 | Algorithm: CORAL
[37m[36mINFO[0m[0m 02/19 04:01:00 | Dataset: VLCS
