[37m[36mINFO[0m[0m 02/18 12:45:14 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 3 --dataset VLCS --trial_seed 2 --hparams_seed 7
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 7
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/VLCS/CORAL/[3]/250218_12-45-14_resnet50_GENIE
	out_root: train_output/VLCS/CORAL/[3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [3]
	trial_seed: 2
	unique_name: 250218_12-45-14_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 0.00023761560100715143
	batch_size: 20
	weight_decay: 4.1733891298839565e-05
	mmd_gamma: 6.082179025695601
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 02/18 12:45:14 | n_steps = 5001
[37m[36mINFO[0m[0m 02/18 12:45:14 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/18 12:45:14 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/18 12:45:14 | 
[37m[36mINFO[0m[0m 02/18 12:45:14 | Testenv name escaping te_V -> te_V
[37m[36mINFO[0m[0m 02/18 12:45:14 | Test envs = [3], name = te_V
[37m[36mINFO[0m[0m 02/18 12:45:14 | Train environments: [0, 1, 2], Test environments: [3]
[37m[36mINFO[0m[0m 02/18 12:45:14 | Batch sizes for each domain: [20, 20, 20, 0] (total=60)
[37m[36mINFO[0m[0m 02/18 12:45:14 | steps-per-epoch for each domain: 56.60, 106.25, 131.30 -> min = 56.60
[37m[36mINFO[0m[0m 02/18 12:45:15 | # of params = 23518277
[37m[36mINFO[0m[0m 02/18 12:48:02 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 02/18 12:48:02 | 0.442429    0.462222    0.493349    0.473509    1.252592    0.620141    0.593640    0.467294    0.459510    0.392612    0.367378    0.442429    0.462222    0           0.000000    1.761064    0.062163    1.427902    165.030205 
[37m[36mINFO[0m[0m 02/18 12:53:15 | 0.703813    0.708148    0.825477    0.805521    0.505015    0.994700    0.989399    0.734588    0.713748    0.747144    0.713415    0.703813    0.708148    200         3.533569    0.592622    0.010308    0.776966    158.330085 
[37m[36mINFO[0m[0m 02/18 12:58:39 | 0.774898    0.768889    0.863203    0.846304    0.407871    0.999117    0.992933    0.747765    0.753296    0.842727    0.792683    0.774898    0.768889    400         7.067138    0.386676    0.007997    0.874472    148.543621 
[37m[36mINFO[0m[0m 02/18 13:04:08 | 0.760829    0.760000    0.885337    0.846364    0.401775    1.000000    0.992933    0.803765    0.770245    0.852247    0.775915    0.760829    0.760000    600         10.600707   0.345665    0.006464    0.829621    162.759470 
[37m[36mINFO[0m[0m 02/18 13:09:22 | 0.775639    0.745185    0.889518    0.835262    0.423473    1.000000    0.989399    0.797647    0.741996    0.870906    0.774390    0.775639    0.745185    800         14.134276   0.310324    0.005894    0.777433    159.216524 
[37m[36mINFO[0m[0m 02/18 13:14:43 | 0.768974    0.770370    0.895869    0.842675    0.429553    1.000000    0.989399    0.829647    0.762712    0.857959    0.775915    0.768974    0.770370    1000        17.667845   0.281762    0.005786    0.849403    150.922444 
[37m[36mINFO[0m[0m 02/18 13:20:11 | 0.761940    0.761481    0.902011    0.844523    0.444016    0.999117    0.996466    0.831059    0.762712    0.875857    0.774390    0.761940    0.761481    1200        21.201413   0.259053    0.005311    0.836666    160.872914 
[37m[36mINFO[0m[0m 02/18 13:25:43 | 0.749352    0.758519    0.930923    0.853316    0.419772    1.000000    0.989399    0.873882    0.770245    0.918888    0.800305    0.749352    0.758519    1400        24.734982   0.232033    0.005180    0.856302    160.047638 
[37m[36mINFO[0m[0m 02/18 13:31:37 | 0.744169    0.749630    0.882838    0.810410    0.529557    0.997350    0.985866    0.778353    0.689266    0.872810    0.756098    0.744169    0.749630    1600        28.268551   0.204249    0.005095    0.961406    161.784492 
[37m[36mINFO[0m[0m 02/18 13:37:03 | 0.726027    0.708148    0.940552    0.846113    0.463677    1.000000    0.989399    0.903529    0.760829    0.918126    0.788110    0.726027    0.708148    1800        31.802120   0.196432    0.004774    0.804034    165.349346 
[37m[36mINFO[0m[0m 02/18 13:42:36 | 0.763051    0.754074    0.952381    0.854775    0.504194    1.000000    0.996466    0.913882    0.772128    0.943260    0.795732    0.763051    0.754074    2000        35.335689   0.146150    0.005007    0.853306    162.055939 
[37m[36mINFO[0m[0m 02/18 13:48:08 | 0.747871    0.731852    0.953199    0.839070    0.497908    0.999117    0.992933    0.913412    0.751412    0.947068    0.772866    0.747871    0.731852    2200        38.869258   0.173211    0.004504    0.848556    162.389864 
[37m[36mINFO[0m[0m 02/18 13:53:40 | 0.713439    0.712593    0.936413    0.832296    0.518598    1.000000    0.996466    0.882353    0.706215    0.926885    0.794207    0.713439    0.712593    2400        42.402827   0.142120    0.004594    0.862697    159.706204 
[37m[36mINFO[0m[0m 02/18 13:59:04 | 0.736764    0.748148    0.957652    0.839255    0.527250    1.000000    0.985866    0.912941    0.751412    0.960015    0.780488    0.736764    0.748148    2600        45.936396   0.138558    0.004451    0.822921    159.731885 
[37m[36mINFO[0m[0m 02/18 14:04:43 | 0.720104    0.737778    0.959712    0.840039    0.576063    0.999117    0.996466    0.928000    0.740113    0.952018    0.783537    0.720104    0.737778    2800        49.469965   0.104177    0.004392    0.898073    158.669521 
[37m[36mINFO[0m[0m 02/18 14:10:24 | 0.744169    0.745185    0.980022    0.852103    0.483212    1.000000    0.992933    0.963294    0.764595    0.976771    0.798780    0.744169    0.745185    3000        53.003534   0.103365    0.004176    0.854340    170.643434 
[37m[36mINFO[0m[0m 02/18 14:15:50 | 0.767494    0.768889    0.976213    0.842257    0.589990    1.000000    0.989399    0.955294    0.772128    0.973343    0.765244    0.767494    0.768889    3200        56.537102   0.076179    0.004250    0.791234    168.013163 
[37m[36mINFO[0m[0m 02/18 14:21:09 | 0.753425    0.765926    0.972759    0.840595    0.617752    0.997350    0.992933    0.946824    0.751412    0.974105    0.777439    0.753425    0.765926    3400        60.070671   0.079077    0.004015    0.840429    150.974204 
[37m[36mINFO[0m[0m 02/18 14:26:50 | 0.758978    0.768889    0.975687    0.842419    0.682379    0.999117    0.992933    0.957647    0.772128    0.970297    0.762195    0.758978    0.768889    3600        63.604240   0.099634    0.003992    0.853557    169.728365 
[37m[36mINFO[0m[0m 02/18 14:32:15 | 0.760459    0.762963    0.984668    0.847261    0.585593    1.000000    0.992933    0.976471    0.768362    0.977532    0.780488    0.760459    0.762963    3800        67.137809   0.070749    0.003918    0.884819    148.414842 
[37m[36mINFO[0m[0m 02/18 14:37:58 | 0.718623    0.717037    0.989283    0.851368    0.601586    1.000000    0.996466    0.981176    0.766478    0.986672    0.791159    0.718623    0.717037    4000        70.671378   0.046528    0.003717    0.910497    160.300857 
[37m[36mINFO[0m[0m 02/18 14:43:26 | 0.752684    0.760000    0.985496    0.834605    0.647153    1.000000    0.989399    0.975529    0.747646    0.980960    0.766768    0.752684    0.760000    4200        74.204947   0.047089    0.003761    0.822493    163.754145 
[37m[36mINFO[0m[0m 02/18 14:48:54 | 0.739726    0.751111    0.989761    0.842161    0.626916    1.000000    0.996466    0.980706    0.749529    0.988576    0.780488    0.739726    0.751111    4400        77.738516   0.052241    0.003828    0.866570    154.713846 
[37m[36mINFO[0m[0m 02/18 14:54:06 | 0.744169    0.745185    0.985743    0.840756    0.646987    1.000000    0.996466    0.977412    0.751412    0.979817    0.774390    0.744169    0.745185    4600        81.272085   0.039873    0.003375    0.789500    154.315327 
[37m[36mINFO[0m[0m 02/18 14:59:17 | 0.721585    0.740741    0.992113    0.838831    0.667502    1.000000    0.992933    0.987765    0.747646    0.988576    0.775915    0.721585    0.740741    4800        84.805654   0.035343    0.003426    0.816550    147.589174 
[37m[36mINFO[0m[0m 02/18 15:04:29 | 0.712329    0.736296    0.988245    0.838879    0.736668    1.000000    0.989399    0.978824    0.758945    0.985910    0.768293    0.712329    0.736296    5000        88.339223   0.026915    0.003150    0.827211    146.286345 
[37m[36mINFO[0m[0m 02/18 15:04:29 | Cumulative gradient change saved at train_output/VLCS/CORAL/[3]/250218_12-45-14_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/18 15:04:31 | ---
[37m[36mINFO[0m[0m 02/18 15:04:31 | test-domain validation(oracle) = 76.897%
[37m[36mINFO[0m[0m 02/18 15:04:31 | training-domain validation(iid) = 76.305%
[37m[36mINFO[0m[0m 02/18 15:04:31 | last = 71.233%
[37m[36mINFO[0m[0m 02/18 15:04:31 | last (inD) = 83.888%
[37m[36mINFO[0m[0m 02/18 15:04:31 | training-domain validation (iid, inD) = 85.478%
[37m[36mINFO[0m[0m 02/18 15:04:31 | === Summary ===
[37m[36mINFO[0m[0m 02/18 15:04:31 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 3 --dataset VLCS --trial_seed 2 --hparams_seed 7
[37m[36mINFO[0m[0m 02/18 15:04:31 | Unique name: 250218_12-45-14_resnet50_GENIE
[37m[36mINFO[0m[0m 02/18 15:04:31 | Out path: train_output/VLCS/CORAL/[3]/250218_12-45-14_resnet50_GENIE
[37m[36mINFO[0m[0m 02/18 15:04:31 | Algorithm: CORAL
[37m[36mINFO[0m[0m 02/18 15:04:31 | Dataset: VLCS
