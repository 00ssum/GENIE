[37m[36mINFO[0m[0m 01/28 21:54:15 | Command :: /jsm0707/DomainBed/Large-scale/train_all.py resnet50_EVE config/resnet50_EVE.yaml --algorithm CORAL --test_envs 3 --dataset VLCS --trial_seed 0 --hparams_seed 9
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 9.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_EVE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 9
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_EVE
	out_dir: train_output/VLCS/CORAL/[3]/250128_21-54-15_resnet50_EVE
	out_root: train_output/VLCS/CORAL/[3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [3]
	trial_seed: 0
	unique_name: 250128_21-54-15_resnet50_EVE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: EVE
	freeze_bn: False
	pretrained: True
	lr: 5.5014200978340895e-05
	batch_size: 15
	weight_decay: 3.288190104805334e-05
	mmd_gamma: 0.11332382437966244
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 01/28 21:54:15 | n_steps = 5001
[37m[36mINFO[0m[0m 01/28 21:54:15 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 01/28 21:54:15 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 01/28 21:54:15 | Target test envs = [[3]]
[37m[36mINFO[0m[0m 01/28 21:54:15 | 
[37m[36mINFO[0m[0m 01/28 21:54:15 | Testenv name escaping te_V -> te_V
[37m[36mINFO[0m[0m 01/28 21:54:15 | Test envs = [3], name = te_V
[37m[36mINFO[0m[0m 01/28 21:54:15 | Batch sizes for each domain: [15, 15, 15, 0] (total=45)
[37m[36mINFO[0m[0m 01/28 21:54:15 | steps-per-epoch for each domain: 75.47, 141.67, 175.07 -> min = 75.47
[37m[36mINFO[0m[0m 01/28 21:54:17 | # of params = 23518277
[37m[36mINFO[0m[0m 01/28 21:56:41 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 01/28 21:56:41 | 0.475009    0.472593    0.502234    0.506338    1.250189    0.633392    0.639576    0.485647    0.495292    0.387662    0.384146    0.475009    0.472593    0           0.000000    1.840033    0.074077    1.712467    142.129631 
[37m[36mINFO[0m[0m 01/28 22:01:09 | 0.783784    0.804444    0.855374    0.843476    0.400774    0.998233    0.996466    0.743059    0.738230    0.824829    0.795732    0.783784    0.804444    200         2.650177    0.518911    0.093407    0.620283    144.162414 
[37m[36mINFO[0m[0m 01/28 22:05:37 | 0.807479    0.804444    0.868685    0.848450    0.386562    0.999117    1.000000    0.758118    0.741996    0.848819    0.803354    0.807479    0.804444    400         5.300353    0.375106    0.074228    0.650900    138.011365 
[37m[36mINFO[0m[0m 01/28 22:10:00 | 0.784894    0.779259    0.874880    0.856103    0.403926    0.999117    1.000000    0.797647    0.798493    0.827875    0.769817    0.784894    0.779259    600         7.950530    0.324591    0.067880    0.627276    136.844747 
[37m[36mINFO[0m[0m 01/28 22:14:29 | 0.798593    0.804444    0.898943    0.861572    0.376453    1.000000    1.000000    0.814118    0.764595    0.882711    0.820122    0.798593    0.804444    800         10.600707   0.319985    0.057895    0.631159    142.034187 
[37m[36mINFO[0m[0m 01/28 22:18:56 | 0.780822    0.782222    0.899372    0.853532    0.382366    0.999117    1.000000    0.807529    0.774011    0.891470    0.786585    0.780822    0.782222    1000        13.250883   0.297430    0.057678    0.588330    149.017651 
[37m[36mINFO[0m[0m 01/28 22:23:25 | 0.791188    0.805926    0.911080    0.855804    0.397919    1.000000    1.000000    0.843294    0.777778    0.889947    0.789634    0.791188    0.805926    1200        15.901060   0.276685    0.054782    0.579387    152.386528 
[37m[36mINFO[0m[0m 01/28 22:27:47 | 0.788227    0.789630    0.884634    0.821076    0.473306    0.999117    0.992933    0.819294    0.740113    0.835491    0.730183    0.788227    0.789630    1400        18.551237   0.251498    0.054339    0.554977    151.214524 
[37m[36mINFO[0m[0m 01/28 22:32:19 | 0.756387    0.779259    0.918421    0.850202    0.444068    1.000000    0.996466    0.848941    0.772128    0.906321    0.782012    0.756387    0.779259    1600        21.201413   0.233827    0.052400    0.625767    146.650100 
[37m[36mINFO[0m[0m 01/28 22:36:47 | 0.788967    0.805926    0.913964    0.852188    0.446992    1.000000    1.000000    0.852706    0.792844    0.889185    0.763720    0.788967    0.805926    1800        23.851590   0.242384    0.050805    0.648833    138.853647 
[37m[36mINFO[0m[0m 01/28 22:41:29 | 0.764902    0.780741    0.934105    0.846597    0.444399    1.000000    1.000000    0.880000    0.760829    0.922315    0.778963    0.764902    0.780741    2000        26.501767   0.202305    0.052171    0.642781    153.287857 
[37m[36mINFO[0m[0m 01/28 22:46:03 | 0.762680    0.767407    0.880050    0.829321    0.570455    0.997350    1.000000    0.818353    0.760829    0.824448    0.727134    0.762680    0.767407    2200        29.151943   0.195565    0.050746    0.614777    150.600595 
[37m[36mINFO[0m[0m 01/28 22:50:19 | 0.752314    0.739259    0.919784    0.823211    0.569693    0.998233    0.996466    0.877647    0.755179    0.883473    0.717988    0.752314    0.739259    2400        31.802120   0.170759    0.050071    0.586688    138.855300 
[37m[36mINFO[0m[0m 01/28 22:54:44 | 0.737875    0.742222    0.950236    0.852367    0.451978    1.000000    1.000000    0.902118    0.779661    0.948591    0.777439    0.737875    0.742222    2600        34.452297   0.172362    0.047605    0.635988    137.950039 
[37m[36mINFO[0m[0m 01/28 22:59:19 | 0.753054    0.749630    0.959296    0.838586    0.516521    1.000000    1.000000    0.922824    0.730697    0.955065    0.785061    0.753054    0.749630    2800        37.102473   0.143058    0.050681    0.660155    142.622633 
[37m[36mINFO[0m[0m 01/28 23:03:53 | 0.758608    0.757037    0.943185    0.840188    0.518266    0.998233    0.996466    0.874353    0.734463    0.956969    0.789634    0.758608    0.757037    3000        39.752650   0.138405    0.051015    0.650893    144.082092 
[37m[36mINFO[0m[0m 01/28 23:08:32 | 0.746020    0.752593    0.951813    0.838467    0.523659    1.000000    1.000000    0.912941    0.760829    0.942498    0.754573    0.746020    0.752593    3200        42.402827   0.108882    0.056461    0.625836    154.438505 
[37m[36mINFO[0m[0m 01/28 23:12:50 | 0.766013    0.774815    0.965524    0.842054    0.547058    1.000000    1.000000    0.928941    0.753296    0.967631    0.772866    0.766013    0.774815    3400        45.053004   0.112229    0.053028    0.587098    140.410102 
[37m[36mINFO[0m[0m 01/28 23:16:59 | 0.691225    0.691852    0.959333    0.828052    0.637883    0.999117    0.996466    0.944000    0.719397    0.934882    0.768293    0.691225    0.691852    3600        47.703180   0.102394    0.051569    0.557685    136.841564 
[37m[36mINFO[0m[0m 01/28 23:21:13 | 0.747871    0.764444    0.959182    0.846537    0.640348    1.000000    1.000000    0.903059    0.743879    0.974486    0.795732    0.747871    0.764444    3800        50.353357   0.089372    0.049131    0.590175    136.370090 
[37m[36mINFO[0m[0m 01/28 23:25:15 | 0.749352    0.762963    0.978424    0.842562    0.603823    1.000000    1.000000    0.966118    0.753296    0.969155    0.774390    0.749352    0.762963    4000        53.003534   0.077241    0.055326    0.547957    132.644443 
[37m[36mINFO[0m[0m 01/28 23:29:27 | 0.715661    0.714074    0.975116    0.832088    0.514035    1.000000    0.996466    0.960000    0.726930    0.965347    0.772866    0.715661    0.714074    4200        55.653710   0.072705    0.051984    0.573963    136.828817 
[37m[36mINFO[0m[0m 01/28 23:33:41 | 0.723436    0.731852    0.979783    0.846555    0.701732    1.000000    0.996466    0.967529    0.762712    0.971820    0.780488    0.723436    0.731852    4400        58.303887   0.060810    0.052504    0.591715    135.610888 
[37m[36mINFO[0m[0m 01/28 23:37:53 | 0.731951    0.754074    0.982023    0.834748    0.739315    1.000000    0.996466    0.962824    0.728814    0.983244    0.778963    0.731951    0.754074    4600        60.954064   0.067888    0.048581    0.563311    139.047459 
[37m[36mINFO[0m[0m 01/28 23:42:11 | 0.760089    0.757037    0.980750    0.852665    0.726281    0.999117    1.000000    0.961412    0.768362    0.981721    0.789634    0.760089    0.757037    4800        63.604240   0.063883    0.047970    0.589238    140.612414 
[37m[36mINFO[0m[0m 01/28 23:46:42 | 0.752314    0.755556    0.982844    0.849018    0.752666    1.000000    1.000000    0.963765    0.758945    0.984768    0.788110    0.752314    0.755556    5000        66.254417   0.049635    0.049189    0.635982    143.217655 
[37m[36mINFO[0m[0m 01/28 23:46:42 | Cumulative gradient change saved at train_output/VLCS/CORAL/[3]/250128_21-54-15_resnet50_EVE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 01/28 23:46:43 | ---
[37m[36mINFO[0m[0m 01/28 23:46:43 | test-domain validation(oracle) = 79.119%
[37m[36mINFO[0m[0m 01/28 23:46:43 | training-domain validation(iid) = 79.859%
[37m[36mINFO[0m[0m 01/28 23:46:43 | last = 75.231%
[37m[36mINFO[0m[0m 01/28 23:46:43 | last (inD) = 84.902%
[37m[36mINFO[0m[0m 01/28 23:46:43 | training-domain validation (iid, inD) = 86.157%
[37m[36mINFO[0m[0m 01/28 23:46:43 | === Summary ===
[37m[36mINFO[0m[0m 01/28 23:46:43 | Command: /jsm0707/DomainBed/Large-scale/train_all.py resnet50_EVE config/resnet50_EVE.yaml --algorithm CORAL --test_envs 3 --dataset VLCS --trial_seed 0 --hparams_seed 9
[37m[36mINFO[0m[0m 01/28 23:46:43 | Unique name: 250128_21-54-15_resnet50_EVE
[37m[36mINFO[0m[0m 01/28 23:46:43 | Out path: train_output/VLCS/CORAL/[3]/250128_21-54-15_resnet50_EVE
[37m[36mINFO[0m[0m 01/28 23:46:43 | Algorithm: CORAL
[37m[36mINFO[0m[0m 01/28 23:46:43 | Dataset: VLCS
[37m[36mINFO[0m[0m 01/28 23:46:43 | Max test_in: 0.8075
