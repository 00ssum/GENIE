[37m[36mINFO[0m[0m 01/28 07:50:53 | Command :: /jsm0707/DomainBed/Large-scale/train_all.py resnet50_EVE config/resnet50_EVE.yaml --algorithm CORAL --test_envs 2 --dataset VLCS --trial_seed 2 --hparams_seed 18
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 9.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_EVE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 18
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_EVE
	out_dir: train_output/VLCS/CORAL/[2]/250128_07-50-53_resnet50_EVE
	out_root: train_output/VLCS/CORAL/[2]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [2]
	trial_seed: 2
	unique_name: 250128_07-50-53_resnet50_EVE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.5
	class_balanced: False
	optimizer: EVE
	freeze_bn: False
	pretrained: True
	lr: 0.00011902331527815511
	batch_size: 15
	weight_decay: 1.4821095235078581e-05
	mmd_gamma: 0.1155889708129413
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 01/28 07:50:53 | n_steps = 5001
[37m[36mINFO[0m[0m 01/28 07:50:53 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 01/28 07:50:53 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 01/28 07:50:53 | Target test envs = [[2]]
[37m[36mINFO[0m[0m 01/28 07:50:53 | 
[37m[36mINFO[0m[0m 01/28 07:50:54 | Testenv name escaping te_S -> te_S
[37m[36mINFO[0m[0m 01/28 07:50:54 | Test envs = [2], name = te_S
[37m[36mINFO[0m[0m 01/28 07:50:54 | Batch sizes for each domain: [15, 15, 0, 15] (total=45)
[37m[36mINFO[0m[0m 01/28 07:50:54 | steps-per-epoch for each domain: 75.47, 141.67, 180.07 -> min = 75.47
[37m[36mINFO[0m[0m 01/28 07:50:55 | # of params = 23518277
[37m[36mINFO[0m[0m 01/28 07:53:15 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 01/28 07:53:15 | 0.477152    0.474085    0.578328    0.602499    1.214575    0.681979    0.685512    0.517647    0.585687    0.477152    0.474085    0.535357    0.536296    0           0.000000    1.854956    0.153027    1.004564    139.320123 
[37m[36mINFO[0m[0m 01/28 07:57:24 | 0.748286    0.731707    0.862857    0.859226    0.361986    1.000000    1.000000    0.742588    0.749529    0.748286    0.731707    0.845983    0.828148    200         2.650177    0.485582    0.145850    0.549756    138.405344 
[37m[36mINFO[0m[0m 01/28 08:01:37 | 0.684692    0.684451    0.869414    0.846169    0.378409    1.000000    1.000000    0.756706    0.732580    0.684692    0.684451    0.851536    0.805926    400         5.300353    0.345996    0.104592    0.582026    136.977558 
[37m[36mINFO[0m[0m 01/28 08:05:52 | 0.712110    0.721037    0.893070    0.879548    0.337543    1.000000    1.000000    0.794353    0.785311    0.712110    0.721037    0.884857    0.853333    600         7.950530    0.315212    0.094285    0.571315    140.654449 
[37m[36mINFO[0m[0m 01/28 08:10:02 | 0.777609    0.750000    0.898097    0.885192    0.351434    1.000000    0.996466    0.793882    0.790960    0.777609    0.750000    0.900407    0.868148    800         10.600707   0.282531    0.085180    0.541098    141.214068 
[37m[36mINFO[0m[0m 01/28 08:14:17 | 0.726200    0.681402    0.897898    0.868220    0.363475    0.999117    0.992933    0.805647    0.770245    0.726200    0.681402    0.888930    0.841481    1000        13.250883   0.270179    0.079249    0.555095    144.082667 
[37m[36mINFO[0m[0m 01/28 08:18:29 | 0.749810    0.751524    0.919046    0.878025    0.329036    1.000000    1.000000    0.838588    0.777778    0.749810    0.751524    0.918549    0.856296    1200        15.901060   0.257311    0.073742    0.536399    144.093584 
[37m[36mINFO[0m[0m 01/28 08:22:39 | 0.734958    0.737805    0.924831    0.879858    0.341845    1.000000    1.000000    0.847059    0.796610    0.734958    0.737805    0.927434    0.842963    1400        18.551237   0.243348    0.073597    0.560683    138.175794 
[37m[36mINFO[0m[0m 01/28 08:26:53 | 0.712490    0.728659    0.929238    0.867889    0.354760    1.000000    1.000000    0.851765    0.753296    0.712490    0.728659    0.935950    0.850370    1600        21.201413   0.231112    0.071271    0.566528    140.757381 
[37m[36mINFO[0m[0m 01/28 08:31:10 | 0.676314    0.707317    0.925264    0.869772    0.390930    0.999117    1.000000    0.850353    0.758945    0.676314    0.707317    0.926324    0.850370    1800        23.851590   0.210399    0.071750    0.563839    144.436540 
[37m[36mINFO[0m[0m 01/28 08:35:24 | 0.753618    0.756098    0.940056    0.868714    0.417277    1.000000    0.992933    0.872000    0.770245    0.753618    0.756098    0.948167    0.842963    2000        26.501767   0.191907    0.068353    0.538779    145.679694 
[37m[36mINFO[0m[0m 01/28 08:39:36 | 0.719345    0.765244    0.941208    0.872953    0.433243    1.000000    1.000000    0.879529    0.775895    0.719345    0.765244    0.944095    0.842963    2200        29.151943   0.169482    0.069303    0.548989    142.150026 
[37m[36mINFO[0m[0m 01/28 08:43:45 | 0.746382    0.751524    0.936720    0.862576    0.445839    1.000000    0.996466    0.854588    0.764595    0.746382    0.751524    0.955572    0.826667    2400        31.802120   0.161284    0.073087    0.561637    136.969028 
[37m[36mINFO[0m[0m 01/28 08:48:04 | 0.726580    0.724085    0.956396    0.871183    0.422352    0.999117    0.992933    0.906353    0.770245    0.726580    0.724085    0.963717    0.850370    2600        34.452297   0.150309    0.067909    0.588534    140.893410 
[37m[36mINFO[0m[0m 01/28 08:52:20 | 0.742574    0.721037    0.962782    0.864227    0.456559    0.998233    0.992933    0.920471    0.762712    0.742574    0.721037    0.969641    0.837037    2800        37.102473   0.137029    0.062905    0.555448    145.413004 
[37m[36mINFO[0m[0m 01/28 08:56:30 | 0.701066    0.710366    0.946324    0.849873    0.484620    1.000000    0.992933    0.878588    0.734463    0.701066    0.710366    0.960385    0.822222    3000        39.752650   0.128450    0.064831    0.539314    141.969829 
[37m[36mINFO[0m[0m 01/28 09:00:43 | 0.718964    0.728659    0.973738    0.868728    0.480408    1.000000    0.996466    0.943059    0.760829    0.718964    0.728659    0.978156    0.848889    3200        42.402827   0.144333    0.058285    0.555089    141.747329 
[37m[36mINFO[0m[0m 01/28 09:04:57 | 0.671363    0.696646    0.954205    0.841718    0.487100    0.997350    0.996466    0.901176    0.721281    0.671363    0.696646    0.964087    0.807407    3400        45.053004   0.107333    0.068495    0.582827    138.240455 
[37m[36mINFO[0m[0m 01/28 09:09:17 | 0.693069    0.672256    0.962291    0.874696    0.427048    1.000000    0.996466    0.926118    0.768362    0.693069    0.672256    0.960755    0.859259    3600        47.703180   0.106611    0.063837    0.588842    142.128682 
[37m[36mINFO[0m[0m 01/28 09:13:33 | 0.701066    0.710366    0.973075    0.872367    0.497229    1.000000    1.000000    0.945882    0.781544    0.701066    0.710366    0.973343    0.835556    3800        50.353357   0.090622    0.064010    0.563672    142.873354 
[37m[36mINFO[0m[0m 01/28 09:17:44 | 0.692688    0.725610    0.968336    0.861053    0.477039    1.000000    0.996466    0.931294    0.757062    0.692688    0.725610    0.973713    0.829630    4000        53.003534   0.110329    0.058955    0.548905    141.360693 
[37m[36mINFO[0m[0m 01/28 09:21:56 | 0.720868    0.727134    0.981092    0.874116    0.635064    1.000000    1.000000    0.956235    0.785311    0.720868    0.727134    0.987042    0.837037    4200        55.653710   0.078788    0.064291    0.552505    141.145734 
[37m[36mINFO[0m[0m 01/28 09:26:10 | 0.711348    0.705793    0.972728    0.873086    0.467215    1.000000    1.000000    0.944471    0.777778    0.711348    0.705793    0.973713    0.841481    4400        58.303887   0.096604    0.059444    0.570537    140.478719 
[37m[36mINFO[0m[0m 01/28 09:30:21 | 0.728865    0.693598    0.982062    0.870365    0.627530    0.998233    0.989399    0.959059    0.768362    0.728865    0.693598    0.988893    0.853333    4600        60.954064   0.066341    0.061062    0.564626    137.778108 
[37m[36mINFO[0m[0m 01/28 09:34:39 | 0.730008    0.672256    0.978013    0.865971    0.597617    0.997350    0.989399    0.949647    0.755179    0.730008    0.672256    0.987042    0.853333    4800        63.604240   0.052971    0.062906    0.581386    141.942159 
[37m[36mINFO[0m[0m 01/28 09:38:57 | 0.717822    0.717988    0.989781    0.850599    0.588628    0.998233    0.996466    0.982588    0.741996    0.717822    0.717988    0.988523    0.813333    5000        66.254417   0.047841    0.062945    0.584345    140.849738 
[37m[36mINFO[0m[0m 01/28 09:38:57 | Cumulative gradient change saved at train_output/VLCS/CORAL/[2]/250128_07-50-53_resnet50_EVE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 01/28 09:38:59 | ---
[37m[36mINFO[0m[0m 01/28 09:38:59 | test-domain validation(oracle) = 71.935%
[37m[36mINFO[0m[0m 01/28 09:38:59 | training-domain validation(iid) = 77.761%
[37m[36mINFO[0m[0m 01/28 09:38:59 | last = 71.782%
[37m[36mINFO[0m[0m 01/28 09:38:59 | last (inD) = 85.060%
[37m[36mINFO[0m[0m 01/28 09:38:59 | training-domain validation (iid, inD) = 88.519%
[37m[36mINFO[0m[0m 01/28 09:38:59 | === Summary ===
[37m[36mINFO[0m[0m 01/28 09:38:59 | Command: /jsm0707/DomainBed/Large-scale/train_all.py resnet50_EVE config/resnet50_EVE.yaml --algorithm CORAL --test_envs 2 --dataset VLCS --trial_seed 2 --hparams_seed 18
[37m[36mINFO[0m[0m 01/28 09:38:59 | Unique name: 250128_07-50-53_resnet50_EVE
[37m[36mINFO[0m[0m 01/28 09:38:59 | Out path: train_output/VLCS/CORAL/[2]/250128_07-50-53_resnet50_EVE
[37m[36mINFO[0m[0m 01/28 09:38:59 | Algorithm: CORAL
[37m[36mINFO[0m[0m 01/28 09:38:59 | Dataset: VLCS
[37m[36mINFO[0m[0m 01/28 09:38:59 | Max test_in: 0.7776
