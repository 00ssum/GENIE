[37m[36mINFO[0m[0m 02/06 16:13:34 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 2 --dataset VLCS --trial_seed 0 --hparams_seed 0
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/VLCS/CORAL/[2]/250206_16-13-34_resnet50_GENIE
	out_root: train_output/VLCS/CORAL/[2]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [2]
	trial_seed: 0
	unique_name: 250206_16-13-34_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	mmd_gamma: 1.0
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 02/06 16:13:34 | n_steps = 5001
[37m[36mINFO[0m[0m 02/06 16:13:34 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/06 16:13:34 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/06 16:13:34 | 
[37m[36mINFO[0m[0m 02/06 16:13:34 | Testenv name escaping te_S -> te_S
[37m[36mINFO[0m[0m 02/06 16:13:34 | Test envs = [2], name = te_S
[37m[36mINFO[0m[0m 02/06 16:13:34 | Train environments: [0, 1, 3], Test environments: [2]
[37m[36mINFO[0m[0m 02/06 16:13:34 | Batch sizes for each domain: [32, 32, 0, 32] (total=96)
[37m[36mINFO[0m[0m 02/06 16:13:34 | steps-per-epoch for each domain: 35.38, 66.41, 84.41 -> min = 35.38
[37m[36mINFO[0m[0m 02/06 16:13:36 | # of params = 23518277
[37m[36mINFO[0m[0m 02/06 16:16:09 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 02/06 16:16:09 | 0.384615    0.387195    0.504871    0.521514    1.300006    0.611307    0.628975    0.459765    0.489642    0.384615    0.387195    0.443539    0.445926    0           0.000000    1.803949    0.061857    1.965703    151.177292 
[37m[36mINFO[0m[0m 02/06 16:23:21 | 0.746763    0.704268    0.880442    0.871345    0.346934    0.998233    1.000000    0.770824    0.753296    0.746763    0.704268    0.872270    0.860741    200         5.653710    0.458638    0.030736    1.311590    170.269477 
[37m[36mINFO[0m[0m 02/06 16:30:32 | 0.715156    0.689024    0.891232    0.867889    0.354605    1.000000    1.000000    0.791059    0.753296    0.715156    0.689024    0.882636    0.850370    400         11.307420   0.293100    0.020852    1.343713    161.329573 
[37m[36mINFO[0m[0m 02/06 16:37:39 | 0.706017    0.684451    0.914291    0.870893    0.358994    1.000000    1.000000    0.832471    0.760829    0.706017    0.684451    0.910404    0.851852    600         16.961131   0.263137    0.017755    1.364218    154.972093 
[37m[36mINFO[0m[0m 02/06 16:45:01 | 0.715918    0.685976    0.931725    0.869052    0.359326    1.000000    1.000000    0.860706    0.762712    0.715918    0.685976    0.934469    0.844444    800         22.614841   0.204396    0.017564    1.365156    168.479062 
[37m[36mINFO[0m[0m 02/06 16:52:14 | 0.726580    0.699695    0.946690    0.873976    0.367357    1.000000    0.996466    0.888941    0.772128    0.726580    0.699695    0.951129    0.853333    1000        28.268551   0.168196    0.016696    1.404637    152.464492 
[37m[36mINFO[0m[0m 02/06 16:59:40 | 0.704874    0.679878    0.955186    0.865863    0.379506    1.000000    1.000000    0.907765    0.766478    0.704874    0.679878    0.957793    0.831111    1200        33.922261   0.145866    0.016558    1.380218    169.568322 
[37m[36mINFO[0m[0m 02/06 17:06:44 | 0.689261    0.655488    0.974654    0.872685    0.412610    1.000000    1.000000    0.952471    0.772128    0.689261    0.655488    0.971492    0.845926    1400        39.575972   0.114287    0.015885    1.341317    155.883507 
[37m[36mINFO[0m[0m 02/06 17:14:05 | 0.709825    0.693598    0.974155    0.861335    0.453975    1.000000    1.000000    0.940235    0.751412    0.709825    0.693598    0.982229    0.832593    1600        45.229682   0.081818    0.016126    1.413783    158.638333 
[37m[36mINFO[0m[0m 02/06 17:21:13 | 0.714775    0.714939    0.982121    0.863882    0.475704    1.000000    0.996466    0.963765    0.755179    0.714775    0.714939    0.982599    0.840000    1800        50.883392   0.080235    0.015391    1.329393    161.545258 
[37m[36mINFO[0m[0m 02/06 17:28:17 | 0.698401    0.689024    0.989046    0.872643    0.501078    1.000000    1.000000    0.983059    0.764595    0.698401    0.689024    0.984080    0.853333    2000        56.537102   0.065244    0.014322    1.338432    156.240145 
[37m[36mINFO[0m[0m 02/06 17:35:16 | 0.712110    0.672256    0.987240    0.871492    0.542683    0.999117    0.992933    0.977412    0.781544    0.712110    0.672256    0.985191    0.840000    2200        62.190813   0.047933    0.014003    1.312846    156.913196 
[37m[36mINFO[0m[0m 02/06 17:42:15 | 0.686596    0.687500    0.990213    0.861999    0.566319    1.000000    0.996466    0.982118    0.749529    0.686596    0.687500    0.988523    0.840000    2400        67.844523   0.036495    0.013540    1.301241    158.087361 
[37m[36mINFO[0m[0m 02/06 17:49:24 | 0.690784    0.682927    0.995078    0.870040    0.552346    1.000000    1.000000    0.991529    0.762712    0.690784    0.682927    0.993706    0.847407    2600        73.498233   0.031270    0.012370    1.375245    153.971226 
[37m[36mINFO[0m[0m 02/06 17:56:25 | 0.711348    0.698171    0.993767    0.870216    0.569359    1.000000    1.000000    0.988706    0.772128    0.711348    0.698171    0.992595    0.838519    2800        79.151943   0.027056    0.011829    1.344729    152.679046 
[37m[36mINFO[0m[0m 02/06 18:03:47 | 0.709444    0.692073    0.996536    0.870801    0.613499    1.000000    1.000000    0.992941    0.766478    0.709444    0.692073    0.996668    0.845926    3000        84.805654   0.020623    0.011178    1.443477    152.951907 
[37m[36mINFO[0m[0m 02/06 18:10:51 | 0.698020    0.666159    0.997900    0.879322    0.565701    0.999117    1.000000    0.997176    0.789077    0.698020    0.666159    0.997408    0.848889    3200        90.459364   0.023206    0.011003    1.296365    164.390897 
[37m[36mINFO[0m[0m 02/06 18:18:35 | 0.698020    0.681402    0.997601    0.874208    0.570084    1.000000    1.000000    0.995765    0.779661    0.698020    0.681402    0.997038    0.842963    3400        96.113074   0.012785    0.010066    1.449634    174.612000 
[37m[36mINFO[0m[0m 02/06 18:25:48 | 0.683168    0.664634    0.997657    0.868290    0.594933    1.000000    1.000000    0.994824    0.758945    0.683168    0.664634    0.998149    0.845926    3600        101.766784  0.014147    0.009532    1.371401    158.070834 
[37m[36mINFO[0m[0m 02/06 18:32:58 | 0.703732    0.679878    0.994474    0.869341    0.702528    1.000000    0.992933    0.988235    0.772128    0.703732    0.679878    0.995187    0.842963    3800        107.420495  0.016531    0.009497    1.354989    159.455877 
[37m[36mINFO[0m[0m 02/06 18:40:10 | 0.693450    0.687500    0.998879    0.861963    0.635470    1.000000    1.000000    0.998118    0.753296    0.693450    0.687500    0.998519    0.832593    4000        113.074205  0.011896    0.009032    1.297170    172.481933 
[37m[36mINFO[0m[0m 02/06 18:47:40 | 0.698401    0.670732    0.997254    0.864813    0.639241    1.000000    0.992933    0.994353    0.757062    0.698401    0.670732    0.997408    0.844444    4200        118.727915  0.009251    0.008488    1.384310    173.277490 
[37m[36mINFO[0m[0m 02/06 18:55:09 | 0.715156    0.695122    0.998442    0.858182    0.617481    1.000000    0.996466    0.997176    0.751412    0.715156    0.695122    0.998149    0.826667    4400        124.381625  0.008459    0.008131    1.407813    167.212691 
[37m[36mINFO[0m[0m 02/06 19:02:16 | 0.706017    0.681402    0.998902    0.861427    0.636261    1.000000    1.000000    0.996706    0.745763    0.706017    0.681402    1.000000    0.838519    4600        130.035336  0.005812    0.007557    1.337645    160.053147 
[37m[36mINFO[0m[0m 02/06 19:09:34 | 0.706778    0.708841    0.999036    0.866047    0.601279    1.000000    1.000000    0.998588    0.755179    0.706778    0.708841    0.998519    0.842963    4800        135.689046  0.007204    0.007505    1.398836    158.021613 
[37m[36mINFO[0m[0m 02/06 19:16:41 | 0.674410    0.655488    0.995022    0.868452    0.715594    1.000000    0.996466    0.992471    0.777778    0.674410    0.655488    0.992595    0.831111    5000        141.342756  0.011508    0.007433    1.316964    163.243469 
[37m[36mINFO[0m[0m 02/06 19:16:41 | Cumulative gradient change saved at train_output/VLCS/CORAL/[2]/250206_16-13-34_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/06 19:16:42 | ---
[37m[36mINFO[0m[0m 02/06 19:16:42 | test-domain validation(oracle) = 71.478%
[37m[36mINFO[0m[0m 02/06 19:16:42 | training-domain validation(iid) = 69.802%
[37m[36mINFO[0m[0m 02/06 19:16:42 | last = 67.441%
[37m[36mINFO[0m[0m 02/06 19:16:42 | last (inD) = 86.845%
[37m[36mINFO[0m[0m 02/06 19:16:42 | training-domain validation (iid, inD) = 87.932%
[37m[36mINFO[0m[0m 02/06 19:16:42 | === Summary ===
[37m[36mINFO[0m[0m 02/06 19:16:42 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 2 --dataset VLCS --trial_seed 0 --hparams_seed 0
[37m[36mINFO[0m[0m 02/06 19:16:42 | Unique name: 250206_16-13-34_resnet50_GENIE
[37m[36mINFO[0m[0m 02/06 19:16:42 | Out path: train_output/VLCS/CORAL/[2]/250206_16-13-34_resnet50_GENIE
[37m[36mINFO[0m[0m 02/06 19:16:42 | Algorithm: CORAL
[37m[36mINFO[0m[0m 02/06 19:16:42 | Dataset: VLCS
