[37m[36mINFO[0m[0m 02/15 13:13:14 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 1 2 3 --dataset VLCS --trial_seed 2 --hparams_seed 10
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 10
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/VLCS/CORAL/[1, 2, 3]/250215_13-13-14_resnet50_GENIE
	out_root: train_output/VLCS/CORAL/[1, 2, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [1, 2, 3]
	trial_seed: 2
	unique_name: 250215_13-13-14_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.5
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 7.494887873901297e-05
	batch_size: 23
	weight_decay: 0.000495139494108363
	mmd_gamma: 1.4713820315478223
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 02/15 13:13:14 | n_steps = 5001
[37m[36mINFO[0m[0m 02/15 13:13:14 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/15 13:13:14 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/15 13:13:14 | 
[37m[36mINFO[0m[0m 02/15 13:13:14 | Testenv name escaping te_L_S_V -> te_L_S_V
[37m[36mINFO[0m[0m 02/15 13:13:14 | Test envs = [1, 2, 3], name = te_L_S_V
[37m[36mINFO[0m[0m 02/15 13:13:14 | Train environments: [0], Test environments: [1, 2, 3]
[37m[36mINFO[0m[0m 02/15 13:13:14 | Batch sizes for each domain: [23, 0, 0, 0] (total=23)
[37m[36mINFO[0m[0m 02/15 13:13:14 | steps-per-epoch for each domain: 49.22 -> min = 49.22
[37m[36mINFO[0m[0m 02/15 13:13:16 | # of params = 23518277
[37m[36mINFO[0m[0m 02/15 13:15:55 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 02/15 13:15:55 | 0.433117    0.425667    0.620141    0.593640    1.085546    0.620141    0.593640    0.467294    0.459510    0.391851    0.358232    0.440207    0.459259    0           0.000000    1.816085    0.000000    1.242536    157.785104 
[37m[36mINFO[0m[0m 02/15 13:19:02 | 0.576246    0.583579    1.000000    1.000000    0.000331    1.000000    1.000000    0.517647    0.534840    0.602056    0.617378    0.609034    0.598519    200         4.063604    0.047733    0.000000    0.177718    151.758247 
[37m[36mINFO[0m[0m 02/15 13:21:55 | 0.520687    0.533177    0.999117    1.000000    0.001078    0.999117    1.000000    0.474353    0.485876    0.545316    0.564024    0.542392    0.549630    400         8.127208    0.001588    0.000000    0.128559    146.983319 
[37m[36mINFO[0m[0m 02/15 13:25:10 | 0.483749    0.491409    1.000000    0.989399    0.013961    1.000000    0.989399    0.465882    0.480226    0.459634    0.471037    0.525731    0.522963    600         12.190813   0.012423    0.000000    0.151829    164.535699 
[37m[36mINFO[0m[0m 02/15 13:28:26 | 0.517274    0.524212    1.000000    0.996466    0.003714    1.000000    0.996466    0.476235    0.489642    0.508759    0.527439    0.566827    0.555556    800         16.254417   0.000448    0.000000    0.152825    165.525609 
[37m[36mINFO[0m[0m 02/15 13:31:20 | 0.523102    0.536210    1.000000    1.000000    0.000422    1.000000    1.000000    0.473412    0.493409    0.533511    0.567073    0.562384    0.548148    1000        20.318021   0.000090    0.000000    0.107092    152.447181 
[37m[36mINFO[0m[0m 02/15 13:34:00 | 0.517649    0.521307    1.000000    0.996466    0.003315    1.000000    0.996466    0.476706    0.489642    0.519040    0.533537    0.557201    0.540741    1200        24.381625   0.000082    0.000000    0.120109    135.557048 
[37m[36mINFO[0m[0m 02/15 13:36:49 | 0.520514    0.531665    1.000000    1.000000    0.001918    1.000000    1.000000    0.476235    0.493409    0.525514    0.556402    0.559793    0.545185    1400        28.445230   0.000030    0.000000    0.153087    138.247509 
[37m[36mINFO[0m[0m 02/15 13:39:49 | 0.520361    0.532159    1.000000    1.000000    0.001412    1.000000    1.000000    0.475765    0.493409    0.525895    0.556402    0.559422    0.546667    1600        32.508834   0.000022    0.000000    0.143051    151.769444 
[37m[36mINFO[0m[0m 02/15 13:42:32 | 0.520854    0.531651    1.000000    1.000000    0.001129    1.000000    1.000000    0.475765    0.493409    0.525895    0.554878    0.560903    0.546667    1800        36.572438   0.000019    0.000000    0.124169    138.713087 
[37m[36mINFO[0m[0m 02/15 13:45:27 | 0.519874    0.530155    1.000000    1.000000    0.000805    1.000000    1.000000    0.473882    0.493409    0.527799    0.553354    0.557942    0.543704    2000        40.636042   0.000018    0.000000    0.183879    137.984456 
[37m[36mINFO[0m[0m 02/15 13:48:28 | 0.525047    0.536647    1.000000    1.000000    0.001137    1.000000    1.000000    0.474824    0.493409    0.532749    0.560976    0.567568    0.555556    2200        44.699647   0.000038    0.000000    0.143382    151.646357 
[37m[36mINFO[0m[0m 02/15 13:51:28 | 0.524273    0.535151    1.000000    1.000000    0.001183    1.000000    1.000000    0.474353    0.493409    0.532749    0.559451    0.565716    0.552593    2400        48.763251   0.000023    0.000000    0.142348    151.992797 
[37m[36mINFO[0m[0m 02/15 13:54:24 | 0.523786    0.533626    1.000000    1.000000    0.000740    1.000000    1.000000    0.474353    0.493409    0.533511    0.554878    0.563495    0.552593    2600        52.826855   0.000022    0.000000    0.167007    142.263505 
[37m[36mINFO[0m[0m 02/15 13:57:44 | 0.517131    0.527452    1.000000    1.000000    0.001206    1.000000    1.000000    0.473882    0.491525    0.524752    0.542683    0.552758    0.548148    2800        56.890459   0.000024    0.000000    0.200405    160.533581 
[37m[36mINFO[0m[0m 02/15 14:01:09 | 0.516211    0.524144    1.000000    1.000000    0.000597    1.000000    1.000000    0.472941    0.493409    0.525895    0.544207    0.549796    0.534815    3000        60.954064   0.000022    0.000000    0.145580    175.657198 
[37m[36mINFO[0m[0m 02/15 14:04:19 | 0.520950    0.528688    1.000000    1.000000    0.000447    1.000000    1.000000    0.474824    0.493409    0.530084    0.554878    0.557942    0.537778    3200        65.017668   0.000025    0.000000    0.128969    164.047045 
[37m[36mINFO[0m[0m 02/15 14:07:28 | 0.519051    0.526148    1.000000    1.000000    0.000480    1.000000    1.000000    0.474353    0.493409    0.528561    0.547256    0.554239    0.537778    3400        69.081272   0.000017    0.000000    0.163922    156.391167 
[37m[36mINFO[0m[0m 02/15 14:11:01 | 0.516599    0.525146    1.000000    1.000000    0.000541    1.000000    1.000000    0.472941    0.493409    0.527799    0.545732    0.549056    0.536296    3600        73.144876   0.000019    0.000000    0.158100    181.312745 
[37m[36mINFO[0m[0m 02/15 14:14:32 | 0.513878    0.523142    1.000000    1.000000    0.000636    1.000000    1.000000    0.471529    0.493409    0.524752    0.542683    0.545354    0.533333    3800        77.208481   0.000021    0.000000    0.139420    182.942844 
[37m[36mINFO[0m[0m 02/15 14:17:35 | 0.513404    0.522662    1.000000    1.000000    0.000489    1.000000    1.000000    0.470118    0.493409    0.524372    0.544207    0.545724    0.530370    4000        81.272085   0.000020    0.000000    0.128005    157.853293 
[37m[36mINFO[0m[0m 02/15 14:20:49 | 0.511573    0.520687    1.000000    1.000000    0.000418    1.000000    1.000000    0.468706    0.493409    0.523991    0.544207    0.542021    0.524444    4200        85.335689   0.000013    0.000000    0.226398    148.426528 
[37m[36mINFO[0m[0m 02/15 14:24:07 | 0.509653    0.519043    1.000000    1.000000    0.000694    1.000000    1.000000    0.468235    0.491525    0.520183    0.541159    0.540541    0.524444    4400        89.399293   0.000030    0.000000    0.181298    162.023462 
[37m[36mINFO[0m[0m 02/15 14:27:33 | 0.513093    0.525994    1.000000    1.000000    0.000089    1.000000    1.000000    0.466824    0.489642    0.529322    0.559451    0.543132    0.528889    4600        93.462898   0.000087    0.000000    0.137085    177.872001 
[37m[36mINFO[0m[0m 02/15 14:30:35 | 0.508532    0.518401    1.000000    1.000000    0.000373    1.000000    1.000000    0.466353    0.489642    0.520183    0.539634    0.539060    0.525926    4800        97.526502   0.000028    0.000000    0.141630    154.469365 
[37m[36mINFO[0m[0m 02/15 14:33:46 | 0.508539    0.517427    1.000000    1.000000    0.000301    1.000000    1.000000    0.466353    0.489642    0.520944    0.541159    0.538319    0.521481    5000        101.590106  0.000017    0.000000    0.207995    149.237013 
[37m[36mINFO[0m[0m 02/15 14:33:46 | Cumulative gradient change saved at train_output/VLCS/CORAL/[1, 2, 3]/250215_13-13-14_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/15 14:33:50 | ---
[37m[36mINFO[0m[0m 02/15 14:33:50 | test-domain validation(oracle) = 57.625%
[37m[36mINFO[0m[0m 02/15 14:33:50 | training-domain validation(iid) = 57.625%
[37m[36mINFO[0m[0m 02/15 14:33:50 | last = 50.854%
[37m[36mINFO[0m[0m 02/15 14:33:50 | last (inD) = 100.000%
[37m[36mINFO[0m[0m 02/15 14:33:50 | training-domain validation (iid, inD) = 100.000%
[37m[36mINFO[0m[0m 02/15 14:33:50 | === Summary ===
[37m[36mINFO[0m[0m 02/15 14:33:50 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 1 2 3 --dataset VLCS --trial_seed 2 --hparams_seed 10
[37m[36mINFO[0m[0m 02/15 14:33:50 | Unique name: 250215_13-13-14_resnet50_GENIE
[37m[36mINFO[0m[0m 02/15 14:33:50 | Out path: train_output/VLCS/CORAL/[1, 2, 3]/250215_13-13-14_resnet50_GENIE
[37m[36mINFO[0m[0m 02/15 14:33:50 | Algorithm: CORAL
[37m[36mINFO[0m[0m 02/15 14:33:50 | Dataset: VLCS
