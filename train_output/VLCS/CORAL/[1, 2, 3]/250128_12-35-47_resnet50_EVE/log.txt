[37m[36mINFO[0m[0m 01/28 12:35:47 | Command :: /jsm0707/Large-scale/train_all.py resnet50_EVE config/resnet50_EVE.yaml --algorithm CORAL --test_envs 1 2 3 --dataset VLCS --trial_seed 1 --hparams_seed 2
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_EVE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 2
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_EVE
	out_dir: train_output/VLCS/CORAL/[1, 2, 3]/250128_12-35-47_resnet50_EVE
	out_root: train_output/VLCS/CORAL/[1, 2, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [1, 2, 3]
	trial_seed: 1
	unique_name: 250128_12-35-47_resnet50_EVE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.5
	class_balanced: False
	optimizer: EVE
	freeze_bn: False
	pretrained: True
	lr: 0.0001126313085293539
	batch_size: 38
	weight_decay: 0.006639128805224463
	mmd_gamma: 0.28205739923739065
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 01/28 12:35:47 | n_steps = 5001
[37m[36mINFO[0m[0m 01/28 12:35:47 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 01/28 12:35:47 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 01/28 12:35:47 | 
[37m[36mINFO[0m[0m 01/28 12:35:47 | Testenv name escaping te_L_S_V -> te_L_S_V
[37m[36mINFO[0m[0m 01/28 12:35:47 | Test envs = [1, 2, 3], name = te_L_S_V
[37m[36mINFO[0m[0m 01/28 12:35:47 | Train environments: [0], Test environments: [1, 2, 3]
[37m[36mINFO[0m[0m 01/28 12:35:47 | Batch sizes for each domain: [38, 0, 0, 0] (total=38)
[37m[36mINFO[0m[0m 01/28 12:35:47 | steps-per-epoch for each domain: 29.79 -> min = 29.79
[37m[36mINFO[0m[0m 01/28 12:35:49 | # of params = 23518277
[37m[36mINFO[0m[0m 01/28 12:38:10 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 01/28 12:38:10 | 0.432326    0.428842    0.613958    0.618375    0.971187    0.613958    0.618375    0.466824    0.461394    0.376618    0.419207    0.453536    0.405926    0           0.000000    1.801724    0.000000    1.393095    139.787008 
[37m[36mINFO[0m[0m 01/28 12:41:17 | 0.574723    0.572579    1.000000    1.000000    0.001182    1.000000    1.000000    0.496471    0.495292    0.586824    0.586890    0.640874    0.635556    200         6.713781    0.042691    0.000000    0.172460    152.541426 
[37m[36mINFO[0m[0m 01/28 12:44:28 | 0.537973    0.546242    1.000000    1.000000    0.000628    1.000000    1.000000    0.478588    0.482109    0.567022    0.564024    0.568308    0.592593    400         13.427562   0.002276    0.000000    0.215092    147.059981 
[37m[36mINFO[0m[0m 01/28 12:47:23 | 0.525225    0.527566    1.000000    1.000000    0.001032    1.000000    1.000000    0.473412    0.472693    0.549505    0.539634    0.552758    0.570370    600         20.141343   0.000367    0.000000    0.182065    139.184401 
[37m[36mINFO[0m[0m 01/28 12:50:35 | 0.495294    0.501573    1.000000    1.000000    0.001381    1.000000    1.000000    0.462118    0.465160    0.522468    0.510671    0.501296    0.528889    800         26.855124   0.000446    0.000000    0.244862    142.191575 
[37m[36mINFO[0m[0m 01/28 12:53:39 | 0.494908    0.502131    1.000000    1.000000    0.003984    1.000000    1.000000    0.459765    0.459510    0.512186    0.507622    0.512773    0.539259    1000        33.568905   0.001257    0.000000    0.187975    146.933327 
[37m[36mINFO[0m[0m 01/28 12:56:44 | 0.451192    0.455791    1.000000    1.000000    0.004278    1.000000    1.000000    0.421176    0.425612    0.485529    0.457317    0.446872    0.484444    1200        40.282686   0.000838    0.000000    0.207435    143.537220 
[37m[36mINFO[0m[0m 01/28 12:59:42 | 0.485273    0.495244    1.000000    0.996466    0.008881    1.000000    0.996466    0.444706    0.448211    0.493526    0.490854    0.517586    0.546667    1400        46.996466   0.005644    0.000000    0.179927    141.520580 
[37m[36mINFO[0m[0m 01/28 13:02:46 | 0.462122    0.474656    0.999117    0.992933    0.012891    0.999117    0.992933    0.416941    0.433145    0.458873    0.463415    0.510552    0.527407    1600        53.710247   0.002155    0.000000    0.170079    150.784650 
[37m[36mINFO[0m[0m 01/28 13:05:39 | 0.374984    0.379973    1.000000    0.996466    0.007543    1.000000    0.996466    0.339765    0.352166    0.437167    0.407012    0.348019    0.380741    1800        60.424028   0.009369    0.000000    0.176761    137.649536 
[37m[36mINFO[0m[0m 01/28 13:08:40 | 0.405438    0.412280    0.999117    0.996466    0.005700    0.999117    0.996466    0.375529    0.384181    0.466108    0.449695    0.374676    0.402963    2000        67.137809   0.000586    0.000000    0.207129    138.711093 
[37m[36mINFO[0m[0m 01/28 13:11:42 | 0.342713    0.339509    0.993816    0.989399    0.028290    0.993816    0.989399    0.350118    0.370998    0.364433    0.320122    0.313588    0.327407    2200        73.851590   0.019338    0.000000    0.202257    142.357481 
[37m[36mINFO[0m[0m 01/28 13:14:40 | 0.367088    0.371110    1.000000    0.996466    0.005867    1.000000    0.996466    0.333647    0.348399    0.417746    0.385671    0.349870    0.379259    2400        80.565371   0.001946    0.000000    0.198019    137.844116 
[37m[36mINFO[0m[0m 01/28 13:17:37 | 0.281739    0.295130    0.999117    0.996466    0.009429    0.999117    0.996466    0.200941    0.239171    0.349200    0.326220    0.295076    0.320000    2600        87.279152   0.012214    0.000000    0.185378    140.070936 
[37m[36mINFO[0m[0m 01/28 13:20:40 | 0.263754    0.264537    0.994700    0.978799    0.065812    0.994700    0.978799    0.306353    0.316384    0.169840    0.164634    0.315068    0.312593    2800        93.992933   0.011501    0.000000    0.174424    148.164062 
[37m[36mINFO[0m[0m 01/28 13:23:42 | 0.337608    0.351681    0.993816    0.992933    0.029260    0.993816    0.992933    0.301176    0.333333    0.402133    0.376524    0.309515    0.345185    3000        100.706714  0.008078    0.000000    0.193541    142.776249 
[37m[36mINFO[0m[0m 01/28 13:26:37 | 0.338943    0.338898    0.998233    0.989399    0.045267    0.998233    0.989399    0.352000    0.354049    0.342727    0.330793    0.322103    0.331852    3200        107.420495  0.011166    0.000000    0.188555    138.106546 
[37m[36mINFO[0m[0m 01/28 13:29:44 | 0.224775    0.241486    0.976148    0.978799    0.062008    0.976148    0.978799    0.122353    0.163842    0.318355    0.285061    0.233617    0.275556    3400        114.134276  0.034513    0.000000    0.226319    141.140733 
[37m[36mINFO[0m[0m 01/28 13:32:43 | 0.348236    0.355387    1.000000    0.985866    0.023282    1.000000    0.985866    0.351529    0.367232    0.390327    0.356707    0.302851    0.342222    3600        120.848057  0.032686    0.000000    0.212419    136.583523 
[37m[36mINFO[0m[0m 01/28 13:35:47 | 0.356436    0.363311    1.000000    0.989399    0.019524    1.000000    0.989399    0.361882    0.372881    0.396801    0.368902    0.310626    0.348148    3800        127.561837  0.001433    0.000000    0.223427    138.990509 
[37m[36mINFO[0m[0m 01/28 13:38:48 | 0.241453    0.241986    0.955830    0.954064    0.223781    0.955830    0.954064    0.324235    0.322034    0.183168    0.192073    0.216957    0.211852    4000        134.275618  0.023076    0.000000    0.182845    144.568294 
[37m[36mINFO[0m[0m 01/28 13:41:46 | 0.367509    0.369787    1.000000    0.989399    0.038848    1.000000    0.989399    0.368000    0.380414    0.412795    0.370427    0.321733    0.358519    4200        140.989399  0.026061    0.000000    0.174521    142.948805 
[37m[36mINFO[0m[0m 01/28 13:44:45 | 0.364716    0.374326    0.997350    0.992933    0.021780    0.997350    0.992933    0.336941    0.352166    0.402894    0.384146    0.354313    0.386667    4400        147.703180  0.011773    0.000000    0.191099    141.523276 
[37m[36mINFO[0m[0m 01/28 13:47:45 | 0.304470    0.309116    0.998233    0.985866    0.039403    0.998233    0.985866    0.275765    0.290019    0.337014    0.326220    0.300629    0.311111    4600        154.416961  0.040824    0.000000    0.197813    140.038945 
[37m[36mINFO[0m[0m 01/28 13:50:49 | 0.170293    0.170362    0.988516    0.975265    0.092517    0.988516    0.975265    0.121882    0.137476    0.195735    0.167683    0.193262    0.205926    4800        161.130742  0.039758    0.000000    0.225651    139.248538 
[37m[36mINFO[0m[0m 01/28 13:53:51 | 0.274407    0.299830    0.994700    0.992933    0.026709    0.994700    0.992933    0.197647    0.254237    0.369002    0.344512    0.256572    0.300741    5000        167.844523  0.014624    0.000000    0.174665    146.627205 
[37m[36mINFO[0m[0m 01/28 13:53:51 | Cumulative gradient change saved at train_output/VLCS/CORAL/[1, 2, 3]/250128_12-35-47_resnet50_EVE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 01/28 13:53:53 | ---
[37m[36mINFO[0m[0m 01/28 13:53:53 | test-domain validation(oracle) = 57.472%
[37m[36mINFO[0m[0m 01/28 13:53:53 | training-domain validation(iid) = 57.472%
[37m[36mINFO[0m[0m 01/28 13:53:53 | last = 27.441%
[37m[36mINFO[0m[0m 01/28 13:53:53 | last (inD) = 99.293%
[37m[36mINFO[0m[0m 01/28 13:53:53 | training-domain validation (iid, inD) = 100.000%
[37m[36mINFO[0m[0m 01/28 13:53:53 | === Summary ===
[37m[36mINFO[0m[0m 01/28 13:53:53 | Command: /jsm0707/Large-scale/train_all.py resnet50_EVE config/resnet50_EVE.yaml --algorithm CORAL --test_envs 1 2 3 --dataset VLCS --trial_seed 1 --hparams_seed 2
[37m[36mINFO[0m[0m 01/28 13:53:53 | Unique name: 250128_12-35-47_resnet50_EVE
[37m[36mINFO[0m[0m 01/28 13:53:53 | Out path: train_output/VLCS/CORAL/[1, 2, 3]/250128_12-35-47_resnet50_EVE
[37m[36mINFO[0m[0m 01/28 13:53:53 | Algorithm: CORAL
[37m[36mINFO[0m[0m 01/28 13:53:53 | Dataset: VLCS
