[37m[36mINFO[0m[0m 01/26 21:53:21 | Command :: /jsm0707/Large-scale/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm CORAL --test_envs 1 2 3 --dataset VLCS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_sgd.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_sgd
	out_dir: train_output/VLCS/CORAL/[1, 2, 3]/250126_21-53-21_resnet50_sgd
	out_root: train_output/VLCS/CORAL/[1, 2, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [1, 2, 3]
	trial_seed: 0
	unique_name: 250126_21-53-21_resnet50_sgd
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: sgd
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	mmd_gamma: 1.0
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 01/26 21:53:21 | n_steps = 5001
[37m[36mINFO[0m[0m 01/26 21:53:21 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 01/26 21:53:21 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 01/26 21:53:21 | 
[37m[36mINFO[0m[0m 01/26 21:53:21 | Testenv name escaping te_L_S_V -> te_L_S_V
[37m[36mINFO[0m[0m 01/26 21:53:21 | Test envs = [1, 2, 3], name = te_L_S_V
[37m[36mINFO[0m[0m 01/26 21:53:21 | Train environments: [0], Test environments: [1, 2, 3]
[37m[36mINFO[0m[0m 01/26 21:53:21 | Batch sizes for each domain: [32, 0, 0, 0] (total=32)
[37m[36mINFO[0m[0m 01/26 21:53:21 | steps-per-epoch for each domain: 35.38 -> min = 35.38
[37m[36mINFO[0m[0m 01/26 21:53:23 | # of params = 23518277
[37m[36mINFO[0m[0m 01/26 21:55:29 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 01/26 21:55:29 | 0.171642    0.145696    0.087456    0.077739    1.898513    0.087456    0.077739    0.187294    0.160075    0.185834    0.157012    0.141799    0.120000    0           0.000000    1.820007    0.000000    1.294302    125.490732 
[37m[36mINFO[0m[0m 01/26 21:58:08 | 0.423501    0.433414    0.628975    0.646643    0.785902    0.628975    0.646643    0.459294    0.489642    0.374334    0.376524    0.436875    0.434074    200         5.653710    1.189219    0.000000    0.146469    129.439318 
[37m[36mINFO[0m[0m 01/26 22:00:45 | 0.381833    0.397727    0.799470    0.802120    0.542572    0.799470    0.802120    0.428235    0.478343    0.337776    0.342988    0.379489    0.371852    400         11.307420   0.654415    0.000000    0.141669    127.302029 
[37m[36mINFO[0m[0m 01/26 22:03:20 | 0.345969    0.342973    0.922261    0.915194    0.386818    0.922261    0.915194    0.392941    0.423729    0.293983    0.289634    0.350981    0.315556    600         16.961131   0.463838    0.000000    0.144074    126.033515 
[37m[36mINFO[0m[0m 01/26 22:05:56 | 0.377030    0.367563    0.973498    0.968198    0.270097    0.973498    0.968198    0.419294    0.418079    0.327494    0.321646    0.384302    0.362963    800         22.614841   0.310908    0.000000    0.143958    127.332235 
[37m[36mINFO[0m[0m 01/26 22:08:31 | 0.402316    0.385364    0.990283    0.989399    0.184004    0.990283    0.989399    0.412706    0.416196    0.376618    0.338415    0.417623    0.401481    1000        28.268551   0.207464    0.000000    0.142960    125.841169 
[37m[36mINFO[0m[0m 01/26 22:11:07 | 0.433481    0.411112    0.995583    0.992933    0.125454    0.995583    0.992933    0.424000    0.418079    0.430312    0.384146    0.446131    0.431111    1200        33.922261   0.135930    0.000000    0.144599    126.779392 
[37m[36mINFO[0m[0m 01/26 22:13:45 | 0.439602    0.421670    0.996466    0.996466    0.087331    0.996466    0.996466    0.422118    0.410546    0.439452    0.408537    0.457238    0.445926    1400        39.575972   0.094874    0.000000    0.142110    129.041219 
[37m[36mINFO[0m[0m 01/26 22:16:25 | 0.448617    0.433051    0.998233    0.996466    0.063249    0.998233    0.996466    0.422588    0.408663    0.449733    0.425305    0.473528    0.465185    1600        45.229682   0.066959    0.000000    0.147846    129.747372 
[37m[36mINFO[0m[0m 01/26 22:18:59 | 0.454782    0.442110    0.999117    0.996466    0.047678    0.999117    0.996466    0.421176    0.416196    0.460015    0.439024    0.483154    0.471111    1800        50.883392   0.050580    0.000000    0.142075    125.018627 
[37m[36mINFO[0m[0m 01/26 22:21:34 | 0.462505    0.448912    0.997350    1.000000    0.037363    0.997350    1.000000    0.424471    0.419962    0.469155    0.451220    0.493891    0.475556    2000        56.537102   0.039830    0.000000    0.139731    127.039039 
[37m[36mINFO[0m[0m 01/26 22:24:12 | 0.456045    0.445251    1.000000    1.000000    0.029789    1.000000    1.000000    0.416471    0.410546    0.459254    0.448171    0.492410    0.477037    2200        62.190813   0.032437    0.000000    0.146258    128.595371 
[37m[36mINFO[0m[0m 01/26 22:26:45 | 0.460630    0.449393    0.999117    1.000000    0.024669    0.999117    1.000000    0.419765    0.412429    0.462681    0.454268    0.499445    0.481481    2400        67.844523   0.024918    0.000000    0.141628    124.239232 
[37m[36mINFO[0m[0m 01/26 22:29:22 | 0.458834    0.449379    1.000000    1.000000    0.020883    1.000000    1.000000    0.417412    0.412429    0.460015    0.452744    0.499074    0.482963    2600        73.498233   0.021265    0.000000    0.143960    127.978208 
[37m[36mINFO[0m[0m 01/26 22:31:57 | 0.468667    0.457528    1.000000    1.000000    0.017968    1.000000    1.000000    0.424000    0.414313    0.471820    0.464939    0.510181    0.493333    2800        79.151943   0.017157    0.000000    0.138466    127.704644 
[37m[36mINFO[0m[0m 01/26 22:34:36 | 0.468877    0.458516    0.999117    1.000000    0.015801    0.999117    1.000000    0.421647    0.414313    0.472582    0.464939    0.512403    0.496296    3000        84.805654   0.014691    0.000000    0.141044    130.463927 
[37m[36mINFO[0m[0m 01/26 22:37:10 | 0.471821    0.460922    1.000000    1.000000    0.014041    1.000000    1.000000    0.424471    0.419962    0.475628    0.467988    0.515365    0.494815    3200        90.459364   0.012836    0.000000    0.141518    125.780070 
[37m[36mINFO[0m[0m 01/26 22:39:47 | 0.471307    0.462749    1.000000    1.000000    0.012573    1.000000    1.000000    0.422588    0.418079    0.474486    0.466463    0.516846    0.503704    3400        96.113074   0.012173    0.000000    0.144649    127.231758 
[37m[36mINFO[0m[0m 01/26 22:42:23 | 0.477105    0.466516    1.000000    1.000000    0.011333    1.000000    1.000000    0.428706    0.421846    0.480579    0.471037    0.522029    0.506667    3600        101.766784  0.009865    0.000000    0.146290    126.500840 
[37m[36mINFO[0m[0m 01/26 22:44:58 | 0.476918    0.468012    1.000000    1.000000    0.010263    1.000000    1.000000    0.427765    0.421846    0.480960    0.472561    0.522029    0.509630    3800        107.420495  0.009551    0.000000    0.152579    124.083007 
[37m[36mINFO[0m[0m 01/26 22:47:32 | 0.475745    0.466516    0.999117    1.000000    0.009364    0.999117    1.000000    0.427294    0.421846    0.477913    0.471037    0.522029    0.506667    4000        113.074205  0.008829    0.000000    0.147392    124.108147 
[37m[36mINFO[0m[0m 01/26 22:50:05 | 0.482111    0.470270    1.000000    1.000000    0.008627    1.000000    1.000000    0.432471    0.425612    0.485910    0.474085    0.527953    0.511111    4200        118.727915  0.007886    0.000000    0.140194    125.024173 
[37m[36mINFO[0m[0m 01/26 22:52:42 | 0.479037    0.469134    1.000000    1.000000    0.008029    1.000000    1.000000    0.431529    0.423729    0.480960    0.472561    0.524621    0.511111    4400        124.381625  0.006777    0.000000    0.140742    128.967533 
[37m[36mINFO[0m[0m 01/26 22:55:17 | 0.483209    0.471885    1.000000    1.000000    0.007471    1.000000    1.000000    0.433882    0.427495    0.487053    0.474085    0.528693    0.514074    4600        130.035336  0.006302    0.000000    0.143017    126.483951 
[37m[36mINFO[0m[0m 01/26 22:57:50 | 0.482682    0.472887    0.999117    1.000000    0.007013    0.999117    1.000000    0.433412    0.427495    0.487053    0.475610    0.527582    0.515556    4800        135.689046  0.006178    0.000000    0.141358    124.306041 
[37m[36mINFO[0m[0m 01/26 23:00:27 | 0.485485    0.476252    1.000000    1.000000    0.006570    1.000000    1.000000    0.436235    0.433145    0.488195    0.475610    0.532025    0.520000    5000        141.342756  0.005401    0.000000    0.148661    126.916700 
[37m[36mINFO[0m[0m 01/26 23:00:28 | Cumulative gradient change saved at train_output/VLCS/CORAL/[1, 2, 3]/250126_21-53-21_resnet50_sgd/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 01/26 23:00:29 | ---
[37m[36mINFO[0m[0m 01/26 23:00:29 | test-domain validation(oracle) = 48.549%
[37m[36mINFO[0m[0m 01/26 23:00:29 | training-domain validation(iid) = 46.251%
[37m[36mINFO[0m[0m 01/26 23:00:29 | last = 48.549%
[37m[36mINFO[0m[0m 01/26 23:00:29 | last (inD) = 100.000%
[37m[36mINFO[0m[0m 01/26 23:00:29 | training-domain validation (iid, inD) = 100.000%
[37m[36mINFO[0m[0m 01/26 23:00:29 | === Summary ===
[37m[36mINFO[0m[0m 01/26 23:00:29 | Command: /jsm0707/Large-scale/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm CORAL --test_envs 1 2 3 --dataset VLCS
[37m[36mINFO[0m[0m 01/26 23:00:29 | Unique name: 250126_21-53-21_resnet50_sgd
[37m[36mINFO[0m[0m 01/26 23:00:29 | Out path: train_output/VLCS/CORAL/[1, 2, 3]/250126_21-53-21_resnet50_sgd
[37m[36mINFO[0m[0m 01/26 23:00:29 | Algorithm: CORAL
[37m[36mINFO[0m[0m 01/26 23:00:29 | Dataset: VLCS
