[37m[36mINFO[0m[0m 02/06 16:12:13 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 1 --dataset VLCS --trial_seed 0 --hparams_seed 0
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/VLCS/CORAL/[1]/250206_16-12-13_resnet50_GENIE
	out_root: train_output/VLCS/CORAL/[1]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [1]
	trial_seed: 0
	unique_name: 250206_16-12-13_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	mmd_gamma: 1.0
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 02/06 16:12:13 | n_steps = 5001
[37m[36mINFO[0m[0m 02/06 16:12:13 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/06 16:12:13 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/06 16:12:13 | 
[37m[36mINFO[0m[0m 02/06 16:12:13 | Testenv name escaping te_L -> te_L
[37m[36mINFO[0m[0m 02/06 16:12:13 | Test envs = [1], name = te_L
[37m[36mINFO[0m[0m 02/06 16:12:13 | Train environments: [0, 2, 3], Test environments: [1]
[37m[36mINFO[0m[0m 02/06 16:12:13 | Batch sizes for each domain: [32, 0, 32, 32] (total=96)
[37m[36mINFO[0m[0m 02/06 16:12:13 | steps-per-epoch for each domain: 35.38, 82.06, 84.41 -> min = 35.38
[37m[36mINFO[0m[0m 02/06 16:12:14 | # of params = 23518277
[37m[36mINFO[0m[0m 02/06 16:14:43 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 02/06 16:14:43 | 0.459765    0.489642    0.479821    0.487365    1.429644    0.611307    0.628975    0.459765    0.489642    0.384615    0.387195    0.443539    0.445926    0           0.000000    1.800286    0.042625    1.077914    147.356549 
[37m[36mINFO[0m[0m 02/06 16:18:19 | 0.639529    0.632768    0.914008    0.889527    0.303930    0.998233    1.000000    0.639529    0.632768    0.853008    0.804878    0.890781    0.863704    200         5.653710    0.399343    0.030156    0.300289    156.059171 
[37m[36mINFO[0m[0m 02/06 16:22:10 | 0.670588    0.659134    0.920756    0.894974    0.307686    0.998233    1.000000    0.670588    0.659134    0.862148    0.806402    0.901888    0.878519    400         11.307420   0.234851    0.021611    0.334679    164.007915 
[37m[36mINFO[0m[0m 02/06 16:26:04 | 0.663529    0.664783    0.945037    0.888306    0.310799    1.000000    0.996466    0.663529    0.664783    0.901752    0.800305    0.933358    0.868148    600         16.961131   0.188283    0.019225    0.311805    171.548549 
[37m[36mINFO[0m[0m 02/06 16:29:51 | 0.648941    0.653484    0.951918    0.887001    0.319880    0.999117    1.000000    0.648941    0.653484    0.916984    0.798780    0.939652    0.862222    800         22.614841   0.148770    0.018370    0.291147    169.002591 
[37m[36mINFO[0m[0m 02/06 16:33:46 | 0.641882    0.634652    0.958531    0.887784    0.335651    1.000000    0.996466    0.641882    0.634652    0.919650    0.797256    0.955942    0.869630    1000        28.268551   0.127715    0.016504    0.326443    169.416888 
[37m[36mINFO[0m[0m 02/06 16:37:32 | 0.657412    0.647834    0.977934    0.890819    0.343792    1.000000    0.996466    0.657412    0.647834    0.962681    0.804878    0.971122    0.871111    1200        33.922261   0.095880    0.016416    0.308774    164.795228 
[37m[36mINFO[0m[0m 02/06 16:41:20 | 0.648471    0.630885    0.981439    0.891445    0.366607    1.000000    1.000000    0.648471    0.630885    0.968012    0.798780    0.976305    0.875556    1400        39.575972   0.078728    0.015561    0.310906    165.967431 
[37m[36mINFO[0m[0m 02/06 16:45:08 | 0.667765    0.670433    0.983177    0.886972    0.405173    1.000000    1.000000    0.667765    0.670433    0.969155    0.795732    0.980378    0.865185    1600        45.229682   0.061475    0.015202    0.314538    164.435360 
[37m[36mINFO[0m[0m 02/06 16:49:08 | 0.656000    0.668550    0.987458    0.892068    0.420983    1.000000    1.000000    0.656000    0.668550    0.978294    0.812500    0.984080    0.863704    1800        50.883392   0.050108    0.014152    0.366697    167.108285 
[37m[36mINFO[0m[0m 02/06 16:52:50 | 0.645176    0.647834    0.987421    0.891488    0.402078    0.999117    1.000000    0.645176    0.647834    0.979436    0.803354    0.983710    0.871111    2000        56.537102   0.047540    0.013469    0.313019    159.515253 
[37m[36mINFO[0m[0m 02/06 16:56:47 | 0.607059    0.600753    0.973477    0.877760    0.469012    1.000000    0.992933    0.607059    0.600753    0.961158    0.801829    0.959274    0.838519    2200        62.190813   0.037430    0.012733    0.350964    166.838371 
[37m[36mINFO[0m[0m 02/06 17:00:31 | 0.595765    0.574388    0.991069    0.882874    0.470297    1.000000    0.996466    0.595765    0.574388    0.981721    0.800305    0.991485    0.851852    2400        67.844523   0.035822    0.011958    0.321692    158.909429 
[37m[36mINFO[0m[0m 02/06 17:04:24 | 0.639529    0.627119    0.995987    0.889527    0.447603    1.000000    1.000000    0.639529    0.627119    0.993145    0.804878    0.994817    0.863704    2600        73.498233   0.030345    0.011397    0.352192    162.825839 
[37m[36mINFO[0m[0m 02/06 17:08:10 | 0.629176    0.613936    0.994489    0.887433    0.471864    1.000000    0.996466    0.629176    0.613936    0.991241    0.812500    0.992225    0.853333    2800        79.151943   0.024754    0.011383    0.323375    161.302203 
[37m[36mINFO[0m[0m 02/06 17:12:03 | 0.647529    0.644068    0.995065    0.881672    0.506753    0.999117    0.996466    0.647529    0.644068    0.992003    0.777439    0.994076    0.871111    3000        84.805654   0.022872    0.010434    0.347654    163.485129 
[37m[36mINFO[0m[0m 02/06 17:15:39 | 0.668706    0.676083    0.993971    0.893392    0.508337    1.000000    1.000000    0.668706    0.676083    0.988576    0.795732    0.993336    0.884444    3200        90.459364   0.019099    0.010280    0.315800    153.368159 
[37m[36mINFO[0m[0m 02/06 17:19:26 | 0.660706    0.659134    0.996104    0.881483    0.498050    1.000000    1.000000    0.660706    0.659134    0.992384    0.789634    0.995927    0.854815    3400        96.113074   0.017920    0.009638    0.313253    163.929929 
[37m[36mINFO[0m[0m 02/06 17:23:04 | 0.640941    0.634652    0.997754    0.890050    0.490917    1.000000    1.000000    0.640941    0.634652    0.997334    0.807927    0.995927    0.862222    3600        101.766784  0.015751    0.009499    0.279352    162.303229 
[37m[36mINFO[0m[0m 02/06 17:26:49 | 0.642824    0.630885    0.996241    0.890107    0.520049    1.000000    1.000000    0.642824    0.630885    0.993907    0.814024    0.994817    0.856296    3800        107.420495  0.012013    0.009021    0.315923    161.971694 
[37m[36mINFO[0m[0m 02/06 17:30:31 | 0.607059    0.598870    0.998879    0.888392    0.490053    1.000000    0.996466    0.607059    0.598870    0.998858    0.809451    0.997779    0.859259    4000        113.074205  0.009234    0.008470    0.300040    161.707315 
[37m[36mINFO[0m[0m 02/06 17:34:15 | 0.654118    0.653484    0.998614    0.887044    0.515401    1.000000    1.000000    0.654118    0.653484    0.996954    0.803354    0.998889    0.857778    4200        118.727915  0.010056    0.008172    0.325928    158.424047 
[37m[36mINFO[0m[0m 02/06 17:37:59 | 0.608000    0.595104    0.997112    0.885344    0.496371    1.000000    0.996466    0.608000    0.595104    0.994669    0.800305    0.996668    0.859259    4400        124.381625  0.009222    0.007916    0.288566    166.444072 
[37m[36mINFO[0m[0m 02/06 17:41:42 | 0.634353    0.627119    0.998258    0.891849    0.518123    1.000000    0.996466    0.634353    0.627119    0.998477    0.809451    0.996298    0.869630    4600        130.035336  0.008140    0.007857    0.313208    160.782037 
[37m[36mINFO[0m[0m 02/06 17:45:20 | 0.624000    0.612053    0.997881    0.883022    0.517549    1.000000    1.000000    0.624000    0.612053    0.997715    0.795732    0.995927    0.853333    4800        135.689046  0.009005    0.007504    0.305564    156.774207 
[37m[36mINFO[0m[0m 02/06 17:49:04 | 0.639059    0.632768    0.998868    0.890064    0.481965    1.000000    1.000000    0.639059    0.632768    0.997715    0.809451    0.998889    0.860741    5000        141.342756  0.007140    0.007148    0.336251    157.009749 
[37m[36mINFO[0m[0m 02/06 17:49:04 | Cumulative gradient change saved at train_output/VLCS/CORAL/[1]/250206_16-12-13_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/06 17:49:06 | ---
[37m[36mINFO[0m[0m 02/06 17:49:06 | test-domain validation(oracle) = 66.871%
[37m[36mINFO[0m[0m 02/06 17:49:06 | training-domain validation(iid) = 67.059%
[37m[36mINFO[0m[0m 02/06 17:49:06 | last = 63.906%
[37m[36mINFO[0m[0m 02/06 17:49:06 | last (inD) = 89.006%
[37m[36mINFO[0m[0m 02/06 17:49:06 | training-domain validation (iid, inD) = 89.497%
[37m[36mINFO[0m[0m 02/06 17:49:06 | === Summary ===
[37m[36mINFO[0m[0m 02/06 17:49:06 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 1 --dataset VLCS --trial_seed 0 --hparams_seed 0
[37m[36mINFO[0m[0m 02/06 17:49:06 | Unique name: 250206_16-12-13_resnet50_GENIE
[37m[36mINFO[0m[0m 02/06 17:49:06 | Out path: train_output/VLCS/CORAL/[1]/250206_16-12-13_resnet50_GENIE
[37m[36mINFO[0m[0m 02/06 17:49:06 | Algorithm: CORAL
[37m[36mINFO[0m[0m 02/06 17:49:06 | Dataset: VLCS
