[37m[36mINFO[0m[0m 01/27 09:24:15 | Command :: /jsm0707/DomainBed/Large-scale/train_all.py resnet50_EVE config/resnet50_EVE.yaml --algorithm CORAL --test_envs 1 --dataset VLCS --trial_seed 0 --hparams_seed 16
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 9.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_EVE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 16
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_EVE
	out_dir: train_output/VLCS/CORAL/[1]/250127_09-24-15_resnet50_EVE
	out_root: train_output/VLCS/CORAL/[1]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [1]
	trial_seed: 0
	unique_name: 250127_09-24-15_resnet50_EVE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: GENIE
	freeze_bn: False
	pretrained: True
	lr: 4.249952708249365e-05
	batch_size: 17
	weight_decay: 9.786966598736845e-06
	mmd_gamma: 1.0088701382180452
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 01/27 09:24:15 | n_steps = 5001
[37m[36mINFO[0m[0m 01/27 09:24:15 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 01/27 09:24:15 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 01/27 09:24:15 | Target test envs = [[1]]
[37m[36mINFO[0m[0m 01/27 09:24:15 | 
[37m[36mINFO[0m[0m 01/27 09:24:15 | Testenv name escaping te_L -> te_L
[37m[36mINFO[0m[0m 01/27 09:24:15 | Test envs = [1], name = te_L
[37m[36mINFO[0m[0m 01/27 09:24:15 | Batch sizes for each domain: [17, 0, 17, 17] (total=51)
[37m[36mINFO[0m[0m 01/27 09:24:15 | steps-per-epoch for each domain: 66.59, 154.47, 158.88 -> min = 66.59
[37m[36mINFO[0m[0m 01/27 09:24:16 | # of params = 23518277
[37m[36mINFO[0m[0m 01/27 09:26:30 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 01/27 09:26:30 | 0.459765    0.489642    0.479944    0.487365    1.298931    0.611307    0.628975    0.459765    0.489642    0.384615    0.387195    0.443910    0.445926    0           0.000000    1.752585    0.059044    1.282558    132.364661 
[37m[36mINFO[0m[0m 01/27 09:29:25 | 0.643765    0.636535    0.898465    0.877371    0.334767    0.996466    0.996466    0.643765    0.636535    0.837395    0.792683    0.861533    0.842963    200         3.003534    0.405681    0.036346    0.196260    135.609089 
[37m[36mINFO[0m[0m 01/27 09:32:25 | 0.656471    0.638418    0.902039    0.869862    0.374187    0.997350    0.989399    0.656471    0.638418    0.831683    0.769817    0.877083    0.850370    400         6.007067    0.263933    0.024870    0.210364    137.473553 
[37m[36mINFO[0m[0m 01/27 09:35:17 | 0.703529    0.693032    0.908176    0.867497    0.359523    0.998233    0.992933    0.703529    0.693032    0.836253    0.760671    0.890041    0.848889    600         9.010601    0.226021    0.021560    0.184733    135.291549 
[37m[36mINFO[0m[0m 01/27 09:38:12 | 0.679529    0.670433    0.937942    0.896047    0.305868    0.998233    1.000000    0.679529    0.670433    0.892232    0.815549    0.923362    0.872593    800         12.014134   0.207715    0.020275    0.197886    135.739741 
[37m[36mINFO[0m[0m 01/27 09:41:03 | 0.648000    0.647834    0.947452    0.889148    0.326896    1.000000    1.000000    0.648000    0.647834    0.909368    0.817073    0.932988    0.850370    1000        15.017668   0.168764    0.019339    0.181005    134.210323 
[37m[36mINFO[0m[0m 01/27 09:44:00 | 0.644235    0.647834    0.941919    0.892253    0.354155    0.996466    0.992933    0.644235    0.647834    0.905560    0.820122    0.923732    0.863704    1200        18.021201   0.148853    0.018071    0.203813    136.126295 
[37m[36mINFO[0m[0m 01/27 09:46:54 | 0.640000    0.638418    0.966009    0.895045    0.326850    1.000000    1.000000    0.640000    0.638418    0.940975    0.814024    0.957053    0.871111    1400        21.024735   0.136007    0.016959    0.194382    135.124642 
[37m[36mINFO[0m[0m 01/27 09:49:45 | 0.623529    0.623352    0.964729    0.889964    0.336987    1.000000    1.000000    0.623529    0.623352    0.936024    0.798780    0.958164    0.871111    1600        24.028269   0.135308    0.016482    0.185208    134.374996 
[37m[36mINFO[0m[0m 01/27 09:52:40 | 0.627765    0.636535    0.951963    0.875105    0.420146    0.997350    0.992933    0.627765    0.636535    0.918888    0.782012    0.939652    0.850370    1800        27.031802   0.114188    0.016437    0.199751    134.606969 
[37m[36mINFO[0m[0m 01/27 09:55:33 | 0.573647    0.570621    0.960248    0.868876    0.373396    0.998233    0.996466    0.573647    0.570621    0.928789    0.782012    0.953721    0.828148    2000        30.035336   0.099719    0.016064    0.189052    135.072514 
[37m[36mINFO[0m[0m 01/27 09:58:23 | 0.622118    0.621469    0.967088    0.884067    0.411565    1.000000    1.000000    0.622118    0.621469    0.950876    0.801829    0.950389    0.850370    2200        33.038869   0.095539    0.015591    0.190557    132.175915 
[37m[36mINFO[0m[0m 01/27 10:01:16 | 0.599529    0.574388    0.962344    0.878867    0.399121    0.999117    0.996466    0.599529    0.574388    0.936786    0.794207    0.951129    0.845926    2400        36.042403   0.097517    0.014440    0.192395    134.787291 
[37m[36mINFO[0m[0m 01/27 10:04:06 | 0.623529    0.615819    0.979260    0.885111    0.406815    1.000000    1.000000    0.623529    0.615819    0.959254    0.807927    0.978526    0.847407    2600        39.045936   0.072034    0.014908    0.185586    132.804741 
[37m[36mINFO[0m[0m 01/27 10:06:58 | 0.663059    0.661017    0.981342    0.889978    0.392438    0.999117    1.000000    0.663059    0.661017    0.962681    0.800305    0.982229    0.869630    2800        42.049470   0.075036    0.014029    0.198981    132.534847 
[37m[36mINFO[0m[0m 01/27 10:09:58 | 0.581647    0.570621    0.978475    0.873462    0.497449    0.999117    0.989399    0.581647    0.570621    0.959634    0.785061    0.976675    0.845926    3000        45.053004   0.054239    0.014271    0.225259    134.845629 
[37m[36mINFO[0m[0m 01/27 10:12:51 | 0.583059    0.572505    0.982677    0.876948    0.409460    1.000000    0.996466    0.583059    0.572505    0.968393    0.800305    0.979637    0.834074    3200        48.056537   0.058839    0.012957    0.196407    133.035870 
[37m[36mINFO[0m[0m 01/27 10:15:51 | 0.617882    0.610169    0.984295    0.871316    0.491606    1.000000    0.996466    0.617882    0.610169    0.969916    0.778963    0.982969    0.838519    3400        51.060071   0.038505    0.014104    0.217322    136.540612 
[37m[36mINFO[0m[0m 01/27 10:18:42 | 0.647059    0.640301    0.994358    0.884446    0.493926    1.000000    1.000000    0.647059    0.640301    0.990480    0.789634    0.992595    0.863704    3600        54.063604   0.031520    0.013048    0.192962    133.027580 
[37m[36mINFO[0m[0m 01/27 10:21:38 | 0.639529    0.644068    0.991434    0.884067    0.463753    0.999117    1.000000    0.639529    0.644068    0.986291    0.801829    0.988893    0.850370    3800        57.067138   0.040633    0.012181    0.218002    132.010005 
[37m[36mINFO[0m[0m 01/27 10:24:33 | 0.620235    0.613936    0.991964    0.884251    0.488835    1.000000    0.992933    0.620235    0.613936    0.985149    0.809451    0.990744    0.850370    4000        60.070671   0.050975    0.011675    0.198190    135.050709 
[37m[36mINFO[0m[0m 01/27 10:27:31 | 0.636235    0.634652    0.990092    0.876573    0.502885    1.000000    1.000000    0.636235    0.634652    0.982864    0.792683    0.987412    0.837037    4200        63.074205   0.038561    0.012528    0.212814    135.857550 
[37m[36mINFO[0m[0m 01/27 10:30:23 | 0.633412    0.632768    0.995236    0.887044    0.486401    1.000000    1.000000    0.633412    0.632768    0.992003    0.803354    0.993706    0.857778    4400        66.077739   0.033250    0.011997    0.199124    132.659502 
[37m[36mINFO[0m[0m 01/27 10:33:22 | 0.636235    0.632768    0.994990    0.890093    0.457541    1.000000    1.000000    0.636235    0.632768    0.992003    0.812500    0.992966    0.857778    4600        69.081272   0.020776    0.011419    0.219444    134.224219 
[37m[36mINFO[0m[0m 01/27 10:36:16 | 0.603765    0.587571    0.993604    0.871734    0.532747    1.000000    0.992933    0.603765    0.587571    0.988957    0.791159    0.991855    0.831111    4800        72.084806   0.017549    0.011508    0.202004    133.987862 
[37m[36mINFO[0m[0m 01/27 10:39:08 | 0.622118    0.615819    0.996365    0.880362    0.475086    1.000000    0.996466    0.622118    0.615819    0.993907    0.795732    0.995187    0.848889    5000        75.088339   0.025999    0.010262    0.181195    135.721503 
[37m[36mINFO[0m[0m 01/27 10:39:08 | Cumulative gradient change saved at train_output/VLCS/CORAL/[1]/250127_09-24-15_resnet50_EVE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 01/27 10:39:09 | ---
[37m[36mINFO[0m[0m 01/27 10:39:09 | test-domain validation(oracle) = 70.353%
[37m[36mINFO[0m[0m 01/27 10:39:09 | training-domain validation(iid) = 67.953%
[37m[36mINFO[0m[0m 01/27 10:39:09 | last = 62.212%
[37m[36mINFO[0m[0m 01/27 10:39:09 | last (inD) = 88.036%
[37m[36mINFO[0m[0m 01/27 10:39:09 | training-domain validation (iid, inD) = 89.605%
[37m[36mINFO[0m[0m 01/27 10:39:09 | === Summary ===
[37m[36mINFO[0m[0m 01/27 10:39:09 | Command: /jsm0707/DomainBed/Large-scale/train_all.py resnet50_EVE config/resnet50_EVE.yaml --algorithm CORAL --test_envs 1 --dataset VLCS --trial_seed 0 --hparams_seed 16
[37m[36mINFO[0m[0m 01/27 10:39:09 | Unique name: 250127_09-24-15_resnet50_EVE
[37m[36mINFO[0m[0m 01/27 10:39:09 | Out path: train_output/VLCS/CORAL/[1]/250127_09-24-15_resnet50_EVE
[37m[36mINFO[0m[0m 01/27 10:39:09 | Algorithm: CORAL
[37m[36mINFO[0m[0m 01/27 10:39:09 | Dataset: VLCS
[37m[36mINFO[0m[0m 01/27 10:39:09 | Max test_in: 0.7035
