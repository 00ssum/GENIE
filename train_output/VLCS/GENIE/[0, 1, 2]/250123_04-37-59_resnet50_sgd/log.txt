[37m[36mINFO[0m[0m 01/23 04:37:59 | Command :: /jsm0707/DomainBed/Large-scale/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm GENIE --test_envs 0 1 2 --dataset VLCS --trial_seed 1 --hparams_seed 3
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: GENIE
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_sgd.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 3
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_sgd
	out_dir: train_output/VLCS/GENIE/[0, 1, 2]/250123_04-37-59_resnet50_sgd
	out_root: train_output/VLCS/GENIE/[0, 1, 2]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 1, 2]
	trial_seed: 1
	unique_name: 250123_04-37-59_resnet50_sgd
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.5
	class_balanced: False
	optimizer: sgd
	freeze_bn: False
	pretrained: True
	lr: 0.00018664964766736356
	batch_size: 13
	weight_decay: 0.0001969969539389593
	momentum: 0.9565803977949621
	convergence_rate: 0.0028330774780203315
	moving_avg: 0.9695056010375268
	p: 0.6341415393704041
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 01/23 04:37:59 | n_steps = 5001
[37m[36mINFO[0m[0m 01/23 04:37:59 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 01/23 04:37:59 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 01/23 04:37:59 | 
[37m[36mINFO[0m[0m 01/23 04:37:59 | Testenv name escaping te_C_L_S -> te_C_L_S
[37m[36mINFO[0m[0m 01/23 04:37:59 | Test envs = [0, 1, 2], name = te_C_L_S
[37m[36mINFO[0m[0m 01/23 04:37:59 | Train environments: [3], Test environments: [0, 1, 2]
[37m[36mINFO[0m[0m 01/23 04:37:59 | Batch sizes for each domain: [0, 0, 0, 13] (total=13)
[37m[36mINFO[0m[0m 01/23 04:37:59 | steps-per-epoch for each domain: 207.77 -> min = 207.77
[37m[36mINFO[0m[0m 01/23 04:38:00 | # of params = 23518277
[37m[36mINFO[0m[0m 01/23 04:40:15 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 01/23 04:40:15 | 0.145686    0.151869    0.158090    0.174815    1.709296    0.083039    0.102473    0.127059    0.141243    0.226961    0.211890    0.158090    0.174815    0           0.000000    1.831048    0.966793    133.480873 
[37m[36mINFO[0m[0m 01/23 04:43:10 | 0.783405    0.782804    0.862643    0.857778    0.436342    0.963781    0.946996    0.602353    0.602637    0.784082    0.798780    0.862643    0.857778    200         0.962606    0.732423    0.184233    138.279433 
[37m[36mINFO[0m[0m 01/23 04:46:00 | 0.778181    0.767280    0.878934    0.845926    0.421189    0.985866    0.978799    0.566118    0.559322    0.782559    0.763720    0.878934    0.845926    400         1.925213    0.389302    0.162125    136.666338 
[37m[36mINFO[0m[0m 01/23 04:48:54 | 0.775271    0.770831    0.903739    0.845926    0.451735    0.992933    0.985866    0.557176    0.546139    0.775704    0.780488    0.903739    0.845926    600         2.887819    0.346142    0.165614    140.865879 
[37m[36mINFO[0m[0m 01/23 04:51:39 | 0.779845    0.772953    0.900777    0.848889    0.479866    0.992933    0.968198    0.589176    0.576271    0.757426    0.774390    0.900777    0.848889    800         3.850426    0.297420    0.142393    136.577120 
[37m[36mINFO[0m[0m 01/23 04:54:34 | 0.790523    0.791845    0.911144    0.848889    0.455611    0.994700    0.985866    0.598118    0.596987    0.778751    0.792683    0.911144    0.848889    1000        4.813032    0.258720    0.179785    138.807787 
[37m[36mINFO[0m[0m 01/23 04:57:33 | 0.757360    0.756980    0.911884    0.850370    0.439480    0.996466    0.982332    0.528471    0.538606    0.747144    0.750000    0.911884    0.850370    1200        5.775639    0.247486    0.211128    137.270179 
[37m[36mINFO[0m[0m 01/23 05:00:34 | 0.788781    0.793548    0.930766    0.865185    0.458072    0.994700    0.985866    0.580706    0.583804    0.790937    0.810976    0.930766    0.865185    1400        6.738245    0.250880    0.219769    137.108540 
[37m[36mINFO[0m[0m 01/23 05:03:36 | 0.803514    0.799170    0.941133    0.866667    0.437108    0.994700    0.985866    0.652706    0.640301    0.763138    0.771341    0.941133    0.866667    1600        7.700852    0.205470    0.210073    139.350091 
[37m[36mINFO[0m[0m 01/23 05:06:28 | 0.801157    0.789747    0.938171    0.872593    0.431579    0.985866    0.975265    0.632000    0.619586    0.785605    0.774390    0.938171    0.872593    1800        8.663458    0.197263    0.177265    135.927979 
[37m[36mINFO[0m[0m 01/23 05:09:16 | 0.807982    0.813499    0.957793    0.875556    0.392784    0.995583    0.989399    0.648471    0.655367    0.779893    0.795732    0.957793    0.875556    2000        9.626064    0.157206    0.145226    139.210257 
[37m[36mINFO[0m[0m 01/23 05:12:07 | 0.795101    0.781246    0.947797    0.869630    0.414444    0.984099    0.971731    0.617882    0.608286    0.783321    0.763720    0.947797    0.869630    2200        10.588671   0.182648    0.170693    136.064992 
[37m[36mINFO[0m[0m 01/23 05:15:00 | 0.801372    0.793167    0.957423    0.860741    0.491389    0.995583    0.978799    0.634353    0.630885    0.774181    0.769817    0.957423    0.860741    2400        11.551277   0.128128    0.203004    132.628691 
[37m[36mINFO[0m[0m 01/23 05:18:04 | 0.801622    0.799348    0.949648    0.851852    0.616765    0.992049    0.968198    0.642824    0.647834    0.769992    0.782012    0.949648    0.851852    2600        12.513884   0.130875    0.217064    140.809233 
[37m[36mINFO[0m[0m 01/23 05:21:00 | 0.803761    0.797394    0.967790    0.859259    0.492688    0.995583    0.982332    0.632000    0.630885    0.783701    0.778963    0.967790    0.859259    2800        13.476490   0.152179    0.200786    136.169249 
[37m[36mINFO[0m[0m 01/23 05:23:50 | 0.781230    0.779296    0.958164    0.860741    0.501580    0.985866    0.961131    0.590118    0.593220    0.767708    0.783537    0.958164    0.860741    3000        14.439097   0.127314    0.182407    132.813995 
[37m[36mINFO[0m[0m 01/23 05:26:40 | 0.801964    0.805793    0.964458    0.860741    0.520605    0.988516    0.982332    0.618824    0.627119    0.798553    0.807927    0.964458    0.860741    3200        15.401703   0.115960    0.152784    140.028500 
[37m[36mINFO[0m[0m 01/23 05:29:27 | 0.782746    0.776283    0.975194    0.847407    0.551165    0.992049    0.971731    0.583529    0.578154    0.772658    0.778963    0.975194    0.847407    3400        16.364310   0.099639    0.155713    135.886556 
[37m[36mINFO[0m[0m 01/23 05:32:14 | 0.781834    0.771506    0.984450    0.854815    0.584127    0.985866    0.964664    0.581647    0.580038    0.777989    0.769817    0.984450    0.854815    3600        17.326916   0.067136    0.168745    132.951967 
[37m[36mINFO[0m[0m 01/23 05:35:03 | 0.784770    0.778341    0.952610    0.837037    0.542435    0.983216    0.978799    0.611765    0.621469    0.759330    0.734756    0.952610    0.837037    3800        18.289522   0.087187    0.157784    137.946038 
[37m[36mINFO[0m[0m 01/23 05:38:12 | 0.796052    0.791792    0.979637    0.865185    0.576845    0.992933    0.978799    0.624471    0.625235    0.770754    0.771341    0.979637    0.865185    4000        19.252129   0.083513    0.240137    140.416811 
[37m[36mINFO[0m[0m 01/23 05:41:07 | 0.793313    0.787050    0.991114    0.859259    0.563538    0.984099    0.964664    0.595765    0.600753    0.800076    0.795732    0.991114    0.859259    4200        20.214735   0.076859    0.186089    137.829459 
[37m[36mINFO[0m[0m 01/23 05:43:58 | 0.768943    0.774370    0.973343    0.845926    0.627762    0.971731    0.971731    0.554824    0.580038    0.780274    0.771341    0.973343    0.845926    4400        21.177342   0.057288    0.171032    136.649075 
[37m[36mINFO[0m[0m 01/23 05:46:46 | 0.792937    0.790673    0.984450    0.860741    0.611591    0.991166    0.975265    0.604706    0.610169    0.782940    0.786585    0.984450    0.860741    4600        22.139948   0.058104    0.161169    135.634452 
[37m[36mINFO[0m[0m 01/23 05:49:38 | 0.800689    0.812441    0.980378    0.860741    0.663638    0.990283    0.985866    0.641412    0.657250    0.770373    0.794207    0.980378    0.860741    4800        23.102555   0.062283    0.183848    135.943668 
[37m[36mINFO[0m[0m 01/23 05:52:26 | 0.776670    0.776397    0.977046    0.850370    0.843011    0.984982    0.978799    0.568941    0.566855    0.776085    0.783537    0.977046    0.850370    5000        24.065161   0.049908    0.181011    130.920981 
[37m[36mINFO[0m[0m 01/23 05:52:26 | Cumulative gradient change saved at train_output/VLCS/GENIE/[0, 1, 2]/250123_04-37-59_resnet50_sgd/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 01/23 05:52:27 | ---
[37m[36mINFO[0m[0m 01/23 05:52:27 | test-domain validation(oracle) = 80.798%
[37m[36mINFO[0m[0m 01/23 05:52:27 | training-domain validation(iid) = 80.798%
[37m[36mINFO[0m[0m 01/23 05:52:27 | last = 77.667%
[37m[36mINFO[0m[0m 01/23 05:52:27 | last (inD) = 85.037%
[37m[36mINFO[0m[0m 01/23 05:52:27 | training-domain validation (iid, inD) = 87.556%
[37m[36mINFO[0m[0m 01/23 05:52:27 | === Summary ===
[37m[36mINFO[0m[0m 01/23 05:52:27 | Command: /jsm0707/DomainBed/Large-scale/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm GENIE --test_envs 0 1 2 --dataset VLCS --trial_seed 1 --hparams_seed 3
[37m[36mINFO[0m[0m 01/23 05:52:27 | Unique name: 250123_04-37-59_resnet50_sgd
[37m[36mINFO[0m[0m 01/23 05:52:27 | Out path: train_output/VLCS/GENIE/[0, 1, 2]/250123_04-37-59_resnet50_sgd
[37m[36mINFO[0m[0m 01/23 05:52:27 | Algorithm: GENIE
[37m[36mINFO[0m[0m 01/23 05:52:27 | Dataset: VLCS
