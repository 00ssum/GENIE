[37m[36mINFO[0m[0m 03/15 04:54:03 | Command :: /jsm0707/GENIE/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm GENIE --test_envs 0 1 2 --dataset VLCS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: GENIE
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_adam.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_adam
	out_dir: train_output/VLCS/GENIE/[0, 1, 2]/250315_04-54-03_resnet50_adam
	out_root: train_output/VLCS/GENIE/[0, 1, 2]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 1, 2]
	trial_seed: 0
	unique_name: 250315_04-54-03_resnet50_adam
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: adam
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	momentum: 0.9
	convergence_rate: 0.015
	moving_avg: 0.95
	p: 0.4
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 03/15 04:54:04 | n_steps = 5001
[37m[36mINFO[0m[0m 03/15 04:54:04 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/15 04:54:04 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/15 04:54:04 | 
[37m[36mINFO[0m[0m 03/15 04:54:04 | Testenv name escaping te_C_L_S -> te_C_L_S
[37m[36mINFO[0m[0m 03/15 04:54:04 | Test envs = [0, 1, 2], name = te_C_L_S
[37m[36mINFO[0m[0m 03/15 04:54:04 | Train environments: [3], Test environments: [0, 1, 2]
[37m[36mINFO[0m[0m 03/15 04:54:04 | Batch sizes for each domain: [0, 0, 0, 32] (total=32)
[37m[36mINFO[0m[0m 03/15 04:54:04 | steps-per-epoch for each domain: 84.41 -> min = 84.41
[37m[36mINFO[0m[0m 03/15 04:54:04 | # of params = 23518277
[37m[36mINFO[0m[0m 03/15 04:56:10 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/15 04:56:10 | 0.485229    0.501938    0.443539    0.445926    1.683896    0.611307    0.628975    0.459765    0.489642    0.384615    0.387195    0.443539    0.445926    0           0.000000    1.766220    0.916184    125.076536 
[37m[36mINFO[0m[0m 03/15 04:58:50 | 0.741905    0.724541    0.865605    0.817778    0.498202    0.955830    0.954064    0.538353    0.512241    0.731531    0.707317    0.865605    0.817778    200         2.369493    0.535581    0.177313    123.760975 
[37m[36mINFO[0m[0m 03/15 05:01:28 | 0.777447    0.777462    0.907071    0.838519    0.477436    0.979682    0.975265    0.608941    0.610169    0.743717    0.746951    0.907071    0.838519    400         4.738986    0.302901    0.179195    122.736073 
[37m[36mINFO[0m[0m 03/15 05:04:09 | 0.758439    0.749895    0.928545    0.837037    0.470034    0.984982    0.982332    0.539765    0.531073    0.750571    0.736280    0.928545    0.837037    600         7.108478    0.236436    0.173614    125.950575 
[37m[36mINFO[0m[0m 03/15 05:06:50 | 0.779280    0.768810    0.941873    0.826667    0.576035    0.973498    0.971731    0.586353    0.572505    0.777989    0.762195    0.941873    0.826667    800         9.477971    0.172918    0.178810    125.634744 
[37m[36mINFO[0m[0m 03/15 05:09:28 | 0.738993    0.728816    0.955942    0.835556    0.502823    0.969965    0.971731    0.540235    0.534840    0.706778    0.679878    0.955942    0.835556    1000        11.847464   0.179404    0.170069    123.470616 
[37m[36mINFO[0m[0m 03/15 05:12:08 | 0.784907    0.773641    0.966309    0.848889    0.510315    0.959364    0.950530    0.621176    0.615819    0.774181    0.754573    0.966309    0.848889    1200        14.216957   0.120661    0.177839    124.909543 
[37m[36mINFO[0m[0m 03/15 05:14:46 | 0.761853    0.758486    0.959645    0.842963    0.677499    0.969965    0.968198    0.570353    0.572505    0.745240    0.734756    0.959645    0.842963    1400        16.586449   0.098192    0.167470    124.576210 
[37m[36mINFO[0m[0m 03/15 05:17:24 | 0.778627    0.776870    0.947797    0.828148    0.970577    0.973498    0.968198    0.616000    0.613936    0.746382    0.748476    0.947797    0.828148    1600        18.955942   0.084144    0.167359    123.838630 
[37m[36mINFO[0m[0m 03/15 05:20:02 | 0.755895    0.740755    0.984450    0.845926    0.666595    0.966431    0.975265    0.567059    0.544256    0.734196    0.702744    0.984450    0.845926    1800        21.325435   0.100765    0.173061    123.358177 
[37m[36mINFO[0m[0m 03/15 05:22:41 | 0.741363    0.725588    0.980378    0.807407    0.862188    0.978799    0.971731    0.541176    0.516008    0.704113    0.689024    0.980378    0.807407    2000        23.694928   0.065345    0.171677    124.790342 
[37m[36mINFO[0m[0m 03/15 05:25:20 | 0.761685    0.764853    0.929285    0.831111    0.626463    0.943463    0.950530    0.610824    0.621469    0.730769    0.722561    0.929285    0.831111    2200        26.064421   0.072646    0.175315    124.063453 
[37m[36mINFO[0m[0m 03/15 05:27:56 | 0.783443    0.774168    0.987412    0.862222    0.687536    0.976148    0.982332    0.600000    0.593220    0.774181    0.746951    0.987412    0.862222    2400        28.433913   0.087655    0.168179    122.097788 
[37m[36mINFO[0m[0m 03/15 05:30:40 | 0.753557    0.733167    0.996298    0.842963    0.726651    0.960247    0.950530    0.556706    0.538606    0.743717    0.710366    0.996298    0.842963    2600        30.803406   0.022123    0.200734    124.054120 
[37m[36mINFO[0m[0m 03/15 05:33:22 | 0.766868    0.758994    0.992966    0.847407    0.758640    0.970848    0.968198    0.588706    0.572505    0.741051    0.736280    0.992966    0.847407    2800        33.172899   0.024741    0.199757    122.585039 
[37m[36mINFO[0m[0m 03/15 05:36:10 | 0.756948    0.731231    0.990004    0.826667    0.787273    0.968198    0.961131    0.570353    0.540490    0.732292    0.692073    0.990004    0.826667    3000        35.542392   0.033917    0.214999    124.856545 
[37m[36mINFO[0m[0m 03/15 05:39:01 | 0.773154    0.769164    0.990004    0.832593    0.739398    0.969965    0.961131    0.602353    0.617702    0.747144    0.728659    0.990004    0.832593    3200        37.911884   0.039637    0.236167    123.576240 
[37m[36mINFO[0m[0m 03/15 05:41:50 | 0.766105    0.756531    0.993336    0.834074    0.857660    0.966431    0.964664    0.585882    0.576271    0.746002    0.728659    0.993336    0.834074    3400        40.281377   0.021283    0.230194    123.222322 
[37m[36mINFO[0m[0m 03/15 05:44:43 | 0.761048    0.748204    0.991485    0.835556    0.727607    0.974382    0.968198    0.576471    0.570621    0.732292    0.705793    0.991485    0.835556    3600        42.650870   0.038145    0.239635    124.241745 
[37m[36mINFO[0m[0m 03/15 05:47:36 | 0.782270    0.773546    0.987412    0.848889    0.980032    0.962898    0.957597    0.623059    0.625235    0.760853    0.737805    0.987412    0.848889    3800        45.020363   0.015514    0.239713    125.663957 
[37m[36mINFO[0m[0m 03/15 05:50:26 | 0.776447    0.758037    0.996668    0.854815    0.734664    0.974382    0.950530    0.591059    0.578154    0.763899    0.745427    0.996668    0.854815    4000        47.389856   0.030443    0.241677    121.082282 
[37m[36mINFO[0m[0m 03/15 05:53:16 | 0.734043    0.718018    0.988893    0.816296    0.894811    0.937279    0.925795    0.553882    0.549906    0.710967    0.678354    0.988893    0.816296    4200        49.759348   0.012778    0.238628    122.841227 
[37m[36mINFO[0m[0m 03/15 05:56:12 | 0.776554    0.768471    0.977786    0.845926    0.973103    0.974382    0.968198    0.612706    0.617702    0.742574    0.719512    0.977786    0.845926    4400        52.128841   0.024872    0.254724    125.324001 
[37m[36mINFO[0m[0m 03/15 05:59:09 | 0.778192    0.771519    0.999260    0.848889    0.908665    0.971731    0.968198    0.592471    0.585687    0.770373    0.760671    0.999260    0.848889    4600        54.498334   0.005838    0.258265    124.759587 
[37m[36mINFO[0m[0m 03/15 06:01:47 | 0.749347    0.736815    0.988523    0.829630    0.810675    0.975265    0.968198    0.543529    0.527307    0.729246    0.714939    0.988523    0.829630    4800        56.867827   0.016546    0.173753    123.402593 
[37m[36mINFO[0m[0m 03/15 06:04:25 | 0.765637    0.770431    0.987042    0.835556    0.754914    0.954947    0.964664    0.586824    0.595104    0.755141    0.751524    0.987042    0.835556    5000        59.237320   0.038898    0.185572    121.056185 
[37m[36mINFO[0m[0m 03/15 06:04:25 | Cumulative gradient change saved at train_output/VLCS/GENIE/[0, 1, 2]/250315_04-54-03_resnet50_adam/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/15 06:04:27 | ---
[37m[36mINFO[0m[0m 03/15 06:04:27 | test-domain validation(oracle) = 77.745%
[37m[36mINFO[0m[0m 03/15 06:04:27 | training-domain validation(iid) = 78.344%
[37m[36mINFO[0m[0m 03/15 06:04:27 | last = 76.564%
[37m[36mINFO[0m[0m 03/15 06:04:27 | last (inD) = 83.556%
[37m[36mINFO[0m[0m 03/15 06:04:27 | training-domain validation (iid, inD) = 86.222%
[37m[36mINFO[0m[0m 03/15 06:04:27 | === Summary ===
[37m[36mINFO[0m[0m 03/15 06:04:27 | Command: /jsm0707/GENIE/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm GENIE --test_envs 0 1 2 --dataset VLCS
[37m[36mINFO[0m[0m 03/15 06:04:27 | Unique name: 250315_04-54-03_resnet50_adam
[37m[36mINFO[0m[0m 03/15 06:04:27 | Out path: train_output/VLCS/GENIE/[0, 1, 2]/250315_04-54-03_resnet50_adam
[37m[36mINFO[0m[0m 03/15 06:04:27 | Algorithm: GENIE
[37m[36mINFO[0m[0m 03/15 06:04:27 | Dataset: VLCS
