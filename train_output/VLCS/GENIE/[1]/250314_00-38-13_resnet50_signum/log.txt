[37m[36mINFO[0m[0m 03/14 00:38:13 | Command :: /jsm0707/GENIE/train_all.py resnet50_signum config/resnet50_signum.yaml --algorithm GENIE --test_envs 1 --dataset VLCS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: GENIE
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_signum.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_signum
	out_dir: train_output/VLCS/GENIE/[1]/250314_00-38-13_resnet50_signum
	out_root: train_output/VLCS/GENIE/[1]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [1]
	trial_seed: 0
	unique_name: 250314_00-38-13_resnet50_signum
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: signum
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	momentum: 0.9
	convergence_rate: 0.015
	moving_avg: 0.95
	p: 0.4
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 03/14 00:38:13 | n_steps = 5001
[37m[36mINFO[0m[0m 03/14 00:38:13 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/14 00:38:13 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/14 00:38:13 | 
[37m[36mINFO[0m[0m 03/14 00:38:13 | Testenv name escaping te_L -> te_L
[37m[36mINFO[0m[0m 03/14 00:38:13 | Test envs = [1], name = te_L
[37m[36mINFO[0m[0m 03/14 00:38:13 | Train environments: [0, 2, 3], Test environments: [1]
[37m[36mINFO[0m[0m 03/14 00:38:13 | Batch sizes for each domain: [32, 0, 32, 32] (total=96)
[37m[36mINFO[0m[0m 03/14 00:38:13 | steps-per-epoch for each domain: 35.38, 82.06, 84.41 -> min = 35.38
[37m[36mINFO[0m[0m 03/14 00:38:14 | # of params = 23518277
[37m[36mINFO[0m[0m 03/14 00:40:24 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/14 00:40:24 | 0.459765    0.489642    0.479821    0.487365    1.428250    0.611307    0.628975    0.459765    0.489642    0.384615    0.387195    0.443539    0.445926    0           0.000000    1.800293    1.112366    129.417678 
[37m[36mINFO[0m[0m 03/14 00:43:48 | 0.624471    0.610169    0.912574    0.890093    0.296482    0.997350    1.000000    0.624471    0.610169    0.849962    0.812500    0.890411    0.857778    200         5.653710    0.378081    0.356535    132.366952 
[37m[36mINFO[0m[0m 03/14 00:46:58 | 0.669647    0.664783    0.925887    0.894959    0.301355    0.998233    1.000000    0.669647    0.664783    0.869764    0.804878    0.909663    0.880000    400         11.307420   0.225504    0.280811    133.965143 
[37m[36mINFO[0m[0m 03/14 00:50:01 | 0.624941    0.621469    0.940213    0.888511    0.324184    1.000000    1.000000    0.624941    0.621469    0.887281    0.801829    0.933358    0.863704    600         16.961131   0.183122    0.254961    131.377447 
[37m[36mINFO[0m[0m 03/14 00:53:02 | 0.650824    0.645951    0.956891    0.891327    0.317298    0.998233    0.996466    0.650824    0.645951    0.926123    0.806402    0.946316    0.871111    800         22.614841   0.143777    0.244659    132.271346 
[37m[36mINFO[0m[0m 03/14 00:56:01 | 0.627765    0.625235    0.963319    0.894855    0.330942    1.000000    0.996466    0.627765    0.625235    0.930312    0.814024    0.959645    0.874074    1000        28.268551   0.125981    0.243699    130.855683 
[37m[36mINFO[0m[0m 03/14 00:59:02 | 0.641882    0.649718    0.974553    0.889788    0.413716    1.000000    0.996466    0.641882    0.649718    0.957350    0.800305    0.966309    0.872593    1200        33.922261   0.092454    0.245940    131.641700 
[37m[36mINFO[0m[0m 03/14 01:02:20 | 0.614118    0.610169    0.978936    0.890804    0.425235    1.000000    0.996466    0.614118    0.610169    0.964204    0.803354    0.972603    0.872593    1400        39.575972   0.086633    0.317967    133.689266 
[37m[36mINFO[0m[0m 03/14 01:05:50 | 0.660235    0.666667    0.975189    0.887438    0.470908    0.999117    1.000000    0.660235    0.666667    0.951257    0.792683    0.975194    0.869630    1600        45.229682   0.067329    0.403757    129.551570 
[37m[36mINFO[0m[0m 03/14 01:09:24 | 0.643294    0.651601    0.983357    0.896047    0.402543    1.000000    1.000000    0.643294    0.651601    0.975248    0.815549    0.974824    0.872593    1800        50.883392   0.064083    0.418221    130.476274 
[37m[36mINFO[0m[0m 03/14 01:12:48 | 0.627294    0.627119    0.987557    0.891298    0.475534    1.000000    0.996466    0.627294    0.627119    0.975628    0.803354    0.987042    0.874074    2000        56.537102   0.045939    0.371277    129.994159 
[37m[36mINFO[0m[0m 03/14 01:16:03 | 0.593412    0.587571    0.987342    0.890064    0.524142    1.000000    1.000000    0.593412    0.587571    0.979056    0.809451    0.982969    0.860741    2200        62.190813   0.031807    0.314531    131.469017 
[37m[36mINFO[0m[0m 03/14 01:19:05 | 0.629647    0.615819    0.984387    0.879403    0.635164    0.998233    0.996466    0.629647    0.615819    0.976771    0.798780    0.978156    0.842963    2400        67.844523   0.032286    0.257469    130.479047 
[37m[36mINFO[0m[0m 03/14 01:22:06 | 0.603294    0.587571    0.990966    0.882048    0.459777    1.000000    1.000000    0.603294    0.587571    0.984006    0.797256    0.988893    0.848889    2600        73.498233   0.040014    0.250114    131.491202 
[37m[36mINFO[0m[0m 03/14 01:25:05 | 0.632941    0.636535    0.991189    0.882309    0.598768    1.000000    0.996466    0.632941    0.636535    0.981340    0.792683    0.992225    0.857778    2800        79.151943   0.027517    0.244113    130.445723 
[37m[36mINFO[0m[0m 03/14 01:28:06 | 0.662118    0.659134    0.996745    0.893929    0.605696    1.000000    1.000000    0.662118    0.659134    0.995050    0.800305    0.995187    0.881481    3000        84.805654   0.027659    0.245860    131.160784 
[37m[36mINFO[0m[0m 03/14 01:31:18 | 0.649882    0.638418    0.992525    0.881758    0.615990    1.000000    0.996466    0.649882    0.638418    0.992384    0.786585    0.985191    0.862222    3200        90.459364   0.019676    0.299893    131.960349 
[37m[36mINFO[0m[0m 03/14 01:34:17 | 0.654118    0.645951    0.996499    0.885069    0.674266    1.000000    1.000000    0.654118    0.645951    0.995050    0.803354    0.994447    0.851852    3400        96.113074   0.017182    0.250380    128.966125 
[37m[36mINFO[0m[0m 03/14 01:37:45 | 0.617882    0.612053    0.995240    0.887130    0.593409    1.000000    1.000000    0.617882    0.612053    0.992384    0.812500    0.993336    0.848889    3600        101.766784  0.022260    0.392443    130.220659 
[37m[36mINFO[0m[0m 03/14 01:40:46 | 0.630118    0.625235    0.994711    0.888511    0.578025    1.000000    1.000000    0.630118    0.625235    0.988576    0.801829    0.995557    0.863704    3800        107.420495  0.019310    0.250393    130.498942 
[37m[36mINFO[0m[0m 03/14 01:43:45 | 0.638118    0.612053    0.997870    0.890382    0.608966    1.000000    0.996466    0.638118    0.612053    0.996573    0.810976    0.997038    0.863704    4000        113.074205  0.017753    0.248877    129.488738 
[37m[36mINFO[0m[0m 03/14 01:46:45 | 0.646118    0.625235    0.987603    0.887423    0.718937    1.000000    1.000000    0.646118    0.625235    0.980579    0.791159    0.982229    0.871111    4200        118.727915  0.011476    0.245214    130.731771 
[37m[36mINFO[0m[0m 03/14 01:49:45 | 0.640000    0.625235    0.996612    0.889849    0.564757    1.000000    1.000000    0.640000    0.625235    0.993907    0.786585    0.995927    0.882963    4400        124.381625  0.023836    0.249125    130.469378 
[37m[36mINFO[0m[0m 03/14 01:53:18 | 0.609882    0.613936    0.997867    0.890382    0.693679    1.000000    0.996466    0.609882    0.613936    0.996192    0.810976    0.997408    0.863704    4600        130.035336  0.006449    0.414337    129.924302 
[37m[36mINFO[0m[0m 03/14 01:56:32 | 0.657882    0.645951    0.992733    0.870694    0.689454    1.000000    0.996466    0.657882    0.645951    0.988195    0.765244    0.990004    0.850370    4800        135.689046  0.012438    0.316400    130.737581 
[37m[36mINFO[0m[0m 03/14 01:59:36 | 0.642824    0.623352    0.999379    0.887813    0.676714    1.000000    0.996466    0.642824    0.623352    0.999619    0.800305    0.998519    0.866667    5000        141.342756  0.010962    0.249566    133.741503 
[37m[36mINFO[0m[0m 03/14 01:59:36 | Cumulative gradient change saved at train_output/VLCS/GENIE/[1]/250314_00-38-13_resnet50_signum/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/14 01:59:37 | ---
[37m[36mINFO[0m[0m 03/14 01:59:37 | test-domain validation(oracle) = 66.024%
[37m[36mINFO[0m[0m 03/14 01:59:37 | training-domain validation(iid) = 64.329%
[37m[36mINFO[0m[0m 03/14 01:59:37 | last = 64.282%
[37m[36mINFO[0m[0m 03/14 01:59:37 | last (inD) = 88.781%
[37m[36mINFO[0m[0m 03/14 01:59:37 | training-domain validation (iid, inD) = 89.605%
[37m[36mINFO[0m[0m 03/14 01:59:37 | === Summary ===
[37m[36mINFO[0m[0m 03/14 01:59:37 | Command: /jsm0707/GENIE/train_all.py resnet50_signum config/resnet50_signum.yaml --algorithm GENIE --test_envs 1 --dataset VLCS
[37m[36mINFO[0m[0m 03/14 01:59:37 | Unique name: 250314_00-38-13_resnet50_signum
[37m[36mINFO[0m[0m 03/14 01:59:37 | Out path: train_output/VLCS/GENIE/[1]/250314_00-38-13_resnet50_signum
[37m[36mINFO[0m[0m 03/14 01:59:37 | Algorithm: GENIE
[37m[36mINFO[0m[0m 03/14 01:59:37 | Dataset: VLCS
