[37m[36mINFO[0m[0m 03/14 05:33:25 | Command :: /jsm0707/GENIE/train_all.py B_VLCS1_signum config/resnet50_signum.yaml --trial_seed 1 --hparams_seed 2 --algorithm GENIE --test_envs 1 --dataset VLCS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: GENIE
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_signum.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 2
	in_domain: False
	model_save: None
	mpa: False
	name: B_VLCS1_signum
	out_dir: train_output/VLCS/GENIE/[1]/250314_05-33-25_B_VLCS1_signum
	out_root: train_output/VLCS/GENIE/[1]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [1]
	trial_seed: 1
	unique_name: 250314_05-33-25_B_VLCS1_signum
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.5
	class_balanced: False
	optimizer: signum
	freeze_bn: False
	pretrained: True
	lr: 0.0001126313085293539
	batch_size: 38
	weight_decay: 0.006639128805224463
	momentum: 0.844808580961198
	convergence_rate: 0.0072584840023010066
	moving_avg: 0.9222220369334958
	p: 0.1472838851744452
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 03/14 05:33:25 | n_steps = 5001
[37m[36mINFO[0m[0m 03/14 05:33:25 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/14 05:33:25 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/14 05:33:25 | 
[37m[36mINFO[0m[0m 03/14 05:33:25 | Testenv name escaping te_L -> te_L
[37m[36mINFO[0m[0m 03/14 05:33:25 | Test envs = [1], name = te_L
[37m[36mINFO[0m[0m 03/14 05:33:25 | Train environments: [0, 2, 3], Test environments: [1]
[37m[36mINFO[0m[0m 03/14 05:33:25 | Batch sizes for each domain: [38, 0, 38, 38] (total=114)
[37m[36mINFO[0m[0m 03/14 05:33:25 | steps-per-epoch for each domain: 29.79, 69.11, 71.08 -> min = 29.79
[37m[36mINFO[0m[0m 03/14 05:33:26 | # of params = 23518277
[37m[36mINFO[0m[0m 03/14 05:35:35 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/14 05:35:35 | 0.467294    0.461394    0.499304    0.509453    1.334253    0.613958    0.618375    0.467294    0.461394    0.420792    0.486280    0.463162    0.423704    0           0.000000    1.863111    1.088853    128.158237 
[37m[36mINFO[0m[0m 03/14 05:38:38 | 0.693647    0.681733    0.895247    0.891033    0.307050    0.997350    0.996466    0.693647    0.681733    0.817974    0.827744    0.870418    0.848889    200         6.713781    0.411090    0.270947    129.024646 
[37m[36mINFO[0m[0m 03/14 05:41:44 | 0.635294    0.615819    0.917849    0.907587    0.273004    0.999117    0.996466    0.635294    0.615819    0.849581    0.855183    0.904850    0.871111    400         13.427562   0.249750    0.271462    130.762889 
[37m[36mINFO[0m[0m 03/14 05:44:45 | 0.648471    0.645951    0.931336    0.910882    0.253772    0.999117    0.992933    0.648471    0.645951    0.880046    0.858232    0.914846    0.881481    600         20.141343   0.225608    0.266895    127.841187 
[37m[36mINFO[0m[0m 03/14 05:47:46 | 0.685647    0.674200    0.934527    0.910925    0.287407    0.999117    0.992933    0.685647    0.674200    0.878142    0.862805    0.926324    0.877037    800         26.855124   0.190454    0.270559    127.094989 
[37m[36mINFO[0m[0m 03/14 05:50:49 | 0.595294    0.576271    0.947660    0.897453    0.276807    1.000000    0.996466    0.595294    0.576271    0.905179    0.827744    0.937801    0.868148    1000        33.568905   0.173498    0.265069    129.788746 
[37m[36mINFO[0m[0m 03/14 05:53:52 | 0.657882    0.659134    0.953686    0.905426    0.286668    1.000000    0.996466    0.657882    0.659134    0.916222    0.835366    0.944835    0.884444    1200        40.282686   0.143746    0.270427    129.059335 
[37m[36mINFO[0m[0m 03/14 05:56:56 | 0.677647    0.676083    0.958377    0.908171    0.313561    0.999117    1.000000    0.677647    0.676083    0.921554    0.844512    0.954461    0.880000    1400        46.996466   0.125522    0.282378    127.386956 
[37m[36mINFO[0m[0m 03/14 05:59:58 | 0.666353    0.661017    0.965650    0.905407    0.311145    1.000000    0.992933    0.666353    0.661017    0.928789    0.853659    0.968160    0.869630    1600        53.710247   0.109737    0.269534    128.688728 
[37m[36mINFO[0m[0m 03/14 06:02:59 | 0.651765    0.644068    0.978671    0.896113    0.320950    1.000000    0.989399    0.651765    0.644068    0.962300    0.830793    0.973713    0.868148    1800        60.424028   0.092265    0.265265    127.938548 
[37m[36mINFO[0m[0m 03/14 06:06:03 | 0.640000    0.630885    0.978802    0.891161    0.354824    1.000000    0.989399    0.640000    0.630885    0.963062    0.829268    0.973343    0.854815    2000        67.137809   0.078254    0.267003    130.320956 
[37m[36mINFO[0m[0m 03/14 06:09:05 | 0.664941    0.642185    0.980653    0.897857    0.393208    1.000000    0.992933    0.664941    0.642185    0.963062    0.838415    0.978897    0.862222    2200        73.851590   0.067240    0.267562    128.053724 
[37m[36mINFO[0m[0m 03/14 06:12:09 | 0.630588    0.610169    0.985445    0.891427    0.374989    1.000000    0.996466    0.630588    0.610169    0.974105    0.817073    0.982229    0.860741    2400        80.565371   0.066752    0.264695    130.924473 
[37m[36mINFO[0m[0m 03/14 06:15:10 | 0.653176    0.653484    0.985924    0.899281    0.418510    1.000000    0.992933    0.653176    0.653484    0.972582    0.832317    0.985191    0.872593    2600        87.279152   0.051388    0.261318    129.641592 
[37m[36mINFO[0m[0m 03/14 06:18:17 | 0.649882    0.625235    0.991314    0.894152    0.441578    0.999117    0.989399    0.649882    0.625235    0.986672    0.832317    0.988153    0.860741    2800        93.992933   0.044150    0.272415    131.790349 
[37m[36mINFO[0m[0m 03/14 06:21:19 | 0.652235    0.629002    0.990420    0.896346    0.463847    1.000000    0.992933    0.652235    0.629002    0.978294    0.835366    0.992966    0.860741    3000        100.706714  0.040703    0.266344    129.505779 
[37m[36mINFO[0m[0m 03/14 06:24:25 | 0.691294    0.664783    0.981305    0.884413    0.600785    1.000000    0.996466    0.691294    0.664783    0.966870    0.806402    0.977046    0.850370    3200        107.420495  0.033162    0.272100    130.623385 
[37m[36mINFO[0m[0m 03/14 06:27:26 | 0.636235    0.621469    0.991947    0.891802    0.495612    1.000000    0.992933    0.636235    0.621469    0.983244    0.824695    0.992595    0.857778    3400        114.134276  0.035592    0.271175    127.055073 
[37m[36mINFO[0m[0m 03/14 06:30:30 | 0.626353    0.610169    0.995219    0.891308    0.512160    1.000000    0.992933    0.626353    0.610169    0.990099    0.824695    0.995557    0.856296    3600        120.848057  0.028203    0.277054    129.051321 
[37m[36mINFO[0m[0m 03/14 06:33:39 | 0.625412    0.604520    0.989080    0.887419    0.522377    1.000000    0.996466    0.625412    0.604520    0.980198    0.810976    0.987042    0.854815    3800        127.561837  0.027090    0.273336    133.882989 
[37m[36mINFO[0m[0m 03/14 06:36:40 | 0.618824    0.617702    0.995222    0.892281    0.479047    1.000000    0.992933    0.618824    0.617702    0.990480    0.823171    0.995187    0.860741    4000        134.275618  0.024572    0.263282    128.417402 
[37m[36mINFO[0m[0m 03/14 06:39:43 | 0.661176    0.644068    0.996104    0.902866    0.518465    1.000000    0.992933    0.661176    0.644068    0.992384    0.846037    0.995927    0.869630    4200        140.989399  0.021932    0.267206    130.113676 
[37m[36mINFO[0m[0m 03/14 06:42:46 | 0.655529    0.634652    0.993346    0.892006    0.542667    1.000000    0.996466    0.655529    0.634652    0.987814    0.826220    0.992225    0.853333    4400        147.703180  0.019019    0.264627    129.232752 
[37m[36mINFO[0m[0m 03/14 06:45:48 | 0.659765    0.632768    0.988625    0.894647    0.648191    1.000000    0.996466    0.659765    0.632768    0.984387    0.844512    0.981488    0.842963    4600        154.416961  0.016427    0.273049    127.918632 
[37m[36mINFO[0m[0m 03/14 06:48:52 | 0.667765    0.659134    0.996858    0.900459    0.571388    1.000000    0.996466    0.667765    0.659134    0.993907    0.832317    0.996668    0.872593    4800        161.130742  0.020887    0.267798    130.253511 
[37m[36mINFO[0m[0m 03/14 06:51:58 | 0.595294    0.581921    0.994115    0.884717    0.551162    1.000000    0.992933    0.595294    0.581921    0.990861    0.806402    0.991485    0.854815    5000        167.844523  0.015959    0.267198    132.942495 
[37m[36mINFO[0m[0m 03/14 06:51:58 | Cumulative gradient change saved at train_output/VLCS/GENIE/[1]/250314_05-33-25_B_VLCS1_signum/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/14 06:52:00 | ---
[37m[36mINFO[0m[0m 03/14 06:52:00 | test-domain validation(oracle) = 69.365%
[37m[36mINFO[0m[0m 03/14 06:52:00 | training-domain validation(iid) = 68.565%
[37m[36mINFO[0m[0m 03/14 06:52:00 | last = 59.529%
[37m[36mINFO[0m[0m 03/14 06:52:00 | last (inD) = 88.472%
[37m[36mINFO[0m[0m 03/14 06:52:00 | training-domain validation (iid, inD) = 91.092%
[37m[36mINFO[0m[0m 03/14 06:52:00 | === Summary ===
[37m[36mINFO[0m[0m 03/14 06:52:00 | Command: /jsm0707/GENIE/train_all.py B_VLCS1_signum config/resnet50_signum.yaml --trial_seed 1 --hparams_seed 2 --algorithm GENIE --test_envs 1 --dataset VLCS
[37m[36mINFO[0m[0m 03/14 06:52:00 | Unique name: 250314_05-33-25_B_VLCS1_signum
[37m[36mINFO[0m[0m 03/14 06:52:00 | Out path: train_output/VLCS/GENIE/[1]/250314_05-33-25_B_VLCS1_signum
[37m[36mINFO[0m[0m 03/14 06:52:00 | Algorithm: GENIE
[37m[36mINFO[0m[0m 03/14 06:52:00 | Dataset: VLCS
