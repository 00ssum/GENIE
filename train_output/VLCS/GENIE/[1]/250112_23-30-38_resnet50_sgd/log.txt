[37m[36mINFO[0m[0m 01/12 23:30:38 | Command :: /jsm0707/DomainBed/Large-scale/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm GENIE --test_envs 1 --dataset VLCS --trial_seed 1 --hparams_seed 2
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: GENIE
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_sgd.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 2
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_sgd
	out_dir: train_output/VLCS/GENIE/[1]/250112_23-30-38_resnet50_sgd
	out_root: train_output/VLCS/GENIE/[1]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [1]
	trial_seed: 1
	unique_name: 250112_23-30-38_resnet50_sgd
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.5
	class_balanced: False
	optimizer: sgd
	freeze_bn: False
	pretrained: True
	lr: 0.0001126313085293539
	batch_size: 38
	weight_decay: 0.006639128805224463
	momentum: 0.844808580961198
	convergence_rate: 0.0072584840023010066
	moving_avg: 0.9222220369334958
	p: 0.1472838851744452
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 01/12 23:30:38 | n_steps = 5001
[37m[36mINFO[0m[0m 01/12 23:30:38 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 01/12 23:30:38 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 01/12 23:30:38 | Target test envs = [[1]]
[37m[36mINFO[0m[0m 01/12 23:30:38 | 
[37m[36mINFO[0m[0m 01/12 23:30:38 | Testenv name escaping te_L -> te_L
[37m[36mINFO[0m[0m 01/12 23:30:38 | Test envs = [1], name = te_L
[37m[36mINFO[0m[0m 01/12 23:30:38 | Batch sizes for each domain: [38, 0, 38, 38] (total=114)
[37m[36mINFO[0m[0m 01/12 23:30:38 | steps-per-epoch for each domain: 29.79, 69.11, 71.08 -> min = 29.79
[37m[36mINFO[0m[0m 01/12 23:30:39 | # of params = 23518277
[37m[36mINFO[0m[0m 01/12 23:32:55 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 01/12 23:32:55 | 0.467294    0.461394    0.499304    0.509453    1.334253    0.613958    0.618375    0.467294    0.461394    0.420792    0.486280    0.463162    0.423704    0           0.000000    1.863111    1.179197    135.002412 
[37m[36mINFO[0m[0m 01/12 23:36:15 | 0.693647    0.681733    0.895247    0.891033    0.307050    0.997350    0.996466    0.693647    0.681733    0.817974    0.827744    0.870418    0.848889    200         6.713781    0.411090    0.301402    138.806443 
[37m[36mINFO[0m[0m 01/12 23:39:32 | 0.635294    0.615819    0.917849    0.907587    0.273004    0.999117    0.996466    0.635294    0.615819    0.849581    0.855183    0.904850    0.871111    400         13.427562   0.249750    0.303364    137.024845 
[37m[36mINFO[0m[0m 01/12 23:42:55 | 0.648471    0.645951    0.931336    0.910882    0.253772    0.999117    0.992933    0.648471    0.645951    0.880046    0.858232    0.914846    0.881481    600         20.141343   0.225608    0.334086    135.435811 
[37m[36mINFO[0m[0m 01/12 23:46:14 | 0.685647    0.674200    0.934527    0.910925    0.287407    0.999117    0.992933    0.685647    0.674200    0.878142    0.862805    0.926324    0.877037    800         26.855124   0.190454    0.325095    133.210552 
[37m[36mINFO[0m[0m 01/12 23:49:26 | 0.595294    0.576271    0.947660    0.897453    0.276807    1.000000    0.996466    0.595294    0.576271    0.905179    0.827744    0.937801    0.868148    1000        33.568905   0.173498    0.292609    133.402829 
[37m[36mINFO[0m[0m 01/12 23:52:38 | 0.657882    0.659134    0.953686    0.905426    0.286668    1.000000    0.996466    0.657882    0.659134    0.916222    0.835366    0.944835    0.884444    1200        40.282686   0.143746    0.284799    135.365404 
[37m[36mINFO[0m[0m 01/12 23:55:58 | 0.677647    0.676083    0.958377    0.908171    0.313561    0.999117    1.000000    0.677647    0.676083    0.921554    0.844512    0.954461    0.880000    1400        46.996466   0.125522    0.330159    133.657019 
[37m[36mINFO[0m[0m 01/12 23:59:20 | 0.666353    0.661017    0.965650    0.905407    0.311145    1.000000    0.992933    0.666353    0.661017    0.928789    0.853659    0.968160    0.869630    1600        53.710247   0.109737    0.330688    136.179061 
[37m[36mINFO[0m[0m 01/13 00:02:33 | 0.651765    0.644068    0.978671    0.896113    0.320950    1.000000    0.989399    0.651765    0.644068    0.962300    0.830793    0.973713    0.868148    1800        60.424028   0.092265    0.293947    133.678357 
[37m[36mINFO[0m[0m 01/13 00:05:48 | 0.640000    0.630885    0.978802    0.891161    0.354824    1.000000    0.989399    0.640000    0.630885    0.963062    0.829268    0.973343    0.854815    2000        67.137809   0.078254    0.287103    137.430385 
[37m[36mINFO[0m[0m 01/13 00:09:05 | 0.664941    0.642185    0.980653    0.897857    0.393208    1.000000    0.992933    0.664941    0.642185    0.963062    0.838415    0.978897    0.862222    2200        73.851590   0.067240    0.300618    137.132017 
[37m[36mINFO[0m[0m 01/13 00:12:26 | 0.630588    0.610169    0.985445    0.891427    0.374989    1.000000    0.996466    0.630588    0.610169    0.974105    0.817073    0.982229    0.860741    2400        80.565371   0.066752    0.326339    135.702072 
[37m[36mINFO[0m[0m 01/13 00:15:43 | 0.653176    0.653484    0.985924    0.899281    0.418510    1.000000    0.992933    0.653176    0.653484    0.972582    0.832317    0.985191    0.872593    2600        87.279152   0.051388    0.309236    135.441594 
[37m[36mINFO[0m[0m 01/13 00:18:56 | 0.649882    0.625235    0.991314    0.894152    0.441578    0.999117    0.989399    0.649882    0.625235    0.986672    0.832317    0.988153    0.860741    2800        93.992933   0.044150    0.285606    136.142093 
[37m[36mINFO[0m[0m 01/13 00:22:08 | 0.652235    0.629002    0.990420    0.896346    0.463847    1.000000    0.992933    0.652235    0.629002    0.978294    0.835366    0.992966    0.860741    3000        100.706714  0.040703    0.292168    133.534194 
[37m[36mINFO[0m[0m 01/13 00:25:29 | 0.691294    0.664783    0.981305    0.884413    0.600785    1.000000    0.996466    0.691294    0.664783    0.966870    0.806402    0.977046    0.850370    3200        107.420495  0.033162    0.331948    134.634367 
[37m[36mINFO[0m[0m 01/13 00:28:50 | 0.636235    0.621469    0.991947    0.891802    0.495612    1.000000    0.992933    0.636235    0.621469    0.983244    0.824695    0.992595    0.857778    3400        114.134276  0.035592    0.329067    135.023764 
[37m[36mINFO[0m[0m 01/13 00:32:03 | 0.626353    0.610169    0.995219    0.891308    0.512160    1.000000    0.992933    0.626353    0.610169    0.990099    0.824695    0.995557    0.856296    3600        120.848057  0.028203    0.298227    132.614225 
[37m[36mINFO[0m[0m 01/13 00:35:15 | 0.625412    0.604520    0.989080    0.887419    0.522377    1.000000    0.996466    0.625412    0.604520    0.980198    0.810976    0.987042    0.854815    3800        127.561837  0.027090    0.289745    134.831989 
[37m[36mINFO[0m[0m 01/13 00:38:35 | 0.618824    0.617702    0.995222    0.892281    0.479047    1.000000    0.992933    0.618824    0.617702    0.990480    0.823171    0.995187    0.860741    4000        134.275618  0.024572    0.331130    133.698519 
[37m[36mINFO[0m[0m 01/13 00:41:56 | 0.661176    0.644068    0.996104    0.902866    0.518465    1.000000    0.992933    0.661176    0.644068    0.992384    0.846037    0.995927    0.869630    4200        140.989399  0.021932    0.326889    135.131425 
[37m[36mINFO[0m[0m 01/13 00:45:13 | 0.655529    0.634652    0.993346    0.892006    0.542667    1.000000    0.996466    0.655529    0.634652    0.987814    0.826220    0.992225    0.853333    4400        147.703180  0.019019    0.303406    136.312407 
[37m[36mINFO[0m[0m 01/13 00:48:25 | 0.659765    0.632768    0.988625    0.894647    0.648191    1.000000    0.996466    0.659765    0.632768    0.984387    0.844512    0.981488    0.842963    4600        154.416961  0.016427    0.284852    135.058737 
[37m[36mINFO[0m[0m 01/13 00:51:46 | 0.667765    0.659134    0.996858    0.900459    0.571388    1.000000    0.996466    0.667765    0.659134    0.993907    0.832317    0.996668    0.872593    4800        161.130742  0.020887    0.322948    136.994799 
[37m[36mINFO[0m[0m 01/13 00:55:08 | 0.595294    0.581921    0.994115    0.884717    0.551162    1.000000    0.992933    0.595294    0.581921    0.990861    0.806402    0.991485    0.854815    5000        167.844523  0.015959    0.328806    136.062531 
[37m[36mINFO[0m[0m 01/13 00:55:08 | ---
[37m[36mINFO[0m[0m 01/13 00:55:08 | test-domain validation(oracle) = 69.365%
[37m[36mINFO[0m[0m 01/13 00:55:08 | training-domain validation(iid) = 68.565%
[37m[36mINFO[0m[0m 01/13 00:55:08 | last = 59.529%
[37m[36mINFO[0m[0m 01/13 00:55:08 | last (inD) = 88.472%
[37m[36mINFO[0m[0m 01/13 00:55:08 | training-domain validation (iid, inD) = 91.092%
[37m[36mINFO[0m[0m 01/13 00:55:08 | === Summary ===
[37m[36mINFO[0m[0m 01/13 00:55:08 | Command: /jsm0707/DomainBed/Large-scale/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm GENIE --test_envs 1 --dataset VLCS --trial_seed 1 --hparams_seed 2
[37m[36mINFO[0m[0m 01/13 00:55:08 | Unique name: 250112_23-30-38_resnet50_sgd
[37m[36mINFO[0m[0m 01/13 00:55:08 | Out path: train_output/VLCS/GENIE/[1]/250112_23-30-38_resnet50_sgd
[37m[36mINFO[0m[0m 01/13 00:55:08 | Algorithm: GENIE
[37m[36mINFO[0m[0m 01/13 00:55:08 | Dataset: VLCS
[37m[36mINFO[0m[0m 01/13 00:55:08 | Max test_in: 0.6936
