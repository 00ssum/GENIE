[37m[36mINFO[0m[0m 03/15 00:04:23 | Command :: /jsm0707/GENIE/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm GENIE --test_envs 1 2 3 --dataset VLCS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: GENIE
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_adam.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_adam
	out_dir: train_output/VLCS/GENIE/[1, 2, 3]/250315_00-04-23_resnet50_adam
	out_root: train_output/VLCS/GENIE/[1, 2, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [1, 2, 3]
	trial_seed: 0
	unique_name: 250315_00-04-23_resnet50_adam
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: adam
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	momentum: 0.9
	convergence_rate: 0.015
	moving_avg: 0.95
	p: 0.4
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 03/15 00:04:23 | n_steps = 5001
[37m[36mINFO[0m[0m 03/15 00:04:23 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/15 00:04:23 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/15 00:04:23 | 
[37m[36mINFO[0m[0m 03/15 00:04:23 | Testenv name escaping te_L_S_V -> te_L_S_V
[37m[36mINFO[0m[0m 03/15 00:04:23 | Test envs = [1, 2, 3], name = te_L_S_V
[37m[36mINFO[0m[0m 03/15 00:04:23 | Train environments: [0], Test environments: [1, 2, 3]
[37m[36mINFO[0m[0m 03/15 00:04:23 | Batch sizes for each domain: [32, 0, 0, 0] (total=32)
[37m[36mINFO[0m[0m 03/15 00:04:23 | steps-per-epoch for each domain: 35.38 -> min = 35.38
[37m[36mINFO[0m[0m 03/15 00:04:24 | # of params = 23518277
[37m[36mINFO[0m[0m 03/15 00:06:22 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/15 00:06:22 | 0.429307    0.440921    0.611307    0.628975    1.009365    0.611307    0.628975    0.459765    0.489642    0.384615    0.387195    0.443539    0.445926    0           0.000000    1.820007    1.467764    116.296668 
[37m[36mINFO[0m[0m 03/15 00:08:51 | 0.526213    0.508156    1.000000    0.996466    0.003611    1.000000    0.996466    0.486118    0.467043    0.531988    0.513720    0.560533    0.543704    200         5.653710    0.036457    0.149319    119.010367 
[37m[36mINFO[0m[0m 03/15 00:11:33 | 0.523669    0.505820    1.000000    0.996466    0.002769    1.000000    0.996466    0.482824    0.468927    0.535796    0.513720    0.552388    0.534815    400         11.307420   0.000034    0.214677    119.027210 
[37m[36mINFO[0m[0m 03/15 00:14:07 | 0.520535    0.507910    1.000000    0.996466    0.003692    1.000000    0.996466    0.478118    0.468927    0.539985    0.525915    0.543502    0.528889    600         16.961131   0.000054    0.155090    122.789426 
[37m[36mINFO[0m[0m 03/15 00:16:47 | 0.516389    0.503394    1.000000    1.000000    0.001542    1.000000    1.000000    0.476235    0.468927    0.533130    0.518293    0.539800    0.522963    800         22.614841   0.000014    0.201381    120.072264 
[37m[36mINFO[0m[0m 03/15 00:19:17 | 0.516665    0.501122    1.000000    1.000000    0.001549    1.000000    1.000000    0.474824    0.465160    0.533892    0.515244    0.541281    0.522963    1000        28.268551   0.000019    0.157918    118.506106 
[37m[36mINFO[0m[0m 03/15 00:22:01 | 0.517930    0.500106    1.000000    1.000000    0.001426    1.000000    1.000000    0.475294    0.465160    0.533511    0.512195    0.544983    0.522963    1200        33.922261   0.000009    0.199956    123.375293 
[37m[36mINFO[0m[0m 03/15 00:24:30 | 0.516092    0.499075    1.000000    1.000000    0.001136    1.000000    1.000000    0.476235    0.465160    0.527799    0.507622    0.544243    0.524444    1400        39.575972   0.000009    0.146493    120.239472 
[37m[36mINFO[0m[0m 03/15 00:27:18 | 0.519869    0.503458    1.000000    1.000000    0.001672    1.000000    1.000000    0.476235    0.463277    0.535796    0.515244    0.547575    0.531852    1600        45.229682   0.000009    0.211151    125.120779 
[37m[36mINFO[0m[0m 03/15 00:29:51 | 0.519872    0.503458    1.000000    1.000000    0.001688    1.000000    1.000000    0.476235    0.463277    0.536177    0.515244    0.547205    0.531852    1800        50.883392   0.000006    0.145082    124.201115 
[37m[36mINFO[0m[0m 03/15 00:32:24 | 0.541902    0.519934    1.000000    1.000000    0.001429    1.000000    1.000000    0.488471    0.468927    0.555598    0.544207    0.581636    0.546667    2000        56.537102   0.000019    0.143089    124.928415 
[37m[36mINFO[0m[0m 03/15 00:35:01 | 0.539832    0.518304    1.000000    1.000000    0.001070    1.000000    1.000000    0.487529    0.467043    0.552551    0.542683    0.579415    0.545185    2200        62.190813   0.000006    0.184389    120.116145 
[37m[36mINFO[0m[0m 03/15 00:37:45 | 0.537951    0.515806    1.000000    1.000000    0.001078    1.000000    1.000000    0.487059    0.467043    0.552932    0.539634    0.573862    0.540741    2400        67.844523   0.000008    0.211699    121.632161 
[37m[36mINFO[0m[0m 03/15 00:40:21 | 0.517354    0.502512    1.000000    1.000000    0.001822    1.000000    1.000000    0.479059    0.470810    0.509139    0.515244    0.563865    0.521481    2600        73.498233   0.000034    0.176486    120.899100 
[37m[36mINFO[0m[0m 03/15 00:42:50 | 0.536546    0.512906    1.000000    1.000000    0.000112    1.000000    1.000000    0.485647    0.468927    0.545316    0.532012    0.578675    0.537778    2800        79.151943   0.000023    0.142278    120.356268 
[37m[36mINFO[0m[0m 03/15 00:45:21 | 0.538009    0.516045    1.000000    1.000000    0.000128    1.000000    1.000000    0.484706    0.470810    0.550647    0.536585    0.578675    0.540741    3000        84.805654   0.000004    0.148054    121.088322 
[37m[36mINFO[0m[0m 03/15 00:47:56 | 0.538319    0.514924    1.000000    1.000000    0.000145    1.000000    1.000000    0.485647    0.468927    0.550267    0.536585    0.579045    0.539259    3200        90.459364   0.000003    0.176083    119.610313 
[37m[36mINFO[0m[0m 03/15 00:50:36 | 0.539115    0.516913    1.000000    1.000000    0.000165    1.000000    1.000000    0.486118    0.468927    0.552551    0.538110    0.578675    0.543704    3400        96.113074   0.000004    0.213381    117.885527 
[37m[36mINFO[0m[0m 03/15 00:53:05 | 0.539783    0.516434    1.000000    1.000000    0.000206    1.000000    1.000000    0.486588    0.468927    0.554455    0.539634    0.578304    0.540741    3600        101.766784  0.000003    0.148090    119.464019 
[37m[36mINFO[0m[0m 03/15 00:55:37 | 0.539245    0.515418    1.000000    1.000000    0.000192    1.000000    1.000000    0.486118    0.468927    0.553313    0.536585    0.578304    0.540741    3800        107.420495  0.000003    0.149952    121.662181 
[37m[36mINFO[0m[0m 03/15 00:58:03 | 0.538995    0.515911    1.000000    1.000000    0.000177    1.000000    1.000000    0.486118    0.468927    0.552932    0.536585    0.577934    0.542222    4000        113.074205  0.000002    0.146674    116.855144 
[37m[36mINFO[0m[0m 03/15 01:00:43 | 0.537664    0.514804    1.000000    1.000000    0.000203    1.000000    1.000000    0.484706    0.467043    0.553313    0.538110    0.574972    0.539259    4200        118.727915  0.000003    0.205920    118.530925 
[37m[36mINFO[0m[0m 03/15 01:03:21 | 0.529678    0.511904    1.000000    1.000000    0.000087    1.000000    1.000000    0.480000    0.468927    0.539985    0.530488    0.569049    0.536296    4400        124.381625  0.000007    0.178204    122.293958 
[37m[36mINFO[0m[0m 03/15 01:05:50 | 0.535044    0.512786    1.000000    1.000000    0.000133    1.000000    1.000000    0.482824    0.467043    0.551409    0.533537    0.570900    0.537778    4600        130.035336  0.000004    0.146429    119.792866 
[37m[36mINFO[0m[0m 03/15 01:08:17 | 0.533442    0.512292    1.000000    1.000000    0.000128    1.000000    1.000000    0.481412    0.467043    0.549124    0.533537    0.569789    0.536296    4800        135.689046  0.000003    0.142430    118.274569 
[37m[36mINFO[0m[0m 03/15 01:10:49 | 0.533315    0.512292    1.000000    1.000000    0.000130    1.000000    1.000000    0.481412    0.467043    0.548743    0.533537    0.569789    0.536296    5000        141.342756  0.000002    0.172746    117.658359 
[37m[36mINFO[0m[0m 03/15 01:10:49 | Cumulative gradient change saved at train_output/VLCS/GENIE/[1, 2, 3]/250315_00-04-23_resnet50_adam/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/15 01:10:50 | ---
[37m[36mINFO[0m[0m 03/15 01:10:50 | test-domain validation(oracle) = 54.190%
[37m[36mINFO[0m[0m 03/15 01:10:50 | training-domain validation(iid) = 51.639%
[37m[36mINFO[0m[0m 03/15 01:10:50 | last = 53.331%
[37m[36mINFO[0m[0m 03/15 01:10:50 | last (inD) = 100.000%
[37m[36mINFO[0m[0m 03/15 01:10:50 | training-domain validation (iid, inD) = 100.000%
[37m[36mINFO[0m[0m 03/15 01:10:51 | === Summary ===
[37m[36mINFO[0m[0m 03/15 01:10:51 | Command: /jsm0707/GENIE/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm GENIE --test_envs 1 2 3 --dataset VLCS
[37m[36mINFO[0m[0m 03/15 01:10:51 | Unique name: 250315_00-04-23_resnet50_adam
[37m[36mINFO[0m[0m 03/15 01:10:51 | Out path: train_output/VLCS/GENIE/[1, 2, 3]/250315_00-04-23_resnet50_adam
[37m[36mINFO[0m[0m 03/15 01:10:51 | Algorithm: GENIE
[37m[36mINFO[0m[0m 03/15 01:10:51 | Dataset: VLCS
