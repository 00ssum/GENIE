[37m[36mINFO[0m[0m 01/23 06:59:54 | Command :: /jsm0707/DomainBed/Large-scale/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm gsnr1224 --test_envs 1 2 3 --dataset VLCS --trial_seed 1 --hparams_seed 3
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: gsnr1224
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_sgd.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 3
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_sgd
	out_dir: train_output/VLCS/gsnr1224/[1, 2, 3]/250123_06-59-54_resnet50_sgd
	out_root: train_output/VLCS/gsnr1224/[1, 2, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [1, 2, 3]
	trial_seed: 1
	unique_name: 250123_06-59-54_resnet50_sgd
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.5
	class_balanced: False
	optimizer: sgd
	freeze_bn: False
	pretrained: True
	lr: 0.00018664964766736356
	batch_size: 13
	weight_decay: 0.0001969969539389593
	momentum: 0.9565803977949621
	convergence_rate: 0.0028330774780203315
	moving_avg: 0.9695056010375268
	p: 0.6341415393704041
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 01/23 06:59:54 | n_steps = 5001
[37m[36mINFO[0m[0m 01/23 06:59:54 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 01/23 06:59:54 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 01/23 06:59:54 | 
[37m[36mINFO[0m[0m 01/23 06:59:54 | Testenv name escaping te_L_S_V -> te_L_S_V
[37m[36mINFO[0m[0m 01/23 06:59:54 | Test envs = [1, 2, 3], name = te_L_S_V
[37m[36mINFO[0m[0m 01/23 06:59:54 | Train environments: [0], Test environments: [1, 2, 3]
[37m[36mINFO[0m[0m 01/23 06:59:54 | Batch sizes for each domain: [13, 0, 0, 0] (total=13)
[37m[36mINFO[0m[0m 01/23 06:59:54 | steps-per-epoch for each domain: 87.08 -> min = 87.08
[37m[36mINFO[0m[0m 01/23 06:59:56 | # of params = 23518277
[37m[36mINFO[0m[0m 01/23 07:02:12 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 01/23 07:02:12 | 0.233600    0.231950    0.460247    0.399293    1.499255    0.460247    0.399293    0.297882    0.284369    0.243717    0.250000    0.159200    0.161481    0           0.000000    1.960658    2.278742    133.330714 
[37m[36mINFO[0m[0m 01/23 07:04:58 | 0.610002    0.602975    0.999117    1.000000    0.000995    0.999117    1.000000    0.568471    0.580038    0.618812    0.605183    0.642725    0.623704    200         2.296820    0.123305    0.166417    132.550960 
[37m[36mINFO[0m[0m 01/23 07:07:51 | 0.582652    0.586737    1.000000    1.000000    0.000297    1.000000    1.000000    0.539765    0.546139    0.604341    0.605183    0.603850    0.608889    400         4.593640    0.002407    0.167804    139.665162 
[37m[36mINFO[0m[0m 01/23 07:10:58 | 0.571739    0.574540    1.000000    1.000000    0.000227    1.000000    1.000000    0.517647    0.521657    0.595202    0.596037    0.602369    0.605926    600         6.890459    0.000935    0.260483    134.328882 
[37m[36mINFO[0m[0m 01/23 07:13:51 | 0.548884    0.556361    1.000000    1.000000    0.000197    1.000000    1.000000    0.481882    0.489642    0.573877    0.585366    0.590892    0.594074    800         9.187279    0.001428    0.190135    134.883946 
[37m[36mINFO[0m[0m 01/23 07:16:40 | 0.571196    0.571939    1.000000    1.000000    0.000182    1.000000    1.000000    0.500235    0.504708    0.603580    0.605183    0.609774    0.605926    1000        11.484099   0.000209    0.172129    135.162123 
[37m[36mINFO[0m[0m 01/23 07:19:29 | 0.540865    0.551472    1.000000    1.000000    0.000607    1.000000    1.000000    0.487529    0.483992    0.557502    0.580793    0.577564    0.589630    1200        13.780919   0.000872    0.171177    133.983209 
[37m[36mINFO[0m[0m 01/23 07:22:20 | 0.564740    0.570655    1.000000    1.000000    0.000181    1.000000    1.000000    0.497412    0.500942    0.594440    0.602134    0.602369    0.608889    1400        16.077739   0.000284    0.175888    136.187437 
[37m[36mINFO[0m[0m 01/23 07:25:17 | 0.573469    0.577308    1.000000    1.000000    0.000137    1.000000    1.000000    0.502588    0.510358    0.604341    0.608232    0.613476    0.613333    1600        18.374558   0.000193    0.216867    133.752254 
[37m[36mINFO[0m[0m 01/23 07:28:28 | 0.573370    0.579868    1.000000    1.000000    0.000152    1.000000    1.000000    0.503529    0.512241    0.599772    0.603659    0.616809    0.623704    1800        20.671378   0.000237    0.266087    137.860333 
[37m[36mINFO[0m[0m 01/23 07:31:18 | 0.634092    0.634406    1.000000    1.000000    0.000112    1.000000    1.000000    0.568471    0.568738    0.661462    0.672256    0.672344    0.662222    2000        22.968198   0.000857    0.161589    137.540764 
[37m[36mINFO[0m[0m 01/23 07:34:06 | 0.616512    0.612934    1.000000    1.000000    0.000130    1.000000    1.000000    0.566588    0.563089    0.629855    0.637195    0.653091    0.638519    2200        25.265018   0.000219    0.168732    134.305063 
[37m[36mINFO[0m[0m 01/23 07:36:52 | 0.622175    0.622906    0.999117    1.000000    0.000072    0.999117    1.000000    0.560941    0.561205    0.645088    0.661585    0.660496    0.645926    2400        27.561837   0.000097    0.162397    133.277293 
[37m[36mINFO[0m[0m 01/23 07:40:02 | 0.590742    0.596758    1.000000    1.000000    0.000083    1.000000    1.000000    0.528471    0.538606    0.618431    0.625000    0.625324    0.626667    2600        29.858657   0.000199    0.268759    135.852851 
[37m[36mINFO[0m[0m 01/23 07:43:01 | 0.592225    0.591988    1.000000    1.000000    0.000069    1.000000    1.000000    0.528000    0.534840    0.622239    0.618902    0.626435    0.622222    2800        32.155477   0.000024    0.234661    131.807394 
[37m[36mINFO[0m[0m 01/23 07:45:43 | 0.591944    0.590972    1.000000    1.000000    0.000067    1.000000    1.000000    0.527529    0.534840    0.622239    0.615854    0.626064    0.622222    3000        34.452297   0.000034    0.162408    130.098951 
[37m[36mINFO[0m[0m 01/23 07:48:31 | 0.580799    0.589908    1.000000    1.000000    0.000184    1.000000    1.000000    0.519059    0.532957    0.603199    0.621951    0.620141    0.614815    3200        36.749117   0.003408    0.157338    136.407861 
[37m[36mINFO[0m[0m 01/23 07:51:18 | 0.573825    0.586126    1.000000    1.000000    0.000319    1.000000    1.000000    0.516235    0.529190    0.591394    0.615854    0.613847    0.613333    3400        39.045936   0.000084    0.175442    132.160894 
[37m[36mINFO[0m[0m 01/23 07:54:27 | 0.574094    0.584122    1.000000    1.000000    0.000115    1.000000    1.000000    0.508706    0.529190    0.598248    0.612805    0.615328    0.610370    3600        41.342756   0.000151    0.292883    130.301224 
[37m[36mINFO[0m[0m 01/23 07:57:12 | 0.566425    0.580608    1.000000    1.000000    0.000281    1.000000    1.000000    0.511529    0.529190    0.587966    0.606707    0.599778    0.605926    3800        43.639576   0.000147    0.162327    132.611251 
[37m[36mINFO[0m[0m 01/23 07:59:55 | 0.564579    0.577334    1.000000    1.000000    0.000281    1.000000    1.000000    0.510118    0.525424    0.586062    0.602134    0.597556    0.604444    4000        45.936396   0.000086    0.149193    132.810216 
[37m[36mINFO[0m[0m 01/23 08:02:44 | 0.569101    0.578724    1.000000    1.000000    0.000191    1.000000    1.000000    0.510588    0.531073    0.591013    0.602134    0.605702    0.602963    4200        48.233216   0.000041    0.155580    137.907093 
[37m[36mINFO[0m[0m 01/23 08:05:55 | 0.573103    0.580608    1.000000    1.000000    0.000115    1.000000    1.000000    0.510588    0.529190    0.596725    0.606707    0.611996    0.605926    4400        50.530035   0.000053    0.282254    134.209644 
[37m[36mINFO[0m[0m 01/23 08:08:45 | 0.573174    0.580312    1.000000    1.000000    0.000052    1.000000    1.000000    0.502118    0.517891    0.602818    0.608232    0.614587    0.614815    4600        52.826855   0.000162    0.175063    135.350673 
[37m[36mINFO[0m[0m 01/23 08:11:31 | 0.571092    0.578831    1.000000    1.000000    0.000044    1.000000    1.000000    0.498824    0.517891    0.603199    0.608232    0.611255    0.610370    4800        55.123675   0.000055    0.162538    133.561842 
[37m[36mINFO[0m[0m 01/23 08:14:20 | 0.569738    0.579127    1.000000    1.000000    0.000085    1.000000    1.000000    0.505412    0.521657    0.592917    0.611280    0.610885    0.604444    5000        57.420495   0.000142    0.161085    137.238829 
[37m[36mINFO[0m[0m 01/23 08:14:21 | Cumulative gradient change saved at train_output/VLCS/gsnr1224/[1, 2, 3]/250123_06-59-54_resnet50_sgd/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 01/23 08:14:22 | ---
[37m[36mINFO[0m[0m 01/23 08:14:22 | test-domain validation(oracle) = 63.409%
[37m[36mINFO[0m[0m 01/23 08:14:22 | training-domain validation(iid) = 61.000%
[37m[36mINFO[0m[0m 01/23 08:14:22 | last = 56.974%
[37m[36mINFO[0m[0m 01/23 08:14:22 | last (inD) = 100.000%
[37m[36mINFO[0m[0m 01/23 08:14:22 | training-domain validation (iid, inD) = 100.000%
[37m[36mINFO[0m[0m 01/23 08:14:22 | === Summary ===
[37m[36mINFO[0m[0m 01/23 08:14:22 | Command: /jsm0707/DomainBed/Large-scale/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm gsnr1224 --test_envs 1 2 3 --dataset VLCS --trial_seed 1 --hparams_seed 3
[37m[36mINFO[0m[0m 01/23 08:14:22 | Unique name: 250123_06-59-54_resnet50_sgd
[37m[36mINFO[0m[0m 01/23 08:14:22 | Out path: train_output/VLCS/gsnr1224/[1, 2, 3]/250123_06-59-54_resnet50_sgd
[37m[36mINFO[0m[0m 01/23 08:14:22 | Algorithm: gsnr1224
[37m[36mINFO[0m[0m 01/23 08:14:22 | Dataset: VLCS
