[37m[36mINFO[0m[0m 03/13 22:06:15 | Command :: /jsm0707/GENIE/train_all.py resnet50_signum config/resnet50_signum.yaml --algorithm GENIE --test_envs 0 --dataset VLCS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: GENIE
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_signum.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_signum
	out_dir: train_output/VLCS/GENIE/[0]/250313_22-06-15_resnet50_signum
	out_root: train_output/VLCS/GENIE/[0]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0]
	trial_seed: 0
	unique_name: 250313_22-06-15_resnet50_signum
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: signum
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	momentum: 0.9
	convergence_rate: 0.015
	moving_avg: 0.95
	p: 0.4
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 03/13 22:06:15 | n_steps = 5001
[37m[36mINFO[0m[0m 03/13 22:06:15 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/13 22:06:15 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/13 22:06:15 | 
[37m[36mINFO[0m[0m 03/13 22:06:15 | Testenv name escaping te_C -> te_C
[37m[36mINFO[0m[0m 03/13 22:06:15 | Test envs = [0], name = te_C
[37m[36mINFO[0m[0m 03/13 22:06:15 | Train environments: [1, 2, 3], Test environments: [0]
[37m[36mINFO[0m[0m 03/13 22:06:15 | Batch sizes for each domain: [0, 32, 32, 32] (total=96)
[37m[36mINFO[0m[0m 03/13 22:06:15 | steps-per-epoch for each domain: 66.41, 82.06, 84.41 -> min = 66.41
[37m[36mINFO[0m[0m 03/13 22:06:17 | # of params = 23518277
[37m[36mINFO[0m[0m 03/13 22:08:32 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/13 22:08:32 | 0.611307    0.628975    0.429430    0.440921    1.325308    0.611307    0.628975    0.459765    0.489642    0.384615    0.387195    0.443910    0.445926    0           0.000000    1.786248    1.577886    133.270270 
[37m[36mINFO[0m[0m 03/13 22:14:40 | 0.979682    0.982332    0.818708    0.802204    0.525977    0.979682    0.982332    0.765647    0.766478    0.826352    0.794207    0.864124    0.845926    200         3.011765    0.613265    1.154960    137.024721 
[37m[36mINFO[0m[0m 03/13 22:20:53 | 0.990283    0.989399    0.851513    0.815031    0.506724    0.990283    0.989399    0.787765    0.777778    0.867479    0.812500    0.899297    0.854815    400         6.023529    0.439934    1.185668    136.136483 
[37m[36mINFO[0m[0m 03/13 22:26:59 | 0.978799    0.978799    0.863587    0.806043    0.537001    0.978799    0.978799    0.815059    0.770245    0.882331    0.806402    0.893373    0.841481    600         9.035294    0.382308    1.137133    138.223536 
[37m[36mINFO[0m[0m 03/13 22:33:05 | 0.980565    0.975265    0.889591    0.808271    0.567184    0.980565    0.975265    0.842824    0.781544    0.905179    0.800305    0.920770    0.842963    800         12.047059   0.337380    1.146938    136.657612 
[37m[36mINFO[0m[0m 03/13 22:39:07 | 0.973498    0.964664    0.882848    0.779324    0.624137    0.973498    0.964664    0.836706    0.726930    0.876999    0.760671    0.934839    0.850370    1000        15.058824   0.288833    1.135509    134.995466 
[37m[36mINFO[0m[0m 03/13 22:45:06 | 0.972615    0.978799    0.924023    0.806383    0.608359    0.972615    0.978799    0.876706    0.747646    0.938309    0.803354    0.957053    0.868148    1200        18.070588   0.247545    1.110452    136.782896 
[37m[36mINFO[0m[0m 03/13 22:51:16 | 0.973498    0.982332    0.902586    0.767140    0.785484    0.973498    0.982332    0.844235    0.709981    0.911653    0.748476    0.951870    0.842963    1400        21.082353   0.214699    1.146105    141.212865 
[37m[36mINFO[0m[0m 03/13 22:57:33 | 0.986749    0.982332    0.946216    0.803572    0.797655    0.986749    0.982332    0.912471    0.758945    0.954684    0.786585    0.971492    0.865185    1600        24.094118   0.175344    1.147535    147.127185 
[37m[36mINFO[0m[0m 03/13 23:03:30 | 0.974382    0.964664    0.945656    0.789203    0.740226    0.974382    0.964664    0.896471    0.730697    0.963823    0.785061    0.976675    0.851852    1800        27.105882   0.154230    1.118197    133.592050 
[37m[36mINFO[0m[0m 03/13 23:09:32 | 0.969965    0.978799    0.964218    0.805947    0.833172    0.969965    0.978799    0.944941    0.779661    0.970297    0.777439    0.977416    0.860741    2000        30.117647   0.122457    1.124654    137.401903 
[37m[36mINFO[0m[0m 03/13 23:15:29 | 0.963781    0.964664    0.938775    0.777440    0.918462    0.963781    0.964664    0.923765    0.728814    0.930693    0.756098    0.961866    0.847407    2200        33.129412   0.121229    1.111627    134.060638 
[37m[36mINFO[0m[0m 03/13 23:21:23 | 0.978799    0.982332    0.976522    0.799128    1.002774    0.978799    0.982332    0.963765    0.758945    0.981721    0.786585    0.984080    0.851852    2400        36.141176   0.095430    1.095418    135.246442 
[37m[36mINFO[0m[0m 03/13 23:27:17 | 0.970848    0.961131    0.970697    0.802892    1.004767    0.970848    0.961131    0.967529    0.785311    0.963442    0.777439    0.981118    0.845926    2600        39.152941   0.086804    1.096431    135.028821 
[37m[36mINFO[0m[0m 03/13 23:33:19 | 0.980565    0.971731    0.958047    0.782759    0.922521    0.980565    0.971731    0.930353    0.740113    0.962300    0.763720    0.981488    0.844444    2800        42.164706   0.086623    1.122836    136.563976 
[37m[36mINFO[0m[0m 03/13 23:39:10 | 0.976148    0.975265    0.985135    0.794760    1.022992    0.976148    0.975265    0.977882    0.760829    0.990480    0.780488    0.987042    0.842963    3000        45.176471   0.065604    1.100185    131.533659 
[37m[36mINFO[0m[0m 03/13 23:45:02 | 0.981449    0.971731    0.984749    0.788526    1.016295    0.981449    0.971731    0.974588    0.734463    0.987433    0.789634    0.992225    0.841481    3200        48.188235   0.058405    1.083733    135.021239 
[37m[36mINFO[0m[0m 03/13 23:51:01 | 0.979682    0.978799    0.978081    0.792250    1.156110    0.979682    0.978799    0.953412    0.745763    0.989718    0.785061    0.991114    0.845926    3400        51.200000   0.043333    1.113505    136.181260 
[37m[36mINFO[0m[0m 03/13 23:57:00 | 0.970848    0.982332    0.985169    0.796149    1.111576    0.970848    0.982332    0.982588    0.766478    0.984768    0.780488    0.988153    0.841481    3600        54.211765   0.049157    1.113874    136.089939 
[37m[36mINFO[0m[0m 03/14 00:02:50 | 0.986749    0.982332    0.986772    0.785696    1.095146    0.986749    0.982332    0.985882    0.743879    0.985910    0.785061    0.988523    0.828148    3800        57.223529   0.045499    1.087301    132.492349 
[37m[36mINFO[0m[0m 03/14 00:08:38 | 0.972615    0.971731    0.987015    0.796170    1.246434    0.972615    0.971731    0.984000    0.760829    0.986672    0.772866    0.990374    0.854815    4000        60.235294   0.047422    1.089970    130.615676 
[37m[36mINFO[0m[0m 03/14 00:14:31 | 0.962014    0.964664    0.977473    0.783549    1.306968    0.962014    0.964664    0.976941    0.743879    0.969916    0.766768    0.985561    0.840000    4200        63.247059   0.032536    1.102114    131.843597 
[37m[36mINFO[0m[0m 03/14 00:20:25 | 0.984982    0.985866    0.992693    0.791208    1.134605    0.984982    0.985866    0.990118    0.723164    0.993145    0.792683    0.994817    0.857778    4400        66.258824   0.034464    1.104809    133.754680 
[37m[36mINFO[0m[0m 03/14 00:26:20 | 0.981449    0.978799    0.994347    0.786495    1.198137    0.981449    0.978799    0.992000    0.726930    0.997334    0.788110    0.993706    0.844444    4600        69.270588   0.032135    1.099889    135.025394 
[37m[36mINFO[0m[0m 03/14 00:32:11 | 0.983216    0.982332    0.993945    0.792093    1.328002    0.983216    0.982332    0.990118    0.764595    0.995050    0.783537    0.996668    0.828148    4800        72.282353   0.027902    1.096411    130.919990 
[37m[36mINFO[0m[0m 03/14 00:38:08 | 0.978799    0.978799    0.995614    0.800053    1.266126    0.978799    0.978799    0.992471    0.757062    0.997334    0.794207    0.997038    0.848889    5000        75.294118   0.031919    1.105879    136.506706 
[37m[36mINFO[0m[0m 03/14 00:38:08 | Cumulative gradient change saved at train_output/VLCS/GENIE/[0]/250313_22-06-15_resnet50_signum/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/14 00:38:09 | ---
[37m[36mINFO[0m[0m 03/14 00:38:09 | test-domain validation(oracle) = 99.028%
[37m[36mINFO[0m[0m 03/14 00:38:09 | training-domain validation(iid) = 99.028%
[37m[36mINFO[0m[0m 03/14 00:38:09 | last = 97.880%
[37m[36mINFO[0m[0m 03/14 00:38:09 | last (inD) = 80.005%
[37m[36mINFO[0m[0m 03/14 00:38:09 | training-domain validation (iid, inD) = 81.503%
[37m[36mINFO[0m[0m 03/14 00:38:09 | === Summary ===
[37m[36mINFO[0m[0m 03/14 00:38:09 | Command: /jsm0707/GENIE/train_all.py resnet50_signum config/resnet50_signum.yaml --algorithm GENIE --test_envs 0 --dataset VLCS
[37m[36mINFO[0m[0m 03/14 00:38:09 | Unique name: 250313_22-06-15_resnet50_signum
[37m[36mINFO[0m[0m 03/14 00:38:09 | Out path: train_output/VLCS/GENIE/[0]/250313_22-06-15_resnet50_signum
[37m[36mINFO[0m[0m 03/14 00:38:09 | Algorithm: GENIE
[37m[36mINFO[0m[0m 03/14 00:38:09 | Dataset: VLCS
