[37m[36mINFO[0m[0m 03/14 04:23:54 | Command :: /jsm0707/GENIE/train_all.py resnet50_signum config/resnet50_signum.yaml --algorithm GENIE --test_envs 3 --dataset VLCS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: GENIE
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_signum.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_signum
	out_dir: train_output/VLCS/GENIE/[3]/250314_04-23-54_resnet50_signum
	out_root: train_output/VLCS/GENIE/[3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [3]
	trial_seed: 0
	unique_name: 250314_04-23-54_resnet50_signum
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: signum
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	momentum: 0.9
	convergence_rate: 0.015
	moving_avg: 0.95
	p: 0.4
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 03/14 04:23:54 | n_steps = 5001
[37m[36mINFO[0m[0m 03/14 04:23:54 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/14 04:23:54 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/14 04:23:54 | 
[37m[36mINFO[0m[0m 03/14 04:23:54 | Testenv name escaping te_V -> te_V
[37m[36mINFO[0m[0m 03/14 04:23:54 | Test envs = [3], name = te_V
[37m[36mINFO[0m[0m 03/14 04:23:54 | Train environments: [0, 1, 2], Test environments: [3]
[37m[36mINFO[0m[0m 03/14 04:23:54 | Batch sizes for each domain: [32, 32, 32, 0] (total=96)
[37m[36mINFO[0m[0m 03/14 04:23:54 | steps-per-epoch for each domain: 35.38, 66.41, 82.06 -> min = 35.38
[37m[36mINFO[0m[0m 03/14 04:23:55 | # of params = 23518277
[37m[36mINFO[0m[0m 03/14 04:26:08 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/14 04:26:08 | 0.457608    0.462222    0.488838    0.505118    1.203772    0.615724    0.632509    0.465412    0.497175    0.385377    0.385671    0.457608    0.462222    0           0.000000    1.809193    1.903451    130.601681 
[37m[36mINFO[0m[0m 03/14 04:32:04 | 0.793410    0.798519    0.868822    0.850423    0.386815    0.999117    1.000000    0.780235    0.757062    0.827113    0.794207    0.793410    0.798519    200         5.653710    0.445723    1.113028    133.999022 
[37m[36mINFO[0m[0m 03/14 04:37:57 | 0.779341    0.754074    0.876679    0.847822    0.394051    1.000000    1.000000    0.769412    0.740113    0.860625    0.803354    0.779341    0.754074    400         11.307420   0.324317    1.106506    131.062009 
[37m[36mINFO[0m[0m 03/14 04:43:49 | 0.768604    0.754074    0.902880    0.860587    0.412611    1.000000    1.000000    0.830118    0.789077    0.878522    0.792683    0.768604    0.754074    600         16.961131   0.282383    1.097830    133.077936 
[37m[36mINFO[0m[0m 03/14 04:49:42 | 0.763791    0.768889    0.922962    0.855504    0.417096    1.000000    1.000000    0.856471    0.757062    0.912414    0.809451    0.763791    0.768889    800         22.614841   0.242060    1.103949    131.419861 
[37m[36mINFO[0m[0m 03/14 04:55:31 | 0.724917    0.720000    0.920029    0.836022    0.499531    0.998233    0.992933    0.863529    0.751412    0.898324    0.763720    0.724917    0.720000    1000        28.268551   0.205404    1.096211    130.185927 
[37m[36mINFO[0m[0m 03/14 05:01:19 | 0.743799    0.758519    0.932654    0.836254    0.474700    1.000000    1.000000    0.861176    0.709981    0.936786    0.798780    0.743799    0.758519    1200        33.922261   0.173223    1.080987    131.334229 
[37m[36mINFO[0m[0m 03/14 05:07:07 | 0.752314    0.751111    0.948072    0.850185    0.482708    1.000000    1.000000    0.912000    0.785311    0.932216    0.765244    0.752314    0.751111    1400        39.575972   0.166648    1.107442    127.021873 
[37m[36mINFO[0m[0m 03/14 05:12:51 | 0.732321    0.734815    0.970058    0.840158    0.549774    1.000000    0.996466    0.938353    0.741996    0.971820    0.782012    0.732321    0.734815    1600        45.229682   0.130350    1.083265    127.204180 
[37m[36mINFO[0m[0m 03/14 05:18:35 | 0.716031    0.725926    0.948887    0.841210    0.642092    0.994700    0.989399    0.900706    0.747646    0.951257    0.786585    0.716031    0.725926    1800        50.883392   0.098176    1.091848    126.033530 
[37m[36mINFO[0m[0m 03/14 05:24:18 | 0.784154    0.782222    0.978170    0.859439    0.657557    1.000000    0.996466    0.966118    0.781544    0.968393    0.800305    0.784154    0.782222    2000        56.537102   0.083477    1.068328    129.158740 
[37m[36mINFO[0m[0m 03/14 05:30:06 | 0.748982    0.743704    0.973884    0.852205    0.660745    0.998233    0.996466    0.953882    0.779661    0.969535    0.780488    0.748982    0.743704    2200        62.190813   0.063445    1.075217    132.411625 
[37m[36mINFO[0m[0m 03/14 05:35:56 | 0.714920    0.711111    0.980090    0.836255    0.705775    1.000000    1.000000    0.970353    0.741996    0.969916    0.766768    0.714920    0.711111    2400        67.844523   0.074444    1.092727    131.474393 
[37m[36mINFO[0m[0m 03/14 05:41:46 | 0.748612    0.748148    0.988521    0.850005    0.823963    1.000000    1.000000    0.981176    0.766478    0.984387    0.783537    0.748612    0.748148    2600        73.498233   0.066535    1.104100    129.265888 
[37m[36mINFO[0m[0m 03/14 05:47:33 | 0.740096    0.742222    0.961598    0.842113    0.710811    0.999117    1.000000    0.907765    0.738230    0.977913    0.788110    0.740096    0.742222    2800        79.151943   0.048819    1.093130    128.521907 
[37m[36mINFO[0m[0m 03/14 05:53:27 | 0.745280    0.739259    0.992651    0.840589    0.850279    1.000000    1.000000    0.988235    0.738230    0.989718    0.783537    0.745280    0.739259    3000        84.805654   0.045578    1.124326    129.239419 
[37m[36mINFO[0m[0m 03/14 05:59:18 | 0.726027    0.737778    0.979251    0.822594    0.887154    1.000000    1.000000    0.949176    0.694915    0.988576    0.772866    0.726027    0.737778    3200        90.459364   0.039042    1.115144    128.392568 
[37m[36mINFO[0m[0m 03/14 06:05:11 | 0.725657    0.717037    0.991132    0.842400    0.839413    0.999117    0.996466    0.984941    0.753296    0.989337    0.777439    0.725657    0.717037    3400        96.113074   0.033433    1.108771    130.360381 
[37m[36mINFO[0m[0m 03/14 06:11:02 | 0.744169    0.734815    0.996034    0.851679    0.912036    1.000000    1.000000    0.991529    0.760829    0.996573    0.794207    0.744169    0.734815    3600        101.766784  0.035475    1.105624    130.297153 
[37m[36mINFO[0m[0m 03/14 06:16:53 | 0.695298    0.688889    0.992158    0.839991    0.693350    1.000000    1.000000    0.984471    0.728814    0.992003    0.791159    0.695298    0.688889    3800        107.420495  0.035896    1.097741    131.842197 
[37m[36mINFO[0m[0m 03/14 06:22:41 | 0.737875    0.739259    0.988562    0.844313    0.895852    0.999117    0.996466    0.976471    0.751412    0.990099    0.785061    0.737875    0.739259    4000        113.074205  0.025057    1.089873    129.431752 
[37m[36mINFO[0m[0m 03/14 06:28:32 | 0.724546    0.724444    0.994174    0.846526    0.897262    1.000000    0.996466    0.988235    0.770245    0.994288    0.772866    0.724546    0.724444    4200        118.727915  0.017762    1.108547    129.614771 
[37m[36mINFO[0m[0m 03/14 06:34:21 | 0.729730    0.746667    0.965894    0.837887    1.101999    1.000000    0.996466    0.956706    0.770245    0.940975    0.746951    0.729730    0.746667    4400        124.381625  0.031971    1.096756    130.025471 
[37m[36mINFO[0m[0m 03/14 06:40:11 | 0.754906    0.749630    0.996614    0.852163    0.933328    0.999117    0.992933    0.995294    0.781544    0.995430    0.782012    0.754906    0.749630    4600        130.035336  0.023933    1.106208    128.405475 
[37m[36mINFO[0m[0m 03/14 06:45:56 | 0.714920    0.722963    0.995840    0.843793    0.828429    1.000000    0.992933    0.992471    0.745763    0.995050    0.792683    0.714920    0.722963    4800        135.689046  0.019911    1.084208    127.749924 
[37m[36mINFO[0m[0m 03/14 06:51:45 | 0.738245    0.734815    0.994562    0.840696    0.960174    1.000000    0.996466    0.986353    0.734463    0.997334    0.791159    0.738245    0.734815    5000        141.342756  0.020979    1.093735    130.842472 
[37m[36mINFO[0m[0m 03/14 06:51:45 | Cumulative gradient change saved at train_output/VLCS/GENIE/[3]/250314_04-23-54_resnet50_signum/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/14 06:51:47 | ---
[37m[36mINFO[0m[0m 03/14 06:51:47 | test-domain validation(oracle) = 79.341%
[37m[36mINFO[0m[0m 03/14 06:51:47 | training-domain validation(iid) = 76.860%
[37m[36mINFO[0m[0m 03/14 06:51:47 | last = 73.825%
[37m[36mINFO[0m[0m 03/14 06:51:47 | last (inD) = 84.070%
[37m[36mINFO[0m[0m 03/14 06:51:47 | training-domain validation (iid, inD) = 86.059%
[37m[36mINFO[0m[0m 03/14 06:51:47 | === Summary ===
[37m[36mINFO[0m[0m 03/14 06:51:47 | Command: /jsm0707/GENIE/train_all.py resnet50_signum config/resnet50_signum.yaml --algorithm GENIE --test_envs 3 --dataset VLCS
[37m[36mINFO[0m[0m 03/14 06:51:47 | Unique name: 250314_04-23-54_resnet50_signum
[37m[36mINFO[0m[0m 03/14 06:51:47 | Out path: train_output/VLCS/GENIE/[3]/250314_04-23-54_resnet50_signum
[37m[36mINFO[0m[0m 03/14 06:51:47 | Algorithm: GENIE
[37m[36mINFO[0m[0m 03/14 06:51:47 | Dataset: VLCS
