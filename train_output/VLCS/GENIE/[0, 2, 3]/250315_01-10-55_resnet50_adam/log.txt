[37m[36mINFO[0m[0m 03/15 01:10:55 | Command :: /jsm0707/GENIE/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm GENIE --test_envs 0 2 3 --dataset VLCS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: GENIE
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_adam.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_adam
	out_dir: train_output/VLCS/GENIE/[0, 2, 3]/250315_01-10-55_resnet50_adam
	out_root: train_output/VLCS/GENIE/[0, 2, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 2, 3]
	trial_seed: 0
	unique_name: 250315_01-10-55_resnet50_adam
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: adam
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	momentum: 0.9
	convergence_rate: 0.015
	moving_avg: 0.95
	p: 0.4
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 03/15 01:10:55 | n_steps = 5001
[37m[36mINFO[0m[0m 03/15 01:10:55 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/15 01:10:55 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/15 01:10:55 | 
[37m[36mINFO[0m[0m 03/15 01:10:55 | Testenv name escaping te_C_S_V -> te_C_S_V
[37m[36mINFO[0m[0m 03/15 01:10:55 | Test envs = [0, 2, 3], name = te_C_S_V
[37m[36mINFO[0m[0m 03/15 01:10:55 | Train environments: [1], Test environments: [0, 2, 3]
[37m[36mINFO[0m[0m 03/15 01:10:55 | Batch sizes for each domain: [0, 32, 0, 0] (total=32)
[37m[36mINFO[0m[0m 03/15 01:10:55 | steps-per-epoch for each domain: 66.41 -> min = 66.41
[37m[36mINFO[0m[0m 03/15 01:10:56 | # of params = 23518277
[37m[36mINFO[0m[0m 03/15 01:12:56 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/15 01:12:56 | 0.207824    0.200549    0.481412    0.453861    0.992768    0.090106    0.074205    0.481412    0.453861    0.314928    0.317073    0.218438    0.210370    0           0.000000    1.627299    1.644124    118.121566 
[37m[36mINFO[0m[0m 03/15 01:18:40 | 0.612898    0.613596    0.769412    0.770245    0.612552    0.693463    0.689046    0.769412    0.770245    0.536938    0.548780    0.608293    0.602963    200         3.011765    0.725113    1.110046    122.576218 
[37m[36mINFO[0m[0m 03/15 01:24:23 | 0.657394    0.628546    0.815059    0.751412    0.612857    0.683746    0.681979    0.815059    0.751412    0.654227    0.603659    0.634210    0.600000    400         6.023529    0.524170    1.108878    121.112448 
[37m[36mINFO[0m[0m 03/15 01:30:15 | 0.698921    0.693631    0.836235    0.766478    0.594156    0.808304    0.823322    0.836235    0.766478    0.601676    0.571646    0.686783    0.685926    600         9.035294    0.449372    1.148365    121.624595 
[37m[36mINFO[0m[0m 03/15 01:35:58 | 0.525597    0.507591    0.867294    0.734463    0.706075    0.386042    0.385159    0.867294    0.734463    0.616146    0.573171    0.574602    0.564444    800         12.047059   0.393156    1.111555    121.485321 
[37m[36mINFO[0m[0m 03/15 01:41:50 | 0.548404    0.521472    0.865882    0.715631    0.735732    0.333039    0.296820    0.865882    0.715631    0.695735    0.664634    0.616438    0.602963    1000        15.058824   0.327503    1.135447    124.139655 
[37m[36mINFO[0m[0m 03/15 01:47:43 | 0.549469    0.522494    0.903059    0.766478    0.897223    0.446996    0.416961    0.903059    0.766478    0.573496    0.557927    0.627916    0.592593    1200        18.070588   0.272761    1.147786    123.935118 
[37m[36mINFO[0m[0m 03/15 01:53:30 | 0.530139    0.498569    0.873882    0.743879    0.973404    0.403710    0.399293    0.873882    0.743879    0.577304    0.530488    0.609404    0.565926    1400        21.082353   0.213198    1.118463    123.098234 
[37m[36mINFO[0m[0m 03/15 01:59:22 | 0.621984    0.609787    0.948706    0.768362    0.849655    0.606890    0.607774    0.948706    0.768362    0.569688    0.556402    0.689374    0.665185    1600        24.094118   0.201153    1.130874    125.919729 
[37m[36mINFO[0m[0m 03/15 02:05:10 | 0.543838    0.513818    0.937412    0.747646    0.859944    0.367491    0.342756    0.937412    0.747646    0.615004    0.585366    0.649019    0.613333    1800        27.105882   0.143841    1.133317    121.770497 
[37m[36mINFO[0m[0m 03/15 02:10:59 | 0.512528    0.490064    0.952000    0.775895    0.784755    0.310954    0.293286    0.952000    0.775895    0.628332    0.600610    0.598297    0.576296    2000        30.117647   0.148063    1.129071    123.137195 
[37m[36mINFO[0m[0m 03/15 02:16:51 | 0.533133    0.492997    0.963765    0.768362    0.886937    0.410777    0.353357    0.963765    0.768362    0.592917    0.568598    0.595705    0.557037    2200        33.129412   0.122670    1.136815    123.887183 
[37m[36mINFO[0m[0m 03/15 02:22:40 | 0.481521    0.470567    0.977882    0.753296    1.130915    0.290636    0.303887    0.977882    0.753296    0.610053    0.567073    0.543873    0.540741    2400        36.141176   0.080144    1.121979    125.045253 
[37m[36mINFO[0m[0m 03/15 02:28:23 | 0.597608    0.576180    0.974588    0.775895    0.935083    0.553004    0.547703    0.974588    0.775895    0.623382    0.582317    0.616438    0.598519    2600        39.152941   0.095607    1.101173    122.507782 
[37m[36mINFO[0m[0m 03/15 02:34:10 | 0.518045    0.503756    0.968000    0.777778    0.945169    0.398410    0.409894    0.968000    0.777778    0.568165    0.548780    0.587560    0.552593    2800        42.164706   0.093514    1.120905    122.655590 
[37m[36mINFO[0m[0m 03/15 02:40:05 | 0.578560    0.555591    0.986353    0.785311    1.343069    0.499117    0.487633    0.986353    0.785311    0.599391    0.574695    0.637171    0.604444    3000        45.176471   0.040183    1.139145    127.123474 
[37m[36mINFO[0m[0m 03/15 02:45:58 | 0.578602    0.568560    0.988235    0.787194    0.967267    0.530035    0.519435    0.988235    0.787194    0.570449    0.564024    0.635320    0.622222    3200        48.188235   0.073705    1.132370    126.444298 
[37m[36mINFO[0m[0m 03/15 02:51:41 | 0.557899    0.543745    0.966588    0.726930    1.179387    0.501767    0.480565    0.966588    0.726930    0.525133    0.510671    0.646797    0.640000    3400        51.200000   0.077826    1.114871    120.729932 
[37m[36mINFO[0m[0m 03/15 02:57:34 | 0.544109    0.532236    0.996235    0.775895    1.278437    0.425795    0.406360    0.996235    0.775895    0.544554    0.551829    0.661977    0.638519    3600        54.211765   0.033882    1.132615    125.930709 
[37m[36mINFO[0m[0m 03/15 03:03:30 | 0.571545    0.583719    0.995294    0.796610    1.551517    0.501767    0.544170    0.995294    0.796610    0.572734    0.564024    0.640133    0.642963    3800        57.223529   0.044988    1.142956    127.438981 
[37m[36mINFO[0m[0m 03/15 03:09:18 | 0.530800    0.521252    0.986824    0.753296    1.351622    0.435512    0.462898    0.986824    0.753296    0.556740    0.530488    0.600148    0.570370    4000        60.235294   0.038963    1.123923    123.032031 
[37m[36mINFO[0m[0m 03/15 03:15:10 | 0.517807    0.496003    0.968000    0.725047    1.752933    0.370141    0.371025    0.968000    0.725047    0.560548    0.524390    0.622732    0.592593    4200        63.247059   0.040777    1.151484    122.461999 
[37m[36mINFO[0m[0m 03/15 03:21:02 | 0.641280    0.624430    0.985882    0.787194    1.141239    0.750883    0.742049    0.985882    0.787194    0.522087    0.504573    0.650870    0.626667    4400        66.258824   0.087950    1.145235    122.248039 
[37m[36mINFO[0m[0m 03/15 03:26:58 | 0.559656    0.552198    0.993412    0.757062    1.616000    0.419611    0.438163    0.993412    0.757062    0.620335    0.602134    0.639023    0.616296    4600        69.270588   0.027916    1.165900    122.777548 
[37m[36mINFO[0m[0m 03/15 03:32:50 | 0.522425    0.497568    0.994824    0.764595    1.440899    0.424912    0.406360    0.994824    0.764595    0.567022    0.541159    0.575342    0.545185    4800        72.282353   0.035118    1.152712    121.638175 
[37m[36mINFO[0m[0m 03/15 03:38:51 | 0.535455    0.523476    0.999059    0.779661    1.287719    0.401060    0.406360    0.999059    0.779661    0.593679    0.565549    0.611625    0.598519    5000        75.294118   0.032007    1.190930    122.967766 
[37m[36mINFO[0m[0m 03/15 03:38:51 | Cumulative gradient change saved at train_output/VLCS/GENIE/[0, 2, 3]/250315_01-10-55_resnet50_adam/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/15 03:38:53 | ---
[37m[36mINFO[0m[0m 03/15 03:38:53 | test-domain validation(oracle) = 69.892%
[37m[36mINFO[0m[0m 03/15 03:38:53 | training-domain validation(iid) = 57.154%
[37m[36mINFO[0m[0m 03/15 03:38:53 | last = 53.545%
[37m[36mINFO[0m[0m 03/15 03:38:53 | last (inD) = 77.966%
[37m[36mINFO[0m[0m 03/15 03:38:53 | training-domain validation (iid, inD) = 79.661%
[37m[36mINFO[0m[0m 03/15 03:38:53 | === Summary ===
[37m[36mINFO[0m[0m 03/15 03:38:53 | Command: /jsm0707/GENIE/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm GENIE --test_envs 0 2 3 --dataset VLCS
[37m[36mINFO[0m[0m 03/15 03:38:53 | Unique name: 250315_01-10-55_resnet50_adam
[37m[36mINFO[0m[0m 03/15 03:38:53 | Out path: train_output/VLCS/GENIE/[0, 2, 3]/250315_01-10-55_resnet50_adam
[37m[36mINFO[0m[0m 03/15 03:38:53 | Algorithm: GENIE
[37m[36mINFO[0m[0m 03/15 03:38:53 | Dataset: VLCS
