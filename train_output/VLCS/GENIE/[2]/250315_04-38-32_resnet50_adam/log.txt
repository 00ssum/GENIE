[37m[36mINFO[0m[0m 03/15 04:38:32 | Command :: /jsm0707/GENIE/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm GENIE --test_envs 2 --dataset VLCS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: GENIE
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_adam.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_adam
	out_dir: train_output/VLCS/GENIE/[2]/250315_04-38-32_resnet50_adam
	out_root: train_output/VLCS/GENIE/[2]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [2]
	trial_seed: 0
	unique_name: 250315_04-38-32_resnet50_adam
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: adam
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	momentum: 0.9
	convergence_rate: 0.015
	moving_avg: 0.95
	p: 0.4
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 03/15 04:38:32 | n_steps = 5001
[37m[36mINFO[0m[0m 03/15 04:38:32 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/15 04:38:32 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/15 04:38:32 | 
[37m[36mINFO[0m[0m 03/15 04:38:32 | Testenv name escaping te_S -> te_S
[37m[36mINFO[0m[0m 03/15 04:38:32 | Test envs = [2], name = te_S
[37m[36mINFO[0m[0m 03/15 04:38:32 | Train environments: [0, 1, 3], Test environments: [2]
[37m[36mINFO[0m[0m 03/15 04:38:32 | Batch sizes for each domain: [32, 32, 0, 32] (total=96)
[37m[36mINFO[0m[0m 03/15 04:38:32 | steps-per-epoch for each domain: 35.38, 66.41, 84.41 -> min = 35.38
[37m[36mINFO[0m[0m 03/15 04:38:33 | # of params = 23518277
[37m[36mINFO[0m[0m 03/15 04:40:44 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/15 04:40:44 | 0.384615    0.387195    0.504871    0.521514    1.299834    0.611307    0.628975    0.459765    0.489642    0.384615    0.387195    0.443539    0.445926    0           0.000000    1.803942    1.757090    129.433301 
[37m[36mINFO[0m[0m 03/15 04:46:45 | 0.766946    0.739329    0.884463    0.870400    0.326272    1.000000    1.000000    0.772235    0.760829    0.766946    0.739329    0.881155    0.850370    200         5.653710    0.434573    1.134807    134.004230 
[37m[36mINFO[0m[0m 03/15 04:52:43 | 0.730008    0.705793    0.903193    0.878652    0.327376    1.000000    1.000000    0.811765    0.779661    0.730008    0.705793    0.897816    0.856296    400         11.307420   0.287839    1.127478    132.681783 
[37m[36mINFO[0m[0m 03/15 04:58:39 | 0.725438    0.687500    0.916622    0.880268    0.341007    0.999117    1.000000    0.832941    0.781544    0.725438    0.687500    0.917808    0.859259    600         16.961131   0.253967    1.115834    133.222516 
[37m[36mINFO[0m[0m 03/15 05:04:37 | 0.716299    0.687500    0.931972    0.872277    0.361798    0.999117    0.996466    0.852706    0.755179    0.716299    0.687500    0.944095    0.865185    800         22.614841   0.199612    1.128077    131.623943 
[37m[36mINFO[0m[0m 03/15 05:10:31 | 0.750190    0.714939    0.944542    0.868165    0.357224    1.000000    1.000000    0.874353    0.736347    0.750190    0.714939    0.959274    0.868148    1000        28.268551   0.170799    1.119104    130.474351 
[37m[36mINFO[0m[0m 03/15 05:16:32 | 0.704494    0.653963    0.960375    0.872268    0.400034    1.000000    0.996466    0.920000    0.775895    0.704494    0.653963    0.961126    0.844444    1200        33.922261   0.141917    1.142841    132.133450 
[37m[36mINFO[0m[0m 03/15 05:22:25 | 0.702589    0.685976    0.964280    0.864968    0.422826    0.999117    1.000000    0.937412    0.760829    0.702589    0.685976    0.956312    0.834074    1400        39.575972   0.127107    1.112509    130.452591 
[37m[36mINFO[0m[0m 03/15 05:28:24 | 0.708302    0.657012    0.975519    0.875380    0.510650    0.999117    1.000000    0.944471    0.768362    0.708302    0.657012    0.982969    0.857778    1600        45.229682   0.092778    1.126636    133.816396 
[37m[36mINFO[0m[0m 03/15 05:34:18 | 0.706398    0.678354    0.979802    0.874018    0.572164    1.000000    0.996466    0.957176    0.779661    0.706398    0.678354    0.982229    0.845926    1800        50.883392   0.087393    1.119922    130.536305 
[37m[36mINFO[0m[0m 03/15 05:40:13 | 0.679741    0.652439    0.977702    0.858104    0.546962    1.000000    1.000000    0.962353    0.747646    0.679741    0.652439    0.970752    0.826667    2000        56.537102   0.069751    1.122407    130.645708 
[37m[36mINFO[0m[0m 03/15 05:46:08 | 0.717060    0.687500    0.985860    0.884796    0.552137    0.998233    1.000000    0.970824    0.796610    0.717060    0.687500    0.988523    0.857778    2200        62.190813   0.057461    1.129723    128.272994 
[37m[36mINFO[0m[0m 03/15 05:51:59 | 0.678218    0.646341    0.986436    0.866985    0.606799    1.000000    1.000000    0.974118    0.768362    0.678218    0.646341    0.985191    0.832593    2400        67.844523   0.047411    1.100323    131.387613 
[37m[36mINFO[0m[0m 03/15 05:57:55 | 0.706017    0.681402    0.991481    0.877665    0.592568    1.000000    1.000000    0.982588    0.779661    0.706017    0.681402    0.991855    0.853333    2600        73.498233   0.038896    1.128408    130.211247 
[37m[36mINFO[0m[0m 03/15 06:03:50 | 0.722391    0.684451    0.974694    0.858056    0.651320    1.000000    0.996466    0.937412    0.728814    0.722391    0.684451    0.986672    0.848889    2800        79.151943   0.045184    1.105201    133.471293 
[37m[36mINFO[0m[0m 03/15 06:09:48 | 0.685072    0.637195    0.989378    0.864016    0.667263    0.998233    0.996466    0.982118    0.757062    0.685072    0.637195    0.987782    0.838519    3000        84.805654   0.031718    1.132521    131.521905 
[37m[36mINFO[0m[0m 03/15 06:15:37 | 0.681645    0.640244    0.992265    0.867571    0.715358    1.000000    1.000000    0.984941    0.762712    0.681645    0.640244    0.991855    0.840000    3200        90.459364   0.028676    1.098242    130.143423 
[37m[36mINFO[0m[0m 03/15 06:21:29 | 0.686596    0.635671    0.994204    0.862323    0.660482    1.000000    1.000000    0.989647    0.751412    0.686596    0.635671    0.992966    0.835556    3400        96.113074   0.030842    1.100753    131.481375 
[37m[36mINFO[0m[0m 03/15 06:27:21 | 0.662224    0.635671    0.989753    0.840942    0.645926    1.000000    0.992933    0.982588    0.726930    0.662224    0.635671    0.986672    0.802963    3600        101.766784  0.032609    1.095046    132.734704 
[37m[36mINFO[0m[0m 03/15 06:33:15 | 0.668698    0.623476    0.984508    0.861413    0.889943    1.000000    0.996466    0.971294    0.755179    0.668698    0.623476    0.982229    0.832593    3800        107.420495  0.019530    1.102836    133.809633 
[37m[36mINFO[0m[0m 03/15 06:39:10 | 0.716299    0.667683    0.994922    0.861999    0.804288    1.000000    0.996466    0.991059    0.749529    0.716299    0.667683    0.993706    0.840000    4000        113.074205  0.018259    1.115876    131.604924 
[37m[36mINFO[0m[0m 03/15 06:45:01 | 0.711729    0.670732    0.996827    0.867713    0.733246    1.000000    1.000000    0.995294    0.743879    0.711729    0.670732    0.995187    0.859259    4200        118.727915  0.016671    1.097370    131.730793 
[37m[36mINFO[0m[0m 03/15 06:51:08 | 0.692688    0.672256    0.994271    0.865553    0.716548    1.000000    1.000000    0.990588    0.755179    0.692688    0.672256    0.992225    0.841481    4400        124.381625  0.014930    1.137486    139.188989 
[37m[36mINFO[0m[0m 03/15 06:56:58 | 0.690784    0.650915    0.987716    0.850931    0.890691    1.000000    1.000000    0.971294    0.723164    0.690784    0.650915    0.991855    0.829630    4600        130.035336  0.013017    1.113152    127.500997 
[37m[36mINFO[0m[0m 03/15 07:02:49 | 0.682407    0.666159    0.993047    0.868918    0.798308    1.000000    1.000000    0.992471    0.760829    0.682407    0.666159    0.986672    0.845926    4800        135.689046  0.020527    1.104216    130.698660 
[37m[36mINFO[0m[0m 03/15 07:08:45 | 0.708682    0.661585    0.997141    0.859184    0.857501    1.000000    1.000000    0.996235    0.741996    0.708682    0.661585    0.995187    0.835556    5000        141.342756  0.013095    1.113440    132.597470 
[37m[36mINFO[0m[0m 03/15 07:08:45 | Cumulative gradient change saved at train_output/VLCS/GENIE/[2]/250315_04-38-32_resnet50_adam/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/15 07:08:46 | ---
[37m[36mINFO[0m[0m 03/15 07:08:46 | test-domain validation(oracle) = 76.695%
[37m[36mINFO[0m[0m 03/15 07:08:46 | training-domain validation(iid) = 71.706%
[37m[36mINFO[0m[0m 03/15 07:08:46 | last = 70.868%
[37m[36mINFO[0m[0m 03/15 07:08:46 | last (inD) = 85.918%
[37m[36mINFO[0m[0m 03/15 07:08:46 | training-domain validation (iid, inD) = 88.480%
[37m[36mINFO[0m[0m 03/15 07:08:46 | === Summary ===
[37m[36mINFO[0m[0m 03/15 07:08:46 | Command: /jsm0707/GENIE/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm GENIE --test_envs 2 --dataset VLCS
[37m[36mINFO[0m[0m 03/15 07:08:46 | Unique name: 250315_04-38-32_resnet50_adam
[37m[36mINFO[0m[0m 03/15 07:08:46 | Out path: train_output/VLCS/GENIE/[2]/250315_04-38-32_resnet50_adam
[37m[36mINFO[0m[0m 03/15 07:08:46 | Algorithm: GENIE
[37m[36mINFO[0m[0m 03/15 07:08:46 | Dataset: VLCS
