[37m[36mINFO[0m[0m 03/15 03:38:57 | Command :: /jsm0707/GENIE/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm GENIE --test_envs 0 1 3 --dataset VLCS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: GENIE
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_adam.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_adam
	out_dir: train_output/VLCS/GENIE/[0, 1, 3]/250315_03-38-57_resnet50_adam
	out_root: train_output/VLCS/GENIE/[0, 1, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 1, 3]
	trial_seed: 0
	unique_name: 250315_03-38-57_resnet50_adam
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: adam
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	momentum: 0.9
	convergence_rate: 0.015
	moving_avg: 0.95
	p: 0.4
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 03/15 03:38:57 | n_steps = 5001
[37m[36mINFO[0m[0m 03/15 03:38:57 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/15 03:38:57 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/15 03:38:57 | 
[37m[36mINFO[0m[0m 03/15 03:38:57 | Testenv name escaping te_C_L_V -> te_C_L_V
[37m[36mINFO[0m[0m 03/15 03:38:57 | Test envs = [0, 1, 3], name = te_C_L_V
[37m[36mINFO[0m[0m 03/15 03:38:57 | Train environments: [2], Test environments: [0, 1, 3]
[37m[36mINFO[0m[0m 03/15 03:38:57 | Batch sizes for each domain: [0, 0, 32, 0] (total=32)
[37m[36mINFO[0m[0m 03/15 03:38:57 | steps-per-epoch for each domain: 82.06 -> min = 82.06
[37m[36mINFO[0m[0m 03/15 03:38:59 | # of params = 23518277
[37m[36mINFO[0m[0m 03/15 03:41:03 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/15 03:41:03 | 0.344798    0.351215    0.438690    0.489329    1.196597    0.150177    0.148410    0.514353    0.514124    0.438690    0.489329    0.369863    0.391111    0           0.000000    1.675835    1.347288    123.209387 
[37m[36mINFO[0m[0m 03/15 03:44:05 | 0.626594    0.638809    0.848058    0.797256    0.568811    0.641343    0.657244    0.609412    0.617702    0.848058    0.797256    0.629026    0.641481    200         2.437167    0.525652    0.265766    128.443892 
[37m[36mINFO[0m[0m 03/15 03:47:04 | 0.620640    0.631289    0.878142    0.801829    0.523040    0.654594    0.689046    0.592000    0.578154    0.878142    0.801829    0.615328    0.626667    400         4.874334    0.402642    0.245508    130.161939 
[37m[36mINFO[0m[0m 03/15 03:50:04 | 0.499874    0.506960    0.846915    0.769817    0.581109    0.356890    0.371025    0.598118    0.591337    0.846915    0.769817    0.544613    0.558519    600         7.311500    0.327592    0.256485    128.551626 
[37m[36mINFO[0m[0m 03/15 03:53:02 | 0.555960    0.586511    0.904037    0.792683    0.645218    0.462898    0.533569    0.584471    0.580038    0.904037    0.792683    0.620511    0.645926    800         9.748667    0.264432    0.252172    127.443287 
[37m[36mINFO[0m[0m 03/15 03:55:59 | 0.615465    0.608795    0.934882    0.795732    0.776804    0.551237    0.554770    0.602824    0.585687    0.934882    0.795732    0.692336    0.685926    1000        12.185834   0.221282    0.251807    127.173975 
[37m[36mINFO[0m[0m 03/15 03:58:56 | 0.661158    0.683313    0.952399    0.777439    0.855847    0.645760    0.681979    0.646118    0.655367    0.952399    0.777439    0.691596    0.712593    1200        14.623001   0.174773    0.247321    127.450383 
[37m[36mINFO[0m[0m 03/15 04:01:50 | 0.588525    0.599962    0.971820    0.789634    0.905836    0.501767    0.519435    0.615529    0.627119    0.971820    0.789634    0.648278    0.653333    1400        17.060168   0.156009    0.253294    123.557775 
[37m[36mINFO[0m[0m 03/15 04:04:47 | 0.628587    0.627752    0.970678    0.780488    0.833178    0.595406    0.632509    0.597647    0.578154    0.970678    0.780488    0.692706    0.672593    1600        19.497334   0.104084    0.244184    127.304730 
[37m[36mINFO[0m[0m 03/15 04:07:42 | 0.671319    0.676849    0.979056    0.801829    1.006233    0.742933    0.749117    0.604235    0.596987    0.979056    0.801829    0.666790    0.684444    1800        21.934501   0.081361    0.244917    126.875516 
[37m[36mINFO[0m[0m 03/15 04:10:39 | 0.655201    0.668204    0.986291    0.806402    1.091493    0.658127    0.671378    0.631059    0.638418    0.986291    0.806402    0.676416    0.694815    2000        24.371668   0.064756    0.248919    126.586535 
[37m[36mINFO[0m[0m 03/15 04:13:36 | 0.488177    0.489769    0.985910    0.785061    1.029752    0.292403    0.293286    0.562353    0.561205    0.985910    0.785061    0.609774    0.614815    2200        26.808835   0.078734    0.242357    128.302199 
[37m[36mINFO[0m[0m 03/15 04:16:27 | 0.499314    0.507024    0.985529    0.795732    1.098553    0.272968    0.286219    0.584471    0.580038    0.985529    0.795732    0.640504    0.654815    2400        29.246002   0.060642    0.234149    124.530826 
[37m[36mINFO[0m[0m 03/15 04:19:26 | 0.671315    0.669485    0.987814    0.800305    1.041858    0.718198    0.720848    0.616000    0.612053    0.987814    0.800305    0.679748    0.675556    2600        31.683168   0.043714    0.246284    129.458652 
[37m[36mINFO[0m[0m 03/15 04:22:19 | 0.678556    0.676695    0.995430    0.810976    1.004065    0.745583    0.742049    0.598118    0.593220    0.995430    0.810976    0.691966    0.694815    2800        34.120335   0.043116    0.238629    125.878938 
[37m[36mINFO[0m[0m 03/15 04:25:16 | 0.576987    0.597268    0.991241    0.792683    1.420875    0.495583    0.544170    0.581176    0.591337    0.991241    0.792683    0.654202    0.656296    3000        36.557502   0.015853    0.240823    128.554935 
[37m[36mINFO[0m[0m 03/15 04:28:11 | 0.590887    0.595668    0.996192    0.807927    1.245512    0.518551    0.519435    0.594353    0.587571    0.996192    0.807927    0.659756    0.680000    3200        38.994669   0.030453    0.243813    126.178334 
[37m[36mINFO[0m[0m 03/15 04:31:03 | 0.667646    0.669514    0.994288    0.812500    1.080644    0.702297    0.703180    0.632000    0.632768    0.994288    0.812500    0.668641    0.672593    3400        41.431835   0.033929    0.243899    122.934342 
[37m[36mINFO[0m[0m 03/15 04:33:57 | 0.609212    0.617960    0.994288    0.794207    1.348861    0.589223    0.618375    0.602353    0.596987    0.994288    0.794207    0.636061    0.638519    3600        43.869002   0.026242    0.249818    124.019237 
[37m[36mINFO[0m[0m 03/15 04:36:45 | 0.594679    0.604142    0.996573    0.798780    1.263903    0.582155    0.604240    0.587294    0.580038    0.996573    0.798780    0.614587    0.628148    3800        46.306169   0.028295    0.233115    121.834429 
[37m[36mINFO[0m[0m 03/15 04:39:34 | 0.574083    0.568838    0.989718    0.789634    1.486148    0.571555    0.565371    0.581647    0.557439    0.989718    0.789634    0.569049    0.583704    4000        48.743336   0.020543    0.237392    121.483699 
[37m[36mINFO[0m[0m 03/15 04:42:23 | 0.673954    0.669808    0.995430    0.807927    1.255197    0.738516    0.752650    0.627294    0.606403    0.995430    0.807927    0.656053    0.650370    4200        51.180503   0.027589    0.232933    122.087392 
[37m[36mINFO[0m[0m 03/15 04:45:12 | 0.662891    0.666376    0.996954    0.778963    1.473622    0.714664    0.713781    0.588706    0.587571    0.996954    0.778963    0.685302    0.697778    4400        53.617669   0.018378    0.236578    121.927478 
[37m[36mINFO[0m[0m 03/15 04:48:00 | 0.627426    0.631790    0.996192    0.782012    1.260437    0.663428    0.703180    0.583529    0.553672    0.996192    0.782012    0.635320    0.638519    4600        56.054836   0.027272    0.226101    123.121557 
[37m[36mINFO[0m[0m 03/15 04:50:58 | 0.623361    0.629787    0.988576    0.772866    1.428555    0.652827    0.681979    0.593412    0.576271    0.988576    0.772866    0.623843    0.631111    4800        58.492003   0.022024    0.271262    123.560040 
[37m[36mINFO[0m[0m 03/15 04:53:58 | 0.564048    0.565094    0.974486    0.771341    1.542989    0.545936    0.568905    0.539765    0.516008    0.974486    0.771341    0.606442    0.610370    5000        60.929170   0.033831    0.282615    123.624533 
[37m[36mINFO[0m[0m 03/15 04:53:58 | Cumulative gradient change saved at train_output/VLCS/GENIE/[0, 1, 3]/250315_03-38-57_resnet50_adam/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/15 04:54:00 | ---
[37m[36mINFO[0m[0m 03/15 04:54:00 | test-domain validation(oracle) = 66.116%
[37m[36mINFO[0m[0m 03/15 04:54:00 | training-domain validation(iid) = 66.765%
[37m[36mINFO[0m[0m 03/15 04:54:00 | last = 56.405%
[37m[36mINFO[0m[0m 03/15 04:54:00 | last (inD) = 77.134%
[37m[36mINFO[0m[0m 03/15 04:54:00 | training-domain validation (iid, inD) = 81.250%
[37m[36mINFO[0m[0m 03/15 04:54:00 | === Summary ===
[37m[36mINFO[0m[0m 03/15 04:54:00 | Command: /jsm0707/GENIE/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm GENIE --test_envs 0 1 3 --dataset VLCS
[37m[36mINFO[0m[0m 03/15 04:54:00 | Unique name: 250315_03-38-57_resnet50_adam
[37m[36mINFO[0m[0m 03/15 04:54:00 | Out path: train_output/VLCS/GENIE/[0, 1, 3]/250315_03-38-57_resnet50_adam
[37m[36mINFO[0m[0m 03/15 04:54:00 | Algorithm: GENIE
[37m[36mINFO[0m[0m 03/15 04:54:00 | Dataset: VLCS
