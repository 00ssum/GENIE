[37m[36mINFO[0m[0m 01/23 00:49:03 | Command :: /jsm0707/DomainBed/Large-scale/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm gsnr1224 --test_envs 0 1 3 --dataset VLCS --trial_seed 2 --hparams_seed 13
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: gsnr1224
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_sgd.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 13
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_sgd
	out_dir: train_output/VLCS/gsnr1224/[0, 1, 3]/250123_00-49-03_resnet50_sgd
	out_root: train_output/VLCS/gsnr1224/[0, 1, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 1, 3]
	trial_seed: 2
	unique_name: 250123_00-49-03_resnet50_sgd
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: sgd
	freeze_bn: False
	pretrained: True
	lr: 0.00010514591448387436
	batch_size: 9
	weight_decay: 2.4366015497066046e-05
	momentum: 0.8057651970808303
	convergence_rate: 0.0034385252902626854
	moving_avg: 0.9744362462979653
	p: 0.5180525095850322
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 01/23 00:49:03 | n_steps = 5001
[37m[36mINFO[0m[0m 01/23 00:49:03 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 01/23 00:49:03 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 01/23 00:49:03 | 
[37m[36mINFO[0m[0m 01/23 00:49:03 | Testenv name escaping te_C_L_V -> te_C_L_V
[37m[36mINFO[0m[0m 01/23 00:49:03 | Test envs = [0, 1, 3], name = te_C_L_V
[37m[36mINFO[0m[0m 01/23 00:49:03 | Train environments: [2], Test environments: [0, 1, 3]
[37m[36mINFO[0m[0m 01/23 00:49:03 | Batch sizes for each domain: [0, 0, 9, 0] (total=9)
[37m[36mINFO[0m[0m 01/23 00:49:03 | steps-per-epoch for each domain: 291.78 -> min = 291.78
[37m[36mINFO[0m[0m 01/23 00:49:04 | # of params = 23518277
[37m[36mINFO[0m[0m 01/23 00:51:22 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 01/23 00:51:22 | 0.113250    0.112580    0.327113    0.350610    1.447605    0.081272    0.109541    0.087059    0.069680    0.327113    0.350610    0.171418    0.158519    0           0.000000    1.626232    1.192491    136.430728 
[37m[36mINFO[0m[0m 01/23 00:54:17 | 0.624936    0.645302    0.790556    0.788110    0.542536    0.704947    0.724382    0.570824    0.602637    0.790556    0.788110    0.599037    0.608889    200         0.685453    0.649674    0.172129    140.569061 
[37m[36mINFO[0m[0m 01/23 00:57:15 | 0.612993    0.627618    0.749810    0.765244    0.588298    0.722615    0.734982    0.531765    0.561205    0.749810    0.765244    0.584598    0.586667    400         1.370906    0.505507    0.176948    141.851697 
[37m[36mINFO[0m[0m 01/23 01:00:07 | 0.680081    0.700180    0.785225    0.763720    0.682622    0.724382    0.717314    0.679059    0.726930    0.785225    0.763720    0.636801    0.656296    600         2.056359    0.445205    0.163513    139.557278 
[37m[36mINFO[0m[0m 01/23 01:02:59 | 0.664747    0.673300    0.852247    0.801829    0.516900    0.721731    0.724382    0.626824    0.642185    0.852247    0.801829    0.645687    0.653333    800         2.741813    0.462490    0.168018    138.464162 
[37m[36mINFO[0m[0m 01/23 01:05:50 | 0.610753    0.615539    0.837014    0.783537    0.643443    0.690813    0.685512    0.526118    0.532957    0.837014    0.783537    0.615328    0.628148    1000        3.427266    0.410443    0.161027    138.621874 
[37m[36mINFO[0m[0m 01/23 01:08:43 | 0.665334    0.663955    0.865956    0.807927    0.518898    0.737633    0.717314    0.605647    0.606403    0.865956    0.807927    0.652721    0.668148    1200        4.112719    0.421355    0.170950    138.411889 
[37m[36mINFO[0m[0m 01/23 01:11:36 | 0.687306    0.694347    0.849581    0.807927    0.633030    0.743816    0.742049    0.663529    0.681733    0.849581    0.807927    0.654572    0.659259    1400        4.798172    0.335958    0.173595    138.318347 
[37m[36mINFO[0m[0m 01/23 01:14:24 | 0.672423    0.686612    0.879284    0.803354    0.613986    0.694346    0.692580    0.658353    0.679849    0.879284    0.803354    0.664569    0.687407    1600        5.483625    0.283914    0.170784    134.417418 
[37m[36mINFO[0m[0m 01/23 01:17:16 | 0.611884    0.631748    0.897182    0.821646    0.495037    0.494700    0.537102    0.640471    0.644068    0.897182    0.821646    0.700481    0.714074    1800        6.169078    0.324243    0.163545    138.914270 
[37m[36mINFO[0m[0m 01/23 01:20:07 | 0.650880    0.650659    0.908606    0.806402    0.553659    0.705830    0.685512    0.589647    0.610169    0.908606    0.806402    0.657164    0.656296    2000        6.854532    0.289534    0.165873    137.258634 
[37m[36mINFO[0m[0m 01/23 01:22:58 | 0.684978    0.682615    0.927647    0.823171    0.559329    0.727915    0.699647    0.615059    0.625235    0.927647    0.823171    0.711959    0.722963    2200        7.539985    0.278908    0.159745    138.557353 
[37m[36mINFO[0m[0m 01/23 01:25:53 | 0.548238    0.564901    0.891851    0.810976    0.518838    0.392226    0.402827    0.624941    0.645951    0.891851    0.810976    0.627545    0.645926    2400        8.225438    0.232581    0.209525    133.924892 
[37m[36mINFO[0m[0m 01/23 01:28:43 | 0.594376    0.613709    0.908606    0.817073    0.542345    0.495583    0.526502    0.634824    0.655367    0.908606    0.817073    0.652721    0.659259    2600        8.910891    0.248799    0.169054    135.663513 
[37m[36mINFO[0m[0m 01/23 01:31:35 | 0.662477    0.676466    0.923839    0.801829    0.631475    0.646643    0.657244    0.636235    0.640301    0.923839    0.801829    0.704554    0.731852    2800        9.596344    0.244914    0.172977    137.490227 
[37m[36mINFO[0m[0m 01/23 01:34:34 | 0.551206    0.576064    0.927266    0.810976    0.564085    0.448763    0.484099    0.604706    0.623352    0.927266    0.810976    0.600148    0.620741    3000        10.281797   0.212009    0.196107    139.851106 
[37m[36mINFO[0m[0m 01/23 01:37:26 | 0.646341    0.649709    0.956969    0.815549    0.594693    0.666078    0.653710    0.602824    0.613936    0.956969    0.815549    0.670122    0.681481    3200        10.967251   0.182962    0.162442    139.683947 
[37m[36mINFO[0m[0m 01/23 01:40:26 | 0.596270    0.602007    0.853770    0.719512    0.759447    0.636042    0.618375    0.516706    0.525424    0.853770    0.719512    0.636061    0.662222    3400        11.652704   0.206882    0.202017    138.927707 
[37m[36mINFO[0m[0m 01/23 01:43:24 | 0.641577    0.671090    0.948210    0.812500    0.630687    0.582155    0.621908    0.660235    0.681733    0.948210    0.812500    0.682340    0.709630    3600        12.338157   0.175440    0.201154    138.490842 
[37m[36mINFO[0m[0m 01/23 01:46:18 | 0.543615    0.569610    0.958111    0.821646    0.647515    0.397527    0.459364    0.613176    0.634652    0.958111    0.821646    0.620141    0.614815    3800        13.023610   0.142786    0.164022    140.592351 
[37m[36mINFO[0m[0m 01/23 01:49:17 | 0.574119    0.586240    0.957350    0.792683    0.764877    0.533569    0.575972    0.562353    0.564972    0.957350    0.792683    0.626435    0.617778    4000        13.709063   0.141474    0.184411    142.312160 
[37m[36mINFO[0m[0m 01/23 01:52:08 | 0.589197    0.598747    0.946306    0.801829    0.684833    0.561837    0.586572    0.586353    0.580038    0.946306    0.801829    0.619400    0.629630    4200        14.394516   0.152691    0.165102    138.077121 
[37m[36mINFO[0m[0m 01/23 01:55:01 | 0.580684    0.610226    0.953161    0.810976    0.772032    0.451413    0.515901    0.637176    0.642185    0.953161    0.810976    0.653462    0.672593    4400        15.079970   0.137352    0.153441    141.783669 
[37m[36mINFO[0m[0m 01/23 01:57:55 | 0.669702    0.680647    0.957350    0.798780    0.829215    0.690813    0.689046    0.619294    0.640301    0.957350    0.798780    0.699000    0.712593    4600        15.765423   0.103612    0.170271    139.647874 
[37m[36mINFO[0m[0m 01/23 02:00:49 | 0.591567    0.617922    0.975248    0.814024    0.812268    0.521201    0.561837    0.596706    0.604520    0.975248    0.814024    0.656794    0.687407    4800        16.450876   0.092729    0.159295    142.061033 
[37m[36mINFO[0m[0m 01/23 02:03:37 | 0.599732    0.614302    0.952018    0.797256    0.940277    0.514134    0.515901    0.630118    0.664783    0.952018    0.797256    0.654943    0.662222    5000        17.136329   0.097229    0.156054    137.129046 
[37m[36mINFO[0m[0m 01/23 02:03:37 | Cumulative gradient change saved at train_output/VLCS/gsnr1224/[0, 1, 3]/250123_00-49-03_resnet50_sgd/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 01/23 02:03:38 | ---
[37m[36mINFO[0m[0m 01/23 02:03:38 | test-domain validation(oracle) = 68.008%
[37m[36mINFO[0m[0m 01/23 02:03:38 | training-domain validation(iid) = 68.498%
[37m[36mINFO[0m[0m 01/23 02:03:38 | last = 59.973%
[37m[36mINFO[0m[0m 01/23 02:03:38 | last (inD) = 79.726%
[37m[36mINFO[0m[0m 01/23 02:03:38 | training-domain validation (iid, inD) = 82.317%
[37m[36mINFO[0m[0m 01/23 02:03:39 | === Summary ===
[37m[36mINFO[0m[0m 01/23 02:03:39 | Command: /jsm0707/DomainBed/Large-scale/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm gsnr1224 --test_envs 0 1 3 --dataset VLCS --trial_seed 2 --hparams_seed 13
[37m[36mINFO[0m[0m 01/23 02:03:39 | Unique name: 250123_00-49-03_resnet50_sgd
[37m[36mINFO[0m[0m 01/23 02:03:39 | Out path: train_output/VLCS/gsnr1224/[0, 1, 3]/250123_00-49-03_resnet50_sgd
[37m[36mINFO[0m[0m 01/23 02:03:39 | Algorithm: gsnr1224
[37m[36mINFO[0m[0m 01/23 02:03:39 | Dataset: VLCS
