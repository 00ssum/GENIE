[37m[36mINFO[0m[0m 01/26 02:12:16 | Command :: /jsm0707/Large-scale/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm ERM --test_envs 1 2 3 --dataset VLCS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: ERM
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_adam.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_adam
	out_dir: train_output/VLCS/ERM/[1, 2, 3]/250126_02-12-16_resnet50_adam
	out_root: train_output/VLCS/ERM/[1, 2, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [1, 2, 3]
	trial_seed: 0
	unique_name: 250126_02-12-16_resnet50_adam
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: adam
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 01/26 02:12:16 | n_steps = 5001
[37m[36mINFO[0m[0m 01/26 02:12:16 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 01/26 02:12:16 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 01/26 02:12:16 | 
[37m[36mINFO[0m[0m 01/26 02:12:16 | Testenv name escaping te_L_S_V -> te_L_S_V
[37m[36mINFO[0m[0m 01/26 02:12:16 | Test envs = [1, 2, 3], name = te_L_S_V
[37m[36mINFO[0m[0m 01/26 02:12:16 | Train environments: [0], Test environments: [1, 2, 3]
[37m[36mINFO[0m[0m 01/26 02:12:16 | Batch sizes for each domain: [32, 0, 0, 0] (total=32)
[37m[36mINFO[0m[0m 01/26 02:12:16 | steps-per-epoch for each domain: 35.38 -> min = 35.38
[37m[36mINFO[0m[0m 01/26 02:12:18 | # of params = 23518277
[37m[36mINFO[0m[0m 01/26 02:14:22 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 01/26 02:14:22 | 0.400874    0.416575    0.694346    0.696113    1.319062    0.694346    0.696113    0.450353    0.487759    0.384996    0.385671    0.367271    0.376296    0           0.000000    1.820007    1.900594    121.554438 
[37m[36mINFO[0m[0m 01/26 02:16:53 | 0.396405    0.389510    1.000000    0.992933    0.021109    1.000000    0.992933    0.346824    0.348399    0.404037    0.399390    0.438356    0.420741    200         5.653710    0.048336    0.140806    123.176358 
[37m[36mINFO[0m[0m 01/26 02:19:27 | 0.288530    0.285356    0.979682    0.957597    0.107677    0.979682    0.957597    0.265412    0.271186    0.201066    0.199695    0.399111    0.385185    400         11.307420   0.014810    0.142998    124.645150 
[37m[36mINFO[0m[0m 01/26 02:21:59 | 0.337202    0.347071    1.000000    1.000000    0.001779    1.000000    1.000000    0.216941    0.242938    0.351866    0.359756    0.442799    0.438519    600         16.961131   0.008096    0.140960    124.279362 
[37m[36mINFO[0m[0m 01/26 02:24:32 | 0.312680    0.312603    1.000000    1.000000    0.000943    1.000000    1.000000    0.183529    0.197740    0.345773    0.344512    0.408738    0.395556    800         22.614841   0.000044    0.140607    124.794039 
[37m[36mINFO[0m[0m 01/26 02:27:08 | 0.309239    0.310478    1.000000    1.000000    0.000049    1.000000    1.000000    0.184471    0.203390    0.340061    0.338415    0.403184    0.389630    1000        28.268551   0.000014    0.143567    127.428580 
[37m[36mINFO[0m[0m 01/26 02:29:40 | 0.310430    0.309490    1.000000    1.000000    0.000045    1.000000    1.000000    0.185412    0.203390    0.341584    0.338415    0.404295    0.386667    1200        33.922261   0.000009    0.142823    123.026384 
[37m[36mINFO[0m[0m 01/26 02:32:12 | 0.337630    0.343629    1.000000    1.000000    0.000036    1.000000    1.000000    0.217412    0.235405    0.354532    0.365854    0.440948    0.429630    1400        39.575972   0.000010    0.136824    124.887437 
[37m[36mINFO[0m[0m 01/26 02:34:43 | 0.332818    0.339277    1.000000    1.000000    0.000037    1.000000    1.000000    0.212706    0.229755    0.350724    0.365854    0.435024    0.422222    1600        45.229682   0.000003    0.137041    122.990455 
[37m[36mINFO[0m[0m 01/26 02:37:14 | 0.329077    0.335283    1.000000    1.000000    0.000030    1.000000    1.000000    0.208941    0.229755    0.348819    0.361280    0.429471    0.414815    1800        50.883392   0.000003    0.142996    123.177023 
[37m[36mINFO[0m[0m 01/26 02:39:47 | 0.337271    0.343002    1.000000    1.000000    0.000023    1.000000    1.000000    0.217412    0.233522    0.355674    0.365854    0.438726    0.429630    2000        56.537102   0.000003    0.143149    124.185280 
[37m[36mINFO[0m[0m 01/26 02:42:20 | 0.351904    0.352263    1.000000    1.000000    0.001569    1.000000    1.000000    0.231059    0.246704    0.351866    0.358232    0.472788    0.451852    2200        62.190813   0.000087    0.140119    125.216340 
[37m[36mINFO[0m[0m 01/26 02:44:55 | 0.326320    0.330430    1.000000    0.996466    0.009283    1.000000    0.996466    0.184941    0.210923    0.355293    0.355183    0.438726    0.425185    2400        67.844523   0.000024    0.137513    127.347434 
[37m[36mINFO[0m[0m 01/26 02:47:30 | 0.175083    0.178705    0.834806    0.819788    0.470534    0.834806    0.819788    0.047059    0.047081    0.261234    0.268293    0.216957    0.220741    2600        73.498233   0.294504    0.135513    127.224156 
[37m[36mINFO[0m[0m 01/26 02:50:03 | 0.196436    0.188269    0.954064    0.932862    0.202226    0.954064    0.932862    0.105882    0.090395    0.223153    0.222561    0.260274    0.251852    2800        79.151943   0.125132    0.140326    125.600333 
[37m[36mINFO[0m[0m 01/26 02:52:36 | 0.205282    0.199847    0.994700    0.982332    0.049066    0.994700    0.982332    0.105412    0.092279    0.235720    0.231707    0.274713    0.275556    3000        84.805654   0.027773    0.138470    125.309790 
[37m[36mINFO[0m[0m 01/26 02:55:07 | 0.244936    0.247411    0.997350    0.989399    0.034626    0.997350    0.989399    0.129882    0.131827    0.318736    0.317073    0.286190    0.293333    3200        90.459364   0.021627    0.138774    123.033898 
[37m[36mINFO[0m[0m 01/26 02:57:36 | 0.216621    0.208527    1.000000    0.985866    0.032013    1.000000    0.985866    0.110118    0.099812    0.264661    0.257622    0.275083    0.268148    3400        96.113074   0.007025    0.137804    121.435134 
[37m[36mINFO[0m[0m 01/26 03:00:08 | 0.225514    0.218154    1.000000    0.992933    0.026375    1.000000    0.992933    0.105412    0.092279    0.288271    0.288110    0.282858    0.274074    3600        101.766784  0.000467    0.138718    123.771458 
[37m[36mINFO[0m[0m 01/26 03:02:43 | 0.209927    0.205422    1.000000    0.985866    0.048178    1.000000    0.985866    0.107765    0.092279    0.252856    0.246951    0.269160    0.277037    3800        107.420495  0.002459    0.139092    127.369561 
[37m[36mINFO[0m[0m 01/26 03:05:12 | 0.243535    0.234923    0.998233    0.992933    0.021178    0.998233    0.992933    0.121882    0.105461    0.295506    0.291159    0.313217    0.308148    4000        113.074205  0.013737    0.139086    121.735492 
[37m[36mINFO[0m[0m 01/26 03:07:47 | 0.233774    0.226062    1.000000    0.992933    0.019660    1.000000    0.992933    0.114824    0.105461    0.295126    0.294207    0.291374    0.278519    4200        118.727915  0.000308    0.137673    126.673879 
[37m[36mINFO[0m[0m 01/26 03:10:17 | 0.232336    0.229400    1.000000    0.992933    0.020513    1.000000    0.992933    0.112000    0.103578    0.294745    0.295732    0.290263    0.288889    4400        124.381625  0.000094    0.139425    122.492451 
[37m[36mINFO[0m[0m 01/26 03:12:47 | 0.230589    0.219126    1.000000    0.992933    0.023893    1.000000    0.992933    0.112471    0.099812    0.289033    0.282012    0.290263    0.275556    4600        130.035336  0.000090    0.139198    122.359932 
[37m[36mINFO[0m[0m 01/26 03:15:20 | 0.231945    0.220651    1.000000    0.992933    0.024999    1.000000    0.992933    0.110118    0.099812    0.293602    0.286585    0.292114    0.275556    4800        135.689046  0.000019    0.143753    123.798856 
[37m[36mINFO[0m[0m 01/26 03:17:56 | 0.232206    0.225866    0.977032    0.968198    0.112592    0.977032    0.968198    0.109176    0.101695    0.302361    0.301829    0.285080    0.274074    5000        141.342756  0.000276    0.139297    128.634733 
[37m[36mINFO[0m[0m 01/26 03:17:56 | Cumulative gradient change saved at train_output/VLCS/ERM/[1, 2, 3]/250126_02-12-16_resnet50_adam/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 01/26 03:17:57 | ---
[37m[36mINFO[0m[0m 01/26 03:17:57 | test-domain validation(oracle) = 40.087%
[37m[36mINFO[0m[0m 01/26 03:17:57 | training-domain validation(iid) = 33.720%
[37m[36mINFO[0m[0m 01/26 03:17:57 | last = 23.221%
[37m[36mINFO[0m[0m 01/26 03:17:57 | last (inD) = 96.820%
[37m[36mINFO[0m[0m 01/26 03:17:57 | training-domain validation (iid, inD) = 100.000%
[37m[36mINFO[0m[0m 01/26 03:17:57 | === Summary ===
[37m[36mINFO[0m[0m 01/26 03:17:57 | Command: /jsm0707/Large-scale/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm ERM --test_envs 1 2 3 --dataset VLCS
[37m[36mINFO[0m[0m 01/26 03:17:57 | Unique name: 250126_02-12-16_resnet50_adam
[37m[36mINFO[0m[0m 01/26 03:17:57 | Out path: train_output/VLCS/ERM/[1, 2, 3]/250126_02-12-16_resnet50_adam
[37m[36mINFO[0m[0m 01/26 03:17:57 | Algorithm: ERM
[37m[36mINFO[0m[0m 01/26 03:17:57 | Dataset: VLCS
