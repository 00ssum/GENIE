[37m[36mINFO[0m[0m 03/14 15:15:00 | Command :: /jsm0707/GENIE/train_all.py resnet50_signum config/resnet50_signum.yaml --algorithm ERM --test_envs 3 --dataset VLCS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: ERM
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_signum.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_signum
	out_dir: train_output/VLCS/ERM/[3]/250314_15-15-00_resnet50_signum
	out_root: train_output/VLCS/ERM/[3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [3]
	trial_seed: 0
	unique_name: 250314_15-15-00_resnet50_signum
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: signum
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 03/14 15:15:00 | n_steps = 5001
[37m[36mINFO[0m[0m 03/14 15:15:00 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/14 15:15:00 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/14 15:15:00 | 
[37m[36mINFO[0m[0m 03/14 15:15:00 | Testenv name escaping te_V -> te_V
[37m[36mINFO[0m[0m 03/14 15:15:00 | Test envs = [3], name = te_V
[37m[36mINFO[0m[0m 03/14 15:15:00 | Train environments: [0, 1, 2], Test environments: [3]
[37m[36mINFO[0m[0m 03/14 15:15:00 | Batch sizes for each domain: [32, 32, 32, 0] (total=96)
[37m[36mINFO[0m[0m 03/14 15:15:00 | steps-per-epoch for each domain: 35.38, 66.41, 82.06 -> min = 35.38
[37m[36mINFO[0m[0m 03/14 15:15:02 | # of params = 23518277
[37m[36mINFO[0m[0m 03/14 15:17:16 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/14 15:17:16 | 0.393558    0.413333    0.468913    0.422612    1.400660    0.477032    0.325088    0.531765    0.523540    0.397944    0.419207    0.393558    0.413333    0           0.000000    1.809193    1.332138    133.418916 
[37m[36mINFO[0m[0m 03/14 15:23:20 | 0.742688    0.752593    0.848173    0.831322    0.425325    1.000000    1.000000    0.730353    0.704331    0.814166    0.789634    0.742688    0.752593    200         5.653710    0.501065    1.145099    134.412191 
[37m[36mINFO[0m[0m 03/14 15:29:24 | 0.650130    0.677037    0.795433    0.780901    0.522970    0.987633    0.992933    0.664471    0.651601    0.734196    0.698171    0.650130    0.677037    400         11.307420   0.438769    1.141685    135.514827 
[37m[36mINFO[0m[0m 03/14 15:35:25 | 0.356905    0.357037    0.631755    0.630031    0.951079    0.903710    0.911661    0.468706    0.470810    0.522848    0.507622    0.356905    0.357037    600         16.961131   0.565434    1.132277    134.916287 
[37m[36mINFO[0m[0m 03/14 15:41:24 | 0.593854    0.601481    0.800242    0.800580    0.607875    0.918728    0.925795    0.728000    0.745763    0.753998    0.730183    0.593854    0.601481    800         22.614841   0.973182    1.141587    130.678787 
[37m[36mINFO[0m[0m 03/14 15:47:25 | 0.397631    0.420741    0.688679    0.686250    0.834865    0.895760    0.901060    0.557176    0.555556    0.613100    0.602134    0.397631    0.420741    1000        28.268551   1.644008    1.139843    132.623918 
[37m[36mINFO[0m[0m 03/14 15:53:15 | 0.484635    0.506667    0.625238    0.643646    0.876461    0.778269    0.802120    0.540706    0.580038    0.556740    0.548780    0.484635    0.506667    1200        33.922261   2.033291    1.104640    129.437264 
[37m[36mINFO[0m[0m 03/14 15:59:07 | 0.255091    0.240000    0.415744    0.450737    1.290126    0.471731    0.568905    0.464000    0.438795    0.311500    0.344512    0.255091    0.240000    1400        39.575972   1.450418    1.095406    132.814503 
[37m[36mINFO[0m[0m 03/14 16:04:58 | 0.417993    0.445926    0.569670    0.571957    1.271311    0.742933    0.720848    0.448941    0.485876    0.517136    0.509146    0.417993    0.445926    1600        45.229682   1.404759    1.103756    130.327442 
[37m[36mINFO[0m[0m 03/14 16:10:46 | 0.416512    0.423704    0.554070    0.553336    1.478489    0.728799    0.756184    0.491294    0.463277    0.442117    0.440549    0.416512    0.423704    1800        50.883392   1.428556    1.095808    128.946645 
[37m[36mINFO[0m[0m 03/14 16:16:32 | 0.322843    0.303704    0.587940    0.591620    1.252159    0.893993    0.893993    0.457412    0.438795    0.412414    0.442073    0.322843    0.303704    2000        56.537102   1.344325    1.094788    127.036038 
[37m[36mINFO[0m[0m 03/14 16:22:19 | 0.276194    0.287407    0.584353    0.598552    0.959139    0.818021    0.840989    0.465882    0.450094    0.469155    0.504573    0.276194    0.287407    2200        62.190813   1.397583    1.096213    128.007833 
[37m[36mINFO[0m[0m 03/14 16:28:12 | 0.306553    0.293333    0.591917    0.627068    1.039156    0.901060    0.918728    0.522824    0.531073    0.351866    0.431402    0.306553    0.293333    2400        67.844523   1.300210    1.101720    131.890683 
[37m[36mINFO[0m[0m 03/14 16:34:05 | 0.443169    0.463704    0.580010    0.595347    0.963561    0.800353    0.795053    0.476235    0.504708    0.463442    0.486280    0.443169    0.463704    2600        73.498233   1.390236    1.109076    131.447679 
[37m[36mINFO[0m[0m 03/14 16:39:53 | 0.268789    0.263704    0.389618    0.401445    1.279646    0.324205    0.385159    0.461176    0.435028    0.383473    0.384146    0.268789    0.263704    2800        79.151943   1.541302    1.093400    129.500515 
[37m[36mINFO[0m[0m 03/14 16:45:42 | 0.261755    0.257778    0.524592    0.522694    1.721275    0.774735    0.780919    0.461647    0.435028    0.337395    0.352134    0.261755    0.257778    3000        84.805654   1.626813    1.103878    128.634543 
[37m[36mINFO[0m[0m 03/14 16:51:39 | 0.264347    0.226667    0.512961    0.530467    1.277701    0.877208    0.851590    0.378353    0.378531    0.283321    0.361280    0.264347    0.226667    3200        90.459364   1.559466    1.112292    134.550546 
[37m[36mINFO[0m[0m 03/14 16:57:37 | 0.420955    0.432593    0.618747    0.627866    1.012048    0.896643    0.872792    0.490824    0.504708    0.468774    0.506098    0.420955    0.432593    3400        96.113074   1.416330    1.125672    132.017405 
[37m[36mINFO[0m[0m 03/14 17:03:38 | 0.428360    0.440000    0.636585    0.646341    1.053783    0.770318    0.777385    0.573176    0.576271    0.566260    0.585366    0.428360    0.440000    3600        101.766784  1.175639    1.136136    134.617658 
[37m[36mINFO[0m[0m 03/14 17:09:34 | 0.315809    0.314074    0.577541    0.614257    0.944899    0.776502    0.844523    0.478588    0.470810    0.477532    0.527439    0.315809    0.314074    3800        107.420495  1.355545    1.124220    130.571856 
[37m[36mINFO[0m[0m 03/14 17:15:35 | 0.350241    0.343704    0.566582    0.575515    1.016646    0.734982    0.756184    0.472000    0.476460    0.492765    0.493902    0.350241    0.343704    4000        113.074205  1.430413    1.121596    136.963359 
[37m[36mINFO[0m[0m 03/14 17:21:33 | 0.289893    0.280000    0.553369    0.572621    1.210753    0.722615    0.784452    0.442824    0.410546    0.494669    0.522866    0.289893    0.280000    4200        118.727915  1.475365    1.144469    128.482797 
[37m[36mINFO[0m[0m 03/14 17:27:21 | 0.347279    0.360000    0.359139    0.392520    2.024368    0.384276    0.371025    0.423529    0.472693    0.269612    0.333841    0.347279    0.360000    4400        124.381625  1.554497    1.094590    129.061187 
[37m[36mINFO[0m[0m 03/14 17:33:12 | 0.303961    0.306667    0.535018    0.559783    2.154991    0.801237    0.787986    0.468706    0.485876    0.335110    0.405488    0.303961    0.306667    4600        130.035336  1.429945    1.095921    132.289205 
[37m[36mINFO[0m[0m 03/14 17:39:01 | 0.299519    0.287407    0.531780    0.536792    1.778408    0.814488    0.812721    0.462118    0.450094    0.318736    0.347561    0.299519    0.287407    4800        135.689046  1.407759    1.094943    130.397802 
[37m[36mINFO[0m[0m 03/14 17:44:53 | 0.268789    0.269630    0.450125    0.510492    1.482005    0.780919    0.823322    0.276235    0.348399    0.293222    0.359756    0.268789    0.269630    5000        141.342756  1.263174    1.103049    131.327424 
[37m[36mINFO[0m[0m 03/14 17:44:53 | Cumulative gradient change saved at train_output/VLCS/ERM/[3]/250314_15-15-00_resnet50_signum/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/14 17:44:54 | ---
[37m[36mINFO[0m[0m 03/14 17:44:54 | test-domain validation(oracle) = 74.269%
[37m[36mINFO[0m[0m 03/14 17:44:54 | training-domain validation(iid) = 74.269%
[37m[36mINFO[0m[0m 03/14 17:44:54 | last = 26.879%
[37m[36mINFO[0m[0m 03/14 17:44:54 | last (inD) = 51.049%
[37m[36mINFO[0m[0m 03/14 17:44:54 | training-domain validation (iid, inD) = 83.132%
[37m[36mINFO[0m[0m 03/14 17:44:55 | === Summary ===
[37m[36mINFO[0m[0m 03/14 17:44:55 | Command: /jsm0707/GENIE/train_all.py resnet50_signum config/resnet50_signum.yaml --algorithm ERM --test_envs 3 --dataset VLCS
[37m[36mINFO[0m[0m 03/14 17:44:55 | Unique name: 250314_15-15-00_resnet50_signum
[37m[36mINFO[0m[0m 03/14 17:44:55 | Out path: train_output/VLCS/ERM/[3]/250314_15-15-00_resnet50_signum
[37m[36mINFO[0m[0m 03/14 17:44:55 | Algorithm: ERM
[37m[36mINFO[0m[0m 03/14 17:44:55 | Dataset: VLCS
