[37m[36mINFO[0m[0m 03/11 23:43:09 | Command :: /jsm0707/GENIE/train_all.py clip_vitb16_GENIE config/clip_vitb16_GENIE.yaml --algorithm ERM --test_envs 3 --dataset VLCS --trial_seed 0 --hparams_seed 18
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: ERM
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/clip_vitb16_GENIE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 18
	in_domain: False
	model_save: None
	mpa: False
	name: clip_vitb16_GENIE
	out_dir: train_output/VLCS/ERM/[3]/250311_23-43-09_clip_vitb16_GENIE
	out_root: train_output/VLCS/ERM/[3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [3]
	trial_seed: 0
	unique_name: 250311_23-43-09_clip_vitb16_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.1
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 0.00021894640154701087
	batch_size: 13
	weight_decay: 7.1565884139944e-05
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: openclip_vit-b16
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 03/11 23:43:09 | n_steps = 5001
[37m[36mINFO[0m[0m 03/11 23:43:09 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/11 23:43:09 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/11 23:43:09 | 
[37m[36mINFO[0m[0m 03/11 23:43:09 | Testenv name escaping te_V -> te_V
[37m[36mINFO[0m[0m 03/11 23:43:09 | Test envs = [3], name = te_V
[37m[36mINFO[0m[0m 03/11 23:43:09 | Train environments: [0, 1, 2], Test environments: [3]
[37m[36mINFO[0m[0m 03/11 23:43:09 | Batch sizes for each domain: [13, 13, 13, 0] (total=39)
[37m[36mINFO[0m[0m 03/11 23:43:09 | steps-per-epoch for each domain: 87.08, 163.46, 202.00 -> min = 87.08
[37m[36mINFO[0m[0m 03/11 23:43:12 | # of params = 86195205
[37m[36mINFO[0m[0m 03/11 23:45:21 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/11 23:45:21 | 0.281007    0.291852    0.396199    0.390588    1.376110    0.345406    0.339223    0.513412    0.497175    0.329779    0.335366    0.281007    0.291852    0           0.000000    1.678708    0.989981    128.321737 
[37m[36mINFO[0m[0m 03/11 23:49:06 | 0.572010    0.564444    0.723719    0.727764    0.669958    0.918728    0.908127    0.640471    0.644068    0.611957    0.631098    0.572010    0.564444    200         2.296820    0.938582    0.461253    132.553883 
[37m[36mINFO[0m[0m 03/11 23:52:53 | 0.557942    0.589630    0.749312    0.736577    0.653240    0.928445    0.897527    0.686588    0.702448    0.632902    0.609756    0.557942    0.589630    400         4.593640    0.607772    0.485985    130.042328 
[37m[36mINFO[0m[0m 03/11 23:56:45 | 0.628286    0.605926    0.799966    0.787029    0.513985    0.957597    0.957597    0.719529    0.717514    0.722772    0.685976    0.628286    0.605926    600         6.890459    0.515644    0.472504    137.797334 
[37m[36mINFO[0m[0m 03/12 00:00:31 | 0.621622    0.620741    0.818988    0.806925    0.478543    0.958481    0.971731    0.726588    0.732580    0.771896    0.716463    0.621622    0.620741    800         9.187279    0.460335    0.461423    133.776667 
[37m[36mINFO[0m[0m 03/12 00:04:20 | 0.643095    0.645926    0.843511    0.816029    0.466115    0.977915    0.968198    0.762824    0.734463    0.789794    0.745427    0.643095    0.645926    1000        11.484099   0.440330    0.469956    134.820604 
[37m[36mINFO[0m[0m 03/12 00:08:03 | 0.655683    0.650370    0.867175    0.824525    0.440301    0.993816    0.978799    0.782118    0.732580    0.825590    0.762195    0.655683    0.650370    1200        13.780919   0.394393    0.471068    128.659626 
[37m[36mINFO[0m[0m 03/12 00:11:41 | 0.656424    0.631111    0.856152    0.823054    0.455916    0.992049    0.985866    0.763765    0.736347    0.812643    0.746951    0.656424    0.631111    1400        16.077739   0.373590    0.449218    128.358072 
[37m[36mINFO[0m[0m 03/12 00:15:21 | 0.673454    0.674074    0.865035    0.818265    0.450727    0.994700    0.975265    0.779765    0.732580    0.820640    0.746951    0.673454    0.674074    1600        18.374558   0.344859    0.451650    129.362247 
[37m[36mINFO[0m[0m 03/12 00:18:59 | 0.651240    0.637037    0.883729    0.815181    0.470293    0.999117    0.982332    0.807059    0.726930    0.845011    0.736280    0.651240    0.637037    1800        20.671378   0.332183    0.446823    128.493898 
[37m[36mINFO[0m[0m 03/12 00:22:40 | 0.629397    0.617778    0.889688    0.814326    0.494428    0.996466    0.968198    0.826824    0.747646    0.845773    0.727134    0.629397    0.617778    2000        22.968198   0.294835    0.445198    132.089614 
[37m[36mINFO[0m[0m 03/12 00:26:19 | 0.628656    0.611852    0.890551    0.804175    0.514537    0.987633    0.971731    0.826824    0.721281    0.857197    0.719512    0.628656    0.611852    2200        25.265018   0.277782    0.457625    127.600175 
[37m[36mINFO[0m[0m 03/12 00:30:02 | 0.643836    0.632593    0.906353    0.807864    0.549747    0.995583    0.975265    0.848000    0.728814    0.875476    0.719512    0.643836    0.632593    2400        27.561837   0.272186    0.461376    130.652797 
[37m[36mINFO[0m[0m 03/12 00:33:47 | 0.632358    0.594074    0.909764    0.800856    0.571758    0.983216    0.954064    0.844706    0.713748    0.901371    0.734756    0.632358    0.594074    2600        29.858657   0.252931    0.460786    132.903330 
[37m[36mINFO[0m[0m 03/12 00:37:29 | 0.624583    0.600000    0.906544    0.800559    0.579327    0.999117    0.989399    0.840471    0.715631    0.880046    0.696646    0.624583    0.600000    2800        32.155477   0.225625    0.475271    127.048162 
[37m[36mINFO[0m[0m 03/12 00:41:12 | 0.614587    0.573333    0.919706    0.807355    0.573692    0.996466    0.975265    0.843765    0.696798    0.918888    0.750000    0.614587    0.573333    3000        34.452297   0.198723    0.468502    129.412171 
[37m[36mINFO[0m[0m 03/12 00:44:52 | 0.617179    0.617778    0.922324    0.810260    0.580968    0.992933    0.950530    0.863529    0.736347    0.910510    0.743902    0.617179    0.617778    3200        36.749117   0.193341    0.456705    128.714460 
[37m[36mINFO[0m[0m 03/12 00:48:34 | 0.619030    0.591111    0.926363    0.792528    0.579861    0.993816    0.957597    0.888471    0.708098    0.896801    0.711890    0.619030    0.591111    3400        39.045936   0.208994    0.461503    129.213103 
[37m[36mINFO[0m[0m 03/12 00:52:16 | 0.641984    0.620741    0.949600    0.812156    0.637918    0.997350    0.971731    0.912000    0.726930    0.939452    0.737805    0.641984    0.620741    3600        41.342756   0.176996    0.463616    129.071432 
[37m[36mINFO[0m[0m 03/12 00:55:59 | 0.629397    0.610370    0.937999    0.816419    0.625248    0.981449    0.985866    0.916706    0.743879    0.915842    0.719512    0.629397    0.610370    3800        43.639576   0.156684    0.463249    130.421625 
[37m[36mINFO[0m[0m 03/12 00:59:41 | 0.605702    0.600000    0.936538    0.798311    0.635145    0.990283    0.978799    0.915294    0.743879    0.904037    0.672256    0.605702    0.600000    4000        45.936396   0.153296    0.454059    131.373839 
[37m[36mINFO[0m[0m 03/12 01:03:23 | 0.580155    0.594074    0.958928    0.815206    0.613664    0.999117    0.989399    0.933647    0.738230    0.944021    0.717988    0.580155    0.594074    4200        48.233216   0.143534    0.463580    129.529369 
[37m[36mINFO[0m[0m 03/12 01:07:07 | 0.641984    0.610370    0.955967    0.816115    0.631809    1.000000    0.992933    0.930353    0.741996    0.937548    0.713415    0.641984    0.610370    4400        50.530035   0.137356    0.470263    129.433920 
[37m[36mINFO[0m[0m 03/12 01:10:48 | 0.599408    0.577778    0.951335    0.800869    0.701946    0.997350    0.975265    0.931294    0.730697    0.925362    0.696646    0.599408    0.577778    4600        52.826855   0.118259    0.451339    130.594752 
[37m[36mINFO[0m[0m 03/12 01:14:27 | 0.606812    0.608889    0.946304    0.823025    0.592313    0.996466    0.985866    0.908706    0.743879    0.933740    0.739329    0.606812    0.608889    4800        55.123675   0.128709    0.455742    128.272290 
[37m[36mINFO[0m[0m 03/12 01:18:10 | 0.613106    0.611852    0.967236    0.803469    0.654463    1.000000    0.975265    0.945882    0.715631    0.955826    0.719512    0.613106    0.611852    5000        57.420495   0.108954    0.467411    129.615958 
[37m[36mINFO[0m[0m 03/12 01:18:11 | Cumulative gradient change saved at train_output/VLCS/ERM/[3]/250311_23-43-09_clip_vitb16_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/12 01:18:13 | ---
[37m[36mINFO[0m[0m 03/12 01:18:13 | test-domain validation(oracle) = 67.345%
[37m[36mINFO[0m[0m 03/12 01:18:13 | training-domain validation(iid) = 65.568%
[37m[36mINFO[0m[0m 03/12 01:18:13 | last = 61.311%
[37m[36mINFO[0m[0m 03/12 01:18:13 | last (inD) = 80.347%
[37m[36mINFO[0m[0m 03/12 01:18:13 | training-domain validation (iid, inD) = 82.452%
[37m[36mINFO[0m[0m 03/12 01:18:13 | === Summary ===
[37m[36mINFO[0m[0m 03/12 01:18:13 | Command: /jsm0707/GENIE/train_all.py clip_vitb16_GENIE config/clip_vitb16_GENIE.yaml --algorithm ERM --test_envs 3 --dataset VLCS --trial_seed 0 --hparams_seed 18
[37m[36mINFO[0m[0m 03/12 01:18:13 | Unique name: 250311_23-43-09_clip_vitb16_GENIE
[37m[36mINFO[0m[0m 03/12 01:18:13 | Out path: train_output/VLCS/ERM/[3]/250311_23-43-09_clip_vitb16_GENIE
[37m[36mINFO[0m[0m 03/12 01:18:13 | Algorithm: ERM
[37m[36mINFO[0m[0m 03/12 01:18:13 | Dataset: VLCS
