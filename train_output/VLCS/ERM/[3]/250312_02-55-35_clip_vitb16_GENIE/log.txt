[37m[36mINFO[0m[0m 03/12 02:55:35 | Command :: /jsm0707/GENIE/train_all.py clip_vitb16_GENIE config/clip_vitb16_GENIE.yaml --algorithm ERM --test_envs 3 --dataset VLCS --trial_seed 1 --hparams_seed 3
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: ERM
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/clip_vitb16_GENIE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 3
	in_domain: False
	model_save: None
	mpa: False
	name: clip_vitb16_GENIE
	out_dir: train_output/VLCS/ERM/[3]/250312_02-55-35_clip_vitb16_GENIE
	out_root: train_output/VLCS/ERM/[3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [3]
	trial_seed: 1
	unique_name: 250312_02-55-35_clip_vitb16_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.5
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 0.00018664964766736356
	batch_size: 13
	weight_decay: 0.0001969969539389593
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: openclip_vit-b16
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 03/12 02:55:35 | n_steps = 5001
[37m[36mINFO[0m[0m 03/12 02:55:35 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/12 02:55:35 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/12 02:55:35 | 
[37m[36mINFO[0m[0m 03/12 02:55:35 | Testenv name escaping te_V -> te_V
[37m[36mINFO[0m[0m 03/12 02:55:35 | Test envs = [3], name = te_V
[37m[36mINFO[0m[0m 03/12 02:55:35 | Train environments: [0, 1, 2], Test environments: [3]
[37m[36mINFO[0m[0m 03/12 02:55:35 | Batch sizes for each domain: [13, 13, 13, 0] (total=39)
[37m[36mINFO[0m[0m 03/12 02:55:35 | steps-per-epoch for each domain: 87.08, 163.46, 202.00 -> min = 87.08
[37m[36mINFO[0m[0m 03/12 02:55:38 | # of params = 86195205
[37m[36mINFO[0m[0m 03/12 02:57:49 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/12 02:57:49 | 0.426138    0.388148    0.479758    0.491892    1.388348    0.597173    0.593640    0.475765    0.468927    0.366337    0.413110    0.426138    0.388148    0           0.000000    1.720389    1.128697    130.027461 
[37m[36mINFO[0m[0m 03/12 03:01:34 | 0.466124    0.453333    0.651112    0.651749    0.818747    0.892226    0.855124    0.595765    0.589454    0.465347    0.510671    0.466124    0.453333    200         2.296820    1.101491    0.462963    132.455888 
[37m[36mINFO[0m[0m 03/12 03:05:16 | 0.554239    0.540741    0.736338    0.731820    0.626060    0.954947    0.957597    0.647059    0.640301    0.607007    0.597561    0.554239    0.540741    400         4.593640    0.747725    0.464900    129.561032 
[37m[36mINFO[0m[0m 03/12 03:09:01 | 0.629026    0.629630    0.813387    0.814506    0.494066    0.988516    0.985866    0.726588    0.745763    0.725057    0.711890    0.629026    0.629630    600         6.890459    0.567253    0.452896    133.786331 
[37m[36mINFO[0m[0m 03/12 03:12:46 | 0.680118    0.665185    0.834578    0.817136    0.448276    0.992049    0.985866    0.745882    0.723164    0.765804    0.742378    0.680118    0.665185    800         9.187279    0.501939    0.461612    132.993556 
[37m[36mINFO[0m[0m 03/12 03:16:28 | 0.606812    0.580741    0.824848    0.793660    0.491612    0.981449    0.982332    0.748235    0.708098    0.744859    0.690549    0.606812    0.580741    1000        11.484099   0.448366    0.450031    131.708302 
[37m[36mINFO[0m[0m 03/12 03:20:13 | 0.642355    0.656296    0.841399    0.820693    0.458976    0.992933    0.985866    0.748706    0.723164    0.782559    0.753049    0.642355    0.656296    1200        13.780919   0.420896    0.464817    132.057109 
[37m[36mINFO[0m[0m 03/12 03:23:54 | 0.604961    0.598519    0.818468    0.807541    0.484478    0.986749    0.985866    0.745882    0.708098    0.722772    0.728659    0.604961    0.598519    1400        16.077739   0.411033    0.460553    129.049533 
[37m[36mINFO[0m[0m 03/12 03:27:38 | 0.664939    0.660741    0.861630    0.812114    0.483633    0.992049    0.968198    0.800000    0.728814    0.792841    0.739329    0.664939    0.660741    1600        18.374558   0.392305    0.464333    131.480513 
[37m[36mINFO[0m[0m 03/12 03:31:23 | 0.633469    0.628148    0.876771    0.815712    0.477178    0.995583    0.971731    0.800000    0.726930    0.834730    0.748476    0.633469    0.628148    1800        20.671378   0.347369    0.464742    131.566248 
[37m[36mINFO[0m[0m 03/12 03:35:03 | 0.633839    0.647407    0.884754    0.829433    0.451125    0.997350    0.989399    0.816471    0.738230    0.840442    0.760671    0.633839    0.647407    2000        22.968198   0.325593    0.457556    128.798902 
[37m[36mINFO[0m[0m 03/12 03:38:47 | 0.596076    0.617778    0.882246    0.812276    0.477433    0.995583    0.989399    0.812235    0.740113    0.838919    0.707317    0.596076    0.617778    2200        25.265018   0.350388    0.461817    131.429347 
[37m[36mINFO[0m[0m 03/12 03:42:32 | 0.638282    0.622222    0.884160    0.825140    0.488305    0.991166    0.975265    0.789647    0.728814    0.871668    0.771341    0.638282    0.622222    2400        27.561837   0.326741    0.472874    130.109122 
[37m[36mINFO[0m[0m 03/12 03:46:13 | 0.639763    0.632593    0.898140    0.833151    0.478656    0.990283    0.975265    0.832471    0.758945    0.871668    0.765244    0.639763    0.632593    2600        29.858657   0.303187    0.463341    128.439388 
[37m[36mINFO[0m[0m 03/12 03:49:56 | 0.648649    0.638519    0.907550    0.820597    0.488113    0.996466    0.975265    0.844235    0.721281    0.881950    0.765244    0.648649    0.638519    2800        32.155477   0.280138    0.462488    130.500340 
[37m[36mINFO[0m[0m 03/12 03:53:40 | 0.609404    0.631111    0.911913    0.812832    0.526161    0.996466    0.985866    0.856941    0.719397    0.882331    0.733232    0.609404    0.631111    3000        34.452297   0.254621    0.465075    130.868057 
[37m[36mINFO[0m[0m 03/12 03:57:23 | 0.599037    0.560000    0.929552    0.822032    0.545611    0.998233    0.975265    0.887529    0.743879    0.902894    0.746951    0.599037    0.560000    3200        36.749117   0.230041    0.458122    131.866068 
[37m[36mINFO[0m[0m 03/12 04:01:04 | 0.590152    0.607407    0.927136    0.814559    0.538069    0.999117    0.975265    0.882824    0.738230    0.899467    0.730183    0.590152    0.607407    3400        39.045936   0.220499    0.456215    129.690943 
[37m[36mINFO[0m[0m 03/12 04:04:48 | 0.567568    0.579259    0.915196    0.799274    0.604200    1.000000    0.989399    0.854118    0.719397    0.891470    0.689024    0.567568    0.579259    3600        41.342756   0.206983    0.477679    127.829107 
[37m[36mINFO[0m[0m 03/12 04:08:30 | 0.553128    0.570370    0.920750    0.807230    0.600230    0.992933    0.982332    0.876706    0.713748    0.892612    0.725610    0.553128    0.570370    3800        43.639576   0.183949    0.452491    131.848725 
[37m[36mINFO[0m[0m 03/12 04:12:11 | 0.616068    0.582222    0.924870    0.821046    0.569189    0.996466    0.992933    0.879059    0.715631    0.899086    0.754573    0.616068    0.582222    4000        45.936396   0.183528    0.456407    130.021492 
[37m[36mINFO[0m[0m 03/12 04:15:55 | 0.627175    0.589630    0.941625    0.827567    0.589623    0.999117    0.985866    0.911059    0.719397    0.914699    0.777439    0.627175    0.589630    4200        48.233216   0.181751    0.455763    132.210427 
[37m[36mINFO[0m[0m 03/12 04:19:39 | 0.599778    0.582222    0.935532    0.803630    0.690678    1.000000    0.978799    0.888471    0.683616    0.918126    0.748476    0.599778    0.582222    4400        50.530035   0.145567    0.473897    130.049184 
[37m[36mINFO[0m[0m 03/12 04:23:22 | 0.631988    0.613333    0.954394    0.830575    0.576788    0.996466    0.982332    0.934118    0.753296    0.932597    0.756098    0.631988    0.613333    4600        52.826855   0.178112    0.454791    131.456932 
[37m[36mINFO[0m[0m 03/12 04:27:06 | 0.612736    0.622222    0.956005    0.823485    0.615188    0.998233    0.989399    0.932235    0.732580    0.937548    0.748476    0.612736    0.622222    4800        55.123675   0.134990    0.469109    130.776613 
[37m[36mINFO[0m[0m 03/12 04:30:49 | 0.632729    0.628148    0.962099    0.833874    0.611303    0.998233    0.985866    0.940235    0.730697    0.947829    0.785061    0.632729    0.628148    5000        57.420495   0.116029    0.461036    130.744587 
[37m[36mINFO[0m[0m 03/12 04:30:50 | Cumulative gradient change saved at train_output/VLCS/ERM/[3]/250312_02-55-35_clip_vitb16_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/12 04:30:52 | ---
[37m[36mINFO[0m[0m 03/12 04:30:52 | test-domain validation(oracle) = 68.012%
[37m[36mINFO[0m[0m 03/12 04:30:52 | training-domain validation(iid) = 63.273%
[37m[36mINFO[0m[0m 03/12 04:30:52 | last = 63.273%
[37m[36mINFO[0m[0m 03/12 04:30:52 | last (inD) = 83.387%
[37m[36mINFO[0m[0m 03/12 04:30:52 | training-domain validation (iid, inD) = 83.387%
[37m[36mINFO[0m[0m 03/12 04:30:52 | === Summary ===
[37m[36mINFO[0m[0m 03/12 04:30:52 | Command: /jsm0707/GENIE/train_all.py clip_vitb16_GENIE config/clip_vitb16_GENIE.yaml --algorithm ERM --test_envs 3 --dataset VLCS --trial_seed 1 --hparams_seed 3
[37m[36mINFO[0m[0m 03/12 04:30:52 | Unique name: 250312_02-55-35_clip_vitb16_GENIE
[37m[36mINFO[0m[0m 03/12 04:30:52 | Out path: train_output/VLCS/ERM/[3]/250312_02-55-35_clip_vitb16_GENIE
[37m[36mINFO[0m[0m 03/12 04:30:52 | Algorithm: ERM
[37m[36mINFO[0m[0m 03/12 04:30:52 | Dataset: VLCS
