[37m[36mINFO[0m[0m 03/04 08:33:35 | Command :: /jsm0707/GENIE/train_all.py clip_vitb16_sgd config/clip_vitb16_sgd.yaml --algorithm ERM --test_envs 3 --dataset VLCS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: ERM
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/clip_vitb16_sgd.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: clip_vitb16_sgd
	out_dir: train_output/VLCS/ERM/[3]/250304_08-33-35_clip_vitb16_sgd
	out_root: train_output/VLCS/ERM/[3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [3]
	trial_seed: 0
	unique_name: 250304_08-33-35_clip_vitb16_sgd
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: sgd
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: clip_vit-b16
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 03/04 08:33:35 | n_steps = 5001
[37m[36mINFO[0m[0m 03/04 08:33:35 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/04 08:33:35 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/04 08:33:35 | 
[37m[36mINFO[0m[0m 03/04 08:33:35 | Testenv name escaping te_V -> te_V
[37m[36mINFO[0m[0m 03/04 08:33:35 | Test envs = [3], name = te_V
[37m[36mINFO[0m[0m 03/04 08:33:35 | Train environments: [0, 1, 2], Test environments: [3]
[37m[36mINFO[0m[0m 03/04 08:33:35 | Batch sizes for each domain: [32, 32, 32, 0] (total=96)
[37m[36mINFO[0m[0m 03/04 08:33:35 | steps-per-epoch for each domain: 35.38, 66.41, 82.06 -> min = 35.38
[37m[36mINFO[0m[0m 03/04 08:33:38 | # of params = 86195205
[37m[36mINFO[0m[0m 03/04 08:35:45 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/04 08:35:45 | 0.192892    0.189630    0.200002    0.188985    1.678219    0.097173    0.074205    0.142588    0.161959    0.360244    0.330793    0.192892    0.189630    0           0.000000    1.649576    1.112745    125.751161 
[37m[36mINFO[0m[0m 03/04 08:41:27 | 0.439837    0.442963    0.530264    0.540062    1.210556    0.654594    0.667845    0.513882    0.517891    0.422315    0.434451    0.439837    0.442963    200         5.653710    1.366876    1.078965    126.186000 
[37m[36mINFO[0m[0m 03/04 08:47:08 | 0.515365    0.515556    0.598913    0.603810    1.040589    0.714664    0.717314    0.585882    0.581921    0.496192    0.512195    0.515365    0.515556    400         11.307420   1.093199    1.075671    126.266456 
[37m[36mINFO[0m[0m 03/04 08:52:47 | 0.556461    0.554074    0.673439    0.687128    0.908090    0.801237    0.816254    0.659294    0.670433    0.559787    0.574695    0.556461    0.554074    600         16.961131   0.952273    1.069799    124.742971 
[37m[36mINFO[0m[0m 03/04 08:58:23 | 0.627916    0.632593    0.771306    0.743181    0.800512    0.923145    0.879859    0.696941    0.691149    0.693831    0.658537    0.627916    0.632593    800         22.614841   0.835124    1.062779    123.393643 
[37m[36mINFO[0m[0m 03/04 09:04:02 | 0.679748    0.675556    0.818091    0.796293    0.703862    0.947880    0.922261    0.726118    0.728814    0.780274    0.737805    0.679748    0.675556    1000        28.268551   0.734854    1.078488    123.784146 
[37m[36mINFO[0m[0m 03/04 09:09:43 | 0.719363    0.706667    0.839425    0.834853    0.621027    0.955830    0.939929    0.744471    0.755179    0.817974    0.809451    0.719363    0.706667    1200        33.922261   0.649961    1.082393    124.280138 
[37m[36mINFO[0m[0m 03/04 09:15:25 | 0.727879    0.725926    0.849448    0.843952    0.557112    0.955830    0.943463    0.762353    0.775895    0.830160    0.812500    0.727879    0.725926    1400        39.575972   0.577200    1.077704    126.239763 
[37m[36mINFO[0m[0m 03/04 09:21:05 | 0.738615    0.740741    0.860264    0.859090    0.513233    0.977032    0.964664    0.769412    0.790960    0.834349    0.821646    0.738615    0.740741    1600        45.229682   0.526076    1.078628    124.837406 
[37m[36mINFO[0m[0m 03/04 09:26:46 | 0.743799    0.745185    0.869611    0.870486    0.476147    0.992049    0.992933    0.787765    0.806026    0.829018    0.812500    0.743799    0.745185    1800        50.883392   0.477022    1.081481    123.889446 
[37m[36mINFO[0m[0m 03/04 09:32:28 | 0.750463    0.746667    0.878158    0.880542    0.449065    0.997350    0.996466    0.790588    0.809793    0.846535    0.835366    0.750463    0.746667    2000        56.537102   0.451681    1.079512    126.548103 
[37m[36mINFO[0m[0m 03/04 09:38:10 | 0.758978    0.748148    0.881378    0.880315    0.422551    1.000000    1.000000    0.793412    0.811676    0.850724    0.829268    0.758978    0.748148    2200        62.190813   0.426405    1.080233    126.424865 
[37m[36mINFO[0m[0m 03/04 09:43:50 | 0.764902    0.761481    0.884396    0.885875    0.406961    1.000000    1.000000    0.800941    0.819209    0.852247    0.838415    0.764902    0.761481    2400        67.844523   0.410458    1.076628    124.613374 
[37m[36mINFO[0m[0m 03/04 09:49:30 | 0.766383    0.765926    0.886906    0.885247    0.394275    1.000000    1.000000    0.808471    0.817326    0.852247    0.838415    0.766383    0.765926    2600        73.498233   0.380974    1.078429    124.338610 
[37m[36mINFO[0m[0m 03/04 09:55:13 | 0.773047    0.767407    0.893179    0.886652    0.383329    1.000000    1.000000    0.819294    0.815443    0.860244    0.844512    0.773047    0.767407    2800        79.151943   0.368280    1.081166    125.924268 
[37m[36mINFO[0m[0m 03/04 10:01:01 | 0.785635    0.779259    0.896338    0.891225    0.370004    1.000000    1.000000    0.823059    0.815443    0.865956    0.858232    0.785635    0.779259    3000        84.805654   0.365621    1.101268    127.667554 
[37m[36mINFO[0m[0m 03/04 10:06:44 | 0.794521    0.789630    0.900311    0.890448    0.361961    1.000000    1.000000    0.829647    0.819209    0.871287    0.852134    0.794521    0.789630    3200        90.459364   0.344453    1.083883    126.244527 
[37m[36mINFO[0m[0m 03/04 10:12:24 | 0.805628    0.795556    0.904045    0.899564    0.349781    1.000000    1.000000    0.832471    0.826742    0.879665    0.871951    0.805628    0.795556    3400        96.113074   0.340196    1.083564    123.256755 
[37m[36mINFO[0m[0m 03/04 10:18:08 | 0.811181    0.814815    0.896063    0.887578    0.363528    0.996466    1.000000    0.819294    0.806026    0.872430    0.856707    0.811181    0.814815    3600        101.766784  0.323273    1.085724    127.249875 
[37m[36mINFO[0m[0m 03/04 10:23:48 | 0.814883    0.804444    0.904171    0.894393    0.338021    1.000000    1.000000    0.824471    0.817326    0.888043    0.865854    0.814883    0.804444    3800        107.420495  0.336432    1.073552    124.841006 
[37m[36mINFO[0m[0m 03/04 10:29:28 | 0.821918    0.819259    0.900531    0.901089    0.340125    0.999117    1.000000    0.819765    0.826742    0.882711    0.876524    0.821918    0.819259    4000        113.074205  0.303286    1.071518    126.408306 
[37m[36mINFO[0m[0m 03/04 10:35:07 | 0.816735    0.810370    0.910684    0.895768    0.328297    1.000000    1.000000    0.839059    0.822976    0.892993    0.864329    0.816735    0.810370    4200        118.727915  0.300019    1.069391    125.080749 
[37m[36mINFO[0m[0m 03/04 10:40:48 | 0.826731    0.817778    0.915461    0.897532    0.323064    0.999117    1.000000    0.848941    0.826742    0.898324    0.865854    0.826731    0.817778    4400        124.381625  0.300474    1.078651    125.194655 
[37m[36mINFO[0m[0m 03/04 10:46:34 | 0.817105    0.823704    0.909251    0.892002    0.334804    1.000000    1.000000    0.840471    0.811676    0.887281    0.864329    0.817105    0.823704    4600        130.035336  0.293225    1.075176    130.535461 
[37m[36mINFO[0m[0m 03/04 10:52:11 | 0.827842    0.831111    0.916046    0.891733    0.324108    1.000000    1.000000    0.847529    0.815443    0.900609    0.859756    0.827842    0.831111    4800        135.689046  0.286236    1.061641    124.651173 
[37m[36mINFO[0m[0m 03/04 10:57:48 | 0.829322    0.835556    0.916987    0.891853    0.320755    1.000000    1.000000    0.850353    0.817326    0.900609    0.858232    0.829322    0.835556    5000        141.342756  0.288037    1.061750    124.928554 
[37m[36mINFO[0m[0m 03/04 10:57:48 | Cumulative gradient change saved at train_output/VLCS/ERM/[3]/250304_08-33-35_clip_vitb16_sgd/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/04 10:57:52 | ---
[37m[36mINFO[0m[0m 03/04 10:57:52 | test-domain validation(oracle) = 82.932%
[37m[36mINFO[0m[0m 03/04 10:57:52 | training-domain validation(iid) = 82.192%
[37m[36mINFO[0m[0m 03/04 10:57:52 | last = 82.932%
[37m[36mINFO[0m[0m 03/04 10:57:52 | last (inD) = 89.185%
[37m[36mINFO[0m[0m 03/04 10:57:52 | training-domain validation (iid, inD) = 90.109%
[37m[36mINFO[0m[0m 03/04 10:57:52 | === Summary ===
[37m[36mINFO[0m[0m 03/04 10:57:52 | Command: /jsm0707/GENIE/train_all.py clip_vitb16_sgd config/clip_vitb16_sgd.yaml --algorithm ERM --test_envs 3 --dataset VLCS
[37m[36mINFO[0m[0m 03/04 10:57:52 | Unique name: 250304_08-33-35_clip_vitb16_sgd
[37m[36mINFO[0m[0m 03/04 10:57:52 | Out path: train_output/VLCS/ERM/[3]/250304_08-33-35_clip_vitb16_sgd
[37m[36mINFO[0m[0m 03/04 10:57:52 | Algorithm: ERM
[37m[36mINFO[0m[0m 03/04 10:57:52 | Dataset: VLCS
