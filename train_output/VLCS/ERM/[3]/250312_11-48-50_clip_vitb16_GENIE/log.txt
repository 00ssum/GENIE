[37m[36mINFO[0m[0m 03/12 11:48:50 | Command :: /jsm0707/GENIE/train_all.py clip_vitb16_GENIE config/clip_vitb16_GENIE.yaml --algorithm ERM --test_envs 3 --dataset VLCS --trial_seed 1 --hparams_seed 14
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: ERM
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/clip_vitb16_GENIE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 14
	in_domain: False
	model_save: None
	mpa: False
	name: clip_vitb16_GENIE
	out_dir: train_output/VLCS/ERM/[3]/250312_11-48-50_clip_vitb16_GENIE
	out_root: train_output/VLCS/ERM/[3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [3]
	trial_seed: 1
	unique_name: 250312_11-48-50_clip_vitb16_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.1
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 0.00011127987942826837
	batch_size: 12
	weight_decay: 3.236767350601091e-05
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: openclip_vit-b16
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 03/12 11:48:50 | n_steps = 5001
[37m[36mINFO[0m[0m 03/12 11:48:50 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/12 11:48:50 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/12 11:48:50 | 
[37m[36mINFO[0m[0m 03/12 11:48:51 | Testenv name escaping te_V -> te_V
[37m[36mINFO[0m[0m 03/12 11:48:51 | Test envs = [3], name = te_V
[37m[36mINFO[0m[0m 03/12 11:48:51 | Train environments: [0, 1, 2], Test environments: [3]
[37m[36mINFO[0m[0m 03/12 11:48:51 | Batch sizes for each domain: [12, 12, 12, 0] (total=36)
[37m[36mINFO[0m[0m 03/12 11:48:51 | steps-per-epoch for each domain: 94.33, 177.08, 218.83 -> min = 94.33
[37m[36mINFO[0m[0m 03/12 11:48:53 | # of params = 86195205
[37m[36mINFO[0m[0m 03/12 11:51:04 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/12 11:51:04 | 0.432062    0.391111    0.481917    0.498959    1.394014    0.609541    0.614841    0.474824    0.468927    0.361386    0.413110    0.432062    0.391111    0           0.000000    1.689570    1.124790    129.853866 
[37m[36mINFO[0m[0m 03/12 11:54:43 | 0.557571    0.540741    0.735141    0.740742    0.642697    0.891343    0.883392    0.660235    0.674200    0.653846    0.664634    0.557571    0.540741    200         2.120141    0.907443    0.426800    133.224221 
[37m[36mINFO[0m[0m 03/12 11:58:18 | 0.607183    0.592593    0.786692    0.776406    0.545373    0.981449    0.971731    0.685176    0.676083    0.693450    0.681402    0.607183    0.592593    400         4.240283    0.629396    0.437535    127.691538 
[37m[36mINFO[0m[0m 03/12 12:01:55 | 0.636061    0.614815    0.821118    0.812485    0.478269    0.987633    0.989399    0.719059    0.719397    0.756664    0.728659    0.636061    0.614815    600         6.360424    0.523354    0.446465    128.183276 
[37m[36mINFO[0m[0m 03/12 12:05:34 | 0.625694    0.595556    0.818087    0.807810    0.492721    0.991166    0.985866    0.732706    0.704331    0.730388    0.733232    0.625694    0.595556    800         8.480565    0.471854    0.436605    131.677892 
[37m[36mINFO[0m[0m 03/12 12:09:14 | 0.647168    0.642963    0.818972    0.802745    0.490052    0.969081    0.946996    0.758588    0.732580    0.729246    0.728659    0.647168    0.642963    1000        10.600707   0.419964    0.442278    131.371126 
[37m[36mINFO[0m[0m 03/12 12:12:55 | 0.640504    0.641481    0.845448    0.826246    0.450639    0.987633    0.975265    0.738353    0.738230    0.810358    0.765244    0.640504    0.641481    1200        12.720848   0.381373    0.442393    132.492576 
[37m[36mINFO[0m[0m 03/12 12:16:36 | 0.608293    0.617778    0.849515    0.805054    0.473871    0.992049    0.992933    0.765176    0.711864    0.791318    0.710366    0.608293    0.617778    1400        14.840989   0.381829    0.433408    134.140971 
[37m[36mINFO[0m[0m 03/12 12:20:17 | 0.557942    0.574815    0.841837    0.811308    0.498728    0.981449    0.985866    0.769882    0.751412    0.774181    0.696646    0.557942    0.574815    1600        16.961131   0.369949    0.443424    132.641427 
[37m[36mINFO[0m[0m 03/12 12:23:57 | 0.664569    0.660741    0.880627    0.832393    0.446638    0.998233    0.989399    0.810824    0.760829    0.832826    0.746951    0.664569    0.660741    1800        19.081272   0.351848    0.436935    132.109645 
[37m[36mINFO[0m[0m 03/12 12:27:33 | 0.592743    0.613333    0.878160    0.827598    0.454506    0.987633    0.985866    0.797647    0.743879    0.849200    0.753049    0.592743    0.613333    2000        21.201413   0.332656    0.433117    130.071950 
[37m[36mINFO[0m[0m 03/12 12:31:11 | 0.615698    0.594074    0.886768    0.831585    0.458266    0.996466    0.989399    0.826824    0.740113    0.837014    0.765244    0.615698    0.594074    2200        23.321555   0.308988    0.433910    130.372817 
[37m[36mINFO[0m[0m 03/12 12:34:45 | 0.576823    0.591111    0.882208    0.811739    0.502372    0.994700    0.989399    0.836235    0.747646    0.815689    0.698171    0.576823    0.591111    2400        25.441696   0.286556    0.435382    127.441305 
[37m[36mINFO[0m[0m 03/12 12:38:23 | 0.619030    0.607407    0.903403    0.819700    0.524430    0.993816    0.975265    0.834824    0.723164    0.881569    0.760671    0.619030    0.607407    2600        27.561837   0.272889    0.436549    130.605198 
[37m[36mINFO[0m[0m 03/12 12:42:01 | 0.640874    0.632593    0.908736    0.819533    0.517331    0.997350    0.978799    0.860235    0.741996    0.868621    0.737805    0.640874    0.632593    2800        29.681979   0.255361    0.439454    130.244157 
[37m[36mINFO[0m[0m 03/12 12:45:40 | 0.567568    0.588148    0.907830    0.821817    0.506655    0.995583    0.982332    0.835294    0.751412    0.892612    0.731707    0.567568    0.588148    3000        31.802120   0.259912    0.436372    131.901912 
[37m[36mINFO[0m[0m 03/12 12:49:16 | 0.603850    0.619259    0.921733    0.834443    0.495970    0.998233    0.985866    0.874353    0.747646    0.892612    0.769817    0.603850    0.619259    3200        33.922261   0.236445    0.428823    130.226369 
[37m[36mINFO[0m[0m 03/12 12:52:53 | 0.561274    0.571852    0.925935    0.812222    0.560598    0.995583    0.982332    0.880471    0.736347    0.901752    0.717988    0.561274    0.571852    3400        36.042403   0.215457    0.429352    130.272574 
[37m[36mINFO[0m[0m 03/12 12:56:28 | 0.599408    0.605926    0.922911    0.820006    0.552142    0.993816    0.985866    0.870118    0.736347    0.904798    0.737805    0.599408    0.605926    3600        38.162544   0.219265    0.430552    129.439575 
[37m[36mINFO[0m[0m 03/12 13:00:01 | 0.614957    0.592593    0.936883    0.811373    0.538558    0.997350    0.978799    0.901647    0.717514    0.911653    0.737805    0.614957    0.592593    3800        40.282686   0.205491    0.431366    126.559382 
[37m[36mINFO[0m[0m 03/12 13:03:33 | 0.630507    0.607407    0.950756    0.819138    0.570976    0.996466    0.968198    0.922824    0.751412    0.932978    0.737805    0.630507    0.607407    4000        42.402827   0.180234    0.419529    128.425171 
[37m[36mINFO[0m[0m 03/12 13:07:05 | 0.602740    0.601481    0.953084    0.806399    0.572662    1.000000    0.975265    0.928941    0.713748    0.930312    0.730183    0.602740    0.601481    4200        44.522968   0.160138    0.423551    127.063369 
[37m[36mINFO[0m[0m 03/12 13:10:38 | 0.564606    0.555556    0.936811    0.784931    0.717990    0.992933    0.964664    0.933647    0.719397    0.883854    0.670732    0.564606    0.555556    4400        46.643110   0.143831    0.431152    126.371670 
[37m[36mINFO[0m[0m 03/12 13:14:13 | 0.607553    0.608889    0.927596    0.805155    0.625102    0.997350    0.978799    0.857412    0.715631    0.928027    0.721037    0.607553    0.608889    4600        48.763251   0.148850    0.418422    131.461048 
[37m[36mINFO[0m[0m 03/12 13:17:53 | 0.645687    0.626667    0.959459    0.822977    0.621205    0.999117    0.989399    0.936000    0.732580    0.943260    0.746951    0.645687    0.626667    4800        50.883392   0.133017    0.440423    132.148248 
[37m[36mINFO[0m[0m 03/12 13:21:28 | 0.637171    0.617778    0.961346    0.824321    0.602130    0.996466    0.971731    0.941647    0.734463    0.945925    0.766768    0.637171    0.617778    5000        53.003534   0.138138    0.430876    129.230055 
[37m[36mINFO[0m[0m 03/12 13:21:29 | Cumulative gradient change saved at train_output/VLCS/ERM/[3]/250312_11-48-50_clip_vitb16_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/12 13:21:31 | ---
[37m[36mINFO[0m[0m 03/12 13:21:31 | test-domain validation(oracle) = 66.457%
[37m[36mINFO[0m[0m 03/12 13:21:31 | training-domain validation(iid) = 60.385%
[37m[36mINFO[0m[0m 03/12 13:21:31 | last = 63.717%
[37m[36mINFO[0m[0m 03/12 13:21:31 | last (inD) = 82.432%
[37m[36mINFO[0m[0m 03/12 13:21:31 | training-domain validation (iid, inD) = 83.444%
[37m[36mINFO[0m[0m 03/12 13:21:31 | === Summary ===
[37m[36mINFO[0m[0m 03/12 13:21:31 | Command: /jsm0707/GENIE/train_all.py clip_vitb16_GENIE config/clip_vitb16_GENIE.yaml --algorithm ERM --test_envs 3 --dataset VLCS --trial_seed 1 --hparams_seed 14
[37m[36mINFO[0m[0m 03/12 13:21:31 | Unique name: 250312_11-48-50_clip_vitb16_GENIE
[37m[36mINFO[0m[0m 03/12 13:21:31 | Out path: train_output/VLCS/ERM/[3]/250312_11-48-50_clip_vitb16_GENIE
[37m[36mINFO[0m[0m 03/12 13:21:31 | Algorithm: ERM
[37m[36mINFO[0m[0m 03/12 13:21:31 | Dataset: VLCS
