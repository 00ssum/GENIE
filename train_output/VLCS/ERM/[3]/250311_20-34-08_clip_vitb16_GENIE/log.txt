[37m[36mINFO[0m[0m 03/11 20:34:08 | Command :: /jsm0707/GENIE/train_all.py clip_vitb16_GENIE config/clip_vitb16_GENIE.yaml --algorithm ERM --test_envs 3 --dataset VLCS --trial_seed 0 --hparams_seed 16
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: ERM
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/clip_vitb16_GENIE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 16
	in_domain: False
	model_save: None
	mpa: False
	name: clip_vitb16_GENIE
	out_dir: train_output/VLCS/ERM/[3]/250311_20-34-08_clip_vitb16_GENIE
	out_root: train_output/VLCS/ERM/[3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [3]
	trial_seed: 0
	unique_name: 250311_20-34-08_clip_vitb16_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 4.249952708249365e-05
	batch_size: 17
	weight_decay: 9.786966598736845e-06
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: openclip_vit-b16
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 03/11 20:34:08 | n_steps = 5001
[37m[36mINFO[0m[0m 03/11 20:34:08 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/11 20:34:08 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/11 20:34:08 | 
[37m[36mINFO[0m[0m 03/11 20:34:08 | Testenv name escaping te_V -> te_V
[37m[36mINFO[0m[0m 03/11 20:34:08 | Test envs = [3], name = te_V
[37m[36mINFO[0m[0m 03/11 20:34:08 | Train environments: [0, 1, 2], Test environments: [3]
[37m[36mINFO[0m[0m 03/11 20:34:08 | Batch sizes for each domain: [17, 17, 17, 0] (total=51)
[37m[36mINFO[0m[0m 03/11 20:34:08 | steps-per-epoch for each domain: 66.59, 125.00, 154.47 -> min = 66.59
[37m[36mINFO[0m[0m 03/11 20:34:11 | # of params = 86195205
[37m[36mINFO[0m[0m 03/11 20:36:25 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/11 20:36:25 | 0.300629    0.306667    0.400041    0.407584    1.385964    0.346290    0.353357    0.515294    0.506591    0.338538    0.362805    0.300629    0.306667    0           0.000000    1.676799    1.369994    132.975863 
[37m[36mINFO[0m[0m 03/11 20:40:44 | 0.608663    0.631111    0.785352    0.780924    0.551606    0.966431    0.946996    0.680941    0.693032    0.708682    0.702744    0.608663    0.631111    200         3.003534    0.665753    0.603676    138.543872 
[37m[36mINFO[0m[0m 03/11 20:45:02 | 0.669382    0.650370    0.823038    0.809669    0.496739    0.983216    0.978799    0.736471    0.730697    0.749429    0.719512    0.669382    0.650370    400         6.007067    0.541523    0.615800    135.036807 
[37m[36mINFO[0m[0m 03/11 20:49:23 | 0.690855    0.675556    0.842335    0.832285    0.427488    0.992049    0.992933    0.734118    0.732580    0.800838    0.771341    0.690855    0.675556    600         9.010601    0.442618    0.617531    136.731649 
[37m[36mINFO[0m[0m 03/11 20:53:39 | 0.645687    0.632593    0.834797    0.811797    0.448608    0.991166    0.989399    0.728000    0.700565    0.785225    0.745427    0.645687    0.632593    800         12.014134   0.400867    0.611446    134.453180 
[37m[36mINFO[0m[0m 03/11 20:57:50 | 0.607183    0.607407    0.853523    0.813992    0.454805    0.999117    0.992933    0.789176    0.732580    0.772277    0.716463    0.607183    0.607407    1000        15.017668   0.364313    0.600359    130.060123 
[37m[36mINFO[0m[0m 03/11 21:02:06 | 0.673084    0.682963    0.875564    0.815684    0.474825    0.995583    0.989399    0.824941    0.745763    0.806169    0.711890    0.673084    0.682963    1200        18.021201   0.332974    0.604049    135.820765 
[37m[36mINFO[0m[0m 03/11 21:06:20 | 0.677157    0.637037    0.898103    0.827640    0.460482    0.990283    0.971731    0.833882    0.762712    0.870145    0.748476    0.677157    0.637037    1400        21.024735   0.287362    0.599328    133.597282 
[37m[36mINFO[0m[0m 03/11 21:10:37 | 0.667901    0.650370    0.903161    0.822654    0.489227    0.999117    0.982332    0.837176    0.732580    0.873191    0.753049    0.667901    0.650370    1600        24.028269   0.257412    0.621096    133.003003 
[37m[36mINFO[0m[0m 03/11 21:14:54 | 0.637171    0.598519    0.905919    0.816592    0.525351    0.991166    0.975265    0.850353    0.738230    0.876238    0.736280    0.637171    0.598519    1800        27.031802   0.244263    0.601118    137.005931 
[37m[36mINFO[0m[0m 03/11 21:19:06 | 0.622732    0.625185    0.923218    0.802943    0.523696    0.998233    0.961131    0.867765    0.717514    0.903656    0.730183    0.622732    0.625185    2000        30.035336   0.229556    0.605548    130.874749 
[37m[36mINFO[0m[0m 03/11 21:23:16 | 0.676786    0.681481    0.916225    0.811188    0.582768    0.998233    0.985866    0.837647    0.717514    0.912795    0.730183    0.676786    0.681481    2200        33.038869   0.195193    0.603628    129.228575 
[37m[36mINFO[0m[0m 03/11 21:27:27 | 0.648649    0.647407    0.938988    0.821763    0.510138    0.997350    0.992933    0.898824    0.726930    0.920792    0.745427    0.648649    0.647407    2400        36.042403   0.179274    0.601265    130.694936 
[37m[36mINFO[0m[0m 03/11 21:31:33 | 0.634950    0.626667    0.942696    0.823987    0.594520    0.998233    0.996466    0.902588    0.719397    0.927266    0.756098    0.634950    0.626667    2600        39.045936   0.150373    0.584993    128.740297 
[37m[36mINFO[0m[0m 03/11 21:35:41 | 0.634950    0.637037    0.951560    0.824597    0.558234    0.995583    0.982332    0.926118    0.755179    0.932978    0.736280    0.634950    0.637037    2800        42.049470   0.158672    0.596068    129.045871 
[37m[36mINFO[0m[0m 03/11 21:39:56 | 0.659385    0.663704    0.961347    0.828560    0.575036    0.999117    0.978799    0.931765    0.740113    0.953161    0.766768    0.659385    0.663704    3000        45.053004   0.133317    0.604399    134.051578 
[37m[36mINFO[0m[0m 03/11 21:44:12 | 0.627545    0.626667    0.956763    0.824442    0.613633    0.999117    0.989399    0.935529    0.747646    0.935644    0.736280    0.627545    0.626667    3200        48.056537   0.133259    0.622300    131.928332 
[37m[36mINFO[0m[0m 03/11 21:48:27 | 0.644946    0.637037    0.965791    0.833887    0.607865    0.999117    0.989399    0.939765    0.736347    0.958492    0.775915    0.644946    0.637037    3400        51.060071   0.100901    0.603498    134.271400 
[37m[36mINFO[0m[0m 03/11 21:52:38 | 0.634950    0.629630    0.973677    0.828824    0.638310    0.996466    0.985866    0.961882    0.755179    0.962681    0.745427    0.634950    0.629630    3600        54.063604   0.089637    0.587728    132.920041 
[37m[36mINFO[0m[0m 03/11 21:56:46 | 0.626064    0.628148    0.972493    0.821051    0.663852    0.997350    0.968198    0.966588    0.749529    0.953542    0.745427    0.626064    0.628148    3800        57.067138   0.092477    0.584559    131.159166 
[37m[36mINFO[0m[0m 03/11 22:00:57 | 0.655683    0.654815    0.957129    0.809806    0.679715    0.992933    0.975265    0.939765    0.719397    0.938690    0.734756    0.655683    0.654815    4000        60.070671   0.090005    0.585254    134.251877 
[37m[36mINFO[0m[0m 03/11 22:05:10 | 0.629767    0.629630    0.979724    0.832141    0.651927    0.998233    0.985866    0.961882    0.751412    0.979056    0.759146    0.629767    0.629630    4200        63.074205   0.071467    0.597538    133.251646 
[37m[36mINFO[0m[0m 03/11 22:09:20 | 0.627175    0.616296    0.975538    0.812084    0.731281    0.999117    0.985866    0.963294    0.715631    0.964204    0.734756    0.627175    0.616296    4400        66.077739   0.060533    0.604658    129.536269 
[37m[36mINFO[0m[0m 03/11 22:13:33 | 0.646797    0.638519    0.975434    0.818307    0.723154    0.999117    0.978799    0.965647    0.730697    0.961538    0.745427    0.646797    0.638519    4600        69.081272   0.064533    0.609144    130.963955 
[37m[36mINFO[0m[0m 03/11 22:17:40 | 0.644576    0.631111    0.975076    0.810883    0.742141    0.999117    0.975265    0.968000    0.736347    0.958111    0.721037    0.644576    0.631111    4800        72.084806   0.064343    0.598290    127.080788 
[37m[36mINFO[0m[0m 03/11 22:21:51 | 0.637171    0.628148    0.984884    0.828064    0.753511    1.000000    0.982332    0.977882    0.745763    0.976771    0.756098    0.637171    0.628148    5000        75.088339   0.047245    0.593716    132.516517 
[37m[36mINFO[0m[0m 03/11 22:21:52 | Cumulative gradient change saved at train_output/VLCS/ERM/[3]/250311_20-34-08_clip_vitb16_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/11 22:21:55 | ---
[37m[36mINFO[0m[0m 03/11 22:21:55 | test-domain validation(oracle) = 67.308%
[37m[36mINFO[0m[0m 03/11 22:21:55 | training-domain validation(iid) = 64.495%
[37m[36mINFO[0m[0m 03/11 22:21:55 | last = 63.717%
[37m[36mINFO[0m[0m 03/11 22:21:55 | last (inD) = 82.806%
[37m[36mINFO[0m[0m 03/11 22:21:55 | training-domain validation (iid, inD) = 83.389%
[37m[36mINFO[0m[0m 03/11 22:21:56 | === Summary ===
[37m[36mINFO[0m[0m 03/11 22:21:56 | Command: /jsm0707/GENIE/train_all.py clip_vitb16_GENIE config/clip_vitb16_GENIE.yaml --algorithm ERM --test_envs 3 --dataset VLCS --trial_seed 0 --hparams_seed 16
[37m[36mINFO[0m[0m 03/11 22:21:56 | Unique name: 250311_20-34-08_clip_vitb16_GENIE
[37m[36mINFO[0m[0m 03/11 22:21:56 | Out path: train_output/VLCS/ERM/[3]/250311_20-34-08_clip_vitb16_GENIE
[37m[36mINFO[0m[0m 03/11 22:21:56 | Algorithm: ERM
[37m[36mINFO[0m[0m 03/11 22:21:56 | Dataset: VLCS
