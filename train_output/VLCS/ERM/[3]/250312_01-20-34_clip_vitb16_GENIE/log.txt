[37m[36mINFO[0m[0m 03/12 01:20:34 | Command :: /jsm0707/GENIE/train_all.py clip_vitb16_GENIE config/clip_vitb16_GENIE.yaml --algorithm ERM --test_envs 3 --dataset VLCS --trial_seed 1 --hparams_seed 1
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: ERM
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/clip_vitb16_GENIE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 1
	in_domain: False
	model_save: None
	mpa: False
	name: clip_vitb16_GENIE
	out_dir: train_output/VLCS/ERM/[3]/250312_01-20-34_clip_vitb16_GENIE
	out_root: train_output/VLCS/ERM/[3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [3]
	trial_seed: 1
	unique_name: 250312_01-20-34_clip_vitb16_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 1.2332416678311953e-05
	batch_size: 13
	weight_decay: 0.0018634819595667504
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: openclip_vit-b16
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 03/12 01:20:34 | n_steps = 5001
[37m[36mINFO[0m[0m 03/12 01:20:34 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/12 01:20:34 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/12 01:20:34 | 
[37m[36mINFO[0m[0m 03/12 01:20:34 | Testenv name escaping te_V -> te_V
[37m[36mINFO[0m[0m 03/12 01:20:34 | Test envs = [3], name = te_V
[37m[36mINFO[0m[0m 03/12 01:20:34 | Train environments: [0, 1, 2], Test environments: [3]
[37m[36mINFO[0m[0m 03/12 01:20:34 | Batch sizes for each domain: [13, 13, 13, 0] (total=39)
[37m[36mINFO[0m[0m 03/12 01:20:34 | steps-per-epoch for each domain: 87.08, 163.46, 202.00 -> min = 87.08
[37m[36mINFO[0m[0m 03/12 01:20:37 | # of params = 86195205
[37m[36mINFO[0m[0m 03/12 01:22:48 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/12 01:22:48 | 0.375417    0.343704    0.457540    0.468743    1.437262    0.545053    0.554770    0.481412    0.476460    0.346154    0.375000    0.375417    0.343704    0           0.000000    1.698044    1.153811    129.629678 
[37m[36mINFO[0m[0m 03/12 01:26:30 | 0.510181    0.543704    0.744529    0.751313    0.607905    0.917845    0.915194    0.672941    0.681733    0.642803    0.657012    0.510181    0.543704    200         2.296820    0.933650    0.461983    130.388994 
[37m[36mINFO[0m[0m 03/12 01:30:11 | 0.623473    0.617778    0.799333    0.787185    0.503485    0.992049    0.985866    0.726588    0.683616    0.679360    0.692073    0.623473    0.617778    400         4.593640    0.606901    0.461878    128.623519 
[37m[36mINFO[0m[0m 03/12 01:33:49 | 0.600889    0.614815    0.820864    0.813771    0.462157    0.986749    0.989399    0.741647    0.747646    0.734196    0.704268    0.600889    0.614815    600         6.890459    0.495126    0.457249    126.654060 
[37m[36mINFO[0m[0m 03/12 01:37:29 | 0.696409    0.653333    0.841853    0.828745    0.442995    0.992049    0.971731    0.760471    0.740113    0.773039    0.774390    0.696409    0.653333    800         9.187279    0.453653    0.458856    127.478103 
[37m[36mINFO[0m[0m 03/12 01:41:09 | 0.623103    0.620741    0.846298    0.830647    0.453001    0.997350    0.985866    0.740706    0.743879    0.800838    0.762195    0.623103    0.620741    1000        11.484099   0.414914    0.456241    128.899578 
[37m[36mINFO[0m[0m 03/12 01:44:53 | 0.662718    0.628148    0.855821    0.814020    0.466519    0.986749    0.975265    0.778353    0.713748    0.802361    0.753049    0.662718    0.628148    1200        13.780919   0.383862    0.458226    132.001256 
[37m[36mINFO[0m[0m 03/12 01:48:35 | 0.611625    0.585185    0.815899    0.785564    0.518539    0.979682    0.975265    0.710588    0.681733    0.757426    0.699695    0.611625    0.585185    1400        16.077739   0.391327    0.457596    130.969619 
[37m[36mINFO[0m[0m 03/12 01:52:22 | 0.634210    0.626667    0.868046    0.812783    0.469741    0.988516    0.971731    0.797647    0.728814    0.817974    0.737805    0.634210    0.626667    1600        18.374558   0.351715    0.466216    133.822182 
[37m[36mINFO[0m[0m 03/12 01:56:06 | 0.650870    0.647407    0.892875    0.824925    0.455592    0.998233    0.982332    0.827765    0.736347    0.852628    0.756098    0.650870    0.647407    1800        20.671378   0.315393    0.458714    132.173412 
[37m[36mINFO[0m[0m 03/12 01:59:47 | 0.639393    0.632593    0.881749    0.823191    0.498608    0.992933    0.982332    0.802353    0.725047    0.849962    0.762195    0.639393    0.632593    2000        22.968198   0.305950    0.460979    128.631150 
[37m[36mINFO[0m[0m 03/12 02:03:32 | 0.634950    0.642963    0.891685    0.816466    0.486673    0.995583    0.982332    0.824941    0.723164    0.854532    0.743902    0.634950    0.642963    2200        25.265018   0.314642    0.466007    131.614449 
[37m[36mINFO[0m[0m 03/12 02:07:14 | 0.629397    0.642963    0.895317    0.828704    0.465026    0.996466    0.985866    0.823529    0.753296    0.865956    0.746951    0.629397    0.642963    2400        27.561837   0.281402    0.465810    128.666398 
[37m[36mINFO[0m[0m 03/12 02:10:55 | 0.641244    0.642963    0.903732    0.822074    0.506582    0.995583    0.978799    0.844706    0.741996    0.870906    0.745427    0.641244    0.642963    2600        29.858657   0.279050    0.462753    129.325084 
[37m[36mINFO[0m[0m 03/12 02:14:37 | 0.633839    0.611852    0.870738    0.799767    0.595675    0.986749    0.968198    0.761412    0.670433    0.864052    0.760671    0.633839    0.611852    2800        32.155477   0.259496    0.459572    129.230065 
[37m[36mINFO[0m[0m 03/12 02:18:18 | 0.588671    0.588148    0.919336    0.811546    0.533894    0.996466    0.985866    0.865882    0.723164    0.895659    0.725610    0.588671    0.588148    3000        34.452297   0.247220    0.460626    129.501116 
[37m[36mINFO[0m[0m 03/12 02:22:00 | 0.546835    0.524444    0.919427    0.799207    0.587847    0.996466    0.978799    0.875294    0.709981    0.886519    0.708841    0.546835    0.524444    3200        36.749117   0.201969    0.457665    130.418474 
[37m[36mINFO[0m[0m 03/12 02:25:40 | 0.600148    0.592593    0.902589    0.811379    0.605832    0.992933    0.971731    0.862588    0.730697    0.852247    0.731707    0.600148    0.592593    3400        39.045936   0.202797    0.451148    129.554988 
[37m[36mINFO[0m[0m 03/12 02:29:22 | 0.581266    0.579259    0.927528    0.819420    0.586926    0.996466    0.989399    0.872941    0.732580    0.913176    0.736280    0.581266    0.579259    3600        41.342756   0.198161    0.470382    128.090123 
[37m[36mINFO[0m[0m 03/12 02:33:05 | 0.552758    0.557037    0.933304    0.797886    0.642673    0.997350    0.985866    0.883294    0.708098    0.919269    0.699695    0.552758    0.557037    3800        43.639576   0.168797    0.459979    130.775421 
[37m[36mINFO[0m[0m 03/12 02:36:45 | 0.638282    0.616296    0.935142    0.813775    0.624180    0.997350    0.982332    0.892235    0.696798    0.915842    0.762195    0.638282    0.616296    4000        45.936396   0.172290    0.460853    128.400775 
[37m[36mINFO[0m[0m 03/12 02:40:28 | 0.624954    0.626667    0.944346    0.802422    0.654000    0.993816    0.975265    0.915765    0.691149    0.923458    0.740854    0.624954    0.626667    4200        48.233216   0.163160    0.465207    129.858012 
[37m[36mINFO[0m[0m 03/12 02:44:12 | 0.634210    0.622222    0.956993    0.814530    0.591569    0.999117    0.992933    0.925176    0.725047    0.946687    0.725610    0.634210    0.622222    4400        50.530035   0.144414    0.478732    127.873861 
[37m[36mINFO[0m[0m 03/12 02:47:58 | 0.614217    0.628148    0.959142    0.816143    0.612243    0.998233    0.975265    0.933647    0.723164    0.945545    0.750000    0.614217    0.628148    4600        52.826855   0.177417    0.455867    134.401943 
[37m[36mINFO[0m[0m 03/12 02:51:39 | 0.591262    0.561481    0.946568    0.805915    0.695040    0.994700    0.964664    0.926118    0.745763    0.918888    0.707317    0.591262    0.561481    4800        55.123675   0.112122    0.465147    128.880936 
[37m[36mINFO[0m[0m 03/12 02:55:20 | 0.620881    0.617778    0.964444    0.819115    0.599746    0.998233    0.978799    0.941176    0.751412    0.953922    0.727134    0.620881    0.617778    5000        57.420495   0.127748    0.466412    127.517470 
[37m[36mINFO[0m[0m 03/12 02:55:21 | Cumulative gradient change saved at train_output/VLCS/ERM/[3]/250312_01-20-34_clip_vitb16_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/12 02:55:23 | ---
[37m[36mINFO[0m[0m 03/12 02:55:23 | test-domain validation(oracle) = 69.641%
[37m[36mINFO[0m[0m 03/12 02:55:23 | training-domain validation(iid) = 62.310%
[37m[36mINFO[0m[0m 03/12 02:55:23 | last = 62.088%
[37m[36mINFO[0m[0m 03/12 02:55:23 | last (inD) = 81.912%
[37m[36mINFO[0m[0m 03/12 02:55:23 | training-domain validation (iid, inD) = 83.065%
[37m[36mINFO[0m[0m 03/12 02:55:23 | === Summary ===
[37m[36mINFO[0m[0m 03/12 02:55:23 | Command: /jsm0707/GENIE/train_all.py clip_vitb16_GENIE config/clip_vitb16_GENIE.yaml --algorithm ERM --test_envs 3 --dataset VLCS --trial_seed 1 --hparams_seed 1
[37m[36mINFO[0m[0m 03/12 02:55:23 | Unique name: 250312_01-20-34_clip_vitb16_GENIE
[37m[36mINFO[0m[0m 03/12 02:55:23 | Out path: train_output/VLCS/ERM/[3]/250312_01-20-34_clip_vitb16_GENIE
[37m[36mINFO[0m[0m 03/12 02:55:23 | Algorithm: ERM
[37m[36mINFO[0m[0m 03/12 02:55:23 | Dataset: VLCS
