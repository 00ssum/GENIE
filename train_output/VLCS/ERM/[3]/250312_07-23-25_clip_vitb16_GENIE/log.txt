[37m[36mINFO[0m[0m 03/12 07:23:25 | Command :: /jsm0707/GENIE/train_all.py clip_vitb16_GENIE config/clip_vitb16_GENIE.yaml --algorithm ERM --test_envs 3 --dataset VLCS --trial_seed 1 --hparams_seed 10
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: ERM
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/clip_vitb16_GENIE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 10
	in_domain: False
	model_save: None
	mpa: False
	name: clip_vitb16_GENIE
	out_dir: train_output/VLCS/ERM/[3]/250312_07-23-25_clip_vitb16_GENIE
	out_root: train_output/VLCS/ERM/[3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [3]
	trial_seed: 1
	unique_name: 250312_07-23-25_clip_vitb16_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.5
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 2.2128485336217652e-05
	batch_size: 9
	weight_decay: 0.00030907441430549757
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: openclip_vit-b16
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 03/12 07:23:25 | n_steps = 5001
[37m[36mINFO[0m[0m 03/12 07:23:25 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/12 07:23:25 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/12 07:23:25 | 
[37m[36mINFO[0m[0m 03/12 07:23:25 | Testenv name escaping te_V -> te_V
[37m[36mINFO[0m[0m 03/12 07:23:25 | Test envs = [3], name = te_V
[37m[36mINFO[0m[0m 03/12 07:23:25 | Train environments: [0, 1, 2], Test environments: [3]
[37m[36mINFO[0m[0m 03/12 07:23:25 | Batch sizes for each domain: [9, 9, 9, 0] (total=27)
[37m[36mINFO[0m[0m 03/12 07:23:25 | steps-per-epoch for each domain: 125.78, 236.11, 291.78 -> min = 125.78
[37m[36mINFO[0m[0m 03/12 07:23:27 | # of params = 86195205
[37m[36mINFO[0m[0m 03/12 07:25:38 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/12 07:25:38 | 0.434284    0.394074    0.482121    0.499467    1.399826    0.610424    0.614841    0.473412    0.468927    0.362529    0.414634    0.434284    0.394074    0           0.000000    1.673457    1.187688    130.108361 
[37m[36mINFO[0m[0m 03/12 07:28:53 | 0.495742    0.515556    0.659511    0.687697    0.754543    0.888693    0.886926    0.564706    0.604520    0.525133    0.571646    0.495742    0.515556    200         1.590106    1.081685    0.313740    131.559694 
[37m[36mINFO[0m[0m 03/12 07:32:09 | 0.574972    0.555556    0.738309    0.740677    0.612193    0.934629    0.925795    0.650824    0.634652    0.629474    0.661585    0.574972    0.555556    400         3.180212    0.689978    0.325063    131.072821 
[37m[36mINFO[0m[0m 03/12 07:35:24 | 0.579785    0.585185    0.750348    0.761985    0.577005    0.969081    0.968198    0.613647    0.619586    0.668317    0.698171    0.579785    0.585185    600         4.770318    0.575658    0.318129    131.769345 
[37m[36mINFO[0m[0m 03/12 07:38:40 | 0.540911    0.552593    0.739944    0.752767    0.596787    0.966431    0.964664    0.605647    0.629002    0.647753    0.664634    0.540911    0.552593    800         6.360424    0.560741    0.321766    131.925135 
[37m[36mINFO[0m[0m 03/12 07:41:51 | 0.607183    0.611852    0.807354    0.804109    0.501765    0.974382    0.978799    0.723765    0.723164    0.723915    0.710366    0.607183    0.611852    1000        7.950530    0.550089    0.315152    127.948933 
[37m[36mINFO[0m[0m 03/12 07:45:06 | 0.626064    0.602963    0.827042    0.810990    0.494952    0.989399    0.971731    0.743059    0.732580    0.748667    0.728659    0.626064    0.602963    1200        9.540636    0.485691    0.322962    129.820702 
[37m[36mINFO[0m[0m 03/12 07:48:21 | 0.609034    0.579259    0.816052    0.782055    0.541416    0.979682    0.971731    0.744941    0.693032    0.723534    0.681402    0.609034    0.579259    1400        11.130742   0.483945    0.315559    131.837786 
[37m[36mINFO[0m[0m 03/12 07:51:35 | 0.555350    0.561481    0.813199    0.797616    0.488084    0.984982    0.985866    0.700235    0.679849    0.754379    0.727134    0.555350    0.561481    1600        12.720848   0.462166    0.310425    131.826293 
[37m[36mINFO[0m[0m 03/12 07:54:50 | 0.620881    0.617778    0.811663    0.789444    0.525348    0.991166    0.982332    0.711529    0.681733    0.732292    0.704268    0.620881    0.617778    1800        14.310954   0.445068    0.320057    131.387793 
[37m[36mINFO[0m[0m 03/12 07:58:03 | 0.577194    0.577778    0.854740    0.808192    0.480401    0.989399    0.975265    0.769412    0.709981    0.805407    0.739329    0.577194    0.577778    2000        15.901060   0.417464    0.317890    129.391697 
[37m[36mINFO[0m[0m 03/12 08:01:21 | 0.641244    0.648889    0.856762    0.817226    0.500365    0.992933    0.985866    0.772706    0.732580    0.804646    0.733232    0.641244    0.648889    2200        17.491166   0.395210    0.328079    132.358679 
[37m[36mINFO[0m[0m 03/12 08:04:38 | 0.615698    0.617778    0.854735    0.808306    0.468280    0.993816    0.982332    0.782118    0.730697    0.788271    0.711890    0.615698    0.617778    2400        19.081272   0.387768    0.321637    132.262347 
[37m[36mINFO[0m[0m 03/12 08:07:53 | 0.654572    0.637037    0.873910    0.819634    0.494380    0.992933    0.964664    0.810824    0.745763    0.817974    0.748476    0.654572    0.637037    2600        20.671378   0.370286    0.326427    130.223980 
[37m[36mINFO[0m[0m 03/12 08:11:04 | 0.636801    0.617778    0.859171    0.810654    0.478334    0.961131    0.943463    0.797647    0.747646    0.818736    0.740854    0.636801    0.617778    2800        22.261484   0.363213    0.312974    128.747866 
[37m[36mINFO[0m[0m 03/12 08:14:18 | 0.611996    0.604444    0.855523    0.812878    0.526735    0.974382    0.964664    0.790588    0.719397    0.801599    0.754573    0.611996    0.604444    3000        23.851590   0.314762    0.321896    129.503021 
[37m[36mINFO[0m[0m 03/12 08:17:31 | 0.564976    0.580741    0.859337    0.801276    0.537061    0.997350    0.989399    0.758118    0.694915    0.822544    0.719512    0.564976    0.580741    3200        25.441696   0.337798    0.315718    129.480695 
[37m[36mINFO[0m[0m 03/12 08:20:45 | 0.594595    0.594074    0.870692    0.812156    0.542392    0.989399    0.971731    0.796706    0.726930    0.825971    0.737805    0.594595    0.594074    3400        27.031802   0.329712    0.319684    129.693463 
[37m[36mINFO[0m[0m 03/12 08:23:57 | 0.627916    0.616296    0.883036    0.807630    0.525900    0.994700    0.968198    0.827294    0.738230    0.827113    0.716463    0.627916    0.616296    3600        28.621908   0.320536    0.318628    128.957685 
[37m[36mINFO[0m[0m 03/12 08:27:13 | 0.639023    0.647407    0.892985    0.814404    0.506563    0.997350    0.982332    0.838118    0.730697    0.843488    0.730183    0.639023    0.647407    3800        30.212014   0.300648    0.321303    131.226784 
[37m[36mINFO[0m[0m 03/12 08:30:24 | 0.616809    0.637037    0.872947    0.797904    0.534262    0.994700    0.982332    0.818353    0.694915    0.805788    0.716463    0.616809    0.637037    4000        31.802120   0.325402    0.314372    128.640841 
[37m[36mINFO[0m[0m 03/12 08:33:40 | 0.542021    0.568889    0.893881    0.804804    0.551798    0.999117    0.989399    0.840941    0.734463    0.841584    0.690549    0.542021    0.568889    4200        33.392226   0.288177    0.320512    131.213836 
[37m[36mINFO[0m[0m 03/12 08:36:52 | 0.557571    0.577778    0.901109    0.803278    0.547510    0.980565    0.971731    0.852235    0.723164    0.870526    0.714939    0.557571    0.577778    4400        34.982332   0.272595    0.321239    128.184847 
[37m[36mINFO[0m[0m 03/12 08:40:10 | 0.611625    0.605926    0.908399    0.811612    0.544823    0.999117    0.978799    0.861647    0.721281    0.864433    0.734756    0.611625    0.605926    4600        36.572438   0.265154    0.330431    131.498268 
[37m[36mINFO[0m[0m 03/12 08:43:27 | 0.520918    0.551111    0.907011    0.797628    0.574409    0.989399    0.971731    0.858824    0.706215    0.872810    0.714939    0.520918    0.551111    4800        38.162544   0.242825    0.326903    131.798294 
[37m[36mINFO[0m[0m 03/12 08:46:41 | 0.594965    0.570370    0.889440    0.801168    0.602304    0.995583    0.975265    0.839529    0.719397    0.833206    0.708841    0.594965    0.570370    5000        39.752650   0.263994    0.319430    130.582564 
[37m[36mINFO[0m[0m 03/12 08:46:42 | Cumulative gradient change saved at train_output/VLCS/ERM/[3]/250312_07-23-25_clip_vitb16_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/12 08:46:44 | ---
[37m[36mINFO[0m[0m 03/12 08:46:44 | test-domain validation(oracle) = 64.124%
[37m[36mINFO[0m[0m 03/12 08:46:44 | training-domain validation(iid) = 65.457%
[37m[36mINFO[0m[0m 03/12 08:46:44 | last = 59.496%
[37m[36mINFO[0m[0m 03/12 08:46:44 | last (inD) = 80.117%
[37m[36mINFO[0m[0m 03/12 08:46:44 | training-domain validation (iid, inD) = 81.963%
[37m[36mINFO[0m[0m 03/12 08:46:44 | === Summary ===
[37m[36mINFO[0m[0m 03/12 08:46:44 | Command: /jsm0707/GENIE/train_all.py clip_vitb16_GENIE config/clip_vitb16_GENIE.yaml --algorithm ERM --test_envs 3 --dataset VLCS --trial_seed 1 --hparams_seed 10
[37m[36mINFO[0m[0m 03/12 08:46:44 | Unique name: 250312_07-23-25_clip_vitb16_GENIE
[37m[36mINFO[0m[0m 03/12 08:46:44 | Out path: train_output/VLCS/ERM/[3]/250312_07-23-25_clip_vitb16_GENIE
[37m[36mINFO[0m[0m 03/12 08:46:44 | Algorithm: ERM
[37m[36mINFO[0m[0m 03/12 08:46:44 | Dataset: VLCS
