[37m[36mINFO[0m[0m 02/27 01:33:16 | Command :: /jsm0707/GENIE/train_all.py clip_vitb16_adam config/clip_vitb16_adam.yaml --algorithm ERM --test_envs 3 --dataset VLCS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: ERM
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/clip_vitb16_adam.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: clip_vitb16_adam
	out_dir: train_output/VLCS/ERM/[3]/250227_01-33-16_clip_vitb16_adam
	out_root: train_output/VLCS/ERM/[3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [3]
	trial_seed: 0
	unique_name: 250227_01-33-16_clip_vitb16_adam
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: adam
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: clip_vit-b16
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 02/27 01:33:16 | n_steps = 5001
[37m[36mINFO[0m[0m 02/27 01:33:16 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/27 01:33:16 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/27 01:33:16 | 
[37m[36mINFO[0m[0m 02/27 01:33:16 | Testenv name escaping te_V -> te_V
[37m[36mINFO[0m[0m 02/27 01:33:16 | Test envs = [3], name = te_V
[37m[36mINFO[0m[0m 02/27 01:33:16 | Train environments: [0, 1, 2], Test environments: [3]
[37m[36mINFO[0m[0m 02/27 01:33:16 | Batch sizes for each domain: [32, 32, 32, 0] (total=96)
[37m[36mINFO[0m[0m 02/27 01:33:16 | steps-per-epoch for each domain: 35.38, 66.41, 82.06 -> min = 35.38
[37m[36mINFO[0m[0m 02/27 01:33:19 | # of params = 86195205
[37m[36mINFO[0m[0m 02/27 01:35:33 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 02/27 01:35:33 | 0.485376    0.482963    0.528613    0.555748    1.109745    0.619258    0.639576    0.537412    0.561205    0.429170    0.466463    0.485376    0.482963    0           0.000000    1.649576    1.332338    132.973442 
[37m[36mINFO[0m[0m 02/27 01:41:51 | 0.693077    0.700741    0.881240    0.872997    0.373116    0.996466    0.992933    0.803765    0.813559    0.843488    0.812500    0.693077    0.700741    200         5.653710    0.381745    1.211012    135.823177 
[37m[36mINFO[0m[0m 02/27 01:48:09 | 0.706775    0.724444    0.909709    0.873326    0.378928    0.982332    0.992933    0.848471    0.794727    0.898324    0.832317    0.706775    0.724444    400         11.307420   0.267898    1.199790    137.874475 
[37m[36mINFO[0m[0m 02/27 01:54:22 | 0.670122    0.675556    0.917503    0.846201    0.500556    0.969081    0.954064    0.866824    0.779661    0.916603    0.804878    0.670122    0.675556    600         16.961131   0.210840    1.200977    133.308004 
[37m[36mINFO[0m[0m 02/27 02:00:52 | 0.719733    0.717037    0.960103    0.864681    0.442424    1.000000    1.000000    0.927529    0.781544    0.952780    0.812500    0.719733    0.717037    800         22.614841   0.168206    1.253941    138.570610 
[37m[36mINFO[0m[0m 02/27 02:07:18 | 0.722695    0.722963    0.949847    0.844015    0.566870    0.997350    0.996466    0.913882    0.762712    0.938309    0.772866    0.722695    0.722963    1000        28.268551   0.130316    1.239796    138.434052 
[37m[36mINFO[0m[0m 02/27 02:13:51 | 0.678267    0.696296    0.970230    0.858840    0.498637    1.000000    0.996466    0.943059    0.772128    0.967631    0.807927    0.678267    0.696296    1200        33.922261   0.116027    1.240206    145.445350 
[37m[36mINFO[0m[0m 02/27 02:20:19 | 0.687153    0.675556    0.974883    0.857238    0.549815    1.000000    1.000000    0.954353    0.768362    0.970297    0.803354    0.687153    0.675556    1400        39.575972   0.084323    1.242332    139.105437 
[37m[36mINFO[0m[0m 02/27 02:26:53 | 0.736024    0.740741    0.977828    0.856258    0.589204    0.998233    0.992933    0.968000    0.774011    0.967251    0.801829    0.736024    0.740741    1600        45.229682   0.085579    1.231073    147.416380 
[37m[36mINFO[0m[0m 02/27 02:33:31 | 0.689004    0.693333    0.982002    0.855523    0.551623    1.000000    0.996466    0.976471    0.775895    0.969535    0.794207    0.689004    0.693333    1800        50.883392   0.061951    1.245987    149.144554 
[37m[36mINFO[0m[0m 02/27 02:39:55 | 0.694558    0.685926    0.972886    0.834120    0.690853    0.994700    0.978799    0.964706    0.747646    0.959254    0.775915    0.694558    0.685926    2000        56.537102   0.060576    1.224964    139.470565 
[37m[36mINFO[0m[0m 02/27 02:46:47 | 0.702332    0.705185    0.986658    0.843865    0.695599    0.999117    0.996466    0.976471    0.768362    0.984387    0.766768    0.702332    0.705185    2200        62.190813   0.060055    1.303039    151.089343 
[37m[36mINFO[0m[0m 02/27 02:53:27 | 0.701962    0.677037    0.984918    0.841581    0.723108    0.999117    0.992933    0.975059    0.758945    0.980579    0.772866    0.701962    0.677037    2400        67.844523   0.046039    1.250854    150.081329 
[37m[36mINFO[0m[0m 02/27 03:00:07 | 0.698630    0.688889    0.982531    0.836499    0.696991    1.000000    0.992933    0.970824    0.726930    0.976771    0.789634    0.698630    0.688889    2600        73.498233   0.047648    1.298153    140.376103 
[37m[36mINFO[0m[0m 02/27 03:06:47 | 0.647168    0.677037    0.982623    0.846885    0.622338    0.998233    0.996466    0.975529    0.775895    0.974105    0.768293    0.647168    0.677037    2800        79.151943   0.056082    1.250959    149.076873 
[37m[36mINFO[0m[0m 02/27 03:13:19 | 0.656424    0.675556    0.983477    0.845976    0.659932    0.999117    0.992933    0.978353    0.772128    0.972963    0.772866    0.656424    0.675556    3000        84.805654   0.051319    1.230750    146.221251 
[37m[36mINFO[0m[0m 02/27 03:19:41 | 0.685302    0.682963    0.986487    0.837061    0.720259    0.999117    0.982332    0.979765    0.751412    0.980579    0.777439    0.685302    0.682963    3200        90.459364   0.039911    1.232107    135.876331 
[37m[36mINFO[0m[0m 02/27 03:26:16 | 0.643465    0.634074    0.979941    0.847063    0.671845    0.998233    0.996466    0.971294    0.762712    0.970297    0.782012    0.643465    0.634074    3400        96.113074   0.044051    1.235360    147.307856 
[37m[36mINFO[0m[0m 02/27 03:32:48 | 0.687523    0.697778    0.992718    0.834198    0.727142    1.000000    0.992933    0.987294    0.730697    0.990861    0.778963    0.687523    0.697778    3600        101.766784  0.040157    1.239964    143.834477 
[37m[36mINFO[0m[0m 02/27 03:39:26 | 0.610515    0.608889    0.985806    0.844917    0.704359    0.996466    0.989399    0.984941    0.774011    0.976009    0.771341    0.610515    0.608889    3800        107.420495  0.036180    1.258191    146.279647 
[37m[36mINFO[0m[0m 02/27 03:46:03 | 0.697149    0.662222    0.992439    0.845976    0.700932    0.999117    0.992933    0.991529    0.772128    0.986672    0.772866    0.697149    0.662222    4000        113.074205  0.041347    1.241402    149.098799 
[37m[36mINFO[0m[0m 02/27 03:52:45 | 0.651240    0.642963    0.986774    0.848128    0.717408    1.000000    0.992933    0.981647    0.774011    0.978675    0.777439    0.651240    0.642963    4200        118.727915  0.047989    1.226783    156.509636 
[37m[36mINFO[0m[0m 02/27 03:59:31 | 0.698260    0.693333    0.990336    0.846215    0.761827    1.000000    0.992933    0.987765    0.775895    0.983244    0.769817    0.698260    0.693333    4400        124.381625  0.028017    1.280480    149.757707 
[37m[36mINFO[0m[0m 02/27 04:06:26 | 0.653091    0.635556    0.986932    0.846777    0.698235    0.998233    1.000000    0.985412    0.779661    0.977152    0.760671    0.653091    0.635556    4600        130.035336  0.033766    1.315239    152.176203 
[37m[36mINFO[0m[0m 02/27 04:13:36 | 0.596816    0.597037    0.987092    0.831077    0.728236    0.999117    0.989399    0.987294    0.740113    0.974867    0.763720    0.596816    0.597037    4800        135.689046  0.038677    1.361250    157.600961 
[37m[36mINFO[0m[0m 02/27 04:21:04 | 0.662718    0.640000    0.988422    0.835232    0.802636    0.997350    0.989399    0.983529    0.749529    0.984387    0.766768    0.662718    0.640000    5000        141.342756  0.028642    1.478466    152.485434 
[37m[36mINFO[0m[0m 02/27 04:21:04 | Cumulative gradient change saved at train_output/VLCS/ERM/[3]/250227_01-33-16_clip_vitb16_adam/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/27 04:21:11 | ---
[37m[36mINFO[0m[0m 02/27 04:21:11 | test-domain validation(oracle) = 73.602%
[37m[36mINFO[0m[0m 02/27 04:21:11 | training-domain validation(iid) = 70.678%
[37m[36mINFO[0m[0m 02/27 04:21:11 | last = 66.272%
[37m[36mINFO[0m[0m 02/27 04:21:11 | last (inD) = 83.523%
[37m[36mINFO[0m[0m 02/27 04:21:11 | training-domain validation (iid, inD) = 87.333%
[37m[36mINFO[0m[0m 02/27 04:21:11 | === Summary ===
[37m[36mINFO[0m[0m 02/27 04:21:11 | Command: /jsm0707/GENIE/train_all.py clip_vitb16_adam config/clip_vitb16_adam.yaml --algorithm ERM --test_envs 3 --dataset VLCS
[37m[36mINFO[0m[0m 02/27 04:21:11 | Unique name: 250227_01-33-16_clip_vitb16_adam
[37m[36mINFO[0m[0m 02/27 04:21:11 | Out path: train_output/VLCS/ERM/[3]/250227_01-33-16_clip_vitb16_adam
[37m[36mINFO[0m[0m 02/27 04:21:11 | Algorithm: ERM
[37m[36mINFO[0m[0m 02/27 04:21:11 | Dataset: VLCS
