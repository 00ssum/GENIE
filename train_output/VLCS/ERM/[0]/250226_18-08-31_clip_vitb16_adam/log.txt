[37m[36mINFO[0m[0m 02/26 18:08:31 | Command :: /jsm0707/GENIE/train_all.py clip_vitb16_adam config/clip_vitb16_adam.yaml --algorithm ERM --test_envs 0 --dataset VLCS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: ERM
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/clip_vitb16_adam.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: clip_vitb16_adam
	out_dir: train_output/VLCS/ERM/[0]/250226_18-08-31_clip_vitb16_adam
	out_root: train_output/VLCS/ERM/[0]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0]
	trial_seed: 0
	unique_name: 250226_18-08-31_clip_vitb16_adam
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: adam
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: clip_vit-b16
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 02/26 18:08:31 | n_steps = 5001
[37m[36mINFO[0m[0m 02/26 18:08:31 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/26 18:08:31 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/26 18:08:31 | 
[37m[36mINFO[0m[0m 02/26 18:08:31 | Testenv name escaping te_C -> te_C
[37m[36mINFO[0m[0m 02/26 18:08:31 | Test envs = [0], name = te_C
[37m[36mINFO[0m[0m 02/26 18:08:31 | Train environments: [1, 2, 3], Test environments: [0]
[37m[36mINFO[0m[0m 02/26 18:08:31 | Batch sizes for each domain: [0, 32, 32, 32] (total=96)
[37m[36mINFO[0m[0m 02/26 18:08:31 | steps-per-epoch for each domain: 66.41, 82.06, 84.41 -> min = 66.41
[37m[36mINFO[0m[0m 02/26 18:08:34 | # of params = 86195205
[37m[36mINFO[0m[0m 02/26 18:10:59 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 02/26 18:10:59 | 0.605124    0.625442    0.486578    0.517070    1.191667    0.605124    0.625442    0.534588    0.574388    0.450876    0.492378    0.474269    0.484444    0           0.000000    1.659496    1.101971    143.446878 
[37m[36mINFO[0m[0m 02/26 18:17:45 | 0.893110    0.901060    0.842134    0.811694    0.542922    0.893110    0.901060    0.790588    0.779661    0.859101    0.810976    0.876712    0.844444    200         3.011765    0.497524    1.269271    152.110250 
[37m[36mINFO[0m[0m 02/26 18:24:33 | 0.950530    0.968198    0.891574    0.815009    0.545808    0.950530    0.968198    0.849882    0.790960    0.905179    0.815549    0.919659    0.838519    400         6.023529    0.339727    1.235241    160.907668 
[37m[36mINFO[0m[0m 02/26 18:31:13 | 0.961131    0.971731    0.919331    0.788738    0.619816    0.961131    0.971731    0.864471    0.757062    0.938690    0.798780    0.954832    0.810370    600         9.035294    0.256226    1.271748    145.611068 
[37m[36mINFO[0m[0m 02/26 18:37:54 | 0.940813    0.961131    0.929902    0.804542    0.676315    0.940813    0.961131    0.912000    0.768362    0.942498    0.818598    0.935209    0.826667    800         12.047059   0.206729    1.237477    153.932771 
[37m[36mINFO[0m[0m 02/26 18:44:35 | 0.964664    0.975265    0.945416    0.802229    0.742931    0.964664    0.975265    0.916706    0.749529    0.955826    0.820122    0.963717    0.837037    1000        15.058824   0.153426    1.228921    155.073196 
[37m[36mINFO[0m[0m 02/26 18:51:13 | 0.962014    0.957597    0.965446    0.804905    0.722241    0.962014    0.957597    0.953882    0.783427    0.967631    0.795732    0.974824    0.835556    1200        18.070588   0.146725    1.268191    144.264575 
[37m[36mINFO[0m[0m 02/26 18:58:01 | 0.958481    0.964664    0.962583    0.780084    0.862411    0.958481    0.964664    0.971294    0.764595    0.951257    0.766768    0.965198    0.808889    1400        21.082353   0.091105    1.286279    150.819283 
[37m[36mINFO[0m[0m 02/26 19:04:57 | 0.966431    0.961131    0.975459    0.793523    0.814334    0.966431    0.961131    0.962353    0.753296    0.984387    0.810976    0.979637    0.816296    1600        24.094118   0.091292    1.274041    161.493950 
[37m[36mINFO[0m[0m 02/26 19:11:58 | 0.962014    0.957597    0.970916    0.800339    0.882507    0.962014    0.957597    0.961882    0.796610    0.977152    0.788110    0.973713    0.816296    1800        27.105882   0.088095    1.347001    151.406151 
[37m[36mINFO[0m[0m 02/26 19:18:56 | 0.964664    0.968198    0.982871    0.801897    0.809161    0.964664    0.968198    0.979765    0.798493    0.984768    0.782012    0.984080    0.825185    2000        30.117647   0.086096    1.328069    151.775463 
[37m[36mINFO[0m[0m 02/26 19:26:04 | 0.937279    0.943463    0.982938    0.789993    0.891727    0.937279    0.943463    0.976941    0.760829    0.987053    0.798780    0.984820    0.810370    2200        33.129412   0.066180    1.367743    155.053097 
[37m[36mINFO[0m[0m 02/26 19:33:18 | 0.935512    0.936396    0.978712    0.786718    0.925019    0.935512    0.936396    0.973647    0.764595    0.982483    0.789634    0.980007    0.805926    2400        36.141176   0.068483    1.330252    167.787243 
[37m[36mINFO[0m[0m 02/26 19:40:26 | 0.962898    0.975265    0.984851    0.792526    0.905091    0.962898    0.975265    0.979294    0.755179    0.988957    0.795732    0.986301    0.826667    2600        39.152941   0.067252    1.342197    159.432369 
[37m[36mINFO[0m[0m 02/26 19:47:17 | 0.943463    0.936396    0.984676    0.789925    0.931804    0.943463    0.936396    0.976941    0.738230    0.988195    0.804878    0.988893    0.826667    2800        42.164706   0.074116    1.289786    152.803093 
[37m[36mINFO[0m[0m 02/26 19:54:03 | 0.967314    0.968198    0.983756    0.795072    0.946241    0.967314    0.968198    0.980706    0.775895    0.979817    0.804878    0.990744    0.804444    3000        45.176471   0.065447    1.244081    157.161067 
[37m[36mINFO[0m[0m 02/26 20:00:59 | 0.953180    0.950530    0.981908    0.783471    1.011491    0.953180    0.950530    0.980706    0.775895    0.980198    0.778963    0.984820    0.795556    3200        48.188235   0.053811    1.259917    164.556561 
[37m[36mINFO[0m[0m 02/26 20:07:39 | 0.939929    0.925795    0.977638    0.758258    1.060078    0.939929    0.925795    0.979765    0.749529    0.979436    0.765244    0.973713    0.760000    3400        51.200000   0.063477    1.253631    148.539382 
[37m[36mINFO[0m[0m 02/26 20:14:17 | 0.944346    0.961131    0.987544    0.775475    0.976748    0.944346    0.961131    0.987765    0.738230    0.988195    0.791159    0.986672    0.797037    3600        54.211765   0.050783    1.223518    153.333352 
[37m[36mINFO[0m[0m 02/26 20:21:04 | 0.944346    0.939929    0.971347    0.768556    0.958450    0.944346    0.939929    0.967059    0.736347    0.984006    0.804878    0.962977    0.764444    3800        57.223529   0.057231    1.252746    156.311116 
[37m[36mINFO[0m[0m 02/26 20:27:51 | 0.960247    0.950530    0.981521    0.770079    1.070530    0.960247    0.950530    0.975059    0.725047    0.981721    0.789634    0.987782    0.795556    4000        60.235294   0.043714    1.252771    157.014577 
[37m[36mINFO[0m[0m 02/26 20:34:37 | 0.930212    0.939929    0.988612    0.781276    0.997130    0.930212    0.939929    0.992471    0.774011    0.987433    0.769817    0.985931    0.800000    4200        63.247059   0.053990    1.290607    147.673956 
[37m[36mINFO[0m[0m 02/26 20:41:43 | 0.934629    0.922261    0.976259    0.760635    1.135848    0.934629    0.922261    0.982588    0.728814    0.968774    0.754573    0.977416    0.798519    4400        66.258824   0.046715    1.303278    165.551007 
[37m[36mINFO[0m[0m 02/26 20:48:42 | 0.954947    0.943463    0.989319    0.785009    0.968470    0.954947    0.943463    0.988235    0.783427    0.989718    0.780488    0.990004    0.791111    4600        69.270588   0.043983    1.324829    153.456063 
[37m[36mINFO[0m[0m 02/26 20:55:32 | 0.964664    0.968198    0.984530    0.762091    1.096762    0.964664    0.968198    0.982118    0.732580    0.985910    0.775915    0.985561    0.777778    4800        72.282353   0.040876    1.300439    149.888923 
[37m[36mINFO[0m[0m 02/26 21:02:26 | 0.927562    0.929329    0.983172    0.771464    1.138293    0.927562    0.929329    0.984941    0.760829    0.977532    0.771341    0.987042    0.782222    5000        75.294118   0.039527    1.264135    161.395155 
[37m[36mINFO[0m[0m 02/26 21:02:26 | Cumulative gradient change saved at train_output/VLCS/ERM/[0]/250226_18-08-31_clip_vitb16_adam/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/26 21:02:30 | ---
[37m[36mINFO[0m[0m 02/26 21:02:30 | test-domain validation(oracle) = 96.466%
[37m[36mINFO[0m[0m 02/26 21:02:30 | training-domain validation(iid) = 95.053%
[37m[36mINFO[0m[0m 02/26 21:02:30 | last = 92.756%
[37m[36mINFO[0m[0m 02/26 21:02:30 | last (inD) = 77.146%
[37m[36mINFO[0m[0m 02/26 21:02:30 | training-domain validation (iid, inD) = 81.501%
[37m[36mINFO[0m[0m 02/26 21:02:30 | === Summary ===
[37m[36mINFO[0m[0m 02/26 21:02:30 | Command: /jsm0707/GENIE/train_all.py clip_vitb16_adam config/clip_vitb16_adam.yaml --algorithm ERM --test_envs 0 --dataset VLCS
[37m[36mINFO[0m[0m 02/26 21:02:30 | Unique name: 250226_18-08-31_clip_vitb16_adam
[37m[36mINFO[0m[0m 02/26 21:02:30 | Out path: train_output/VLCS/ERM/[0]/250226_18-08-31_clip_vitb16_adam
[37m[36mINFO[0m[0m 02/26 21:02:30 | Algorithm: ERM
[37m[36mINFO[0m[0m 02/26 21:02:30 | Dataset: VLCS
