[37m[36mINFO[0m[0m 03/04 02:11:50 | Command :: /jsm0707/GENIE/train_all.py clip_vitb16_sgd config/clip_vitb16_sgd.yaml --algorithm ERM --test_envs 0 --dataset VLCS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: ERM
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/clip_vitb16_sgd.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: clip_vitb16_sgd
	out_dir: train_output/VLCS/ERM/[0]/250304_02-11-50_clip_vitb16_sgd
	out_root: train_output/VLCS/ERM/[0]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0]
	trial_seed: 0
	unique_name: 250304_02-11-50_clip_vitb16_sgd
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: sgd
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: clip_vit-b16
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 03/04 02:11:50 | n_steps = 5001
[37m[36mINFO[0m[0m 03/04 02:11:50 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/04 02:11:50 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/04 02:11:50 | 
[37m[36mINFO[0m[0m 03/04 02:11:50 | Testenv name escaping te_C -> te_C
[37m[36mINFO[0m[0m 03/04 02:11:50 | Test envs = [0], name = te_C
[37m[36mINFO[0m[0m 03/04 02:11:50 | Train environments: [1, 2, 3], Test environments: [0]
[37m[36mINFO[0m[0m 03/04 02:11:50 | Batch sizes for each domain: [0, 32, 32, 32] (total=96)
[37m[36mINFO[0m[0m 03/04 02:11:50 | steps-per-epoch for each domain: 66.41, 82.06, 84.41 -> min = 66.41
[37m[36mINFO[0m[0m 03/04 02:11:53 | # of params = 86195205
[37m[36mINFO[0m[0m 03/04 02:14:03 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/04 02:14:03 | 0.078622    0.074205    0.226199    0.226699    1.639581    0.078622    0.074205    0.143529    0.158192    0.362909    0.330793    0.172158    0.191111    0           0.000000    1.659496    1.097605    129.429867 
[37m[36mINFO[0m[0m 03/04 02:19:48 | 0.437279    0.448763    0.462427    0.443703    1.300019    0.437279    0.448763    0.522824    0.504708    0.425362    0.411585    0.439097    0.414815    200         3.011765    1.421874    1.086426    127.966286 
[37m[36mINFO[0m[0m 03/04 02:25:39 | 0.583922    0.625442    0.529827    0.533056    1.167289    0.583922    0.625442    0.595294    0.589454    0.484006    0.503049    0.510181    0.506667    400         6.023529    1.212510    1.109038    128.321231 
[37m[36mINFO[0m[0m 03/04 02:31:28 | 0.688163    0.685512    0.597991    0.602219    1.063536    0.688163    0.685512    0.663529    0.662900    0.577685    0.580793    0.552758    0.562963    600         9.035294    1.104465    1.097585    129.956424 
[37m[36mINFO[0m[0m 03/04 02:37:15 | 0.712898    0.706714    0.678255    0.669528    0.958566    0.712898    0.706714    0.687059    0.676083    0.735339    0.707317    0.612366    0.625185    800         12.047059   1.002758    1.087379    129.678073 
[37m[36mINFO[0m[0m 03/04 02:43:04 | 0.764134    0.749117    0.726064    0.718095    0.861039    0.764134    0.749117    0.702588    0.689266    0.794745    0.783537    0.680859    0.681481    1000        15.058824   0.900290    1.088155    130.887038 
[37m[36mINFO[0m[0m 03/04 02:48:55 | 0.818905    0.805654    0.760196    0.757531    0.781343    0.818905    0.805654    0.720000    0.726930    0.815308    0.806402    0.745280    0.739259    1200        18.070588   0.807288    1.092305    133.069304 
[37m[36mINFO[0m[0m 03/04 02:54:43 | 0.894876    0.865724    0.785690    0.785093    0.712972    0.894876    0.865724    0.744471    0.758945    0.821782    0.817073    0.790818    0.779259    1400        21.082353   0.730308    1.091073    129.755598 
[37m[36mINFO[0m[0m 03/04 03:00:29 | 0.947880    0.918728    0.806891    0.804536    0.656475    0.947880    0.918728    0.754824    0.774011    0.832826    0.827744    0.833025    0.811852    1600        24.094118   0.676523    1.087498    128.334962 
[37m[36mINFO[0m[0m 03/04 03:06:18 | 0.970848    0.950530    0.818064    0.816379    0.614454    0.970848    0.950530    0.767059    0.794727    0.839299    0.827744    0.847834    0.826667    1800        27.105882   0.624567    1.080349    132.423882 
[37m[36mINFO[0m[0m 03/04 03:12:06 | 0.981449    0.957597    0.831411    0.821467    0.580205    0.981449    0.957597    0.789647    0.789077    0.841203    0.833841    0.863384    0.841481    2000        30.117647   0.589171    1.094970    129.209325 
[37m[36mINFO[0m[0m 03/04 03:17:58 | 0.986749    0.964664    0.835540    0.830989    0.552521    0.986749    0.964664    0.793412    0.811676    0.845011    0.835366    0.868197    0.845926    2200        33.129412   0.544394    1.107738    130.422278 
[37m[36mINFO[0m[0m 03/04 03:23:49 | 0.987633    0.978799    0.841481    0.835012    0.529845    0.987633    0.978799    0.798118    0.804143    0.850724    0.847561    0.875602    0.853333    2400        36.141176   0.521013    1.085938    134.318172 
[37m[36mINFO[0m[0m 03/04 03:29:45 | 0.991166    0.971731    0.849727    0.837601    0.511792    0.991166    0.971731    0.812235    0.806026    0.859863    0.846037    0.877083    0.860741    2600        39.152941   0.497684    1.107507    134.377831 
[37m[36mINFO[0m[0m 03/04 03:35:38 | 0.988516    0.968198    0.848556    0.845283    0.496862    0.988516    0.968198    0.796706    0.822976    0.865956    0.852134    0.883006    0.860741    2800        42.164706   0.485411    1.097816    133.281966 
[37m[36mINFO[0m[0m 03/04 03:41:26 | 0.990283    0.971731    0.859695    0.845899    0.480595    0.990283    0.971731    0.816941    0.809793    0.873953    0.859756    0.888190    0.868148    3000        45.176471   0.472110    1.094901    129.046574 
[37m[36mINFO[0m[0m 03/04 03:47:12 | 0.986749    0.961131    0.864717    0.845647    0.467821    0.986749    0.961131    0.823059    0.798493    0.876238    0.865854    0.894854    0.872593    3200        48.188235   0.446545    1.076594    130.754123 
[37m[36mINFO[0m[0m 03/04 03:53:02 | 0.982332    0.957597    0.864750    0.844946    0.462277    0.982332    0.957597    0.823529    0.804143    0.876238    0.853659    0.894484    0.877037    3400        51.200000   0.427959    1.084971    133.201709 
[37m[36mINFO[0m[0m 03/04 03:58:46 | 0.981449    0.957597    0.872220    0.849730    0.446377    0.981449    0.957597    0.823059    0.807910    0.886900    0.861280    0.906701    0.880000    3600        54.211765   0.414495    1.067772    130.121128 
[37m[36mINFO[0m[0m 03/04 04:04:38 | 0.979682    0.961131    0.875143    0.862738    0.439597    0.979682    0.961131    0.829647    0.830508    0.885377    0.865854    0.910404    0.891852    3800        57.223529   0.408632    1.097048    132.728450 
[37m[36mINFO[0m[0m 03/04 04:10:26 | 0.978799    0.964664    0.875626    0.851527    0.437032    0.978799    0.964664    0.824000    0.813559    0.887662    0.852134    0.915217    0.888889    4000        60.235294   0.398199    1.082113    131.501578 
[37m[36mINFO[0m[0m 03/04 04:16:16 | 0.978799    0.957597    0.880427    0.857552    0.429524    0.978799    0.957597    0.837176    0.821092    0.891851    0.858232    0.912255    0.893333    4200        63.247059   0.378560    1.098333    130.448111 
[37m[36mINFO[0m[0m 03/04 04:22:01 | 0.969965    0.971731    0.879011    0.852425    0.431631    0.969965    0.971731    0.829647    0.804143    0.889947    0.861280    0.917438    0.891852    4400        66.258824   0.423403    1.080952    128.382305 
[37m[36mINFO[0m[0m 03/04 04:27:45 | 0.975265    0.957597    0.886032    0.858627    0.414964    0.975265    0.957597    0.832941    0.813559    0.903275    0.871951    0.921881    0.890370    4600        69.270588   0.365258    1.076097    129.121204 
[37m[36mINFO[0m[0m 03/04 04:33:30 | 0.973498    0.968198    0.886753    0.862040    0.416437    0.973498    0.968198    0.837176    0.821092    0.895278    0.862805    0.927805    0.902222    4800        72.282353   0.358810    1.078511    128.833201 
[37m[36mINFO[0m[0m 03/04 04:39:15 | 0.977915    0.968198    0.892385    0.862457    0.410911    0.977915    0.968198    0.849882    0.819209    0.899467    0.868902    0.927805    0.899259    5000        75.294118   0.356976    1.081997    129.392722 
[37m[36mINFO[0m[0m 03/04 04:39:16 | Cumulative gradient change saved at train_output/VLCS/ERM/[0]/250304_02-11-50_clip_vitb16_sgd/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/04 04:39:19 | ---
[37m[36mINFO[0m[0m 03/04 04:39:19 | test-domain validation(oracle) = 98.763%
[37m[36mINFO[0m[0m 03/04 04:39:19 | training-domain validation(iid) = 97.968%
[37m[36mINFO[0m[0m 03/04 04:39:19 | last = 97.792%
[37m[36mINFO[0m[0m 03/04 04:39:19 | last (inD) = 86.246%
[37m[36mINFO[0m[0m 03/04 04:39:19 | training-domain validation (iid, inD) = 86.274%
[37m[36mINFO[0m[0m 03/04 04:39:19 | === Summary ===
[37m[36mINFO[0m[0m 03/04 04:39:19 | Command: /jsm0707/GENIE/train_all.py clip_vitb16_sgd config/clip_vitb16_sgd.yaml --algorithm ERM --test_envs 0 --dataset VLCS
[37m[36mINFO[0m[0m 03/04 04:39:19 | Unique name: 250304_02-11-50_clip_vitb16_sgd
[37m[36mINFO[0m[0m 03/04 04:39:19 | Out path: train_output/VLCS/ERM/[0]/250304_02-11-50_clip_vitb16_sgd
[37m[36mINFO[0m[0m 03/04 04:39:19 | Algorithm: ERM
[37m[36mINFO[0m[0m 03/04 04:39:19 | Dataset: VLCS
