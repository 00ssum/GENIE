[37m[36mINFO[0m[0m 03/07 22:12:52 | Command :: /jsm0707/GENIE/train_all.py clip_vitb16_GENIE config/clip_vitb16_GENIE.yaml --algorithm ERM --test_envs 0 --dataset VLCS --trial_seed 0 --hparams_seed 15
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: ERM
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/clip_vitb16_GENIE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 15
	in_domain: False
	model_save: None
	mpa: False
	name: clip_vitb16_GENIE
	out_dir: train_output/VLCS/ERM/[0]/250307_22-12-52_clip_vitb16_GENIE
	out_root: train_output/VLCS/ERM/[0]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0]
	trial_seed: 0
	unique_name: 250307_22-12-52_clip_vitb16_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.5
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 0.00010661763546249327
	batch_size: 14
	weight_decay: 9.086452814323981e-06
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: openclip_vit-b16
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 03/07 22:12:52 | n_steps = 5001
[37m[36mINFO[0m[0m 03/07 22:12:52 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/07 22:12:52 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/07 22:12:52 | 
[37m[36mINFO[0m[0m 03/07 22:12:52 | Testenv name escaping te_C -> te_C
[37m[36mINFO[0m[0m 03/07 22:12:52 | Test envs = [0], name = te_C
[37m[36mINFO[0m[0m 03/07 22:12:52 | Train environments: [1, 2, 3], Test environments: [0]
[37m[36mINFO[0m[0m 03/07 22:12:52 | Batch sizes for each domain: [0, 14, 14, 14] (total=42)
[37m[36mINFO[0m[0m 03/07 22:12:52 | steps-per-epoch for each domain: 151.79, 187.57, 192.93 -> min = 151.79
[37m[36mINFO[0m[0m 03/07 22:12:54 | # of params = 86195205
[37m[36mINFO[0m[0m 03/07 22:15:11 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/07 22:15:11 | 0.184629    0.144876    0.358520    0.353511    1.390652    0.184629    0.144876    0.473882    0.459510    0.335110    0.352134    0.266568    0.248889    0           0.000000    1.674204    1.520614    135.379561 
[37m[36mINFO[0m[0m 03/07 22:19:12 | 0.717314    0.717314    0.628377    0.619548    0.899800    0.717314    0.717314    0.636235    0.627119    0.656893    0.646341    0.592003    0.585185    200         1.317647    1.046773    0.504185    140.312567 
[37m[36mINFO[0m[0m 03/07 22:23:07 | 0.795936    0.812721    0.727883    0.742346    0.698926    0.795936    0.812721    0.706353    0.751412    0.749048    0.739329    0.728249    0.736296    400         2.635294    0.797097    0.489710    136.991629 
[37m[36mINFO[0m[0m 03/07 22:27:06 | 0.876325    0.858657    0.745466    0.731206    0.710985    0.876325    0.858657    0.744471    0.741996    0.742574    0.728659    0.749352    0.722963    600         3.952941    0.706006    0.504604    137.944175 
[37m[36mINFO[0m[0m 03/07 22:31:01 | 0.859541    0.858657    0.749834    0.736870    0.697461    0.859541    0.858657    0.728000    0.758945    0.754379    0.730183    0.767123    0.721481    800         5.270588    0.673040    0.485301    138.200966 
[37m[36mINFO[0m[0m 03/07 22:35:03 | 0.833039    0.837456    0.771853    0.721754    0.729878    0.833039    0.837456    0.736471    0.700565    0.788271    0.719512    0.790818    0.745185    1000        6.588235    0.606360    0.502156    141.453906 
[37m[36mINFO[0m[0m 03/07 22:39:02 | 0.825088    0.826855    0.780731    0.730650    0.706148    0.825088    0.826855    0.766118    0.740113    0.786367    0.736280    0.789708    0.715556    1200        7.905882    0.566511    0.476154    143.232188 
[37m[36mINFO[0m[0m 03/07 22:43:00 | 0.944346    0.936396    0.830186    0.761101    0.636241    0.944346    0.936396    0.787294    0.747646    0.846915    0.766768    0.856350    0.768889    1400        9.223529    0.535778    0.514601    134.869644 
[37m[36mINFO[0m[0m 03/07 22:46:57 | 0.869258    0.869258    0.815831    0.744829    0.686897    0.869258    0.869258    0.802353    0.751412    0.820259    0.740854    0.824880    0.742222    1600        10.541176   0.521240    0.491558    138.943198 
[37m[36mINFO[0m[0m 03/07 22:50:52 | 0.801237    0.819788    0.822407    0.728110    0.712825    0.801237    0.819788    0.810353    0.732580    0.842727    0.733232    0.814143    0.718519    1800        11.858824   0.491770    0.482181    139.131691 
[37m[36mINFO[0m[0m 03/07 22:54:50 | 0.903710    0.893993    0.843810    0.746979    0.685327    0.903710    0.893993    0.834353    0.749529    0.837395    0.721037    0.859682    0.770370    2000        13.176471   0.464706    0.490828    139.817885 
[37m[36mINFO[0m[0m 03/07 22:58:44 | 0.865724    0.851590    0.865841    0.755517    0.666977    0.865724    0.851590    0.850824    0.736347    0.877761    0.783537    0.868937    0.746667    2200        14.494118   0.408905    0.489774    135.591305 
[37m[36mINFO[0m[0m 03/07 23:02:46 | 0.897527    0.893993    0.863174    0.728110    0.770490    0.897527    0.893993    0.839059    0.732580    0.866717    0.733232    0.883747    0.718519    2400        15.811765   0.408889    0.505514    141.107364 
[37m[36mINFO[0m[0m 03/07 23:06:50 | 0.810071    0.795053    0.853595    0.734935    0.783882    0.810071    0.795053    0.826824    0.715631    0.872430    0.746951    0.861533    0.742222    2600        17.129412   0.405667    0.524445    138.718729 
[37m[36mINFO[0m[0m 03/07 23:10:48 | 0.899293    0.890459    0.882135    0.727513    0.804674    0.899293    0.890459    0.856941    0.715631    0.897944    0.745427    0.891522    0.721481    2800        18.447059   0.339699    0.516584    134.889928 
[37m[36mINFO[0m[0m 03/07 23:14:44 | 0.891343    0.876325    0.869538    0.731289    0.814023    0.891343    0.876325    0.843765    0.738230    0.878142    0.713415    0.886709    0.742222    3000        19.764706   0.344104    0.496998    136.303753 
[37m[36mINFO[0m[0m 03/07 23:18:51 | 0.901060    0.858657    0.856352    0.717962    0.883049    0.901060    0.858657    0.801412    0.666667    0.885377    0.730183    0.882266    0.757037    3200        21.082353   0.306422    0.532020    141.238858 
[37m[36mINFO[0m[0m 03/07 23:22:54 | 0.845406    0.830389    0.895071    0.722235    0.895117    0.845406    0.830389    0.889412    0.711864    0.899467    0.737805    0.896335    0.717037    3400        22.400000   0.281423    0.514276    140.065799 
[37m[36mINFO[0m[0m 03/07 23:26:52 | 0.894876    0.883392    0.911232    0.733956    0.825788    0.894876    0.883392    0.900235    0.753296    0.908987    0.725610    0.924472    0.722963    3600        23.717647   0.265382    0.500419    137.289190 
[37m[36mINFO[0m[0m 03/07 23:30:49 | 0.893110    0.869258    0.906237    0.746742    0.862687    0.893110    0.869258    0.899765    0.749529    0.906321    0.748476    0.912625    0.742222    3800        25.035294   0.242708    0.495365    138.235197 
[37m[36mINFO[0m[0m 03/07 23:35:00 | 0.894876    0.862191    0.908614    0.713145    0.934073    0.894876    0.862191    0.896941    0.719397    0.918126    0.711890    0.910774    0.708148    4000        26.352941   0.240495    0.530959    144.566219 
[37m[36mINFO[0m[0m 03/07 23:39:04 | 0.894876    0.869258    0.935754    0.728535    0.949424    0.894876    0.869258    0.925176    0.717514    0.940213    0.734756    0.941873    0.733333    4200        27.670588   0.217923    0.516601    141.341703 
[37m[36mINFO[0m[0m 03/07 23:43:08 | 0.907244    0.890459    0.949365    0.727188    0.983129    0.907244    0.890459    0.943529    0.711864    0.949733    0.739329    0.954832    0.730370    4400        28.988235   0.193315    0.511268    140.961432 
[37m[36mINFO[0m[0m 03/07 23:47:09 | 0.818905    0.809187    0.925728    0.722602    0.926625    0.818905    0.809187    0.924706    0.704331    0.927266    0.728659    0.925213    0.734815    4600        30.305882   0.195442    0.513991    138.539323 
[37m[36mINFO[0m[0m 03/07 23:51:11 | 0.862191    0.816254    0.943944    0.728412    0.962027    0.862191    0.816254    0.940235    0.738230    0.949353    0.722561    0.942244    0.724444    4800        31.623529   0.187510    0.503265    141.384342 
[37m[36mINFO[0m[0m 03/07 23:55:16 | 0.795053    0.773852    0.902802    0.715182    1.117557    0.795053    0.773852    0.906353    0.728814    0.897944    0.699695    0.904110    0.717037    5000        32.941176   0.171393    0.524808    139.734659 
[37m[36mINFO[0m[0m 03/07 23:55:16 | Cumulative gradient change saved at train_output/VLCS/ERM/[0]/250307_22-12-52_clip_vitb16_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/07 23:55:21 | ---
[37m[36mINFO[0m[0m 03/07 23:55:21 | test-domain validation(oracle) = 94.435%
[37m[36mINFO[0m[0m 03/07 23:55:21 | training-domain validation(iid) = 94.435%
[37m[36mINFO[0m[0m 03/07 23:55:21 | last = 79.505%
[37m[36mINFO[0m[0m 03/07 23:55:21 | last (inD) = 71.518%
[37m[36mINFO[0m[0m 03/07 23:55:21 | training-domain validation (iid, inD) = 76.110%
[37m[36mINFO[0m[0m 03/07 23:55:21 | === Summary ===
[37m[36mINFO[0m[0m 03/07 23:55:21 | Command: /jsm0707/GENIE/train_all.py clip_vitb16_GENIE config/clip_vitb16_GENIE.yaml --algorithm ERM --test_envs 0 --dataset VLCS --trial_seed 0 --hparams_seed 15
[37m[36mINFO[0m[0m 03/07 23:55:21 | Unique name: 250307_22-12-52_clip_vitb16_GENIE
[37m[36mINFO[0m[0m 03/07 23:55:21 | Out path: train_output/VLCS/ERM/[0]/250307_22-12-52_clip_vitb16_GENIE
[37m[36mINFO[0m[0m 03/07 23:55:21 | Algorithm: ERM
[37m[36mINFO[0m[0m 03/07 23:55:21 | Dataset: VLCS
