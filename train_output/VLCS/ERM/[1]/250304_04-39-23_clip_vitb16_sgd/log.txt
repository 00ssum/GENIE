[37m[36mINFO[0m[0m 03/04 04:39:23 | Command :: /jsm0707/GENIE/train_all.py clip_vitb16_sgd config/clip_vitb16_sgd.yaml --algorithm ERM --test_envs 1 --dataset VLCS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: ERM
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/clip_vitb16_sgd.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: clip_vitb16_sgd
	out_dir: train_output/VLCS/ERM/[1]/250304_04-39-23_clip_vitb16_sgd
	out_root: train_output/VLCS/ERM/[1]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [1]
	trial_seed: 0
	unique_name: 250304_04-39-23_clip_vitb16_sgd
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: sgd
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: clip_vit-b16
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 03/04 04:39:23 | n_steps = 5001
[37m[36mINFO[0m[0m 03/04 04:39:23 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/04 04:39:23 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/04 04:39:23 | 
[37m[36mINFO[0m[0m 03/04 04:39:23 | Testenv name escaping te_L -> te_L
[37m[36mINFO[0m[0m 03/04 04:39:23 | Test envs = [1], name = te_L
[37m[36mINFO[0m[0m 03/04 04:39:23 | Train environments: [0, 2, 3], Test environments: [1]
[37m[36mINFO[0m[0m 03/04 04:39:23 | Batch sizes for each domain: [32, 0, 32, 32] (total=96)
[37m[36mINFO[0m[0m 03/04 04:39:23 | steps-per-epoch for each domain: 35.38, 82.06, 84.41 -> min = 35.38
[37m[36mINFO[0m[0m 03/04 04:39:26 | # of params = 86195205
[37m[36mINFO[0m[0m 03/04 04:41:37 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/04 04:41:37 | 0.158588    0.156309    0.210206    0.200213    1.679053    0.096290    0.074205    0.158588    0.156309    0.362909    0.333841    0.171418    0.192593    0           0.000000    1.706224    1.337375    129.638300 
[37m[36mINFO[0m[0m 03/04 04:45:10 | 0.442353    0.487759    0.505720    0.524302    1.260385    0.632509    0.653710    0.442353    0.487759    0.419269    0.445122    0.465383    0.474074    200         5.653710    1.411955    0.412588    130.658857 
[37m[36mINFO[0m[0m 03/04 04:48:40 | 0.469647    0.468927    0.579993    0.606769    1.087824    0.764134    0.780919    0.469647    0.468927    0.476771    0.504573    0.499074    0.534815    400         11.307420   1.150476    0.410713    128.028117 
[37m[36mINFO[0m[0m 03/04 04:52:10 | 0.542118    0.540490    0.729202    0.720551    0.953751    0.891343    0.869258    0.542118    0.540490    0.669459    0.650915    0.626805    0.641481    600         16.961131   0.996186    0.409964    128.064964 
[37m[36mINFO[0m[0m 03/04 04:55:41 | 0.597176    0.587571    0.822479    0.791128    0.822313    0.953180    0.915194    0.597176    0.587571    0.786748    0.751524    0.727508    0.706667    800         22.614841   0.853950    0.405738    129.305726 
[37m[36mINFO[0m[0m 03/04 04:59:10 | 0.612706    0.604520    0.868483    0.855870    0.698630    0.991166    0.989399    0.612706    0.604520    0.815689    0.804878    0.798593    0.773333    1000        28.268551   0.729380    0.404173    128.059112 
[37m[36mINFO[0m[0m 03/04 05:02:40 | 0.612706    0.610169    0.887263    0.877510    0.592973    0.996466    0.992933    0.612706    0.610169    0.827113    0.827744    0.838208    0.811852    1200        33.922261   0.612417    0.411121    127.585595 
[37m[36mINFO[0m[0m 03/04 05:06:10 | 0.635765    0.638418    0.897677    0.889519    0.509616    0.997350    0.992933    0.635765    0.638418    0.840442    0.844512    0.855239    0.831111    1400        39.575972   0.517801    0.409091    128.566489 
[37m[36mINFO[0m[0m 03/04 05:09:40 | 0.641412    0.634652    0.906846    0.900151    0.453084    0.998233    0.996466    0.641412    0.634652    0.852628    0.852134    0.869678    0.851852    1600        45.229682   0.449390    0.410233    128.462007 
[37m[36mINFO[0m[0m 03/04 05:13:11 | 0.646588    0.640301    0.909080    0.902126    0.409714    0.999117    0.996466    0.646588    0.640301    0.848819    0.852134    0.879304    0.857778    1800        50.883392   0.398392    0.410147    128.734232 
[37m[36mINFO[0m[0m 03/04 05:16:39 | 0.655059    0.655367    0.914387    0.904087    0.376127    0.997350    0.996466    0.655059    0.655367    0.859101    0.850610    0.886709    0.865185    2000        56.537102   0.361093    0.407418    126.226353 
[37m[36mINFO[0m[0m 03/04 05:20:09 | 0.651765    0.644068    0.923642    0.907630    0.354504    0.999117    0.996466    0.651765    0.644068    0.875476    0.859756    0.896335    0.866667    2200        62.190813   0.334386    0.407120    128.722337 
[37m[36mINFO[0m[0m 03/04 05:23:38 | 0.651294    0.649718    0.925159    0.912815    0.333616    0.999117    1.000000    0.651294    0.649718    0.879284    0.865854    0.897075    0.872593    2400        67.844523   0.307736    0.407325    127.560616 
[37m[36mINFO[0m[0m 03/04 05:27:07 | 0.652235    0.640301    0.926846    0.907255    0.321231    0.998233    1.000000    0.652235    0.640301    0.880046    0.852134    0.902258    0.869630    2600        73.498233   0.290151    0.408986    127.504603 
[37m[36mINFO[0m[0m 03/04 05:30:37 | 0.660706    0.651601    0.930377    0.912279    0.302422    0.999117    1.000000    0.660706    0.651601    0.883092    0.861280    0.908923    0.875556    2800        79.151943   0.276473    0.410557    127.180316 
[37m[36mINFO[0m[0m 03/04 05:34:07 | 0.660706    0.645951    0.934672    0.914240    0.291196    0.999117    1.000000    0.660706    0.645951    0.893755    0.859756    0.911144    0.882963    3000        84.805654   0.257685    0.412428    127.404385 
[37m[36mINFO[0m[0m 03/04 05:37:38 | 0.659765    0.649718    0.934129    0.914225    0.283017    0.999117    1.000000    0.659765    0.649718    0.888423    0.858232    0.914846    0.884444    3200        90.459364   0.240663    0.412781    128.761044 
[37m[36mINFO[0m[0m 03/04 05:41:09 | 0.623059    0.647834    0.805312    0.793234    0.686655    0.898410    0.897527    0.623059    0.647834    0.731150    0.708841    0.786375    0.773333    3400        96.113074   0.228814    0.416760    127.406485 
[37m[36mINFO[0m[0m 03/04 05:44:43 | 0.482353    0.512241    0.538195    0.540875    1.350504    0.670495    0.681979    0.482353    0.512241    0.426504    0.417683    0.517586    0.522963    3600        101.766784  0.216424    0.415031    130.980185 
[37m[36mINFO[0m[0m 03/04 05:48:12 | 0.657882    0.651601    0.945308    0.918290    0.261863    1.000000    1.000000    0.657882    0.651601    0.904417    0.870427    0.931507    0.884444    3800        107.420495  0.240993    0.407803    128.059595 
[37m[36mINFO[0m[0m 03/04 05:51:42 | 0.660235    0.655367    0.946958    0.921733    0.256938    1.000000    1.000000    0.660235    0.655367    0.909368    0.868902    0.931507    0.896296    4000        113.074205  0.215309    0.416338    126.757351 
[37m[36mINFO[0m[0m 03/04 05:55:13 | 0.663059    0.661017    0.945680    0.926249    0.247883    0.999117    1.000000    0.663059    0.661017    0.909749    0.876524    0.928175    0.902222    4200        118.727915  0.196430    0.414960    127.650337 
[37m[36mINFO[0m[0m 03/04 05:58:42 | 0.666824    0.664783    0.946900    0.923708    0.245158    0.999117    1.000000    0.666824    0.664783    0.908225    0.868902    0.933358    0.902222    4400        124.381625  0.191439    0.411244    126.362342 
[37m[36mINFO[0m[0m 03/04 06:02:11 | 0.661176    0.662900    0.952647    0.925698    0.243062    0.999117    1.000000    0.661176    0.662900    0.915842    0.870427    0.942984    0.906667    4600        130.035336  0.199868    0.411822    126.608463 
[37m[36mINFO[0m[0m 03/04 06:05:40 | 0.666353    0.668550    0.950974    0.926206    0.237405    0.998233    1.000000    0.666353    0.668550    0.913557    0.871951    0.941133    0.906667    4800        135.689046  0.183061    0.409834    127.741667 
[37m[36mINFO[0m[0m 03/04 06:09:10 | 0.654118    0.651601    0.951098    0.926671    0.242107    0.998233    1.000000    0.654118    0.651601    0.913557    0.868902    0.941503    0.911111    5000        141.342756  0.180849    0.411190    127.782380 
[37m[36mINFO[0m[0m 03/04 06:09:11 | Cumulative gradient change saved at train_output/VLCS/ERM/[1]/250304_04-39-23_clip_vitb16_sgd/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/04 06:09:14 | ---
[37m[36mINFO[0m[0m 03/04 06:09:14 | test-domain validation(oracle) = 66.635%
[37m[36mINFO[0m[0m 03/04 06:09:14 | training-domain validation(iid) = 65.412%
[37m[36mINFO[0m[0m 03/04 06:09:14 | last = 65.412%
[37m[36mINFO[0m[0m 03/04 06:09:14 | last (inD) = 92.667%
[37m[36mINFO[0m[0m 03/04 06:09:14 | training-domain validation (iid, inD) = 92.667%
[37m[36mINFO[0m[0m 03/04 06:09:14 | === Summary ===
[37m[36mINFO[0m[0m 03/04 06:09:14 | Command: /jsm0707/GENIE/train_all.py clip_vitb16_sgd config/clip_vitb16_sgd.yaml --algorithm ERM --test_envs 1 --dataset VLCS
[37m[36mINFO[0m[0m 03/04 06:09:14 | Unique name: 250304_04-39-23_clip_vitb16_sgd
[37m[36mINFO[0m[0m 03/04 06:09:14 | Out path: train_output/VLCS/ERM/[1]/250304_04-39-23_clip_vitb16_sgd
[37m[36mINFO[0m[0m 03/04 06:09:14 | Algorithm: ERM
[37m[36mINFO[0m[0m 03/04 06:09:14 | Dataset: VLCS
