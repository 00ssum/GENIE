[37m[36mINFO[0m[0m 02/26 21:02:35 | Command :: /jsm0707/GENIE/train_all.py clip_vitb16_adam config/clip_vitb16_adam.yaml --algorithm ERM --test_envs 1 --dataset VLCS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: ERM
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/clip_vitb16_adam.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: clip_vitb16_adam
	out_dir: train_output/VLCS/ERM/[1]/250226_21-02-35_clip_vitb16_adam
	out_root: train_output/VLCS/ERM/[1]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [1]
	trial_seed: 0
	unique_name: 250226_21-02-35_clip_vitb16_adam
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: adam
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: clip_vit-b16
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 02/26 21:02:35 | n_steps = 5001
[37m[36mINFO[0m[0m 02/26 21:02:35 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/26 21:02:35 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/26 21:02:35 | 
[37m[36mINFO[0m[0m 02/26 21:02:35 | Testenv name escaping te_L -> te_L
[37m[36mINFO[0m[0m 02/26 21:02:35 | Test envs = [1], name = te_L
[37m[36mINFO[0m[0m 02/26 21:02:35 | Train environments: [0, 2, 3], Test environments: [1]
[37m[36mINFO[0m[0m 02/26 21:02:35 | Batch sizes for each domain: [32, 0, 32, 32] (total=96)
[37m[36mINFO[0m[0m 02/26 21:02:35 | steps-per-epoch for each domain: 35.38, 82.06, 84.41 -> min = 35.38
[37m[36mINFO[0m[0m 02/26 21:02:38 | # of params = 86195205
[37m[36mINFO[0m[0m 02/26 21:05:30 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 02/26 21:05:30 | 0.460706    0.491525    0.483220    0.495946    1.186804    0.611307    0.628975    0.460706    0.491525    0.391851    0.407012    0.446501    0.451852    0           0.000000    1.706224    1.103502    171.011479 
[37m[36mINFO[0m[0m 02/26 21:09:30 | 0.670118    0.698682    0.925601    0.892572    0.327733    0.998233    0.996466    0.670118    0.698682    0.878903    0.833841    0.899667    0.847407    200         5.653710    0.299327    0.408008    158.425396 
[37m[36mINFO[0m[0m 02/26 21:13:22 | 0.621176    0.602637    0.943670    0.885178    0.341807    0.995583    0.989399    0.621176    0.602637    0.913176    0.823171    0.922251    0.842963    400         11.307420   0.180972    0.407888    150.567437 
[37m[36mINFO[0m[0m 02/26 21:17:13 | 0.654118    0.655367    0.964694    0.893601    0.352960    0.992933    0.989399    0.654118    0.655367    0.946687    0.826220    0.954461    0.865185    600         16.961131   0.138849    0.409050    148.774628 
[37m[36mINFO[0m[0m 02/26 21:21:02 | 0.616471    0.621469    0.969650    0.880168    0.384613    0.995583    0.989399    0.616471    0.621469    0.960015    0.815549    0.953351    0.835556    800         22.614841   0.116937    0.430408    143.656479 
[37m[36mINFO[0m[0m 02/26 21:25:00 | 0.628235    0.627119    0.960565    0.872494    0.442401    0.998233    1.000000    0.628235    0.627119    0.936405    0.778963    0.947057    0.838519    1000        28.268551   0.096878    0.428876    151.391390 
[37m[36mINFO[0m[0m 02/26 21:28:54 | 0.628235    0.634652    0.973304    0.865124    0.467860    0.996466    0.989399    0.628235    0.634652    0.963062    0.791159    0.960385    0.814815    1200        33.922261   0.093993    0.416257    151.228668 
[37m[36mINFO[0m[0m 02/26 21:33:00 | 0.617412    0.612053    0.973021    0.869920    0.476905    0.999117    0.996466    0.617412    0.612053    0.956969    0.788110    0.962977    0.825185    1400        39.575972   0.074453    0.410419    163.712114 
[37m[36mINFO[0m[0m 02/26 21:37:07 | 0.614588    0.602637    0.987236    0.876151    0.476209    1.000000    1.000000    0.614588    0.602637    0.980960    0.800305    0.980748    0.828148    1600        45.229682   0.059864    0.426041    162.036208 
[37m[36mINFO[0m[0m 02/26 21:41:01 | 0.603765    0.596987    0.969930    0.858638    0.585754    1.000000    1.000000    0.603765    0.596987    0.951257    0.775915    0.958534    0.800000    1800        50.883392   0.059926    0.409931    152.263962 
[37m[36mINFO[0m[0m 02/26 21:45:06 | 0.636706    0.645951    0.973200    0.863382    0.551938    0.988516    0.992933    0.636706    0.645951    0.958111    0.795732    0.972973    0.801481    2000        56.537102   0.056593    0.406734    162.835854 
[37m[36mINFO[0m[0m 02/26 21:49:05 | 0.591529    0.583804    0.980425    0.860015    0.590589    0.999117    0.996466    0.591529    0.583804    0.970297    0.785061    0.971862    0.798519    2200        62.190813   0.049200    0.405987    158.234969 
[37m[36mINFO[0m[0m 02/26 21:53:02 | 0.595765    0.606403    0.983054    0.862632    0.575252    1.000000    1.000000    0.595765    0.606403    0.969155    0.780488    0.980007    0.807407    2400        67.844523   0.052134    0.406191    156.042390 
[37m[36mINFO[0m[0m 02/26 21:57:07 | 0.643765    0.649718    0.993611    0.869935    0.550731    1.000000    0.996466    0.643765    0.649718    0.989718    0.789634    0.991114    0.823704    2600        73.498233   0.037903    0.407794    163.519316 
[37m[36mINFO[0m[0m 02/26 22:01:02 | 0.624000    0.644068    0.981973    0.865695    0.570229    0.999117    1.000000    0.624000    0.644068    0.977532    0.791159    0.969271    0.805926    2800        79.151943   0.047432    0.406322    153.099418 
[37m[36mINFO[0m[0m 02/26 22:05:10 | 0.640941    0.657250    0.987740    0.875002    0.555459    1.000000    0.996466    0.640941    0.657250    0.982102    0.803354    0.981118    0.825185    3000        84.805654   0.049290    0.421168    164.545944 
[37m[36mINFO[0m[0m 02/26 22:09:09 | 0.616000    0.629002    0.993262    0.864707    0.571094    1.000000    1.000000    0.616000    0.629002    0.992003    0.791159    0.987782    0.802963    3200        90.459364   0.040129    0.404380    158.087477 
[37m[36mINFO[0m[0m 02/26 22:13:16 | 0.631529    0.630885    0.978586    0.842065    0.661182    0.996466    0.989399    0.631529    0.630885    0.973724    0.754573    0.965568    0.782222    3400        96.113074   0.039920    0.415723    163.101990 
[37m[36mINFO[0m[0m 02/26 22:17:12 | 0.648471    0.651601    0.970623    0.841601    0.653497    0.995583    0.996466    0.648471    0.651601    0.971820    0.769817    0.944465    0.758519    3600        101.766784  0.040076    0.408068    154.342072 
[37m[36mINFO[0m[0m 02/26 22:21:00 | 0.592941    0.610169    0.988202    0.856620    0.621597    1.000000    1.000000    0.592941    0.610169    0.978675    0.771341    0.985931    0.798519    3800        107.420495  0.040802    0.405455    146.888892 
[37m[36mINFO[0m[0m 02/26 22:24:51 | 0.609412    0.610169    0.994459    0.866740    0.640623    0.999117    1.000000    0.609412    0.610169    0.993145    0.797256    0.991114    0.802963    4000        113.074205  0.042269    0.408990    149.633835 
[37m[36mINFO[0m[0m 02/26 22:28:48 | 0.627294    0.645951    0.987881    0.867642    0.654855    0.998233    1.000000    0.627294    0.645951    0.980960    0.788110    0.984450    0.814815    4200        118.727915  0.029992    0.409085    155.098924 
[37m[36mINFO[0m[0m 02/26 22:32:37 | 0.623059    0.644068    0.986569    0.860946    0.623993    1.000000    0.996466    0.623059    0.644068    0.975628    0.778963    0.984080    0.807407    4400        124.381625  0.035562    0.410430    146.646999 
[37m[36mINFO[0m[0m 02/26 22:36:27 | 0.613176    0.604520    0.985660    0.859317    0.631647    1.000000    0.992933    0.613176    0.604520    0.970678    0.783537    0.986301    0.801481    4600        130.035336  0.041814    0.409420    148.181149 
[37m[36mINFO[0m[0m 02/26 22:40:15 | 0.608941    0.623352    0.990355    0.862746    0.605474    0.999117    1.000000    0.608941    0.623352    0.989718    0.792683    0.982229    0.795556    4800        135.689046  0.034060    0.420570    144.176022 
[37m[36mINFO[0m[0m 02/26 22:44:06 | 0.609412    0.617702    0.990451    0.864199    0.620818    0.998233    1.000000    0.609412    0.617702    0.992003    0.789634    0.981118    0.802963    5000        141.342756  0.031824    0.412461    148.083146 
[37m[36mINFO[0m[0m 02/26 22:44:06 | Cumulative gradient change saved at train_output/VLCS/ERM/[1]/250226_21-02-35_clip_vitb16_adam/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/26 22:44:09 | ---
[37m[36mINFO[0m[0m 02/26 22:44:09 | test-domain validation(oracle) = 67.012%
[37m[36mINFO[0m[0m 02/26 22:44:09 | training-domain validation(iid) = 65.412%
[37m[36mINFO[0m[0m 02/26 22:44:09 | last = 60.941%
[37m[36mINFO[0m[0m 02/26 22:44:09 | last (inD) = 86.420%
[37m[36mINFO[0m[0m 02/26 22:44:09 | training-domain validation (iid, inD) = 89.360%
[37m[36mINFO[0m[0m 02/26 22:44:09 | === Summary ===
[37m[36mINFO[0m[0m 02/26 22:44:09 | Command: /jsm0707/GENIE/train_all.py clip_vitb16_adam config/clip_vitb16_adam.yaml --algorithm ERM --test_envs 1 --dataset VLCS
[37m[36mINFO[0m[0m 02/26 22:44:09 | Unique name: 250226_21-02-35_clip_vitb16_adam
[37m[36mINFO[0m[0m 02/26 22:44:09 | Out path: train_output/VLCS/ERM/[1]/250226_21-02-35_clip_vitb16_adam
[37m[36mINFO[0m[0m 02/26 22:44:09 | Algorithm: ERM
[37m[36mINFO[0m[0m 02/26 22:44:09 | Dataset: VLCS
