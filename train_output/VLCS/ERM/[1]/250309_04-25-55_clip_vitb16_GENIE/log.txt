[37m[36mINFO[0m[0m 03/09 04:25:55 | Command :: /jsm0707/GENIE/train_all.py clip_vitb16_GENIE config/clip_vitb16_GENIE.yaml --algorithm ERM --test_envs 1 --dataset VLCS --trial_seed 0 --hparams_seed 16
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: ERM
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/clip_vitb16_GENIE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 16
	in_domain: False
	model_save: None
	mpa: False
	name: clip_vitb16_GENIE
	out_dir: train_output/VLCS/ERM/[1]/250309_04-25-55_clip_vitb16_GENIE
	out_root: train_output/VLCS/ERM/[1]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [1]
	trial_seed: 0
	unique_name: 250309_04-25-55_clip_vitb16_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 4.249952708249365e-05
	batch_size: 17
	weight_decay: 9.786966598736845e-06
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: openclip_vit-b16
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 03/09 04:25:55 | n_steps = 5001
[37m[36mINFO[0m[0m 03/09 04:25:55 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/09 04:25:55 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/09 04:25:55 | 
[37m[36mINFO[0m[0m 03/09 04:25:55 | Testenv name escaping te_L -> te_L
[37m[36mINFO[0m[0m 03/09 04:25:55 | Test envs = [1], name = te_L
[37m[36mINFO[0m[0m 03/09 04:25:55 | Train environments: [0, 2, 3], Test environments: [1]
[37m[36mINFO[0m[0m 03/09 04:25:55 | Batch sizes for each domain: [17, 0, 17, 17] (total=51)
[37m[36mINFO[0m[0m 03/09 04:25:55 | steps-per-epoch for each domain: 66.59, 154.47, 158.88 -> min = 66.59
[37m[36mINFO[0m[0m 03/09 04:25:58 | # of params = 86195205
[37m[36mINFO[0m[0m 03/09 04:28:13 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/09 04:28:13 | 0.460235    0.497175    0.485690    0.498995    1.343042    0.612191    0.628975    0.460235    0.497175    0.400228    0.416159    0.444650    0.451852    0           0.000000    1.606020    3.850104    130.824402 
[37m[36mINFO[0m[0m 03/09 04:31:22 | 0.476706    0.489642    0.660216    0.662176    0.847424    0.848057    0.865724    0.476706    0.489642    0.575019    0.554878    0.557571    0.565926    200         3.003534    1.169630    0.290115    130.603028 
[37m[36mINFO[0m[0m 03/09 04:34:52 | 0.595294    0.602637    0.788061    0.779000    0.594920    0.915194    0.904594    0.595294    0.602637    0.756283    0.730183    0.692706    0.702222    400         6.007067    0.666654    0.401786    130.282214 
[37m[36mINFO[0m[0m 03/09 04:38:19 | 0.622118    0.640301    0.832649    0.815843    0.490266    0.976148    0.971731    0.622118    0.640301    0.778370    0.745427    0.743428    0.730370    600         9.010601    0.475861    0.390141    128.928957 
[37m[36mINFO[0m[0m 03/09 04:41:46 | 0.609882    0.606403    0.844127    0.818316    0.471557    0.990283    0.975265    0.609882    0.606403    0.776085    0.725610    0.766013    0.754074    800         12.014134   0.400853    0.388718    129.489895 
[37m[36mINFO[0m[0m 03/09 04:45:18 | 0.591529    0.610169    0.867846    0.846837    0.426087    0.984982    0.982332    0.591529    0.610169    0.809596    0.777439    0.808960    0.780741    1000        15.017668   0.357777    0.411427    129.432464 
[37m[36mINFO[0m[0m 03/09 04:48:48 | 0.602824    0.589454    0.901009    0.844064    0.407030    0.997350    0.978799    0.602824    0.589454    0.853770    0.765244    0.851907    0.788148    1200        18.021201   0.312269    0.404311    128.896101 
[37m[36mINFO[0m[0m 03/09 04:52:16 | 0.631529    0.632768    0.887187    0.831201    0.486988    0.997350    0.989399    0.631529    0.632768    0.827113    0.754573    0.837097    0.749630    1400        21.024735   0.265450    0.391742    129.604460 
[37m[36mINFO[0m[0m 03/09 04:55:45 | 0.657882    0.683616    0.903697    0.826883    0.470673    0.991166    0.975265    0.657882    0.683616    0.860244    0.743902    0.859682    0.761481    1600        24.028269   0.264918    0.395105    129.940705 
[37m[36mINFO[0m[0m 03/09 04:59:17 | 0.617882    0.619586    0.913256    0.826251    0.500973    0.992933    0.961131    0.617882    0.619586    0.869383    0.757622    0.877453    0.760000    1800        27.031802   0.216943    0.414886    129.088951 
[37m[36mINFO[0m[0m 03/09 05:02:44 | 0.644706    0.659134    0.939162    0.854340    0.447302    1.000000    0.996466    0.644706    0.659134    0.907083    0.759146    0.910404    0.807407    2000        30.035336   0.199992    0.389060    129.575110 
[37m[36mINFO[0m[0m 03/09 05:06:08 | 0.602824    0.600753    0.926411    0.820656    0.562523    0.984099    0.950530    0.602824    0.600753    0.902133    0.748476    0.893003    0.762963    2200        33.038869   0.195230    0.376886    128.185717 
[37m[36mINFO[0m[0m 03/09 05:09:33 | 0.618353    0.619586    0.943631    0.831837    0.486928    0.995583    0.982332    0.618353    0.619586    0.922315    0.757622    0.912995    0.755556    2400        36.042403   0.177411    0.388941    127.804474 
[37m[36mINFO[0m[0m 03/09 05:12:59 | 0.598118    0.621469    0.945461    0.834462    0.513736    0.993816    0.975265    0.598118    0.621469    0.916984    0.762195    0.925583    0.765926    2600        39.045936   0.165744    0.392398    127.370798 
[37m[36mINFO[0m[0m 03/09 05:16:27 | 0.594353    0.583804    0.957723    0.845665    0.519760    1.000000    0.989399    0.594353    0.583804    0.939071    0.769817    0.934098    0.777778    2800        42.049470   0.142779    0.399910    127.564156 
[37m[36mINFO[0m[0m 03/09 05:19:54 | 0.620706    0.647834    0.959276    0.851576    0.536435    0.997350    0.989399    0.620706    0.647834    0.948972    0.768293    0.931507    0.797037    3000        45.053004   0.110143    0.397903    127.834677 
[37m[36mINFO[0m[0m 03/09 05:23:17 | 0.634824    0.636535    0.960882    0.827377    0.566313    0.996466    0.975265    0.634824    0.636535    0.940975    0.743902    0.945205    0.762963    3200        48.056537   0.117872    0.375490    127.795295 
[37m[36mINFO[0m[0m 03/09 05:26:42 | 0.608941    0.596987    0.964380    0.827490    0.549580    0.998233    0.968198    0.608941    0.596987    0.948591    0.743902    0.946316    0.770370    3400        51.060071   0.109081    0.381310    128.683431 
[37m[36mINFO[0m[0m 03/09 05:30:08 | 0.609882    0.598870    0.966517    0.836809    0.611369    1.000000    0.992933    0.609882    0.598870    0.955826    0.753049    0.943725    0.764444    3600        54.063604   0.089920    0.382290    129.247879 
[37m[36mINFO[0m[0m 03/09 05:33:33 | 0.609882    0.593220    0.974449    0.830398    0.618083    0.999117    0.982332    0.609882    0.593220    0.964585    0.762195    0.959645    0.746667    3800        57.067138   0.080943    0.379702    129.317559 
[37m[36mINFO[0m[0m 03/09 05:36:56 | 0.609412    0.625235    0.967492    0.829006    0.587354    0.993816    0.978799    0.609412    0.625235    0.950495    0.739329    0.958164    0.768889    4000        60.070671   0.081478    0.375423    127.980259 
[37m[36mINFO[0m[0m 03/09 05:40:21 | 0.615529    0.613936    0.982363    0.843067    0.593742    1.000000    0.989399    0.615529    0.613936    0.974486    0.756098    0.972603    0.783704    4200        63.074205   0.061969    0.381460    128.146237 
[37m[36mINFO[0m[0m 03/09 05:43:48 | 0.630588    0.634652    0.974375    0.824823    0.685121    0.997350    0.982332    0.630588    0.634652    0.966870    0.746951    0.958904    0.745185    4400        66.077739   0.071171    0.393045    128.754309 
[37m[36mINFO[0m[0m 03/09 05:47:16 | 0.536000    0.542373    0.965484    0.821646    0.716976    1.000000    0.989399    0.536000    0.542373    0.937548    0.736280    0.958904    0.739259    4600        69.081272   0.068312    0.392879    129.057181 
[37m[36mINFO[0m[0m 03/09 05:50:45 | 0.582118    0.585687    0.981728    0.832895    0.641406    1.000000    0.975265    0.582118    0.585687    0.972582    0.753049    0.972603    0.770370    4800        72.084806   0.066012    0.398995    129.084417 
[37m[36mINFO[0m[0m 03/09 05:54:12 | 0.586353    0.585687    0.982835    0.849644    0.607130    1.000000    0.989399    0.586353    0.585687    0.972201    0.772866    0.976305    0.786667    5000        75.088339   0.067708    0.396428    128.675036 
[37m[36mINFO[0m[0m 03/09 05:54:13 | Cumulative gradient change saved at train_output/VLCS/ERM/[1]/250309_04-25-55_clip_vitb16_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/09 05:55:09 | ---
[37m[36mINFO[0m[0m 03/09 05:55:09 | test-domain validation(oracle) = 65.788%
[37m[36mINFO[0m[0m 03/09 05:55:09 | training-domain validation(iid) = 64.471%
[37m[36mINFO[0m[0m 03/09 05:55:09 | last = 58.635%
[37m[36mINFO[0m[0m 03/09 05:55:09 | last (inD) = 84.964%
[37m[36mINFO[0m[0m 03/09 05:55:09 | training-domain validation (iid, inD) = 85.434%
[37m[36mINFO[0m[0m 03/09 05:55:09 | === Summary ===
[37m[36mINFO[0m[0m 03/09 05:55:09 | Command: /jsm0707/GENIE/train_all.py clip_vitb16_GENIE config/clip_vitb16_GENIE.yaml --algorithm ERM --test_envs 1 --dataset VLCS --trial_seed 0 --hparams_seed 16
[37m[36mINFO[0m[0m 03/09 05:55:09 | Unique name: 250309_04-25-55_clip_vitb16_GENIE
[37m[36mINFO[0m[0m 03/09 05:55:09 | Out path: train_output/VLCS/ERM/[1]/250309_04-25-55_clip_vitb16_GENIE
[37m[36mINFO[0m[0m 03/09 05:55:09 | Algorithm: ERM
[37m[36mINFO[0m[0m 03/09 05:55:09 | Dataset: VLCS
