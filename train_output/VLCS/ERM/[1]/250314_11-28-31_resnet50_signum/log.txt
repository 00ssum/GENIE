[37m[36mINFO[0m[0m 03/14 11:28:31 | Command :: /jsm0707/GENIE/train_all.py resnet50_signum config/resnet50_signum.yaml --algorithm ERM --test_envs 1 --dataset VLCS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: ERM
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_signum.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_signum
	out_dir: train_output/VLCS/ERM/[1]/250314_11-28-31_resnet50_signum
	out_root: train_output/VLCS/ERM/[1]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [1]
	trial_seed: 0
	unique_name: 250314_11-28-31_resnet50_signum
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: signum
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 03/14 11:28:31 | n_steps = 5001
[37m[36mINFO[0m[0m 03/14 11:28:31 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/14 11:28:31 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/14 11:28:31 | 
[37m[36mINFO[0m[0m 03/14 11:28:31 | Testenv name escaping te_L -> te_L
[37m[36mINFO[0m[0m 03/14 11:28:31 | Test envs = [1], name = te_L
[37m[36mINFO[0m[0m 03/14 11:28:31 | Train environments: [0, 2, 3], Test environments: [1]
[37m[36mINFO[0m[0m 03/14 11:28:31 | Batch sizes for each domain: [32, 0, 32, 32] (total=96)
[37m[36mINFO[0m[0m 03/14 11:28:31 | steps-per-epoch for each domain: 35.38, 82.06, 84.41 -> min = 35.38
[37m[36mINFO[0m[0m 03/14 11:28:32 | # of params = 23518277
[37m[36mINFO[0m[0m 03/14 11:30:44 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/14 11:30:44 | 0.448471    0.461394    0.528018    0.529603    1.387601    0.621908    0.597173    0.448471    0.461394    0.463442    0.492378    0.498704    0.499259    0           0.000000    1.800293    1.130607    131.145366 
[37m[36mINFO[0m[0m 03/14 11:33:43 | 0.652235    0.666667    0.869569    0.851225    0.507527    0.987633    0.982332    0.652235    0.666667    0.793602    0.771341    0.827471    0.800000    200         5.653710    0.426446    0.241964    129.849945 
[37m[36mINFO[0m[0m 03/14 11:36:42 | 0.664000    0.677966    0.852387    0.834448    0.474517    0.956714    0.975265    0.664000    0.677966    0.797411    0.760671    0.803036    0.767407    400         11.307420   0.381383    0.234374    132.691876 
[37m[36mINFO[0m[0m 03/14 11:39:42 | 0.662118    0.676083    0.878072    0.855932    0.537404    0.993816    0.992933    0.662118    0.676083    0.822925    0.791159    0.817475    0.783704    600         16.961131   0.811310    0.234346    133.254797 
[37m[36mINFO[0m[0m 03/14 11:42:44 | 0.486588    0.499058    0.710769    0.697735    0.795943    0.952297    0.961131    0.486588    0.499058    0.602818    0.586890    0.577194    0.545185    800         22.614841   0.885730    0.260826    129.610280 
[37m[36mINFO[0m[0m 03/14 11:45:46 | 0.637647    0.645951    0.651849    0.650842    1.405088    0.810071    0.812721    0.637647    0.645951    0.532369    0.545732    0.613106    0.594074    1000        28.268551   1.274715    0.261476    129.707376 
[37m[36mINFO[0m[0m 03/14 11:48:49 | 0.209412    0.241055    0.537741    0.525900    1.626634    0.758834    0.734982    0.209412    0.241055    0.462681    0.464939    0.391707    0.377778    1200        33.922261   1.473504    0.255218    131.311358 
[37m[36mINFO[0m[0m 03/14 11:51:47 | 0.466353    0.478343    0.588586    0.574742    1.083939    0.736749    0.738516    0.466353    0.478343    0.604722    0.597561    0.424287    0.388148    1400        39.575972   1.729536    0.237452    131.420017 
[37m[36mINFO[0m[0m 03/14 11:54:50 | 0.357647    0.378531    0.577451    0.562740    1.226900    0.734982    0.713781    0.357647    0.378531    0.545316    0.565549    0.452055    0.408889    1600        45.229682   1.578727    0.252147    131.905712 
[37m[36mINFO[0m[0m 03/14 11:57:50 | 0.413176    0.416196    0.300211    0.308800    1.412365    0.436396    0.455830    0.413176    0.416196    0.225438    0.243902    0.238800    0.226667    1800        50.883392   1.454588    0.239424    132.599849 
[37m[36mINFO[0m[0m 03/14 12:00:53 | 0.457882    0.435028    0.365032    0.374014    2.738854    0.596290    0.621908    0.457882    0.435028    0.283701    0.294207    0.215106    0.205926    2000        56.537102   1.470827    0.267325    129.385073 
[37m[36mINFO[0m[0m 03/14 12:03:57 | 0.293647    0.265537    0.351464    0.352280    1.399341    0.406360    0.409894    0.293647    0.265537    0.444402    0.457317    0.203628    0.189630    2200        62.190813   1.411832    0.263696    130.618790 
[37m[36mINFO[0m[0m 03/14 12:06:58 | 0.553412    0.574388    0.527035    0.557497    1.304984    0.704947    0.777385    0.553412    0.574388    0.406702    0.431402    0.469456    0.463704    2400        67.844523   1.410553    0.255707    130.585312 
[37m[36mINFO[0m[0m 03/14 12:10:00 | 0.406588    0.384181    0.405817    0.398743    1.897586    0.473498    0.459364    0.406588    0.384181    0.485529    0.493902    0.258423    0.242963    2600        73.498233   1.414292    0.242536    132.804242 
[37m[36mINFO[0m[0m 03/14 12:12:56 | 0.453176    0.419962    0.484592    0.479327    1.287277    0.668728    0.646643    0.453176    0.419962    0.472201    0.481707    0.312847    0.309630    2800        79.151943   1.392068    0.237639    129.054995 
[37m[36mINFO[0m[0m 03/14 12:15:55 | 0.162353    0.199623    0.433109    0.425801    1.365955    0.592756    0.579505    0.162353    0.199623    0.432597    0.425305    0.273973    0.272593    3000        84.805654   1.397839    0.241518    130.670856 
[37m[36mINFO[0m[0m 03/14 12:18:58 | 0.552000    0.578154    0.558736    0.548631    6.558106    0.785336    0.759717    0.552000    0.578154    0.416603    0.429878    0.474269    0.456296    3200        90.459364   1.415073    0.256919    131.299231 
[37m[36mINFO[0m[0m 03/14 12:22:00 | 0.300235    0.288136    0.503323    0.492456    1.410581    0.834806    0.809187    0.300235    0.288136    0.421554    0.422256    0.253610    0.245926    3400        96.113074   1.396439    0.259630    130.575560 
[37m[36mINFO[0m[0m 03/14 12:25:00 | 0.430588    0.410546    0.501217    0.489937    1.138342    0.697880    0.674912    0.430588    0.410546    0.498477    0.503049    0.307294    0.291852    3600        101.766784  1.419847    0.251836    129.562169 
[37m[36mINFO[0m[0m 03/14 12:27:58 | 0.413176    0.380414    0.521944    0.524244    1.070940    0.800353    0.812721    0.413176    0.380414    0.460777    0.474085    0.304702    0.285926    3800        107.420495  1.398499    0.230735    131.290434 
[37m[36mINFO[0m[0m 03/14 12:30:57 | 0.493647    0.478343    0.502392    0.498141    1.176920    0.793286    0.773852    0.493647    0.478343    0.376238    0.388720    0.337653    0.331852    4000        113.074205  1.492409    0.237019    131.607473 
[37m[36mINFO[0m[0m 03/14 12:33:55 | 0.195765    0.220339    0.502137    0.480260    1.331495    0.666961    0.643110    0.195765    0.220339    0.471439    0.443598    0.368012    0.354074    4200        118.727915  1.423850    0.243477    129.190234 
[37m[36mINFO[0m[0m 03/14 12:36:59 | 0.395765    0.391714    0.500227    0.520622    1.366647    0.831272    0.823322    0.395765    0.391714    0.307692    0.342988    0.361718    0.395556    4400        124.381625  1.516029    0.264158    131.898271 
[37m[36mINFO[0m[0m 03/14 12:39:58 | 0.569412    0.583804    0.570807    0.570410    1.352251    0.701413    0.699647    0.569412    0.583804    0.503046    0.516768    0.507960    0.494815    4600        130.035336  1.443743    0.233147    132.283539 
[37m[36mINFO[0m[0m 03/14 12:42:54 | 0.552471    0.548023    0.555709    0.560892    1.187787    0.796820    0.773852    0.552471    0.548023    0.436024    0.445122    0.434284    0.463704    4800        135.689046  1.409109    0.231544    129.613761 
[37m[36mINFO[0m[0m 03/14 12:45:53 | 0.473882    0.508475    0.521130    0.527358    1.732468    0.696996    0.696113    0.473882    0.508475    0.415080    0.422256    0.451314    0.463704    5000        141.342756  1.465660    0.231530    132.454258 
[37m[36mINFO[0m[0m 03/14 12:45:53 | Cumulative gradient change saved at train_output/VLCS/ERM/[1]/250314_11-28-31_resnet50_signum/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/14 12:45:54 | ---
[37m[36mINFO[0m[0m 03/14 12:45:54 | test-domain validation(oracle) = 66.400%
[37m[36mINFO[0m[0m 03/14 12:45:54 | training-domain validation(iid) = 66.212%
[37m[36mINFO[0m[0m 03/14 12:45:54 | last = 47.388%
[37m[36mINFO[0m[0m 03/14 12:45:54 | last (inD) = 52.736%
[37m[36mINFO[0m[0m 03/14 12:45:54 | training-domain validation (iid, inD) = 85.593%
[37m[36mINFO[0m[0m 03/14 12:45:55 | === Summary ===
[37m[36mINFO[0m[0m 03/14 12:45:55 | Command: /jsm0707/GENIE/train_all.py resnet50_signum config/resnet50_signum.yaml --algorithm ERM --test_envs 1 --dataset VLCS
[37m[36mINFO[0m[0m 03/14 12:45:55 | Unique name: 250314_11-28-31_resnet50_signum
[37m[36mINFO[0m[0m 03/14 12:45:55 | Out path: train_output/VLCS/ERM/[1]/250314_11-28-31_resnet50_signum
[37m[36mINFO[0m[0m 03/14 12:45:55 | Algorithm: ERM
[37m[36mINFO[0m[0m 03/14 12:45:55 | Dataset: VLCS
