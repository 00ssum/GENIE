[37m[36mINFO[0m[0m 03/14 12:45:59 | Command :: /jsm0707/GENIE/train_all.py resnet50_signum config/resnet50_signum.yaml --algorithm ERM --test_envs 2 --dataset VLCS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: ERM
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_signum.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_signum
	out_dir: train_output/VLCS/ERM/[2]/250314_12-45-59_resnet50_signum
	out_root: train_output/VLCS/ERM/[2]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [2]
	trial_seed: 0
	unique_name: 250314_12-45-59_resnet50_signum
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: signum
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 03/14 12:45:59 | n_steps = 5001
[37m[36mINFO[0m[0m 03/14 12:45:59 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/14 12:45:59 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/14 12:45:59 | 
[37m[36mINFO[0m[0m 03/14 12:45:59 | Testenv name escaping te_S -> te_S
[37m[36mINFO[0m[0m 03/14 12:45:59 | Test envs = [2], name = te_S
[37m[36mINFO[0m[0m 03/14 12:45:59 | Train environments: [0, 1, 3], Test environments: [2]
[37m[36mINFO[0m[0m 03/14 12:45:59 | Batch sizes for each domain: [32, 32, 0, 32] (total=96)
[37m[36mINFO[0m[0m 03/14 12:45:59 | steps-per-epoch for each domain: 35.38, 66.41, 84.41 -> min = 35.38
[37m[36mINFO[0m[0m 03/14 12:46:00 | # of params = 23518277
[37m[36mINFO[0m[0m 03/14 12:48:11 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/14 12:48:11 | 0.408606    0.416159    0.559529    0.548285    1.404796    0.662544    0.611307    0.521412    0.546139    0.408606    0.416159    0.494632    0.487407    0           0.000000    1.803942    1.309100    129.217917 
[37m[36mINFO[0m[0m 03/14 12:54:04 | 0.773800    0.733232    0.868780    0.844210    0.441813    0.998233    1.000000    0.731765    0.691149    0.773800    0.733232    0.876342    0.841481    200         5.653710    0.455780    1.126999    127.245123 
[37m[36mINFO[0m[0m 03/14 12:59:59 | 0.614623    0.582317    0.842865    0.819969    0.718091    0.995583    0.989399    0.735529    0.719397    0.614623    0.582317    0.797482    0.751111    400         11.307420   0.390872    1.126437    129.888936 
[37m[36mINFO[0m[0m 03/14 13:05:51 | 0.657273    0.660061    0.843521    0.829866    0.454351    0.994700    0.996466    0.717647    0.721281    0.657273    0.660061    0.818215    0.771852    600         16.961131   0.549313    1.122743    127.473361 
[37m[36mINFO[0m[0m 03/14 13:11:45 | 0.634044    0.597561    0.849577    0.831961    0.627197    0.996466    0.992933    0.735529    0.732580    0.634044    0.597561    0.816735    0.770370    800         22.614841   1.103116    1.111322    131.926312 
[37m[36mINFO[0m[0m 03/14 13:17:37 | 0.597106    0.589939    0.779249    0.762544    0.650531    0.931095    0.911661    0.717647    0.713748    0.597106    0.589939    0.689004    0.662222    1000        28.268551   1.076413    1.111111    130.145153 
[37m[36mINFO[0m[0m 03/14 13:23:28 | 0.404417    0.428354    0.664562    0.654765    1.081853    0.902827    0.897527    0.601412    0.583804    0.404417    0.428354    0.489448    0.482963    1200        33.922261   0.998388    1.107758    128.814373 
[37m[36mINFO[0m[0m 03/14 13:29:16 | 0.339299    0.329268    0.593040    0.603967    1.128547    0.818021    0.833922    0.584941    0.612053    0.339299    0.329268    0.376157    0.365926    1400        39.575972   1.637083    1.085434    130.763192 
[37m[36mINFO[0m[0m 03/14 13:35:07 | 0.341965    0.349085    0.603843    0.609723    0.920682    0.863958    0.876325    0.556235    0.570621    0.341965    0.349085    0.391337    0.382222    1600        45.229682   1.461094    1.111947    128.559714 
[37m[36mINFO[0m[0m 03/14 13:40:54 | 0.368241    0.371951    0.626241    0.629174    0.990384    0.879859    0.890459    0.557176    0.534840    0.368241    0.371951    0.441688    0.462222    1800        50.883392   1.495446    1.096780    128.483329 
[37m[36mINFO[0m[0m 03/14 13:46:44 | 0.210967    0.195122    0.517254    0.530178    1.807898    0.836572    0.819788    0.435294    0.467043    0.210967    0.195122    0.279896    0.303704    2000        56.537102   1.257081    1.113080    127.282661 
[37m[36mINFO[0m[0m 03/14 13:52:35 | 0.445545    0.434451    0.572049    0.562764    1.266278    0.804770    0.830389    0.488941    0.451977    0.445545    0.434451    0.422436    0.405926    2200        62.190813   1.371549    1.103433    129.962525 
[37m[36mINFO[0m[0m 03/14 13:58:23 | 0.327113    0.339939    0.592327    0.592665    1.078105    0.848057    0.837456    0.480941    0.499058    0.327113    0.339939    0.447982    0.441481    2400        67.844523   1.617316    1.106535    127.035744 
[37m[36mINFO[0m[0m 03/14 14:04:16 | 0.347296    0.336890    0.564459    0.558810    1.034912    0.839223    0.848057    0.493176    0.480226    0.347296    0.336890    0.360977    0.348148    2600        73.498233   1.245447    1.115291    129.899253 
[37m[36mINFO[0m[0m 03/14 14:10:07 | 0.393755    0.396341    0.555501    0.560928    0.969665    0.719081    0.706714    0.491294    0.519774    0.393755    0.396341    0.456127    0.456296    2800        79.151943   1.295449    1.107527    129.293861 
[37m[36mINFO[0m[0m 03/14 14:16:03 | 0.381950    0.416159    0.614287    0.601521    1.027297    0.794170    0.798587    0.547765    0.514124    0.381950    0.416159    0.500926    0.491852    3000        84.805654   1.291880    1.135850    128.258443 
[37m[36mINFO[0m[0m 03/14 14:21:51 | 0.451637    0.434451    0.629675    0.616925    0.969489    0.842756    0.805654    0.546824    0.551789    0.451637    0.434451    0.499445    0.493333    3200        90.459364   1.252269    1.096310    129.424863 
[37m[36mINFO[0m[0m 03/14 14:27:45 | 0.302742    0.314024    0.584970    0.576334    1.004027    0.863958    0.826855    0.485176    0.506591    0.302742    0.314024    0.405776    0.395556    3400        96.113074   1.256351    1.107148    132.514472 
[37m[36mINFO[0m[0m 03/14 14:33:28 | 0.452399    0.416159    0.555307    0.560052    1.538818    0.712014    0.727915    0.525176    0.512241    0.452399    0.416159    0.428730    0.440000    3600        101.766784  1.441276    1.080500    127.099243 
[37m[36mINFO[0m[0m 03/14 14:39:13 | 0.456969    0.417683    0.544796    0.536248    1.545122    0.676678    0.664311    0.525647    0.510358    0.456969    0.417683    0.432062    0.434074    3800        107.420495  1.409444    1.080312    128.114914 
[37m[36mINFO[0m[0m 03/14 14:45:02 | 0.464585    0.434451    0.558954    0.561322    1.056625    0.721731    0.731449    0.515294    0.506591    0.464585    0.434451    0.439837    0.445926    4000        113.074205  1.356289    1.109274    128.107463 
[37m[36mINFO[0m[0m 03/14 14:50:52 | 0.385377    0.403963    0.567666    0.558595    1.114232    0.803004    0.805654    0.494588    0.474576    0.385377    0.403963    0.405405    0.395556    4200        118.727915  1.431370    1.102901    128.584987 
[37m[36mINFO[0m[0m 03/14 14:56:53 | 0.420792    0.425305    0.587208    0.564518    1.149841    0.737633    0.720848    0.543059    0.517891    0.420792    0.425305    0.480933    0.454815    4400        124.381625  1.407139    1.146880    132.027803 
[37m[36mINFO[0m[0m 03/14 15:02:52 | 0.324448    0.323171    0.455688    0.453015    1.692940    0.627208    0.653710    0.465882    0.431262    0.324448    0.323171    0.273973    0.274074    4600        130.035336  1.243721    1.125510    133.472090 
[37m[36mINFO[0m[0m 03/14 15:08:57 | 0.238385    0.248476    0.545625    0.566878    1.067056    0.860424    0.862191    0.456941    0.506591    0.238385    0.248476    0.319511    0.331852    4800        135.689046  1.340514    1.135374    138.252233 
[37m[36mINFO[0m[0m 03/14 15:14:56 | 0.470297    0.469512    0.601309    0.590448    1.293036    0.734982    0.720848    0.580235    0.563089    0.470297    0.469512    0.488708    0.487407    5000        141.342756  1.262967    1.147399    129.270619 
[37m[36mINFO[0m[0m 03/14 15:14:56 | Cumulative gradient change saved at train_output/VLCS/ERM/[2]/250314_12-45-59_resnet50_signum/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/14 15:14:57 | ---
[37m[36mINFO[0m[0m 03/14 15:14:57 | test-domain validation(oracle) = 77.380%
[37m[36mINFO[0m[0m 03/14 15:14:57 | training-domain validation(iid) = 77.380%
[37m[36mINFO[0m[0m 03/14 15:14:57 | last = 47.030%
[37m[36mINFO[0m[0m 03/14 15:14:57 | last (inD) = 59.045%
[37m[36mINFO[0m[0m 03/14 15:14:57 | training-domain validation (iid, inD) = 84.421%
[37m[36mINFO[0m[0m 03/14 15:14:57 | === Summary ===
[37m[36mINFO[0m[0m 03/14 15:14:57 | Command: /jsm0707/GENIE/train_all.py resnet50_signum config/resnet50_signum.yaml --algorithm ERM --test_envs 2 --dataset VLCS
[37m[36mINFO[0m[0m 03/14 15:14:57 | Unique name: 250314_12-45-59_resnet50_signum
[37m[36mINFO[0m[0m 03/14 15:14:57 | Out path: train_output/VLCS/ERM/[2]/250314_12-45-59_resnet50_signum
[37m[36mINFO[0m[0m 03/14 15:14:57 | Algorithm: ERM
[37m[36mINFO[0m[0m 03/14 15:14:57 | Dataset: VLCS
