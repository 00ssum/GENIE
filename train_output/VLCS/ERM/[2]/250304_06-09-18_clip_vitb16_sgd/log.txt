[37m[36mINFO[0m[0m 03/04 06:09:18 | Command :: /jsm0707/GENIE/train_all.py clip_vitb16_sgd config/clip_vitb16_sgd.yaml --algorithm ERM --test_envs 2 --dataset VLCS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: ERM
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/clip_vitb16_sgd.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: clip_vitb16_sgd
	out_dir: train_output/VLCS/ERM/[2]/250304_06-09-18_clip_vitb16_sgd
	out_root: train_output/VLCS/ERM/[2]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [2]
	trial_seed: 0
	unique_name: 250304_06-09-18_clip_vitb16_sgd
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: sgd
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: clip_vit-b16
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 03/04 06:09:18 | n_steps = 5001
[37m[36mINFO[0m[0m 03/04 06:09:18 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/04 06:09:18 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/04 06:09:18 | 
[37m[36mINFO[0m[0m 03/04 06:09:18 | Testenv name escaping te_S -> te_S
[37m[36mINFO[0m[0m 03/04 06:09:18 | Test envs = [2], name = te_S
[37m[36mINFO[0m[0m 03/04 06:09:18 | Train environments: [0, 1, 3], Test environments: [2]
[37m[36mINFO[0m[0m 03/04 06:09:18 | Batch sizes for each domain: [32, 32, 0, 32] (total=96)
[37m[36mINFO[0m[0m 03/04 06:09:18 | steps-per-epoch for each domain: 35.38, 66.41, 84.41 -> min = 35.38
[37m[36mINFO[0m[0m 03/04 06:09:20 | # of params = 86195205
[37m[36mINFO[0m[0m 03/04 06:11:28 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/04 06:11:28 | 0.353389    0.330793    0.136780    0.142291    1.700564    0.097173    0.074205    0.142118    0.160075    0.353389    0.330793    0.171048    0.192593    0           0.000000    1.711053    1.101806    126.463870 
[37m[36mINFO[0m[0m 03/04 06:17:07 | 0.400990    0.394817    0.540572    0.561176    1.208117    0.659894    0.685512    0.494588    0.525424    0.400990    0.394817    0.467234    0.472593    200         5.653710    1.387800    1.065879    125.921682 
[37m[36mINFO[0m[0m 03/04 06:22:50 | 0.437548    0.434451    0.612879    0.629856    1.029531    0.765901    0.780919    0.563294    0.585687    0.437548    0.434451    0.509441    0.522963    400         11.307420   1.092287    1.084891    125.784538 
[37m[36mINFO[0m[0m 03/04 06:28:31 | 0.466870    0.457317    0.708921    0.720786    0.905258    0.856007    0.848057    0.655059    0.702448    0.466870    0.457317    0.615698    0.611852    600         16.961131   0.950101    1.078232    125.169808 
[37m[36mINFO[0m[0m 03/04 06:34:09 | 0.488195    0.486280    0.755404    0.752309    0.799970    0.886042    0.883392    0.711529    0.723164    0.488195    0.486280    0.668641    0.650370    800         22.614841   0.834799    1.073727    123.988583 
[37m[36mINFO[0m[0m 03/04 06:39:49 | 0.507997    0.513720    0.800680    0.809464    0.706233    0.947880    0.964664    0.730353    0.757062    0.507997    0.513720    0.723806    0.706667    1000        28.268551   0.738728    1.070236    125.217828 
[37m[36mINFO[0m[0m 03/04 06:45:28 | 0.523991    0.528963    0.830846    0.825781    0.626364    0.982332    0.971731    0.750118    0.758945    0.523991    0.528963    0.760089    0.746667    1200        33.922261   0.653792    1.075623    124.552720 
[37m[36mINFO[0m[0m 03/04 06:51:08 | 0.570830    0.565549    0.853572    0.848410    0.562707    0.993816    0.989399    0.764235    0.772128    0.570830    0.565549    0.802666    0.783704    1400        39.575972   0.576315    1.078548    124.344490 
[37m[36mINFO[0m[0m 03/04 06:56:50 | 0.678599    0.657012    0.871432    0.866970    0.512822    0.997350    0.996466    0.768000    0.777778    0.678599    0.657012    0.848945    0.826667    1600        45.229682   0.524791    1.077297    126.133157 
[37m[36mINFO[0m[0m 03/04 07:02:34 | 0.716679    0.690549    0.877756    0.877558    0.474628    0.998233    0.996466    0.781647    0.794727    0.716679    0.690549    0.853388    0.841481    1800        50.883392   0.473742    1.094300    125.499283 
[37m[36mINFO[0m[0m 03/04 07:08:11 | 0.765804    0.743902    0.884656    0.885861    0.442419    0.999117    0.996466    0.787765    0.800377    0.765804    0.743902    0.867086    0.860741    2000        56.537102   0.439935    1.069166    123.154930 
[37m[36mINFO[0m[0m 03/04 07:13:53 | 0.773420    0.756098    0.886572    0.890496    0.416095    0.999117    1.000000    0.793882    0.800377    0.773420    0.756098    0.866716    0.871111    2200        62.190813   0.405119    1.083462    125.005211 
[37m[36mINFO[0m[0m 03/04 07:19:32 | 0.788271    0.771341    0.888157    0.889684    0.399745    1.000000    1.000000    0.792941    0.809793    0.788271    0.771341    0.871529    0.859259    2400        67.844523   0.387335    1.069311    125.136205 
[37m[36mINFO[0m[0m 03/04 07:25:10 | 0.797411    0.772866    0.893129    0.894834    0.382102    0.998233    0.996466    0.800000    0.815443    0.797411    0.772866    0.881155    0.872593    2600        73.498233   0.374066    1.065676    124.882330 
[37m[36mINFO[0m[0m 03/04 07:30:50 | 0.789414    0.772866    0.897659    0.893007    0.366763    0.999117    1.000000    0.812706    0.807910    0.789414    0.772866    0.881155    0.871111    2800        79.151943   0.355181    1.074457    125.170922 
[37m[36mINFO[0m[0m 03/04 07:36:30 | 0.800457    0.782012    0.901976    0.896506    0.353653    0.999117    1.000000    0.817882    0.815443    0.800457    0.782012    0.888930    0.874074    3000        84.805654   0.338628    1.075643    124.297277 
[37m[36mINFO[0m[0m 03/04 07:42:09 | 0.798172    0.783537    0.903982    0.897133    0.343545    0.999117    1.000000    0.823529    0.817326    0.798172    0.783537    0.889300    0.874074    3200        90.459364   0.327639    1.074892    124.596054 
[37m[36mINFO[0m[0m 03/04 07:47:51 | 0.792841    0.783537    0.907525    0.898883    0.336113    0.999117    1.000000    0.828235    0.821092    0.792841    0.783537    0.895224    0.875556    3400        96.113074   0.322618    1.077759    126.591324 
[37m[36mINFO[0m[0m 03/04 07:53:34 | 0.805788    0.792683    0.909602    0.899602    0.324701    0.999117    1.000000    0.824471    0.817326    0.805788    0.792683    0.905220    0.881481    3600        101.766784  0.314886    1.081182    126.527007 
[37m[36mINFO[0m[0m 03/04 07:59:16 | 0.788652    0.782012    0.907829    0.901176    0.325238    0.999117    1.000000    0.827294    0.811676    0.788652    0.782012    0.897075    0.891852    3800        107.420495  0.300543    1.074720    127.302045 
[37m[36mINFO[0m[0m 03/04 08:04:57 | 0.808454    0.795732    0.911848    0.900950    0.312938    1.000000    1.000000    0.825882    0.815443    0.808454    0.795732    0.909663    0.887407    4000        113.074205  0.290607    1.075162    125.298351 
[37m[36mINFO[0m[0m 03/04 08:10:41 | 0.813024    0.786585    0.913013    0.906650    0.311563    1.000000    1.000000    0.830118    0.819209    0.813024    0.786585    0.908923    0.900741    4200        118.727915  0.309745    1.090827    125.844127 
[37m[36mINFO[0m[0m 03/04 08:16:21 | 0.816070    0.803354    0.919784    0.902072    0.301666    1.000000    1.000000    0.843765    0.817326    0.816070    0.803354    0.915587    0.888889    4400        124.381625  0.280065    1.078826    124.547198 
[37m[36mINFO[0m[0m 03/04 08:22:01 | 0.821782    0.794207    0.922999    0.903687    0.296077    0.999117    1.000000    0.848000    0.819209    0.821782    0.794207    0.921881    0.891852    4600        130.035336  0.266051    1.078257    124.700229 
[37m[36mINFO[0m[0m 03/04 08:27:44 | 0.806931    0.786585    0.921208    0.901804    0.296402    1.000000    1.000000    0.844706    0.813559    0.806931    0.786585    0.918919    0.891852    4800        135.689046  0.252155    1.074456    127.843750 
[37m[36mINFO[0m[0m 03/04 08:33:27 | 0.819878    0.794207    0.923472    0.900816    0.290871    0.999117    1.000000    0.844235    0.813559    0.819878    0.794207    0.927064    0.888889    5000        141.342756  0.271709    1.075288    128.269218 
[37m[36mINFO[0m[0m 03/04 08:33:28 | Cumulative gradient change saved at train_output/VLCS/ERM/[2]/250304_06-09-18_clip_vitb16_sgd/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/04 08:33:32 | ---
[37m[36mINFO[0m[0m 03/04 08:33:32 | test-domain validation(oracle) = 81.607%
[37m[36mINFO[0m[0m 03/04 08:33:32 | training-domain validation(iid) = 81.302%
[37m[36mINFO[0m[0m 03/04 08:33:32 | last = 81.988%
[37m[36mINFO[0m[0m 03/04 08:33:32 | last (inD) = 90.082%
[37m[36mINFO[0m[0m 03/04 08:33:32 | training-domain validation (iid, inD) = 90.665%
[37m[36mINFO[0m[0m 03/04 08:33:32 | === Summary ===
[37m[36mINFO[0m[0m 03/04 08:33:32 | Command: /jsm0707/GENIE/train_all.py clip_vitb16_sgd config/clip_vitb16_sgd.yaml --algorithm ERM --test_envs 2 --dataset VLCS
[37m[36mINFO[0m[0m 03/04 08:33:32 | Unique name: 250304_06-09-18_clip_vitb16_sgd
[37m[36mINFO[0m[0m 03/04 08:33:32 | Out path: train_output/VLCS/ERM/[2]/250304_06-09-18_clip_vitb16_sgd
[37m[36mINFO[0m[0m 03/04 08:33:32 | Algorithm: ERM
[37m[36mINFO[0m[0m 03/04 08:33:32 | Dataset: VLCS
