[37m[36mINFO[0m[0m 03/04 06:19:52 | Command :: /jsm0707/GENIE/train_all.py clip_vitb16_GENIE config/clip_vitb16_GENIE.yaml --algorithm ERM --test_envs 2 --dataset VLCS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: ERM
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/clip_vitb16_GENIE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: clip_vitb16_GENIE
	out_dir: train_output/VLCS/ERM/[2]/250304_06-19-52_clip_vitb16_GENIE
	out_root: train_output/VLCS/ERM/[2]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [2]
	trial_seed: 0
	unique_name: 250304_06-19-52_clip_vitb16_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: clip_vit-b16
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 03/04 06:19:52 | n_steps = 5001
[37m[36mINFO[0m[0m 03/04 06:19:52 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/04 06:19:52 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/04 06:19:52 | 
[37m[36mINFO[0m[0m 03/04 06:19:53 | Testenv name escaping te_S -> te_S
[37m[36mINFO[0m[0m 03/04 06:19:53 | Test envs = [2], name = te_S
[37m[36mINFO[0m[0m 03/04 06:19:53 | Train environments: [0, 1, 3], Test environments: [2]
[37m[36mINFO[0m[0m 03/04 06:19:53 | Batch sizes for each domain: [32, 32, 0, 32] (total=96)
[37m[36mINFO[0m[0m 03/04 06:19:53 | steps-per-epoch for each domain: 35.38, 66.41, 84.41 -> min = 35.38
[37m[36mINFO[0m[0m 03/04 06:19:55 | # of params = 86195205
[37m[36mINFO[0m[0m 03/04 06:22:02 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/04 06:22:02 | 0.392612    0.399390    0.506506    0.524808    1.337478    0.611307    0.621908    0.465412    0.506591    0.392612    0.399390    0.442799    0.445926    0           0.000000    1.711053    1.133963    125.351293 
[37m[36mINFO[0m[0m 03/04 06:27:42 | 0.659177    0.650915    0.832845    0.812435    0.483755    0.988516    0.978799    0.738824    0.732580    0.659177    0.650915    0.771196    0.725926    200         5.653710    0.579280    1.066867    127.098891 
[37m[36mINFO[0m[0m 03/04 06:33:22 | 0.693831    0.675305    0.883939    0.852989    0.401982    0.997350    0.989399    0.798118    0.774011    0.693831    0.675305    0.856350    0.795556    400         11.307420   0.387204    1.064455    126.387833 
[37m[36mINFO[0m[0m 03/04 06:39:00 | 0.704494    0.696646    0.878638    0.847261    0.408126    0.996466    0.992933    0.779765    0.753296    0.704494    0.696646    0.859682    0.795556    600         16.961131   0.328744    1.069270    124.717172 
[37m[36mINFO[0m[0m 03/04 06:44:34 | 0.683549    0.663110    0.892104    0.834099    0.461867    0.991166    0.975265    0.811765    0.755179    0.683549    0.663110    0.873380    0.771852    800         22.614841   0.286247    1.051771    123.859675 
[37m[36mINFO[0m[0m 03/04 06:50:12 | 0.701828    0.666159    0.920023    0.861206    0.412963    0.997350    0.992933    0.868235    0.796610    0.701828    0.666159    0.894484    0.794074    1000        28.268551   0.255095    1.053785    126.766083 
[37m[36mINFO[0m[0m 03/04 06:55:50 | 0.692688    0.666159    0.936790    0.847973    0.447512    0.999117    0.992933    0.892706    0.770245    0.692688    0.666159    0.918549    0.780741    1200        33.922261   0.219665    1.058966    126.753132 
[37m[36mINFO[0m[0m 03/04 07:01:31 | 0.675171    0.647866    0.952646    0.847551    0.466804    1.000000    0.985866    0.917176    0.762712    0.675171    0.647866    0.940763    0.794074    1400        39.575972   0.184681    1.070569    126.145634 
[37m[36mINFO[0m[0m 03/04 07:07:10 | 0.654608    0.655488    0.947190    0.841969    0.496946    1.000000    0.996466    0.901176    0.766478    0.654608    0.655488    0.940392    0.762963    1600        45.229682   0.143930    1.057314    127.779892 
[37m[36mINFO[0m[0m 03/04 07:12:52 | 0.647753    0.614329    0.945771    0.828708    0.598385    0.996466    0.975265    0.913412    0.762712    0.647753    0.614329    0.927434    0.748148    1800        50.883392   0.121067    1.072622    127.999737 
[37m[36mINFO[0m[0m 03/04 07:18:30 | 0.711348    0.644817    0.958779    0.832985    0.587531    0.997350    0.989399    0.908235    0.728814    0.711348    0.644817    0.970752    0.780741    2000        56.537102   0.108771    1.052574    127.173675 
[37m[36mINFO[0m[0m 03/04 07:24:13 | 0.650038    0.632622    0.970314    0.830409    0.562252    1.000000    0.985866    0.948706    0.743879    0.650038    0.632622    0.962236    0.761481    2200        62.190813   0.098892    1.069759    128.506471 
[37m[36mINFO[0m[0m 03/04 07:29:51 | 0.653465    0.608232    0.972636    0.841095    0.653262    1.000000    0.989399    0.950118    0.766478    0.653465    0.608232    0.967790    0.767407    2400        67.844523   0.077847    1.064950    125.497867 
[37m[36mINFO[0m[0m 03/04 07:35:30 | 0.658416    0.620427    0.966843    0.827327    0.651933    0.999117    0.975265    0.926588    0.736347    0.658416    0.620427    0.974824    0.770370    2600        73.498233   0.071300    1.060847    126.736194 
[37m[36mINFO[0m[0m 03/04 07:41:08 | 0.688119    0.658537    0.985415    0.845617    0.613926    1.000000    0.985866    0.973647    0.770245    0.688119    0.658537    0.982599    0.780741    2800        79.151943   0.061349    1.065063    125.050291 
[37m[36mINFO[0m[0m 03/04 07:46:46 | 0.680122    0.643293    0.974839    0.822882    0.802073    0.997350    0.989399    0.972706    0.732580    0.680122    0.643293    0.954461    0.746667    3000        84.805654   0.043536    1.062771    125.530073 
[37m[36mINFO[0m[0m 03/04 07:52:28 | 0.660701    0.640244    0.987455    0.846146    0.654547    1.000000    0.996466    0.979765    0.762712    0.660701    0.640244    0.982599    0.779259    3200        90.459364   0.045983    1.074159    126.867507 
[37m[36mINFO[0m[0m 03/04 07:58:14 | 0.679360    0.644817    0.989436    0.849680    0.636260    0.999117    0.992933    0.984000    0.766478    0.679360    0.644817    0.985191    0.789630    3400        96.113074   0.040242    1.084395    129.237087 
[37m[36mINFO[0m[0m 03/04 08:03:56 | 0.645088    0.615854    0.984571    0.828510    0.685706    0.999117    0.996466    0.974588    0.743879    0.645088    0.615854    0.980007    0.745185    3600        101.766784  0.046225    1.074026    127.430263 
[37m[36mINFO[0m[0m 03/04 08:09:36 | 0.681645    0.661585    0.995392    0.838211    0.709926    1.000000    0.996466    0.992471    0.734463    0.681645    0.661585    0.993706    0.783704    3800        107.420495  0.033363    1.073362    124.711329 
[37m[36mINFO[0m[0m 03/04 08:15:15 | 0.672125    0.660061    0.992947    0.846357    0.706151    1.000000    0.992933    0.991059    0.768362    0.672125    0.660061    0.987782    0.777778    4000        113.074205  0.024596    1.062008    126.773993 
[37m[36mINFO[0m[0m 03/04 08:20:57 | 0.672125    0.649390    0.992813    0.834056    0.755825    1.000000    0.989399    0.989176    0.743879    0.672125    0.649390    0.989263    0.768889    4200        118.727915  0.027451    1.083868    125.509895 
[37m[36mINFO[0m[0m 03/04 08:26:34 | 0.675552    0.629573    0.991921    0.836017    0.777724    0.998233    0.985866    0.990118    0.753296    0.675552    0.629573    0.987412    0.768889    4400        124.381625  0.026387    1.060359    124.844405 
[37m[36mINFO[0m[0m 03/04 08:32:15 | 0.675552    0.637195    0.993991    0.843579    0.719552    1.000000    0.992933    0.990118    0.757062    0.675552    0.637195    0.991855    0.780741    4600        130.035336  0.033241    1.070098    127.066442 
[37m[36mINFO[0m[0m 03/04 08:37:53 | 0.654989    0.632622    0.993351    0.841681    0.681285    1.000000    0.989399    0.991529    0.760829    0.654989    0.632622    0.988523    0.774815    4800        135.689046  0.031872    1.064051    125.355933 
[37m[36mINFO[0m[0m 03/04 08:43:31 | 0.664128    0.641768    0.993481    0.834951    0.772499    0.998233    0.989399    0.987765    0.749529    0.664128    0.641768    0.994447    0.765926    5000        141.342756  0.019642    1.060863    125.693309 
[37m[36mINFO[0m[0m 03/04 08:43:31 | Cumulative gradient change saved at train_output/VLCS/ERM/[2]/250304_06-19-52_clip_vitb16_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/04 08:43:33 | ---
[37m[36mINFO[0m[0m 03/04 08:43:33 | test-domain validation(oracle) = 70.449%
[37m[36mINFO[0m[0m 03/04 08:43:33 | training-domain validation(iid) = 70.183%
[37m[36mINFO[0m[0m 03/04 08:43:33 | last = 66.413%
[37m[36mINFO[0m[0m 03/04 08:43:33 | last (inD) = 83.495%
[37m[36mINFO[0m[0m 03/04 08:43:33 | training-domain validation (iid, inD) = 86.121%
[37m[36mINFO[0m[0m 03/04 08:43:33 | === Summary ===
[37m[36mINFO[0m[0m 03/04 08:43:33 | Command: /jsm0707/GENIE/train_all.py clip_vitb16_GENIE config/clip_vitb16_GENIE.yaml --algorithm ERM --test_envs 2 --dataset VLCS
[37m[36mINFO[0m[0m 03/04 08:43:33 | Unique name: 250304_06-19-52_clip_vitb16_GENIE
[37m[36mINFO[0m[0m 03/04 08:43:33 | Out path: train_output/VLCS/ERM/[2]/250304_06-19-52_clip_vitb16_GENIE
[37m[36mINFO[0m[0m 03/04 08:43:33 | Algorithm: ERM
[37m[36mINFO[0m[0m 03/04 08:43:33 | Dataset: VLCS
