[37m[36mINFO[0m[0m 02/26 22:44:14 | Command :: /jsm0707/GENIE/train_all.py clip_vitb16_adam config/clip_vitb16_adam.yaml --algorithm ERM --test_envs 2 --dataset VLCS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: ERM
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/clip_vitb16_adam.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: clip_vitb16_adam
	out_dir: train_output/VLCS/ERM/[2]/250226_22-44-14_clip_vitb16_adam
	out_root: train_output/VLCS/ERM/[2]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [2]
	trial_seed: 0
	unique_name: 250226_22-44-14_clip_vitb16_adam
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: adam
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: clip_vit-b16
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 02/26 22:44:14 | n_steps = 5001
[37m[36mINFO[0m[0m 02/26 22:44:14 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/26 22:44:14 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/26 22:44:14 | 
[37m[36mINFO[0m[0m 02/26 22:44:14 | Testenv name escaping te_S -> te_S
[37m[36mINFO[0m[0m 02/26 22:44:14 | Test envs = [2], name = te_S
[37m[36mINFO[0m[0m 02/26 22:44:14 | Train environments: [0, 1, 3], Test environments: [2]
[37m[36mINFO[0m[0m 02/26 22:44:14 | Batch sizes for each domain: [32, 32, 0, 32] (total=96)
[37m[36mINFO[0m[0m 02/26 22:44:14 | steps-per-epoch for each domain: 35.38, 66.41, 84.41 -> min = 35.38
[37m[36mINFO[0m[0m 02/26 22:44:18 | # of params = 86195205
[37m[36mINFO[0m[0m 02/26 22:46:53 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 02/26 22:46:53 | 0.404417    0.402439    0.506836    0.525105    1.130035    0.612191    0.628975    0.460706    0.491525    0.404417    0.402439    0.447612    0.454815    0           0.000000    1.711053    1.478252    153.690161 
[37m[36mINFO[0m[0m 02/26 22:53:42 | 0.743717    0.708841    0.907188    0.871894    0.347619    0.995583    0.992933    0.829647    0.787194    0.743717    0.708841    0.896335    0.835556    200         5.653710    0.338768    1.249469    159.253615 
[37m[36mINFO[0m[0m 02/26 23:00:37 | 0.704494    0.699695    0.913563    0.864156    0.390611    0.999117    1.000000    0.848941    0.770245    0.704494    0.699695    0.892632    0.822222    400         11.307420   0.249903    1.340235    146.549999 
[37m[36mINFO[0m[0m 02/26 23:07:12 | 0.701066    0.681402    0.939440    0.864627    0.447903    0.996466    0.996466    0.895529    0.800377    0.701066    0.681402    0.926324    0.797037    600         16.961131   0.201115    1.278964    139.570103 
[37m[36mINFO[0m[0m 02/26 23:14:01 | 0.746002    0.721037    0.947841    0.864811    0.509749    0.999117    0.996466    0.893647    0.789077    0.746002    0.721037    0.950759    0.808889    800         22.614841   0.156115    1.285253    151.645446 
[37m[36mINFO[0m[0m 02/26 23:20:38 | 0.714775    0.692073    0.962502    0.842013    0.536602    0.994700    0.992933    0.943529    0.741996    0.714775    0.692073    0.949278    0.791111    1000        28.268551   0.121912    1.214472    154.170788 
[37m[36mINFO[0m[0m 02/26 23:27:18 | 0.704874    0.676829    0.975432    0.857736    0.473551    0.999117    1.000000    0.962353    0.770245    0.704874    0.676829    0.964828    0.802963    1200        33.922261   0.109172    1.257948    148.322141 
[37m[36mINFO[0m[0m 02/26 23:34:05 | 0.710206    0.722561    0.976215    0.852489    0.567041    0.998233    0.985866    0.961882    0.762712    0.710206    0.722561    0.968530    0.808889    1400        39.575972   0.073353    1.276802    152.210140 
[37m[36mINFO[0m[0m 02/26 23:40:46 | 0.694973    0.660061    0.981299    0.855585    0.632190    1.000000    1.000000    0.971294    0.760829    0.694973    0.660061    0.972603    0.805926    1600        45.229682   0.080668    1.263667    147.438996 
[37m[36mINFO[0m[0m 02/26 23:47:31 | 0.678979    0.669207    0.982329    0.848029    0.631064    0.999117    0.996466    0.970824    0.768362    0.678979    0.669207    0.977046    0.779259    1800        50.883392   0.071653    1.251889    155.120942 
[37m[36mINFO[0m[0m 02/26 23:54:11 | 0.634425    0.632622    0.979283    0.849454    0.637895    1.000000    0.992933    0.963765    0.770245    0.634425    0.632622    0.974084    0.785185    2000        56.537102   0.058905    1.242942    151.834549 
[37m[36mINFO[0m[0m 02/27 00:00:54 | 0.670982    0.640244    0.986107    0.842463    0.654651    1.000000    0.996466    0.981647    0.766478    0.670982    0.640244    0.976675    0.764444    2200        62.190813   0.057997    1.265932    149.516572 
[37m[36mINFO[0m[0m 02/27 00:07:31 | 0.635187    0.605183    0.969043    0.843612    0.729450    0.997350    0.992933    0.962353    0.785311    0.635187    0.605183    0.947427    0.752593    2400        67.844523   0.045227    1.249638    146.466501 
[37m[36mINFO[0m[0m 02/27 00:14:10 | 0.713252    0.685976    0.983060    0.840326    0.625361    1.000000    1.000000    0.971765    0.747646    0.713252    0.685976    0.977416    0.773333    2600        73.498233   0.050411    1.257941    147.848922 
[37m[36mINFO[0m[0m 02/27 00:20:49 | 0.692308    0.692073    0.983700    0.845985    0.653485    1.000000    1.000000    0.970353    0.743879    0.692308    0.692073    0.980748    0.794074    2800        79.151943   0.054847    1.271214    144.462552 
[37m[36mINFO[0m[0m 02/27 00:27:18 | 0.646611    0.634146    0.982525    0.847592    0.764603    0.999117    1.000000    0.984000    0.766478    0.646611    0.634146    0.964458    0.776296    3000        84.805654   0.038526    1.233420    142.232333 
[37m[36mINFO[0m[0m 02/27 00:33:47 | 0.674029    0.658537    0.987490    0.846118    0.661045    1.000000    1.000000    0.975059    0.745763    0.674029    0.658537    0.987412    0.792593    3200        90.459364   0.046864    1.242151    140.829310 
[37m[36mINFO[0m[0m 02/27 00:40:47 | 0.709444    0.698171    0.987520    0.844997    0.641513    0.999117    1.000000    0.977882    0.743879    0.709444    0.698171    0.985561    0.791111    3400        96.113074   0.039858    1.314698    157.398930 
[37m[36mINFO[0m[0m 02/27 00:47:41 | 0.678218    0.647866    0.989450    0.846244    0.723036    1.000000    1.000000    0.983529    0.768362    0.678218    0.647866    0.984820    0.770370    3600        101.766784  0.037038    1.291695    155.221997 
[37m[36mINFO[0m[0m 02/27 00:54:14 | 0.659177    0.650915    0.985884    0.835162    0.761420    1.000000    1.000000    0.980235    0.751412    0.659177    0.650915    0.977416    0.754074    3800        107.420495  0.047874    1.256425    142.138062 
[37m[36mINFO[0m[0m 02/27 01:00:51 | 0.720107    0.681402    0.984215    0.836074    0.706903    0.999117    1.000000    0.966118    0.715631    0.720107    0.681402    0.987412    0.792593    4000        113.074205  0.038483    1.248132    147.208616 
[37m[36mINFO[0m[0m 02/27 01:07:25 | 0.680883    0.644817    0.991255    0.850329    0.708013    1.000000    1.000000    0.986353    0.770245    0.680883    0.644817    0.987412    0.780741    4200        118.727915  0.036894    1.232473    147.899096 
[37m[36mINFO[0m[0m 02/27 01:13:53 | 0.691546    0.650915    0.978758    0.826876    0.862802    1.000000    1.000000    0.958118    0.704331    0.691546    0.650915    0.978156    0.776296    4400        124.381625  0.028438    1.222452    143.306976 
[37m[36mINFO[0m[0m 02/27 01:20:22 | 0.670602    0.650915    0.990523    0.835382    0.763068    0.999117    0.996466    0.985412    0.736347    0.670602    0.650915    0.987042    0.773333    4600        130.035336  0.033727    1.245280    139.290058 
[37m[36mINFO[0m[0m 02/27 01:26:49 | 0.627570    0.612805    0.986986    0.829159    0.796313    0.999117    0.989399    0.992941    0.751412    0.627570    0.612805    0.968900    0.746667    4800        135.689046  0.035096    1.201096    147.039533 
[37m[36mINFO[0m[0m 02/27 01:33:09 | 0.658797    0.664634    0.995255    0.849067    0.717136    0.999117    0.996466    0.992941    0.755179    0.658797    0.664634    0.993706    0.795556    5000        141.342756  0.028622    1.193104    141.549485 
[37m[36mINFO[0m[0m 02/27 01:33:09 | Cumulative gradient change saved at train_output/VLCS/ERM/[2]/250226_22-44-14_clip_vitb16_adam/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/27 01:33:11 | ---
[37m[36mINFO[0m[0m 02/27 01:33:11 | test-domain validation(oracle) = 71.021%
[37m[36mINFO[0m[0m 02/27 01:33:11 | training-domain validation(iid) = 74.372%
[37m[36mINFO[0m[0m 02/27 01:33:11 | last = 65.880%
[37m[36mINFO[0m[0m 02/27 01:33:11 | last (inD) = 84.907%
[37m[36mINFO[0m[0m 02/27 01:33:11 | training-domain validation (iid, inD) = 87.189%
[37m[36mINFO[0m[0m 02/27 01:33:11 | === Summary ===
[37m[36mINFO[0m[0m 02/27 01:33:11 | Command: /jsm0707/GENIE/train_all.py clip_vitb16_adam config/clip_vitb16_adam.yaml --algorithm ERM --test_envs 2 --dataset VLCS
[37m[36mINFO[0m[0m 02/27 01:33:11 | Unique name: 250226_22-44-14_clip_vitb16_adam
[37m[36mINFO[0m[0m 02/27 01:33:11 | Out path: train_output/VLCS/ERM/[2]/250226_22-44-14_clip_vitb16_adam
[37m[36mINFO[0m[0m 02/27 01:33:11 | Algorithm: ERM
[37m[36mINFO[0m[0m 02/27 01:33:11 | Dataset: VLCS
