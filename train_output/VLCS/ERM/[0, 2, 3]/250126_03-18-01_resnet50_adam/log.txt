[37m[36mINFO[0m[0m 01/26 03:18:01 | Command :: /jsm0707/Large-scale/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm ERM --test_envs 0 2 3 --dataset VLCS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: ERM
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_adam.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_adam
	out_dir: train_output/VLCS/ERM/[0, 2, 3]/250126_03-18-01_resnet50_adam
	out_root: train_output/VLCS/ERM/[0, 2, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 2, 3]
	trial_seed: 0
	unique_name: 250126_03-18-01_resnet50_adam
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: adam
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 01/26 03:18:01 | n_steps = 5001
[37m[36mINFO[0m[0m 01/26 03:18:01 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 01/26 03:18:01 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 01/26 03:18:01 | 
[37m[36mINFO[0m[0m 01/26 03:18:02 | Testenv name escaping te_C_S_V -> te_C_S_V
[37m[36mINFO[0m[0m 01/26 03:18:02 | Test envs = [0, 2, 3], name = te_C_S_V
[37m[36mINFO[0m[0m 01/26 03:18:02 | Train environments: [1], Test environments: [0, 2, 3]
[37m[36mINFO[0m[0m 01/26 03:18:02 | Batch sizes for each domain: [0, 32, 0, 0] (total=32)
[37m[36mINFO[0m[0m 01/26 03:18:02 | steps-per-epoch for each domain: 66.41 -> min = 66.41
[37m[36mINFO[0m[0m 01/26 03:18:03 | # of params = 23518277
[37m[36mINFO[0m[0m 01/26 03:20:05 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 01/26 03:20:05 | 0.206158    0.195549    0.482353    0.459510    1.281990    0.089223    0.063604    0.482353    0.459510    0.313404    0.318598    0.215846    0.204444    0           0.000000    1.627299    1.276294    121.146395 
[37m[36mINFO[0m[0m 01/26 03:25:59 | 0.740486    0.730601    0.755765    0.768362    0.638717    0.934629    0.918728    0.755765    0.768362    0.609673    0.596037    0.677157    0.677037    200         3.011765    0.697925    1.145901    124.099458 
[37m[36mINFO[0m[0m 01/26 03:31:49 | 0.647316    0.629492    0.852235    0.772128    0.603182    0.711131    0.689046    0.852235    0.772128    0.632521    0.611280    0.598297    0.588148    400         6.023529    0.486239    1.131314    123.966792 
[37m[36mINFO[0m[0m 01/26 03:37:53 | 0.744231    0.745487    0.889412    0.785311    0.600361    0.900177    0.943463    0.889412    0.785311    0.601676    0.567073    0.730840    0.725926    600         9.035294    0.394003    1.174916    128.993328 
[37m[36mINFO[0m[0m 01/26 03:43:44 | 0.587043    0.555138    0.920000    0.787194    0.619038    0.521201    0.473498    0.920000    0.787194    0.587205    0.554878    0.652721    0.637037    800         12.047059   0.285629    1.134596    123.533109 
[37m[36mINFO[0m[0m 01/26 03:49:37 | 0.529377    0.494154    0.937882    0.770245    0.673224    0.460247    0.424028    0.937882    0.770245    0.552171    0.496951    0.575713    0.561481    1000        15.058824   0.263244    1.143999    124.622327 
[37m[36mINFO[0m[0m 01/26 03:55:32 | 0.631346    0.628522    0.953412    0.760829    0.966018    0.684629    0.710247    0.953412    0.760829    0.568165    0.544207    0.641244    0.631111    1200        18.070588   0.181544    1.144892    125.729028 
[37m[36mINFO[0m[0m 01/26 04:01:22 | 0.526343    0.528015    0.938824    0.758945    0.838564    0.416078    0.413428    0.938824    0.758945    0.535034    0.535061    0.627916    0.635556    1400        21.082353   0.145368    1.123631    125.484545 
[37m[36mINFO[0m[0m 01/26 04:07:12 | 0.659676    0.664891    0.962353    0.762712    1.153540    0.806537    0.812721    0.962353    0.762712    0.518660    0.516768    0.653832    0.665185    1600        24.094118   0.101034    1.137044    122.786640 
[37m[36mINFO[0m[0m 01/26 04:13:05 | 0.529747    0.500406    0.954824    0.762712    1.271356    0.382509    0.385159    0.954824    0.762712    0.591775    0.544207    0.614957    0.571852    1800        27.105882   0.106180    1.148706    123.066466 
[37m[36mINFO[0m[0m 01/26 04:18:57 | 0.500346    0.491379    0.976941    0.785311    0.904815    0.330389    0.321555    0.976941    0.785311    0.545697    0.525915    0.624954    0.626667    2000        30.117647   0.089012    1.143230    123.237215 
[37m[36mINFO[0m[0m 01/26 04:24:50 | 0.534683    0.523800    0.980235    0.800377    1.096698    0.440813    0.438163    0.980235    0.800377    0.545316    0.522866    0.617919    0.610370    2200        33.129412   0.069966    1.152624    122.360908 
[37m[36mINFO[0m[0m 01/26 04:30:41 | 0.652049    0.655323    0.971765    0.785311    1.294154    0.804770    0.812721    0.971765    0.785311    0.491622    0.496951    0.659756    0.656296    2400        36.141176   0.061086    1.133687    124.700731 
[37m[36mINFO[0m[0m 01/26 04:36:28 | 0.531496    0.524731    0.976000    0.772128    1.385245    0.460247    0.445230    0.976000    0.772128    0.541127    0.528963    0.593114    0.600000    2600        39.152941   0.073710    1.112989    124.487778 
[37m[36mINFO[0m[0m 01/26 04:42:18 | 0.605089    0.585938    0.983059    0.757062    1.216072    0.647527    0.660777    0.983059    0.757062    0.534273    0.500000    0.633469    0.597037    2800        42.164706   0.052412    1.126336    124.326535 
[37m[36mINFO[0m[0m 01/26 04:48:17 | 0.488801    0.484086    0.982588    0.762712    1.013560    0.300353    0.303887    0.982588    0.762712    0.606626    0.586890    0.559422    0.561481    3000        45.176471   0.076539    1.155274    127.773543 
[37m[36mINFO[0m[0m 01/26 04:54:12 | 0.598907    0.579993    0.991059    0.785311    1.302931    0.628092    0.607774    0.991059    0.785311    0.512947    0.486280    0.655683    0.645926    3200        48.188235   0.048189    1.133838    128.450337 
[37m[36mINFO[0m[0m 01/26 05:00:04 | 0.608877    0.604505    0.989176    0.751412    1.126711    0.658127    0.674912    0.989176    0.751412    0.535034    0.503049    0.633469    0.635556    3400        51.200000   0.044008    1.123203    127.587593 
[37m[36mINFO[0m[0m 01/26 05:06:00 | 0.564829    0.553423    0.987294    0.787194    1.009565    0.571555    0.561837    0.987294    0.787194    0.507235    0.496951    0.615698    0.601481    3600        54.211765   0.055600    1.140542    127.436496 
[37m[36mINFO[0m[0m 01/26 05:11:53 | 0.514439    0.488881    0.993882    0.758945    1.240871    0.350707    0.321555    0.993882    0.758945    0.549886    0.522866    0.642725    0.622222    3800        57.223529   0.033284    1.135133    125.697480 
[37m[36mINFO[0m[0m 01/26 05:17:44 | 0.521611    0.516058    0.992471    0.792844    1.186067    0.343640    0.335689    0.992471    0.792844    0.565880    0.548780    0.655313    0.663704    4000        60.235294   0.056290    1.132289    124.707811 
[37m[36mINFO[0m[0m 01/26 05:23:41 | 0.518706    0.518276    0.986353    0.783427    1.464568    0.321555    0.335689    0.986353    0.783427    0.580731    0.574695    0.653832    0.644444    4200        63.247059   0.044958    1.150972    127.418514 
[37m[36mINFO[0m[0m 01/26 05:29:37 | 0.453184    0.454289    0.989647    0.764595    1.285094    0.296820    0.282686    0.989647    0.764595    0.472582    0.480183    0.590152    0.600000    4400        66.258824   0.049573    1.146232    126.619931 
[37m[36mINFO[0m[0m 01/26 05:35:32 | 0.514983    0.522049    0.979294    0.772128    1.351660    0.401060    0.409894    0.979294    0.772128    0.488576    0.498476    0.655313    0.657778    4600        69.270588   0.027780    1.150648    124.867308 
[37m[36mINFO[0m[0m 01/26 05:41:23 | 0.488451    0.473030    0.998118    0.785311    1.115631    0.324205    0.286219    0.998118    0.785311    0.576542    0.562500    0.564606    0.570370    4800        72.282353   0.044596    1.129658    124.302139 
[37m[36mINFO[0m[0m 01/26 05:47:14 | 0.520216    0.516518    0.989647    0.764595    1.181861    0.422261    0.416961    0.989647    0.764595    0.503808    0.500000    0.634580    0.632593    5000        75.294118   0.027961    1.136413    124.505238 
[37m[36mINFO[0m[0m 01/26 05:47:14 | Cumulative gradient change saved at train_output/VLCS/ERM/[0, 2, 3]/250126_03-18-01_resnet50_adam/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 01/26 05:47:16 | ---
[37m[36mINFO[0m[0m 01/26 05:47:16 | test-domain validation(oracle) = 74.423%
[37m[36mINFO[0m[0m 01/26 05:47:16 | training-domain validation(iid) = 53.468%
[37m[36mINFO[0m[0m 01/26 05:47:16 | last = 52.022%
[37m[36mINFO[0m[0m 01/26 05:47:16 | last (inD) = 76.460%
[37m[36mINFO[0m[0m 01/26 05:47:16 | training-domain validation (iid, inD) = 80.038%
[37m[36mINFO[0m[0m 01/26 05:47:16 | === Summary ===
[37m[36mINFO[0m[0m 01/26 05:47:16 | Command: /jsm0707/Large-scale/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm ERM --test_envs 0 2 3 --dataset VLCS
[37m[36mINFO[0m[0m 01/26 05:47:16 | Unique name: 250126_03-18-01_resnet50_adam
[37m[36mINFO[0m[0m 01/26 05:47:16 | Out path: train_output/VLCS/ERM/[0, 2, 3]/250126_03-18-01_resnet50_adam
[37m[36mINFO[0m[0m 01/26 05:47:16 | Algorithm: ERM
[37m[36mINFO[0m[0m 01/26 05:47:16 | Dataset: VLCS
