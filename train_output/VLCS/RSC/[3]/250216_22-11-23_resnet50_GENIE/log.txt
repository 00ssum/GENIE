[37m[36mINFO[0m[0m 02/16 22:11:23 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm RSC --test_envs 3 --dataset VLCS --trial_seed 1 --hparams_seed 17
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: RSC
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 17
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/VLCS/RSC/[3]/250216_22-11-23_resnet50_GENIE
	out_root: train_output/VLCS/RSC/[3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [3]
	trial_seed: 1
	unique_name: 250216_22-11-23_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.5
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 0.0002990700776954947
	batch_size: 8
	weight_decay: 4.0966675521600606e-05
	rsc_f_drop_factor: 0.0021514793933271603
	rsc_b_drop_factor: 0.3977570179108589
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 02/16 22:11:23 | n_steps = 5001
[37m[36mINFO[0m[0m 02/16 22:11:23 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/16 22:11:23 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/16 22:11:23 | 
[37m[36mINFO[0m[0m 02/16 22:11:23 | Testenv name escaping te_V -> te_V
[37m[36mINFO[0m[0m 02/16 22:11:23 | Test envs = [3], name = te_V
[37m[36mINFO[0m[0m 02/16 22:11:23 | Train environments: [0, 1, 2], Test environments: [3]
[37m[36mINFO[0m[0m 02/16 22:11:23 | Batch sizes for each domain: [8, 8, 8, 0] (total=24)
[37m[36mINFO[0m[0m 02/16 22:11:23 | steps-per-epoch for each domain: 141.50, 265.62, 328.25 -> min = 141.50
[37m[36mINFO[0m[0m 02/16 22:11:24 | # of params = 23518277
[37m[36mINFO[0m[0m 02/16 22:13:37 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 02/16 22:13:37 | 0.453536    0.405926    0.485800    0.499658    1.378220    0.613958    0.618375    0.466824    0.461394    0.376618    0.419207    0.453536    0.405926    0           0.000000    1.981833    0.955470    132.125220 
[37m[36mINFO[0m[0m 02/16 22:16:59 | 0.728249    0.700741    0.818198    0.832075    0.462751    0.991166    0.992933    0.728471    0.721281    0.734958    0.782012    0.728249    0.700741    200         1.413428    0.666820    0.291854    143.410233 
[37m[36mINFO[0m[0m 02/16 22:20:14 | 0.773787    0.755556    0.846673    0.847583    0.402585    1.000000    1.000000    0.740706    0.736347    0.799315    0.806402    0.773787    0.755556    400         2.826855    0.464002    0.317020    132.141853 
[37m[36mINFO[0m[0m 02/16 22:23:28 | 0.737134    0.717037    0.852345    0.845275    0.402958    0.998233    0.989399    0.763294    0.747646    0.795506    0.798780    0.737134    0.717037    600         4.240283    0.444028    0.310796    131.339536 
[37m[36mINFO[0m[0m 02/16 22:26:49 | 0.729730    0.720000    0.866846    0.855565    0.386045    1.000000    1.000000    0.776471    0.774011    0.824067    0.792683    0.729730    0.720000    800         5.653710    0.406431    0.317676    137.938027 
[37m[36mINFO[0m[0m 02/16 22:30:03 | 0.703813    0.712593    0.831909    0.820435    0.433884    0.999117    0.989399    0.690824    0.700565    0.805788    0.771341    0.703813    0.712593    1000        7.067138    0.389871    0.296002    134.704813 
[37m[36mINFO[0m[0m 02/16 22:33:15 | 0.729730    0.706667    0.876750    0.837845    0.404245    0.998233    0.992933    0.795765    0.740113    0.836253    0.780488    0.729730    0.706667    1200        8.480565    0.364656    0.298815    132.337967 
[37m[36mINFO[0m[0m 02/16 22:36:40 | 0.694187    0.694815    0.868635    0.833105    0.436040    0.999117    0.996466    0.779294    0.758945    0.827494    0.743902    0.694187    0.694815    1400        9.893993    0.342455    0.323993    140.304466 
[37m[36mINFO[0m[0m 02/16 22:40:02 | 0.692706    0.677037    0.873504    0.839143    0.415086    0.998233    0.996466    0.806588    0.774011    0.815689    0.746951    0.692706    0.677037    1600        11.307420   0.331713    0.309988    139.682681 
[37m[36mINFO[0m[0m 02/16 22:43:17 | 0.790818    0.767407    0.888054    0.851433    0.415581    0.999117    0.989399    0.821176    0.764595    0.843869    0.800305    0.790818    0.767407    1800        12.720848   0.334122    0.297009    135.342958 
[37m[36mINFO[0m[0m 02/16 22:46:33 | 0.696039    0.691852    0.875650    0.829667    0.440384    0.997350    0.996466    0.799059    0.760829    0.830541    0.731707    0.696039    0.691852    2000        14.134276   0.309054    0.305905    135.171976 
[37m[36mINFO[0m[0m 02/16 22:49:59 | 0.767123    0.762963    0.879363    0.840893    0.407226    1.000000    0.992933    0.797647    0.740113    0.840442    0.789634    0.767123    0.762963    2200        15.547703   0.330086    0.332725    139.055979 
[37m[36mINFO[0m[0m 02/16 22:53:14 | 0.779341    0.761481    0.888709    0.844343    0.426647    0.998233    0.996466    0.830118    0.743879    0.837776    0.792683    0.779341    0.761481    2400        16.961131   0.287858    0.308141    133.240699 
[37m[36mINFO[0m[0m 02/16 22:56:36 | 0.778230    0.758519    0.881138    0.842777    0.473311    0.999117    0.992933    0.804235    0.745763    0.840061    0.789634    0.778230    0.758519    2600        18.374558   0.283541    0.325638    136.935306 
[37m[36mINFO[0m[0m 02/16 22:59:59 | 0.725287    0.706667    0.893584    0.847631    0.427924    0.998233    0.996466    0.824941    0.747646    0.857578    0.798780    0.725287    0.706667    2800        19.787986   0.294066    0.333176    136.944008 
[37m[36mINFO[0m[0m 02/16 23:03:09 | 0.731581    0.724444    0.912540    0.856353    0.436916    0.999117    0.985866    0.840941    0.764595    0.897563    0.818598    0.731581    0.724444    3000        21.201413   0.267422    0.294868    130.457314 
[37m[36mINFO[0m[0m 02/16 23:06:35 | 0.684191    0.662222    0.870700    0.811361    0.515891    1.000000    0.992933    0.789176    0.691149    0.822925    0.750000    0.684191    0.662222    3200        22.614841   0.280457    0.322671    141.548410 
[37m[36mINFO[0m[0m 02/16 23:09:55 | 0.706405    0.706667    0.862893    0.806913    0.538635    0.996466    0.985866    0.796706    0.706215    0.795506    0.728659    0.706405    0.706667    3400        24.028269   0.259875    0.317322    136.576785 
[37m[36mINFO[0m[0m 02/16 23:13:07 | 0.734543    0.746667    0.920088    0.852491    0.408530    1.000000    0.992933    0.861176    0.762712    0.899086    0.801829    0.734543    0.746667    3600        25.441696   0.289784    0.302965    131.320794 
[37m[36mINFO[0m[0m 02/16 23:16:35 | 0.713810    0.743704    0.907514    0.843117    0.438630    1.000000    0.996466    0.805176    0.732580    0.917365    0.800305    0.713810    0.743704    3800        26.855124   0.234278    0.309544    146.562484 
[37m[36mINFO[0m[0m 02/16 23:19:48 | 0.719733    0.705185    0.915502    0.845712    0.448502    1.000000    0.985866    0.856941    0.757062    0.889566    0.794207    0.719733    0.705185    4000        28.268551   0.237260    0.302385    132.366272 
[37m[36mINFO[0m[0m 02/16 23:23:01 | 0.721214    0.727407    0.902264    0.828536    0.498843    1.000000    0.989399    0.800471    0.708098    0.906321    0.788110    0.721214    0.727407    4200        29.681979   0.232501    0.297004    133.827584 
[37m[36mINFO[0m[0m 02/16 23:26:23 | 0.709367    0.688889    0.921110    0.836241    0.430138    0.995583    0.978799    0.864471    0.725047    0.903275    0.804878    0.709367    0.688889    4400        31.095406   0.231637    0.333154    135.241048 
[37m[36mINFO[0m[0m 02/16 23:29:39 | 0.635690    0.616296    0.909646    0.816741    0.479619    0.993816    0.992933    0.845176    0.711864    0.889947    0.745427    0.635690    0.616296    4600        32.508834   0.225909    0.318776    131.638555 
[37m[36mINFO[0m[0m 02/16 23:32:56 | 0.728249    0.730370    0.941765    0.857316    0.432215    0.999117    0.996466    0.899294    0.772128    0.926885    0.803354    0.728249    0.730370    4800        33.922261   0.220569    0.323265    133.025647 
[37m[36mINFO[0m[0m 02/16 23:36:23 | 0.652721    0.656296    0.924481    0.827006    0.491945    1.000000    0.996466    0.882353    0.726930    0.891089    0.757622    0.652721    0.656296    5000        35.335689   0.194116    0.365032    133.356237 
[37m[36mINFO[0m[0m 02/16 23:36:23 | Cumulative gradient change saved at train_output/VLCS/RSC/[3]/250216_22-11-23_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/16 23:36:24 | ---
[37m[36mINFO[0m[0m 02/16 23:36:24 | test-domain validation(oracle) = 79.082%
[37m[36mINFO[0m[0m 02/16 23:36:24 | training-domain validation(iid) = 72.825%
[37m[36mINFO[0m[0m 02/16 23:36:24 | last = 65.272%
[37m[36mINFO[0m[0m 02/16 23:36:24 | last (inD) = 82.701%
[37m[36mINFO[0m[0m 02/16 23:36:24 | training-domain validation (iid, inD) = 85.732%
[37m[36mINFO[0m[0m 02/16 23:36:24 | === Summary ===
[37m[36mINFO[0m[0m 02/16 23:36:24 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm RSC --test_envs 3 --dataset VLCS --trial_seed 1 --hparams_seed 17
[37m[36mINFO[0m[0m 02/16 23:36:24 | Unique name: 250216_22-11-23_resnet50_GENIE
[37m[36mINFO[0m[0m 02/16 23:36:24 | Out path: train_output/VLCS/RSC/[3]/250216_22-11-23_resnet50_GENIE
[37m[36mINFO[0m[0m 02/16 23:36:24 | Algorithm: RSC
[37m[36mINFO[0m[0m 02/16 23:36:24 | Dataset: VLCS
