[37m[36mINFO[0m[0m 02/16 08:21:00 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm RSC --test_envs 3 --dataset VLCS --trial_seed 1 --hparams_seed 10
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: RSC
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 10
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/VLCS/RSC/[3]/250216_08-21-00_resnet50_GENIE
	out_root: train_output/VLCS/RSC/[3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [3]
	trial_seed: 1
	unique_name: 250216_08-21-00_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.5
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 2.2128485336217652e-05
	batch_size: 9
	weight_decay: 0.00030907441430549757
	rsc_f_drop_factor: 0.11930737869274544
	rsc_b_drop_factor: 0.16188382214285657
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 02/16 08:21:00 | n_steps = 5001
[37m[36mINFO[0m[0m 02/16 08:21:00 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/16 08:21:00 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/16 08:21:00 | 
[37m[36mINFO[0m[0m 02/16 08:21:00 | Testenv name escaping te_V -> te_V
[37m[36mINFO[0m[0m 02/16 08:21:00 | Test envs = [3], name = te_V
[37m[36mINFO[0m[0m 02/16 08:21:00 | Train environments: [0, 1, 2], Test environments: [3]
[37m[36mINFO[0m[0m 02/16 08:21:00 | Batch sizes for each domain: [9, 9, 9, 0] (total=27)
[37m[36mINFO[0m[0m 02/16 08:21:00 | steps-per-epoch for each domain: 125.78, 236.11, 291.78 -> min = 125.78
[37m[36mINFO[0m[0m 02/16 08:21:02 | # of params = 23518277
[37m[36mINFO[0m[0m 02/16 08:23:38 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 02/16 08:23:38 | 0.453536    0.405926    0.485800    0.499658    1.386898    0.613958    0.618375    0.466824    0.461394    0.376618    0.419207    0.453536    0.405926    0           0.000000    2.364953    2.250410    153.373909 
[37m[36mINFO[0m[0m 02/16 08:27:31 | 0.674195    0.691852    0.774210    0.772809    0.572005    0.945230    0.925795    0.642824    0.636535    0.734577    0.756098    0.674195    0.691852    200         1.590106    0.830685    0.389537    155.336140 
[37m[36mINFO[0m[0m 02/16 08:31:24 | 0.710848    0.693333    0.827854    0.834592    0.446587    0.992933    0.985866    0.747294    0.741996    0.743336    0.775915    0.710848    0.693333    400         3.180212    0.556353    0.375603    157.649411 
[37m[36mINFO[0m[0m 02/16 08:35:16 | 0.689374    0.672593    0.830515    0.830103    0.473227    0.993816    0.992933    0.742588    0.738230    0.755141    0.759146    0.689374    0.672593    600         4.770318    0.498149    0.458348    140.313024 
[37m[36mINFO[0m[0m 02/16 08:39:07 | 0.749722    0.734815    0.853501    0.844778    0.413936    0.996466    0.992933    0.746824    0.721281    0.817212    0.820122    0.749722    0.734815    800         6.360424    0.440349    0.457249    140.248632 
[37m[36mINFO[0m[0m 02/16 08:42:47 | 0.738245    0.712593    0.864754    0.853298    0.401870    0.995583    0.992933    0.780706    0.751412    0.817974    0.815549    0.738245    0.712593    1000        7.950530    0.421771    0.383541    143.017976 
[37m[36mINFO[0m[0m 02/16 08:46:18 | 0.780452    0.773333    0.874512    0.859874    0.393598    0.999117    0.992933    0.785882    0.758945    0.838538    0.827744    0.780452    0.773333    1200        9.540636    0.412866    0.343071    142.292480 
[37m[36mINFO[0m[0m 02/16 08:49:54 | 0.772677    0.761481    0.877148    0.853997    0.387467    0.999117    0.996466    0.785412    0.743879    0.846915    0.821646    0.772677    0.761481    1400        11.130742   0.393366    0.367345    142.257484 
[37m[36mINFO[0m[0m 02/16 08:53:32 | 0.747871    0.761481    0.881783    0.855450    0.385298    0.998233    0.992933    0.799059    0.753296    0.848058    0.820122    0.747871    0.761481    1600        12.720848   0.380964    0.381922    141.952923 
[37m[36mINFO[0m[0m 02/16 08:57:11 | 0.770085    0.767407    0.891685    0.860215    0.398181    1.000000    0.996466    0.811765    0.745763    0.863290    0.838415    0.770085    0.767407    1800        14.310954   0.361635    0.382179    142.326844 
[37m[36mINFO[0m[0m 02/16 09:00:46 | 0.776379    0.764444    0.890376    0.857512    0.398906    1.000000    0.992933    0.797176    0.745763    0.873953    0.833841    0.776379    0.764444    2000        15.901060   0.363460    0.371790    140.569909 
[37m[36mINFO[0m[0m 02/16 09:04:24 | 0.770455    0.742222    0.876050    0.844163    0.419118    0.999117    0.996466    0.782118    0.725047    0.846915    0.810976    0.770455    0.742222    2200        17.491166   0.353641    0.349127    148.741752 
[37m[36mINFO[0m[0m 02/16 09:08:09 | 0.710478    0.705185    0.869413    0.824782    0.490854    0.999117    0.992933    0.791529    0.734463    0.817593    0.746951    0.710478    0.705185    2400        19.081272   0.317119    0.410571    142.231640 
[37m[36mINFO[0m[0m 02/16 09:12:02 | 0.714180    0.717037    0.893987    0.842298    0.454209    1.000000    0.992933    0.832000    0.738230    0.849962    0.795732    0.714180    0.717037    2600        20.671378   0.306856    0.446138    144.419788 
[37m[36mINFO[0m[0m 02/16 09:15:46 | 0.764161    0.734815    0.890939    0.842567    0.441503    1.000000    0.992933    0.816000    0.734463    0.856816    0.800305    0.764161    0.734815    2800        22.261484   0.296380    0.390365    146.063684 
[37m[36mINFO[0m[0m 02/16 09:19:31 | 0.700852    0.728889    0.901307    0.851983    0.395437    0.996466    0.992933    0.833882    0.762712    0.873572    0.800305    0.700852    0.728889    3000        23.851590   0.320068    0.375324    149.301403 
[37m[36mINFO[0m[0m 02/16 09:23:18 | 0.749352    0.731852    0.906474    0.847218    0.407348    0.998233    0.989399    0.840000    0.738230    0.881188    0.814024    0.749352    0.731852    3200        25.441696   0.292461    0.388209    149.212129 
[37m[36mINFO[0m[0m 02/16 09:27:11 | 0.740466    0.722963    0.909443    0.845556    0.431998    0.999117    0.992933    0.854118    0.749529    0.875095    0.794207    0.740466    0.722963    3400        27.031802   0.287921    0.458644    142.056076 
[37m[36mINFO[0m[0m 02/16 09:30:44 | 0.667901    0.671111    0.906059    0.845628    0.522265    1.000000    0.996466    0.812235    0.740113    0.905941    0.800305    0.667901    0.671111    3600        28.621908   0.301819    0.376016    136.909692 
[37m[36mINFO[0m[0m 02/16 09:34:15 | 0.687523    0.702222    0.917667    0.837767    0.473846    1.000000    0.996466    0.855059    0.736347    0.897944    0.780488    0.687523    0.702222    3800        30.212014   0.240682    0.359162    139.782072 
[37m[36mINFO[0m[0m 02/16 09:37:45 | 0.560903    0.560000    0.914996    0.828830    0.487030    1.000000    0.996466    0.864941    0.747646    0.880046    0.742378    0.560903    0.560000    4000        31.802120   0.251417    0.370216    135.795614 
[37m[36mINFO[0m[0m 02/16 09:41:23 | 0.736394    0.711111    0.916518    0.843596    0.444944    1.000000    0.996466    0.856941    0.740113    0.892612    0.794207    0.736394    0.711111    4200        33.392226   0.251178    0.419084    134.317493 
[37m[36mINFO[0m[0m 02/16 09:45:03 | 0.720104    0.714074    0.885908    0.823443    0.618401    0.998233    0.985866    0.824000    0.734463    0.835491    0.750000    0.720104    0.714074    4400        34.982332   0.247132    0.392307    141.654932 
[37m[36mINFO[0m[0m 02/16 09:48:33 | 0.732692    0.724444    0.925835    0.842059    0.457869    0.999117    0.992933    0.874353    0.734463    0.904037    0.798780    0.732692    0.724444    4600        36.572438   0.261271    0.375193    134.759038 
[37m[36mINFO[0m[0m 02/16 09:52:06 | 0.740466    0.757037    0.933071    0.845227    0.483546    0.996466    0.992933    0.892235    0.736347    0.910510    0.806402    0.740466    0.757037    4800        38.162544   0.245164    0.379852    137.050393 
[37m[36mINFO[0m[0m 02/16 09:55:45 | 0.723436    0.736296    0.936515    0.839955    0.510178    0.999117    0.989399    0.894588    0.743879    0.915842    0.786585    0.723436    0.736296    5000        39.752650   0.210815    0.427027    133.575059 
[37m[36mINFO[0m[0m 02/16 09:55:45 | Cumulative gradient change saved at train_output/VLCS/RSC/[3]/250216_08-21-00_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/16 09:55:47 | ---
[37m[36mINFO[0m[0m 02/16 09:55:47 | test-domain validation(oracle) = 78.045%
[37m[36mINFO[0m[0m 02/16 09:55:47 | training-domain validation(iid) = 77.009%
[37m[36mINFO[0m[0m 02/16 09:55:47 | last = 72.344%
[37m[36mINFO[0m[0m 02/16 09:55:47 | last (inD) = 83.995%
[37m[36mINFO[0m[0m 02/16 09:55:47 | training-domain validation (iid, inD) = 86.021%
[37m[36mINFO[0m[0m 02/16 09:55:47 | === Summary ===
[37m[36mINFO[0m[0m 02/16 09:55:47 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm RSC --test_envs 3 --dataset VLCS --trial_seed 1 --hparams_seed 10
[37m[36mINFO[0m[0m 02/16 09:55:47 | Unique name: 250216_08-21-00_resnet50_GENIE
[37m[36mINFO[0m[0m 02/16 09:55:47 | Out path: train_output/VLCS/RSC/[3]/250216_08-21-00_resnet50_GENIE
[37m[36mINFO[0m[0m 02/16 09:55:47 | Algorithm: RSC
[37m[36mINFO[0m[0m 02/16 09:55:47 | Dataset: VLCS
