[37m[36mINFO[0m[0m 02/16 16:04:57 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm RSC --test_envs 3 --dataset VLCS --trial_seed 1 --hparams_seed 14
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: RSC
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 14
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/VLCS/RSC/[3]/250216_16-04-57_resnet50_GENIE
	out_root: train_output/VLCS/RSC/[3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [3]
	trial_seed: 1
	unique_name: 250216_16-04-57_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.1
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 0.00011127987942826837
	batch_size: 12
	weight_decay: 3.236767350601091e-05
	rsc_f_drop_factor: 0.35742650108556256
	rsc_b_drop_factor: 0.042922531276760933
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 02/16 16:04:57 | n_steps = 5001
[37m[36mINFO[0m[0m 02/16 16:04:57 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/16 16:04:57 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/16 16:04:57 | 
[37m[36mINFO[0m[0m 02/16 16:04:57 | Testenv name escaping te_V -> te_V
[37m[36mINFO[0m[0m 02/16 16:04:57 | Test envs = [3], name = te_V
[37m[36mINFO[0m[0m 02/16 16:04:57 | Train environments: [0, 1, 2], Test environments: [3]
[37m[36mINFO[0m[0m 02/16 16:04:57 | Batch sizes for each domain: [12, 12, 12, 0] (total=36)
[37m[36mINFO[0m[0m 02/16 16:04:57 | steps-per-epoch for each domain: 94.33, 177.08, 218.83 -> min = 94.33
[37m[36mINFO[0m[0m 02/16 16:04:59 | # of params = 23518277
[37m[36mINFO[0m[0m 02/16 16:07:22 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 02/16 16:07:22 | 0.453536    0.405926    0.485800    0.499658    1.393036    0.613958    0.618375    0.466824    0.461394    0.376618    0.419207    0.453536    0.405926    0           0.000000    2.301101    1.317409    142.021084 
[37m[36mINFO[0m[0m 02/16 16:11:26 | 0.719733    0.718519    0.828421    0.832852    0.444816    0.995583    0.992933    0.722353    0.717514    0.767327    0.788110    0.719733    0.718519    200         2.120141    0.717949    0.502078    143.045303 
[37m[36mINFO[0m[0m 02/16 16:15:32 | 0.704924    0.709630    0.837586    0.835094    0.422472    0.998233    0.992933    0.730824    0.728814    0.783701    0.783537    0.704924    0.709630    400         4.240283    0.515429    0.463251    154.019395 
[37m[36mINFO[0m[0m 02/16 16:19:34 | 0.751944    0.745185    0.837879    0.838154    0.426526    1.000000    0.996466    0.692235    0.702448    0.821401    0.815549    0.751944    0.745185    600         6.360424    0.482372    0.465486    148.722118 
[37m[36mINFO[0m[0m 02/16 16:23:35 | 0.762680    0.730370    0.863644    0.857047    0.392830    0.998233    0.996466    0.779294    0.775895    0.813404    0.798780    0.762680    0.730370    800         8.480565    0.446817    0.458686    148.813375 
[37m[36mINFO[0m[0m 02/16 16:27:39 | 0.750093    0.734815    0.882731    0.852384    0.387434    1.000000    0.996466    0.804706    0.766478    0.843488    0.794207    0.750093    0.734815    1000        10.600707   0.437623    0.527490    138.675190 
[37m[36mINFO[0m[0m 02/16 16:31:48 | 0.778971    0.776296    0.888338    0.863264    0.377075    1.000000    0.996466    0.799059    0.777778    0.865956    0.815549    0.778971    0.776296    1200        12.720848   0.419317    0.544475    140.213738 
[37m[36mINFO[0m[0m 02/16 16:35:42 | 0.686412    0.697778    0.851016    0.820382    0.460761    0.999117    1.000000    0.739765    0.708098    0.814166    0.753049    0.686412    0.697778    1400        14.840989   0.405329    0.494842    135.007121 
[37m[36mINFO[0m[0m 02/16 16:40:01 | 0.774528    0.773333    0.879148    0.846842    0.416677    0.998233    0.992933    0.799529    0.745763    0.839680    0.801829    0.774528    0.773333    1600        16.961131   0.398699    0.537100    151.321684 
[37m[36mINFO[0m[0m 02/16 16:43:55 | 0.752684    0.758519    0.880443    0.849293    0.419859    0.999117    0.992933    0.803294    0.768362    0.838919    0.786585    0.752684    0.758519    1800        19.081272   0.367454    0.459452    142.228257 
[37m[36mINFO[0m[0m 02/16 16:47:47 | 0.748241    0.776296    0.900858    0.852849    0.377186    0.999117    0.992933    0.808941    0.736347    0.894516    0.829268    0.748241    0.776296    2000        21.201413   0.365873    0.483781    135.260797 
[37m[36mINFO[0m[0m 02/16 16:51:28 | 0.780452    0.774815    0.905382    0.852443    0.407387    1.000000    0.996466    0.831529    0.751412    0.884615    0.809451    0.780452    0.774815    2200        23.321555   0.351340    0.446481    132.128190 
[37m[36mINFO[0m[0m 02/16 16:55:09 | 0.764161    0.758519    0.921708    0.859737    0.382090    1.000000    0.996466    0.860706    0.770245    0.904417    0.812500    0.764161    0.758519    2400        25.441696   0.314855    0.443931    132.474594 
[37m[36mINFO[0m[0m 02/16 16:58:52 | 0.742688    0.745185    0.923821    0.855941    0.435946    1.000000    0.996466    0.864000    0.766478    0.907464    0.804878    0.742688    0.745185    2600        27.561837   0.309740    0.431369    135.846682 
[37m[36mINFO[0m[0m 02/16 17:02:44 | 0.748982    0.728889    0.921065    0.844582    0.449361    1.000000    0.996466    0.854588    0.747646    0.908606    0.789634    0.748982    0.728889    2800        29.681979   0.297829    0.492541    134.308298 
[37m[36mINFO[0m[0m 02/16 17:06:31 | 0.746020    0.740741    0.902790    0.852342    0.462409    0.997350    0.992933    0.846588    0.768362    0.864433    0.795732    0.746020    0.740741    3000        31.802120   0.311107    0.441532    138.399401 
[37m[36mINFO[0m[0m 02/16 17:10:31 | 0.736394    0.748148    0.929600    0.849634    0.451289    1.000000    0.996466    0.863059    0.755179    0.925743    0.797256    0.736394    0.748148    3200        33.922261   0.292232    0.504223    139.564276 
[37m[36mINFO[0m[0m 02/16 17:14:33 | 0.704924    0.684444    0.934412    0.836572    0.438464    1.000000    0.996466    0.882824    0.749529    0.920411    0.763720    0.704924    0.684444    3400        36.042403   0.278659    0.529382    136.111715 
[37m[36mINFO[0m[0m 02/16 17:18:43 | 0.691225    0.718519    0.865706    0.797879    0.554541    1.000000    0.992933    0.734588    0.662900    0.862529    0.737805    0.691225    0.718519    3600        38.162544   0.252267    0.574953    134.375641 
[37m[36mINFO[0m[0m 02/16 17:22:45 | 0.734913    0.740741    0.942879    0.851271    0.469850    1.000000    0.985866    0.884235    0.764595    0.944402    0.803354    0.734913    0.740741    3800        40.282686   0.262094    0.538141    134.155516 
[37m[36mINFO[0m[0m 02/16 17:26:53 | 0.665309    0.657778    0.928980    0.834646    0.538191    0.999117    0.992933    0.881882    0.745763    0.905941    0.765244    0.665309    0.657778    4000        42.402827   0.226852    0.555975    137.443318 
[37m[36mINFO[0m[0m 02/16 17:30:54 | 0.703443    0.708148    0.938421    0.839620    0.614005    1.000000    0.996466    0.880000    0.749529    0.935263    0.772866    0.703443    0.708148    4200        44.522968   0.226480    0.527189    134.974319 
[37m[36mINFO[0m[0m 02/16 17:34:48 | 0.689374    0.684444    0.943046    0.833983    0.526898    0.998233    1.000000    0.894118    0.738230    0.936786    0.763720    0.689374    0.684444    4400        46.643110   0.240664    0.495393    134.864455 
[37m[36mINFO[0m[0m 02/16 17:38:37 | 0.742318    0.730370    0.953048    0.842836    0.641549    0.999117    0.992933    0.903059    0.730697    0.956969    0.804878    0.742318    0.730370    4600        48.763251   0.199894    0.453659    138.261425 
[37m[36mINFO[0m[0m 02/16 17:42:18 | 0.689374    0.691852    0.943421    0.832716    0.593596    1.000000    0.996466    0.916706    0.760829    0.913557    0.740854    0.689374    0.691852    4800        50.883392   0.208889    0.444354    132.804078 
[37m[36mINFO[0m[0m 02/16 17:46:05 | 0.687523    0.691852    0.947736    0.824601    0.710327    0.981449    0.957597    0.918118    0.725047    0.943641    0.791159    0.687523    0.691852    5000        53.003534   0.200167    0.443699    138.028343 
[37m[36mINFO[0m[0m 02/16 17:46:05 | Cumulative gradient change saved at train_output/VLCS/RSC/[3]/250216_16-04-57_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/16 17:46:07 | ---
[37m[36mINFO[0m[0m 02/16 17:46:07 | test-domain validation(oracle) = 77.897%
[37m[36mINFO[0m[0m 02/16 17:46:07 | training-domain validation(iid) = 77.897%
[37m[36mINFO[0m[0m 02/16 17:46:07 | last = 68.752%
[37m[36mINFO[0m[0m 02/16 17:46:07 | last (inD) = 82.460%
[37m[36mINFO[0m[0m 02/16 17:46:07 | training-domain validation (iid, inD) = 86.326%
[37m[36mINFO[0m[0m 02/16 17:46:07 | === Summary ===
[37m[36mINFO[0m[0m 02/16 17:46:07 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm RSC --test_envs 3 --dataset VLCS --trial_seed 1 --hparams_seed 14
[37m[36mINFO[0m[0m 02/16 17:46:07 | Unique name: 250216_16-04-57_resnet50_GENIE
[37m[36mINFO[0m[0m 02/16 17:46:07 | Out path: train_output/VLCS/RSC/[3]/250216_16-04-57_resnet50_GENIE
[37m[36mINFO[0m[0m 02/16 17:46:07 | Algorithm: RSC
[37m[36mINFO[0m[0m 02/16 17:46:07 | Dataset: VLCS
