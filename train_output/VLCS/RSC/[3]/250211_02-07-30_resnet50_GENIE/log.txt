[37m[36mINFO[0m[0m 02/11 02:07:30 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm RSC --test_envs 3 --dataset VLCS --trial_seed 0 --hparams_seed 10
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: RSC
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 10
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/VLCS/RSC/[3]/250211_02-07-30_resnet50_GENIE
	out_root: train_output/VLCS/RSC/[3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [3]
	trial_seed: 0
	unique_name: 250211_02-07-30_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.5
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 2.5980189819232268e-05
	batch_size: 22
	weight_decay: 1.2831747186887755e-05
	rsc_f_drop_factor: 0.49049801895660045
	rsc_b_drop_factor: 0.13734507450069044
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 02/11 02:07:30 | n_steps = 5001
[37m[36mINFO[0m[0m 02/11 02:07:30 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/11 02:07:30 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/11 02:07:30 | 
[37m[36mINFO[0m[0m 02/11 02:07:30 | Testenv name escaping te_V -> te_V
[37m[36mINFO[0m[0m 02/11 02:07:30 | Test envs = [3], name = te_V
[37m[36mINFO[0m[0m 02/11 02:07:30 | Train environments: [0, 1, 2], Test environments: [3]
[37m[36mINFO[0m[0m 02/11 02:07:30 | Batch sizes for each domain: [22, 22, 22, 0] (total=66)
[37m[36mINFO[0m[0m 02/11 02:07:30 | steps-per-epoch for each domain: 51.45, 96.59, 119.36 -> min = 51.45
[37m[36mINFO[0m[0m 02/11 02:07:31 | # of params = 23518277
[37m[36mINFO[0m[0m 02/11 02:09:48 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 02/11 02:09:48 | 0.443539    0.445926    0.484878    0.500802    1.257335    0.611307    0.628975    0.460235    0.487759    0.383092    0.385671    0.443539    0.445926    0           0.000000    2.473121    1.460619    135.791655 
[37m[36mINFO[0m[0m 02/11 02:14:55 | 0.699741    0.693333    0.819144    0.820221    0.470591    0.982332    0.978799    0.731765    0.760829    0.743336    0.721037    0.699741    0.693333    200         3.886926    0.842759    0.835185    139.365641 
[37m[36mINFO[0m[0m 02/11 02:20:01 | 0.749352    0.757037    0.851537    0.843577    0.409906    0.997350    1.000000    0.723294    0.721281    0.833968    0.809451    0.749352    0.757037    400         7.773852    0.649044    0.840071    138.539190 
[37m[36mINFO[0m[0m 02/11 02:25:06 | 0.753054    0.762963    0.873685    0.854297    0.387476    1.000000    0.996466    0.772235    0.764595    0.848819    0.801829    0.753054    0.762963    600         11.660777   0.581792    0.834123    137.745531 
[37m[36mINFO[0m[0m 02/11 02:30:08 | 0.782303    0.797037    0.892468    0.855911    0.383787    1.000000    0.996466    0.806118    0.774011    0.871287    0.797256    0.782303    0.797037    800         15.547703   0.533010    0.828246    136.465000 
[37m[36mINFO[0m[0m 02/11 02:35:07 | 0.756757    0.755556    0.884149    0.837605    0.434004    0.998233    0.992933    0.786353    0.736347    0.867860    0.783537    0.756757    0.755556    1000        19.434629   0.510849    0.819154    135.446575 
[37m[36mINFO[0m[0m 02/11 02:40:15 | 0.799334    0.810370    0.903246    0.857239    0.408283    1.000000    1.000000    0.833882    0.800377    0.875857    0.771341    0.799334    0.810370    1200        23.321555   0.502249    0.863144    135.039556 
[37m[36mINFO[0m[0m 02/11 02:45:24 | 0.784154    0.789630    0.911810    0.866535    0.442400    1.000000    1.000000    0.826824    0.794727    0.908606    0.804878    0.784154    0.789630    1400        27.208481   0.466161    0.838070    141.181555 
[37m[36mINFO[0m[0m 02/11 02:50:27 | 0.781933    0.770370    0.917833    0.853593    0.429538    1.000000    1.000000    0.861647    0.790960    0.891851    0.769817    0.781933    0.770370    1600        31.095406   0.455818    0.821974    138.618243 
[37m[36mINFO[0m[0m 02/11 02:55:28 | 0.788227    0.795556    0.919892    0.857884    0.476678    1.000000    0.996466    0.854118    0.789077    0.905560    0.788110    0.788227    0.795556    1800        34.982332   0.426480    0.837925    134.149434 
[37m[36mINFO[0m[0m 02/11 03:00:31 | 0.757497    0.765926    0.906837    0.831610    0.552503    1.000000    0.996466    0.824471    0.751412    0.896040    0.746951    0.757497    0.765926    2000        38.869258   0.410056    0.834626    135.296097 
[37m[36mINFO[0m[0m 02/11 03:05:36 | 0.766383    0.773333    0.925404    0.848571    0.446011    1.000000    1.000000    0.864941    0.775895    0.911272    0.769817    0.766383    0.773333    2200        42.756184   0.421146    0.850006    135.103977 
[37m[36mINFO[0m[0m 02/11 03:10:35 | 0.758608    0.771852    0.947892    0.861962    0.557026    1.000000    1.000000    0.901176    0.794727    0.942498    0.791159    0.758608    0.771852    2400        46.643110   0.386512    0.829691    133.554194 
[37m[36mINFO[0m[0m 02/11 03:15:38 | 0.770455    0.773333    0.939998    0.845671    0.557413    1.000000    1.000000    0.890824    0.770245    0.929170    0.766768    0.770455    0.773333    2600        50.530035   0.356605    0.854900    131.353247 
[37m[36mINFO[0m[0m 02/11 03:20:48 | 0.748982    0.752593    0.956510    0.843925    0.514121    1.000000    0.996466    0.912941    0.753296    0.956588    0.782012    0.748982    0.752593    2800        54.416961   0.339540    0.880335    134.450043 
[37m[36mINFO[0m[0m 02/11 03:25:51 | 0.744909    0.733333    0.938772    0.816617    0.671828    1.000000    1.000000    0.879529    0.728814    0.936786    0.721037    0.744909    0.733333    3000        58.303887   0.330051    0.832376    136.210271 
[37m[36mINFO[0m[0m 02/11 03:30:52 | 0.723436    0.720000    0.967467    0.856432    0.666807    1.000000    1.000000    0.943529    0.779661    0.958873    0.789634    0.723436    0.720000    3200        62.190813   0.313574    0.836839    133.662992 
[37m[36mINFO[0m[0m 02/11 03:35:58 | 0.767123    0.782222    0.964202    0.846388    0.576146    1.000000    1.000000    0.926118    0.749529    0.966489    0.789634    0.767123    0.782222    3400        66.077739   0.317562    0.860437    134.397114 
[37m[36mINFO[0m[0m 02/11 03:40:59 | 0.731951    0.743704    0.967195    0.859050    0.838300    0.999117    0.996466    0.937882    0.783427    0.964585    0.797256    0.731951    0.743704    3600        69.964664   0.308278    0.832174    134.154757 
[37m[36mINFO[0m[0m 02/11 03:46:02 | 0.747131    0.764444    0.979125    0.848797    0.757435    1.000000    0.996466    0.957176    0.774011    0.980198    0.775915    0.747131    0.764444    3800        73.851590   0.285546    0.839197    135.481658 
[37m[36mINFO[0m[0m 02/11 03:51:05 | 0.730100    0.728889    0.967578    0.834042    0.781008    1.000000    1.000000    0.931294    0.723164    0.971439    0.778963    0.730100    0.728889    4000        77.738516   0.283657    0.842229    134.310820 
[37m[36mINFO[0m[0m 02/11 03:56:06 | 0.743058    0.748148    0.981037    0.842831    0.755206    1.000000    1.000000    0.963294    0.749529    0.979817    0.778963    0.743058    0.748148    4200        81.625442   0.280798    0.828405    134.830355 
[37m[36mINFO[0m[0m 02/11 04:01:07 | 0.695298    0.697778    0.977457    0.830581    0.905883    0.999117    0.992933    0.959529    0.745763    0.973724    0.753049    0.695298    0.697778    4400        85.512367   0.261942    0.830247    135.088052 
[37m[36mINFO[0m[0m 02/11 04:06:12 | 0.720844    0.724444    0.980567    0.847111    0.859482    1.000000    0.992933    0.961882    0.774011    0.979817    0.774390    0.720844    0.724444    4600        89.399293   0.257527    0.843800    136.458912 
[37m[36mINFO[0m[0m 02/11 04:11:12 | 0.747871    0.742222    0.986602    0.841516    0.786641    1.000000    1.000000    0.976941    0.760829    0.982864    0.763720    0.747871    0.742222    4800        93.286219   0.264261    0.814253    137.149194 
[37m[36mINFO[0m[0m 02/11 04:16:17 | 0.727508    0.725926    0.982831    0.837600    0.959026    1.000000    1.000000    0.975529    0.755179    0.972963    0.757622    0.727508    0.725926    5000        97.173145   0.247204    0.840839    136.395536 
[37m[36mINFO[0m[0m 02/11 04:16:17 | Cumulative gradient change saved at train_output/VLCS/RSC/[3]/250211_02-07-30_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/11 04:16:18 | ---
[37m[36mINFO[0m[0m 02/11 04:16:18 | test-domain validation(oracle) = 79.933%
[37m[36mINFO[0m[0m 02/11 04:16:18 | training-domain validation(iid) = 78.415%
[37m[36mINFO[0m[0m 02/11 04:16:18 | last = 72.751%
[37m[36mINFO[0m[0m 02/11 04:16:18 | last (inD) = 83.760%
[37m[36mINFO[0m[0m 02/11 04:16:18 | training-domain validation (iid, inD) = 86.653%
[37m[36mINFO[0m[0m 02/11 04:16:18 | === Summary ===
[37m[36mINFO[0m[0m 02/11 04:16:18 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm RSC --test_envs 3 --dataset VLCS --trial_seed 0 --hparams_seed 10
[37m[36mINFO[0m[0m 02/11 04:16:18 | Unique name: 250211_02-07-30_resnet50_GENIE
[37m[36mINFO[0m[0m 02/11 04:16:18 | Out path: train_output/VLCS/RSC/[3]/250211_02-07-30_resnet50_GENIE
[37m[36mINFO[0m[0m 02/11 04:16:18 | Algorithm: RSC
[37m[36mINFO[0m[0m 02/11 04:16:18 | Dataset: VLCS
