[37m[36mINFO[0m[0m 01/29 03:12:27 | Command :: /jsm0707/Large-scale/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm RSC --test_envs 0 2 3 --dataset VLCS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: RSC
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_adam.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_adam
	out_dir: train_output/VLCS/RSC/[0, 2, 3]/250129_03-12-27_resnet50_adam
	out_root: train_output/VLCS/RSC/[0, 2, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 2, 3]
	trial_seed: 0
	unique_name: 250129_03-12-27_resnet50_adam
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: adam
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	rsc_f_drop_factor: 0.3333333333333333
	rsc_b_drop_factor: 0.3333333333333333
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 01/29 03:12:27 | n_steps = 5001
[37m[36mINFO[0m[0m 01/29 03:12:27 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 01/29 03:12:27 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 01/29 03:12:27 | 
[37m[36mINFO[0m[0m 01/29 03:12:27 | Testenv name escaping te_C_S_V -> te_C_S_V
[37m[36mINFO[0m[0m 01/29 03:12:27 | Test envs = [0, 2, 3], name = te_C_S_V
[37m[36mINFO[0m[0m 01/29 03:12:27 | Train environments: [1], Test environments: [0, 2, 3]
[37m[36mINFO[0m[0m 01/29 03:12:27 | Batch sizes for each domain: [0, 32, 0, 0] (total=32)
[37m[36mINFO[0m[0m 01/29 03:12:27 | steps-per-epoch for each domain: 66.41 -> min = 66.41
[37m[36mINFO[0m[0m 01/29 03:12:29 | # of params = 23518277
[37m[36mINFO[0m[0m 01/29 03:14:57 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 01/29 03:14:57 | 0.211818    0.206779    0.486588    0.468927    1.445752    0.070671    0.045936    0.486588    0.468927    0.339680    0.353659    0.225102    0.220741    0           0.000000    2.979122    1.976647    146.219945 
[37m[36mINFO[0m[0m 01/29 03:22:10 | 0.453397    0.453566    0.694118    0.698682    0.744945    0.468198    0.466431    0.694118    0.698682    0.443641    0.454268    0.448352    0.440000    200         3.011765    1.015521    1.424991    147.618533 
[37m[36mINFO[0m[0m 01/29 03:29:30 | 0.445863    0.442325    0.756235    0.755179    0.650954    0.447880    0.431095    0.756235    0.755179    0.441356    0.458841    0.448352    0.437037    400         6.023529    0.709149    1.408119    157.288049 
[37m[36mINFO[0m[0m 01/29 03:36:35 | 0.582959    0.584462    0.813176    0.777778    0.612765    0.669611    0.671378    0.813176    0.777778    0.494669    0.492378    0.584598    0.589630    600         9.035294    0.596230    1.403222    144.403350 
[37m[36mINFO[0m[0m 01/29 03:43:45 | 0.412490    0.402803    0.848471    0.764595    0.636348    0.313604    0.307420    0.848471    0.764595    0.444783    0.429878    0.479082    0.471111    800         12.047059   0.485871    1.372292    155.163339 
[37m[36mINFO[0m[0m 01/29 03:51:11 | 0.526967    0.520921    0.878588    0.757062    0.648035    0.495583    0.498233    0.878588    0.757062    0.525895    0.503049    0.559422    0.561481    1000        15.058824   0.434394    1.396900    166.257541 
[37m[36mINFO[0m[0m 01/29 03:58:28 | 0.544454    0.541092    0.903529    0.768362    0.903830    0.500000    0.494700    0.903529    0.768362    0.522848    0.515244    0.610515    0.613333    1200        18.070588   0.337051    1.382965    160.240889 
[37m[36mINFO[0m[0m 01/29 04:05:34 | 0.492481    0.484540    0.876235    0.732580    0.773864    0.500000    0.459364    0.876235    0.732580    0.467631    0.480183    0.509811    0.514074    1400        21.082353   0.269288    1.373966    151.203287 
[37m[36mINFO[0m[0m 01/29 04:12:48 | 0.416307    0.405116    0.945412    0.760829    0.806819    0.288869    0.289753    0.945412    0.760829    0.481340    0.461890    0.478712    0.463704    1600        24.094118   0.221578    1.398714    154.044670 
[37m[36mINFO[0m[0m 01/29 04:19:56 | 0.551743    0.563069    0.956706    0.751412    0.969454    0.537986    0.572438    0.956706    0.751412    0.528941    0.516768    0.588301    0.600000    1800        27.105882   0.170395    1.406717    147.396828 
[37m[36mINFO[0m[0m 01/29 04:27:10 | 0.464863    0.440066    0.955294    0.760829    1.072775    0.383392    0.378092    0.955294    0.760829    0.536558    0.469512    0.474639    0.472593    2000        30.117647   0.144830    1.426065    148.846565 
[37m[36mINFO[0m[0m 01/29 04:34:32 | 0.494007    0.470207    0.964235    0.762712    1.257562    0.384276    0.356890    0.964235    0.762712    0.520183    0.487805    0.577564    0.565926    2200        33.129412   0.127248    1.475751    146.378979 
[37m[36mINFO[0m[0m 01/29 04:41:32 | 0.488231    0.467872    0.976000    0.777778    1.155601    0.333922    0.300353    0.976000    0.777778    0.522848    0.510671    0.607923    0.592593    2400        36.141176   0.102447    1.361983    147.311388 
[37m[36mINFO[0m[0m 01/29 04:48:39 | 0.505368    0.481691    0.986353    0.779661    1.185010    0.370141    0.318021    0.986353    0.779661    0.536558    0.513720    0.609404    0.613333    2600        39.152941   0.094482    1.401755    146.953827 
[37m[36mINFO[0m[0m 01/29 04:55:50 | 0.490322    0.478102    0.981647    0.745763    1.189008    0.332155    0.314488    0.981647    0.745763    0.559025    0.519817    0.579785    0.600000    2800        42.164706   0.081656    1.405455    149.400362 
[37m[36mINFO[0m[0m 01/29 05:02:57 | 0.465550    0.450371    0.985882    0.777778    1.289789    0.363958    0.353357    0.985882    0.777778    0.484006    0.446646    0.548686    0.551111    3000        45.176471   0.070692    1.386916    149.507323 
[37m[36mINFO[0m[0m 01/29 05:10:07 | 0.439584    0.419777    0.966118    0.757062    0.881111    0.329505    0.335689    0.966118    0.757062    0.506093    0.445122    0.483154    0.478519    3200        48.188235   0.088648    1.395790    150.644610 
[37m[36mINFO[0m[0m 01/29 05:16:57 | 0.503723    0.472228    0.980235    0.740113    1.352725    0.343640    0.303887    0.980235    0.740113    0.579970    0.533537    0.587560    0.579259    3400        51.200000   0.082120    1.311665    148.068188 
[37m[36mINFO[0m[0m 01/29 05:24:08 | 0.442215    0.422766    0.995765    0.777778    1.398530    0.295053    0.296820    0.995765    0.777778    0.497715    0.460366    0.533876    0.511111    3600        54.211765   0.045110    1.430304    145.217973 
[37m[36mINFO[0m[0m 01/29 05:31:22 | 0.430838    0.433529    0.990588    0.785311    1.447846    0.250883    0.272085    0.990588    0.785311    0.499238    0.486280    0.542392    0.542222    3800        57.223529   0.047939    1.430453    147.471878 
[37m[36mINFO[0m[0m 01/29 05:38:35 | 0.432142    0.426862    0.990588    0.762712    1.287280    0.269435    0.268551    0.990588    0.762712    0.492003    0.480183    0.534987    0.531852    4000        60.235294   0.044712    1.408049    151.790458 
[37m[36mINFO[0m[0m 01/29 05:45:46 | 0.442158    0.427700    0.989176    0.779661    1.733279    0.295053    0.293286    0.989176    0.779661    0.491622    0.480183    0.539800    0.509630    4200        63.247059   0.048436    1.407563    148.795033 
[37m[36mINFO[0m[0m 01/29 05:52:39 | 0.433064    0.411525    0.977882    0.749529    1.646375    0.313604    0.268551    0.977882    0.749529    0.480960    0.477134    0.504628    0.488889    4400        66.258824   0.044176    1.352801    143.357873 
[37m[36mINFO[0m[0m 01/29 05:59:43 | 0.429569    0.411765    0.992471    0.770245    1.384257    0.263251    0.247350    0.992471    0.770245    0.490099    0.466463    0.535357    0.521481    4600        69.270588   0.059852    1.382654    146.573211 
[37m[36mINFO[0m[0m 01/29 06:06:54 | 0.462853    0.436112    0.992000    0.760829    1.381460    0.293286    0.265018    0.992000    0.760829    0.511043    0.486280    0.584228    0.557037    4800        72.282353   0.043441    1.415568    147.942554 
[37m[36mINFO[0m[0m 01/29 06:14:17 | 0.436665    0.425270    0.986824    0.783427    1.532158    0.250000    0.247350    0.986824    0.783427    0.493907    0.484756    0.566087    0.543704    5000        75.294118   0.072102    1.443564    154.305424 
[37m[36mINFO[0m[0m 01/29 06:14:17 | Cumulative gradient change saved at train_output/VLCS/RSC/[0, 2, 3]/250129_03-12-27_resnet50_adam/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 01/29 06:14:18 | ---
[37m[36mINFO[0m[0m 01/29 06:14:18 | test-domain validation(oracle) = 58.296%
[37m[36mINFO[0m[0m 01/29 06:14:18 | training-domain validation(iid) = 43.084%
[37m[36mINFO[0m[0m 01/29 06:14:18 | last = 43.666%
[37m[36mINFO[0m[0m 01/29 06:14:18 | last (inD) = 78.343%
[37m[36mINFO[0m[0m 01/29 06:14:18 | training-domain validation (iid, inD) = 78.531%
[37m[36mINFO[0m[0m 01/29 06:14:18 | === Summary ===
[37m[36mINFO[0m[0m 01/29 06:14:18 | Command: /jsm0707/Large-scale/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm RSC --test_envs 0 2 3 --dataset VLCS
[37m[36mINFO[0m[0m 01/29 06:14:18 | Unique name: 250129_03-12-27_resnet50_adam
[37m[36mINFO[0m[0m 01/29 06:14:18 | Out path: train_output/VLCS/RSC/[0, 2, 3]/250129_03-12-27_resnet50_adam
[37m[36mINFO[0m[0m 01/29 06:14:18 | Algorithm: RSC
[37m[36mINFO[0m[0m 01/29 06:14:18 | Dataset: VLCS
