[37m[36mINFO[0m[0m 01/29 01:49:18 | Command :: /jsm0707/Large-scale/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm RSC --test_envs 1 2 3 --dataset VLCS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: RSC
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_adam.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_adam
	out_dir: train_output/VLCS/RSC/[1, 2, 3]/250129_01-49-18_resnet50_adam
	out_root: train_output/VLCS/RSC/[1, 2, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [1, 2, 3]
	trial_seed: 0
	unique_name: 250129_01-49-18_resnet50_adam
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: adam
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	rsc_f_drop_factor: 0.3333333333333333
	rsc_b_drop_factor: 0.3333333333333333
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 01/29 01:49:18 | n_steps = 5001
[37m[36mINFO[0m[0m 01/29 01:49:18 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 01/29 01:49:18 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 01/29 01:49:18 | 
[37m[36mINFO[0m[0m 01/29 01:49:18 | Testenv name escaping te_L_S_V -> te_L_S_V
[37m[36mINFO[0m[0m 01/29 01:49:18 | Test envs = [1, 2, 3], name = te_L_S_V
[37m[36mINFO[0m[0m 01/29 01:49:18 | Train environments: [0], Test environments: [1, 2, 3]
[37m[36mINFO[0m[0m 01/29 01:49:18 | Batch sizes for each domain: [32, 0, 0, 0] (total=32)
[37m[36mINFO[0m[0m 01/29 01:49:18 | steps-per-epoch for each domain: 35.38 -> min = 35.38
[37m[36mINFO[0m[0m 01/29 01:49:21 | # of params = 23518277
[37m[36mINFO[0m[0m 01/29 01:51:48 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 01/29 01:51:48 | 0.363007    0.365408    0.510601    0.438163    1.502413    0.510601    0.438163    0.458824    0.470810    0.388804    0.376524    0.241392    0.248889    0           0.000000    3.164882    3.534254    144.214041 
[37m[36mINFO[0m[0m 01/29 01:55:02 | 0.387179    0.383750    0.996466    1.000000    0.001924    0.996466    1.000000    0.355765    0.367232    0.365194    0.379573    0.440578    0.404444    200         5.653710    0.302002    0.210174    151.536939 
[37m[36mINFO[0m[0m 01/29 01:58:14 | 0.312937    0.320941    1.000000    1.000000    0.000003    1.000000    1.000000    0.239529    0.282486    0.330160    0.327744    0.369123    0.352593    400         11.307420   0.003113    0.186162    154.330925 
[37m[36mINFO[0m[0m 01/29 02:01:33 | 0.366392    0.366606    0.999117    0.996466    0.007257    0.999117    0.996466    0.312941    0.318267    0.341584    0.344512    0.444650    0.437037    600         16.961131   0.025132    0.218773    155.112701 
[37m[36mINFO[0m[0m 01/29 02:04:39 | 0.311483    0.312300    1.000000    1.000000    0.000225    1.000000    1.000000    0.256471    0.265537    0.322925    0.324695    0.355054    0.346667    800         22.614841   0.000223    0.180703    149.953623 
[37m[36mINFO[0m[0m 01/29 02:07:52 | 0.323945    0.329633    1.000000    1.000000    0.000333    1.000000    1.000000    0.260706    0.278719    0.330160    0.335366    0.380970    0.374815    1000        28.268551   0.000058    0.189886    155.245785 
[37m[36mINFO[0m[0m 01/29 02:11:09 | 0.405651    0.388621    0.988516    0.978799    0.069524    0.988516    0.978799    0.363294    0.355932    0.423077    0.405488    0.430581    0.404444    1200        33.922261   0.011761    0.199179    156.477974 
[37m[36mINFO[0m[0m 01/29 02:14:25 | 0.332839    0.333319    0.994700    0.992933    0.015978    0.994700    0.992933    0.288941    0.278719    0.354151    0.359756    0.355424    0.361481    1400        39.575972   0.019021    0.240986    147.340251 
[37m[36mINFO[0m[0m 01/29 02:17:39 | 0.218674    0.226729    0.933746    0.908127    0.207704    0.933746    0.908127    0.254118    0.269303    0.100533    0.123476    0.301370    0.287407    1600        45.229682   0.068570    0.198091    155.104672 
[37m[36mINFO[0m[0m 01/29 02:20:57 | 0.297341    0.290620    1.000000    0.996466    0.016503    1.000000    0.996466    0.287529    0.273070    0.276466    0.272866    0.328027    0.325926    1800        50.883392   0.072418    0.216106    153.969653 
[37m[36mINFO[0m[0m 01/29 02:24:14 | 0.306207    0.299652    0.999117    0.996466    0.010970    0.999117    0.996466    0.288941    0.273070    0.290175    0.288110    0.339504    0.337778    2000        56.537102   0.016691    0.257657    146.181932 
[37m[36mINFO[0m[0m 01/29 02:27:26 | 0.307916    0.321812    0.998233    0.985866    0.034082    0.998233    0.985866    0.241412    0.258004    0.333206    0.342988    0.349130    0.364444    2200        62.190813   0.004577    0.228758    145.874532 
[37m[36mINFO[0m[0m 01/29 02:30:42 | 0.287185    0.292470    0.999117    1.000000    0.001169    0.999117    1.000000    0.224471    0.237288    0.316832    0.320122    0.320252    0.320000    2400        67.844523   0.004568    0.252101    145.976923 
[37m[36mINFO[0m[0m 01/29 02:34:01 | 0.303679    0.304553    1.000000    1.000000    0.002394    1.000000    1.000000    0.251294    0.261770    0.319497    0.317073    0.340244    0.334815    2600        73.498233   0.000780    0.215127    155.154756 
[37m[36mINFO[0m[0m 01/29 02:37:14 | 0.306260    0.308905    1.000000    0.996466    0.004481    1.000000    0.996466    0.262118    0.267420    0.315308    0.317073    0.341355    0.342222    2800        79.151943   0.000217    0.183188    157.200596 
[37m[36mINFO[0m[0m 01/29 02:40:27 | 0.301986    0.300277    1.000000    0.996466    0.007727    1.000000    0.996466    0.254118    0.258004    0.314928    0.310976    0.336912    0.331852    3000        84.805654   0.000069    0.221725    148.389329 
[37m[36mINFO[0m[0m 01/29 02:43:38 | 0.228649    0.223228    0.986749    0.975265    0.067093    0.986749    0.975265    0.117176    0.105461    0.309977    0.307927    0.258793    0.256296    3200        90.459364   0.018414    0.186965    153.231276 
[37m[36mINFO[0m[0m 01/29 02:46:49 | 0.279042    0.287780    1.000000    1.000000    0.001121    1.000000    1.000000    0.200000    0.212806    0.318355    0.321646    0.318771    0.328889    3400        96.113074   0.008506    0.188818    153.476334 
[37m[36mINFO[0m[0m 01/29 02:50:01 | 0.309724    0.307779    0.997350    0.985866    0.073014    0.997350    0.985866    0.289412    0.295669    0.306550    0.298780    0.333210    0.328889    3600        101.766784  0.004180    0.213658    149.242376 
[37m[36mINFO[0m[0m 01/29 02:53:10 | 0.322067    0.327350    1.000000    0.996466    0.015942    1.000000    0.996466    0.281412    0.278719    0.341584    0.355183    0.343206    0.348148    3800        107.420495  0.000182    0.218971    145.033489 
[37m[36mINFO[0m[0m 01/29 02:56:21 | 0.280976    0.287973    1.000000    0.996466    0.016798    1.000000    0.996466    0.200471    0.207156    0.323686    0.332317    0.318771    0.324444    4000        113.074205  0.007378    0.246989    141.242378 
[37m[36mINFO[0m[0m 01/29 02:59:31 | 0.269877    0.279284    0.998233    0.996466    0.017288    0.998233    0.996466    0.194824    0.220339    0.301219    0.306402    0.313588    0.311111    4200        118.727915  0.003542    0.249181    140.911531 
[37m[36mINFO[0m[0m 01/29 03:02:42 | 0.174357    0.181367    0.998233    0.989399    0.047612    0.998233    0.989399    0.157176    0.165725    0.123762    0.126524    0.242133    0.251852    4400        124.381625  0.019003    0.216936    147.604524 
[37m[36mINFO[0m[0m 01/29 03:05:56 | 0.255942    0.260881    1.000000    0.992933    0.031223    1.000000    0.992933    0.215059    0.216573    0.266946    0.268293    0.285820    0.297778    4600        130.035336  0.000595    0.224506    149.219871 
[37m[36mINFO[0m[0m 01/29 03:09:09 | 0.253776    0.250097    1.000000    0.992933    0.038573    1.000000    0.992933    0.197647    0.195857    0.286748    0.275915    0.276934    0.278519    4800        135.689046  0.000090    0.222380    148.063202 
[37m[36mINFO[0m[0m 01/29 03:12:21 | 0.255027    0.247149    0.999117    0.992933    0.028476    0.999117    0.992933    0.191529    0.188324    0.295506    0.282012    0.278045    0.271111    5000        141.342756  0.000026    0.214882    148.847296 
[37m[36mINFO[0m[0m 01/29 03:12:21 | Cumulative gradient change saved at train_output/VLCS/RSC/[1, 2, 3]/250129_01-49-18_resnet50_adam/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 01/29 03:12:22 | ---
[37m[36mINFO[0m[0m 01/29 03:12:22 | test-domain validation(oracle) = 40.565%
[37m[36mINFO[0m[0m 01/29 03:12:22 | training-domain validation(iid) = 38.718%
[37m[36mINFO[0m[0m 01/29 03:12:22 | last = 25.503%
[37m[36mINFO[0m[0m 01/29 03:12:22 | last (inD) = 99.293%
[37m[36mINFO[0m[0m 01/29 03:12:22 | training-domain validation (iid, inD) = 100.000%
[37m[36mINFO[0m[0m 01/29 03:12:22 | === Summary ===
[37m[36mINFO[0m[0m 01/29 03:12:22 | Command: /jsm0707/Large-scale/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm RSC --test_envs 1 2 3 --dataset VLCS
[37m[36mINFO[0m[0m 01/29 03:12:22 | Unique name: 250129_01-49-18_resnet50_adam
[37m[36mINFO[0m[0m 01/29 03:12:22 | Out path: train_output/VLCS/RSC/[1, 2, 3]/250129_01-49-18_resnet50_adam
[37m[36mINFO[0m[0m 01/29 03:12:22 | Algorithm: RSC
[37m[36mINFO[0m[0m 01/29 03:12:22 | Dataset: VLCS
