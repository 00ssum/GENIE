[37m[36mINFO[0m[0m 02/20 16:43:47 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm RSC --test_envs 1 2 3 --dataset VLCS --trial_seed 1 --hparams_seed 15
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: RSC
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 15
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/VLCS/RSC/[1, 2, 3]/250220_16-43-47_resnet50_GENIE
	out_root: train_output/VLCS/RSC/[1, 2, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [1, 2, 3]
	trial_seed: 1
	unique_name: 250220_16-43-47_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 1.7812453400894684e-05
	batch_size: 36
	weight_decay: 3.1651536009272826e-06
	rsc_f_drop_factor: 0.384156695834526
	rsc_b_drop_factor: 0.10268662025909236
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 02/20 16:43:47 | n_steps = 5001
[37m[36mINFO[0m[0m 02/20 16:43:47 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/20 16:43:47 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/20 16:43:47 | 
[37m[36mINFO[0m[0m 02/20 16:43:47 | Testenv name escaping te_L_S_V -> te_L_S_V
[37m[36mINFO[0m[0m 02/20 16:43:47 | Test envs = [1, 2, 3], name = te_L_S_V
[37m[36mINFO[0m[0m 02/20 16:43:47 | Train environments: [0], Test environments: [1, 2, 3]
[37m[36mINFO[0m[0m 02/20 16:43:47 | Batch sizes for each domain: [36, 0, 0, 0] (total=36)
[37m[36mINFO[0m[0m 02/20 16:43:47 | steps-per-epoch for each domain: 31.44 -> min = 31.44
[37m[36mINFO[0m[0m 02/20 16:43:49 | # of params = 23518277
[37m[36mINFO[0m[0m 02/20 16:46:20 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 02/20 16:46:20 | 0.432326    0.428842    0.613958    0.618375    0.956461    0.613958    0.618375    0.466824    0.461394    0.376618    0.419207    0.453536    0.405926    0           0.000000    2.349505    1.132652    149.362876 
[37m[36mINFO[0m[0m 02/20 16:49:37 | 0.571645    0.575932    1.000000    1.000000    0.000587    1.000000    1.000000    0.493647    0.485876    0.582635    0.594512    0.638652    0.647407    200         6.360424    0.253751    0.195390    157.999939 
[37m[36mINFO[0m[0m 02/20 16:52:40 | 0.531116    0.542719    1.000000    1.000000    0.000107    1.000000    1.000000    0.485647    0.483992    0.531988    0.542683    0.575713    0.601481    400         12.720848   0.152085    0.187260    145.602630 
[37m[36mINFO[0m[0m 02/20 16:55:45 | 0.477807    0.491695    0.993816    1.000000    0.000000    0.993816    1.000000    0.480000    0.480226    0.469155    0.501524    0.484265    0.493333    600         19.081272   0.110523    0.280822    129.242574 
[37m[36mINFO[0m[0m 02/20 16:58:58 | 0.411740    0.419029    0.998233    0.996466    0.020715    0.998233    0.996466    0.351529    0.344633    0.397944    0.416159    0.485746    0.496296    800         25.441696   0.141478    0.242781    144.389118 
[37m[36mINFO[0m[0m 02/20 17:02:07 | 0.466187    0.467996    0.999117    0.985866    0.116106    0.999117    0.985866    0.452706    0.455744    0.490099    0.477134    0.455757    0.471111    1000        31.802120   0.306865    0.184480    152.121626 
[37m[36mINFO[0m[0m 02/20 17:05:06 | 0.468712    0.466797    1.000000    0.996466    0.097735    1.000000    0.996466    0.469176    0.459510    0.503046    0.478659    0.433913    0.462222    1200        38.162544   0.127854    0.182458    142.452319 
[37m[36mINFO[0m[0m 02/20 17:08:11 | 0.249376    0.239415    0.991166    0.971731    0.189758    0.991166    0.971731    0.260235    0.265537    0.157273    0.135671    0.330618    0.317037    1400        44.522968   0.147399    0.225075    139.511800 
[37m[36mINFO[0m[0m 02/20 17:11:12 | 0.400433    0.406780    0.988516    1.000000    0.015679    0.988516    1.000000    0.352000    0.367232    0.439452    0.413110    0.409848    0.440000    1600        50.883392   0.148650    0.229298    135.695369 
[37m[36mINFO[0m[0m 02/20 17:14:22 | 0.342572    0.340159    0.998233    0.996466    0.005142    0.998233    0.996466    0.273882    0.293785    0.388043    0.342988    0.365790    0.383704    1800        57.243816   0.156945    0.209453    148.066812 
[37m[36mINFO[0m[0m 02/20 17:17:28 | 0.404280    0.415885    1.000000    0.996466    0.144647    1.000000    0.996466    0.369412    0.399247    0.441356    0.403963    0.402073    0.444444    2000        63.604240   0.142002    0.213423    143.170428 
[37m[36mINFO[0m[0m 02/20 17:20:41 | 0.237349    0.240668    0.864841    0.876325    0.395771    0.864841    0.876325    0.273882    0.297552    0.179741    0.184451    0.258423    0.240000    2200        69.964664   0.185596    0.228840    147.703966 
[37m[36mINFO[0m[0m 02/20 17:23:54 | 0.221896    0.234010    0.822438    0.798587    0.499816    0.822438    0.798587    0.197176    0.220339    0.192688    0.217988    0.275824    0.263704    2400        76.325088   0.905674    0.178996    156.756864 
[37m[36mINFO[0m[0m 02/20 17:27:06 | 0.406440    0.416966    0.721731    0.727915    0.780624    0.721731    0.727915    0.440471    0.444444    0.342346    0.387195    0.436505    0.419259    2600        82.685512   0.660248    0.202686    151.648154 
[37m[36mINFO[0m[0m 02/20 17:29:56 | 0.336844    0.343742    0.947880    0.929329    0.276225    0.947880    0.929329    0.306353    0.322034    0.426504    0.405488    0.277675    0.303704    2800        89.045936   0.462434    0.218537    126.283050 
[37m[36mINFO[0m[0m 02/20 17:32:58 | 0.292539    0.312495    0.974382    0.964664    0.314352    0.974382    0.964664    0.221176    0.263653    0.387281    0.359756    0.269160    0.314074    3000        95.406360   0.282729    0.246147    132.407048 
[37m[36mINFO[0m[0m 02/20 17:35:57 | 0.280775    0.273915    0.988516    0.975265    0.069767    0.988516    0.975265    0.269176    0.280603    0.321021    0.277439    0.252129    0.263704    3200        101.766784  0.228810    0.185323    142.101208 
[37m[36mINFO[0m[0m 02/20 17:38:43 | 0.155859    0.151267    0.977915    0.961131    0.177070    0.977915    0.961131    0.073882    0.097928    0.204874    0.169207    0.188819    0.186667    3400        108.127208  0.249336    0.183164    129.800642 
[37m[36mINFO[0m[0m 02/20 17:41:37 | 0.393179    0.389480    1.000000    0.992933    0.043926    1.000000    0.992933    0.405647    0.408663    0.443641    0.413110    0.330248    0.346667    3600        114.487633  0.176770    0.225677    128.341848 
[37m[36mINFO[0m[0m 02/20 17:44:23 | 0.396229    0.392479    0.998233    0.985866    0.176794    0.998233    0.985866    0.422118    0.414313    0.460015    0.426829    0.306553    0.336296    3800        120.848057  0.146708    0.188106    128.529977 
[37m[36mINFO[0m[0m 02/20 17:47:29 | 0.388195    0.383415    0.999117    0.985866    0.122809    0.999117    0.985866    0.420706    0.418079    0.402894    0.379573    0.340985    0.352593    4000        127.208481  0.177864    0.217844    142.407900 
[37m[36mINFO[0m[0m 02/20 17:50:22 | 0.314455    0.319378    0.998233    0.989399    0.098255    0.998233    0.989399    0.317176    0.337100    0.364433    0.326220    0.261755    0.294815    4200        133.568905  0.165244    0.201386    132.655833 
[37m[36mINFO[0m[0m 02/20 17:53:40 | 0.361679    0.370729    1.000000    0.992933    0.079117    1.000000    0.992933    0.366588    0.382298    0.420411    0.403963    0.298038    0.325926    4400        139.929329  0.129347    0.214915    154.819803 
[37m[36mINFO[0m[0m 02/20 17:56:54 | 0.383996    0.372324    1.000000    0.996466    0.056932    1.000000    0.996466    0.416000    0.403013    0.412034    0.364329    0.323954    0.349630    4600        146.289753  0.122063    0.197764    154.329821 
[37m[36mINFO[0m[0m 02/20 17:59:41 | 0.360886    0.354769    1.000000    0.982332    0.395470    1.000000    0.982332    0.401412    0.395480    0.373953    0.339939    0.307294    0.328889    4800        152.650177  0.110001    0.208062    125.233154 
[37m[36mINFO[0m[0m 02/20 18:03:06 | 0.267042    0.275065    0.991166    0.954064    0.460915    0.991166    0.954064    0.203765    0.242938    0.353008    0.317073    0.244354    0.265185    5000        159.010601  0.158201    0.313978    142.321919 
[37m[36mINFO[0m[0m 02/20 18:03:06 | Cumulative gradient change saved at train_output/VLCS/RSC/[1, 2, 3]/250220_16-43-47_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/20 18:03:07 | ---
[37m[36mINFO[0m[0m 02/20 18:03:07 | test-domain validation(oracle) = 57.164%
[37m[36mINFO[0m[0m 02/20 18:03:07 | training-domain validation(iid) = 57.164%
[37m[36mINFO[0m[0m 02/20 18:03:07 | last = 26.704%
[37m[36mINFO[0m[0m 02/20 18:03:07 | last (inD) = 95.406%
[37m[36mINFO[0m[0m 02/20 18:03:07 | training-domain validation (iid, inD) = 100.000%
[37m[36mINFO[0m[0m 02/20 18:03:07 | === Summary ===
[37m[36mINFO[0m[0m 02/20 18:03:07 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm RSC --test_envs 1 2 3 --dataset VLCS --trial_seed 1 --hparams_seed 15
[37m[36mINFO[0m[0m 02/20 18:03:07 | Unique name: 250220_16-43-47_resnet50_GENIE
[37m[36mINFO[0m[0m 02/20 18:03:07 | Out path: train_output/VLCS/RSC/[1, 2, 3]/250220_16-43-47_resnet50_GENIE
[37m[36mINFO[0m[0m 02/20 18:03:07 | Algorithm: RSC
[37m[36mINFO[0m[0m 02/20 18:03:07 | Dataset: VLCS
