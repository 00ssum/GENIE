[37m[36mINFO[0m[0m 02/20 07:11:38 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm RSC --test_envs 1 2 3 --dataset VLCS --trial_seed 2 --hparams_seed 13
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: RSC
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 13
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/VLCS/RSC/[1, 2, 3]/250220_07-11-38_resnet50_GENIE
	out_root: train_output/VLCS/RSC/[1, 2, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [1, 2, 3]
	trial_seed: 2
	unique_name: 250220_07-11-38_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 0.00010514591448387436
	batch_size: 9
	weight_decay: 2.4366015497066046e-05
	rsc_f_drop_factor: 0.01448541980108109
	rsc_b_drop_factor: 0.13409305572855784
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 02/20 07:11:39 | n_steps = 5001
[37m[36mINFO[0m[0m 02/20 07:11:39 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/20 07:11:39 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/20 07:11:39 | 
[37m[36mINFO[0m[0m 02/20 07:11:39 | Testenv name escaping te_L_S_V -> te_L_S_V
[37m[36mINFO[0m[0m 02/20 07:11:39 | Test envs = [1, 2, 3], name = te_L_S_V
[37m[36mINFO[0m[0m 02/20 07:11:39 | Train environments: [0], Test environments: [1, 2, 3]
[37m[36mINFO[0m[0m 02/20 07:11:39 | Batch sizes for each domain: [9, 0, 0, 0] (total=9)
[37m[36mINFO[0m[0m 02/20 07:11:39 | steps-per-epoch for each domain: 125.78 -> min = 125.78
[37m[36mINFO[0m[0m 02/20 07:11:40 | # of params = 23518277
[37m[36mINFO[0m[0m 02/20 07:14:06 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 02/20 07:14:06 | 0.433117    0.425667    0.620141    0.593640    1.085422    0.620141    0.593640    0.467294    0.459510    0.391851    0.358232    0.440207    0.459259    0           0.000000    1.885601    1.078521    144.985379 
[37m[36mINFO[0m[0m 02/20 07:16:54 | 0.555081    0.552028    0.998233    1.000000    0.006602    0.998233    1.000000    0.473882    0.485876    0.598248    0.573171    0.593114    0.597037    200         1.590106    0.098417    0.156335    136.499694 
[37m[36mINFO[0m[0m 02/20 07:20:01 | 0.245498    0.251890    0.992933    0.989399    0.025955    0.992933    0.989399    0.264471    0.297552    0.145849    0.117378    0.326175    0.340741    400         3.180212    0.050216    0.245481    138.454816 
[37m[36mINFO[0m[0m 02/20 07:23:09 | 0.265660    0.265774    0.970848    0.989399    0.054157    0.970848    0.989399    0.245176    0.265537    0.165651    0.155488    0.386153    0.376296    600         4.770318    0.062203    0.157339    156.341354 
[37m[36mINFO[0m[0m 02/20 07:26:15 | 0.386258    0.385354    0.995583    0.996466    0.009970    0.995583    0.996466    0.356706    0.359699    0.351866    0.344512    0.450204    0.451852    800         6.360424    0.035756    0.158485    154.593493 
[37m[36mINFO[0m[0m 02/20 07:29:03 | 0.371680    0.367570    1.000000    1.000000    0.001096    1.000000    1.000000    0.318588    0.306968    0.362909    0.375000    0.433543    0.420741    1000        7.950530    0.017721    0.138191    140.170405 
[37m[36mINFO[0m[0m 02/20 07:32:17 | 0.364346    0.367661    1.000000    1.000000    0.000570    1.000000    1.000000    0.302118    0.308851    0.363671    0.370427    0.427249    0.423704    1200        9.540636    0.000548    0.175673    158.752924 
[37m[36mINFO[0m[0m 02/20 07:35:20 | 0.403699    0.413346    1.000000    1.000000    0.000806    1.000000    1.000000    0.349176    0.365348    0.387281    0.390244    0.474639    0.484444    1400        11.130742   0.000204    0.130700    156.361646 
[37m[36mINFO[0m[0m 02/20 07:38:16 | 0.390189    0.397597    1.000000    1.000000    0.002056    1.000000    1.000000    0.344941    0.361582    0.373572    0.371951    0.452055    0.459259    1600        12.720848   0.000067    0.124604    151.150320 
[37m[36mINFO[0m[0m 02/20 07:41:14 | 0.379624    0.388025    1.000000    1.000000    0.001723    1.000000    1.000000    0.337882    0.352166    0.366337    0.370427    0.434654    0.441481    1800        14.310954   0.000140    0.143962    148.942069 
[37m[36mINFO[0m[0m 02/20 07:44:19 | 0.359140    0.364293    1.000000    0.996466    0.002567    1.000000    0.996466    0.315294    0.325800    0.353389    0.356707    0.408738    0.410370    2000        15.901060   0.000161    0.129849    159.356668 
[37m[36mINFO[0m[0m 02/20 07:47:14 | 0.339300    0.346539    0.999117    1.000000    0.000881    0.999117    1.000000    0.255529    0.271186    0.348819    0.352134    0.413551    0.416296    2200        17.491166   0.007151    0.127515    149.687639 
[37m[36mINFO[0m[0m 02/20 07:50:06 | 0.360880    0.357185    1.000000    1.000000    0.001534    1.000000    1.000000    0.281882    0.280603    0.357959    0.362805    0.442799    0.428148    2400        19.081272   0.001420    0.140082    143.758030 
[37m[36mINFO[0m[0m 02/20 07:53:12 | 0.366431    0.366000    1.000000    1.000000    0.002396    1.000000    1.000000    0.321882    0.322034    0.357197    0.356707    0.420215    0.419259    2600        20.671378   0.000214    0.163566    153.953183 
[37m[36mINFO[0m[0m 02/20 07:56:17 | 0.362873    0.361618    1.000000    0.996466    0.004108    1.000000    0.996466    0.324706    0.323917    0.351104    0.349085    0.412810    0.411852    2800        22.261484   0.000038    0.124245    159.806175 
[37m[36mINFO[0m[0m 02/20 07:59:16 | 0.351513    0.348733    1.000000    1.000000    0.000171    1.000000    1.000000    0.283294    0.280603    0.348439    0.356707    0.422806    0.408889    3000        23.851590   0.000075    0.126771    153.507054 
[37m[36mINFO[0m[0m 02/20 08:02:19 | 0.358223    0.354783    1.000000    1.000000    0.000619    1.000000    1.000000    0.300706    0.310734    0.353008    0.352134    0.420955    0.401481    3200        25.441696   0.000041    0.145616    153.830960 
[37m[36mINFO[0m[0m 02/20 08:05:21 | 0.359864    0.356040    1.000000    1.000000    0.000470    1.000000    1.000000    0.301176    0.306968    0.353389    0.356707    0.425028    0.404444    3400        27.031802   0.000015    0.167056    148.620118 
[37m[36mINFO[0m[0m 02/20 08:08:22 | 0.355222    0.351766    1.000000    1.000000    0.000090    1.000000    1.000000    0.289882    0.288136    0.351866    0.359756    0.423917    0.407407    3600        28.621908   0.000034    0.117349    157.402081 
[37m[36mINFO[0m[0m 02/20 08:11:18 | 0.358830    0.357642    1.000000    1.000000    0.000113    1.000000    1.000000    0.296941    0.301318    0.354151    0.359756    0.425398    0.411852    3800        30.212014   0.000005    0.157894    144.906195 
[37m[36mINFO[0m[0m 02/20 08:14:11 | 0.357202    0.356999    1.000000    1.000000    0.000228    1.000000    1.000000    0.300235    0.306968    0.353008    0.353659    0.418364    0.410370    4000        31.802120   0.000026    0.164404    140.027980 
[37m[36mINFO[0m[0m 02/20 08:17:13 | 0.358487    0.357627    1.000000    1.000000    0.000246    1.000000    1.000000    0.302588    0.308851    0.353770    0.353659    0.419104    0.410370    4200        33.392226   0.000003    0.179483    145.665467 
[37m[36mINFO[0m[0m 02/20 08:20:13 | 0.359859    0.359242    1.000000    1.000000    0.000259    1.000000    1.000000    0.304471    0.310734    0.354151    0.353659    0.420955    0.413333    4400        34.982332   0.000007    0.173510    144.909524 
[37m[36mINFO[0m[0m 02/20 08:23:16 | 0.360092    0.359736    1.000000    1.000000    0.000198    1.000000    1.000000    0.302588    0.310734    0.353770    0.353659    0.423917    0.414815    4600        36.572438   0.000005    0.168517    149.361173 
[37m[36mINFO[0m[0m 02/20 08:26:10 | 0.363032    0.363236    1.000000    1.000000    0.000143    1.000000    1.000000    0.305412    0.310734    0.356436    0.358232    0.427249    0.420741    4800        38.162544   0.000008    0.135783    147.136094 
[37m[36mINFO[0m[0m 02/20 08:29:11 | 0.363167    0.365121    1.000000    1.000000    0.000190    1.000000    1.000000    0.301647    0.301318    0.359863    0.367378    0.427990    0.426667    5000        39.752650   0.006950    0.161150    148.710768 
[37m[36mINFO[0m[0m 02/20 08:29:11 | Cumulative gradient change saved at train_output/VLCS/RSC/[1, 2, 3]/250220_07-11-38_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/20 08:29:13 | ---
[37m[36mINFO[0m[0m 02/20 08:29:13 | test-domain validation(oracle) = 55.508%
[37m[36mINFO[0m[0m 02/20 08:29:13 | training-domain validation(iid) = 55.508%
[37m[36mINFO[0m[0m 02/20 08:29:13 | last = 36.317%
[37m[36mINFO[0m[0m 02/20 08:29:13 | last (inD) = 100.000%
[37m[36mINFO[0m[0m 02/20 08:29:13 | training-domain validation (iid, inD) = 100.000%
[37m[36mINFO[0m[0m 02/20 08:29:13 | === Summary ===
[37m[36mINFO[0m[0m 02/20 08:29:13 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm RSC --test_envs 1 2 3 --dataset VLCS --trial_seed 2 --hparams_seed 13
[37m[36mINFO[0m[0m 02/20 08:29:13 | Unique name: 250220_07-11-38_resnet50_GENIE
[37m[36mINFO[0m[0m 02/20 08:29:13 | Out path: train_output/VLCS/RSC/[1, 2, 3]/250220_07-11-38_resnet50_GENIE
[37m[36mINFO[0m[0m 02/20 08:29:13 | Algorithm: RSC
[37m[36mINFO[0m[0m 02/20 08:29:13 | Dataset: VLCS
