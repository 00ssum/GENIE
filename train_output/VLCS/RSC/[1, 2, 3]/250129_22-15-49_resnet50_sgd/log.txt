[37m[36mINFO[0m[0m 01/29 22:15:49 | Command :: /jsm0707/Large-scale/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm RSC --test_envs 1 2 3 --dataset VLCS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: RSC
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_sgd.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_sgd
	out_dir: train_output/VLCS/RSC/[1, 2, 3]/250129_22-15-49_resnet50_sgd
	out_root: train_output/VLCS/RSC/[1, 2, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [1, 2, 3]
	trial_seed: 0
	unique_name: 250129_22-15-49_resnet50_sgd
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: sgd
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	rsc_f_drop_factor: 0.3333333333333333
	rsc_b_drop_factor: 0.3333333333333333
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 01/29 22:15:49 | n_steps = 5001
[37m[36mINFO[0m[0m 01/29 22:15:49 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 01/29 22:15:49 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 01/29 22:15:49 | 
[37m[36mINFO[0m[0m 01/29 22:15:49 | Testenv name escaping te_L_S_V -> te_L_S_V
[37m[36mINFO[0m[0m 01/29 22:15:49 | Test envs = [1, 2, 3], name = te_L_S_V
[37m[36mINFO[0m[0m 01/29 22:15:49 | Train environments: [0], Test environments: [1, 2, 3]
[37m[36mINFO[0m[0m 01/29 22:15:49 | Batch sizes for each domain: [32, 0, 0, 0] (total=32)
[37m[36mINFO[0m[0m 01/29 22:15:49 | steps-per-epoch for each domain: 35.38 -> min = 35.38
[37m[36mINFO[0m[0m 01/29 22:15:51 | # of params = 23518277
[37m[36mINFO[0m[0m 01/29 22:18:16 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 01/29 22:18:16 | 0.172273    0.147340    0.087456    0.077739    1.898160    0.087456    0.077739    0.189176    0.161959    0.186215    0.160061    0.141429    0.120000    0           0.000000    3.164882    1.423269    144.180204 
[37m[36mINFO[0m[0m 01/29 22:22:03 | 0.420350    0.431677    0.642226    0.646643    1.195753    0.642226    0.646643    0.460706    0.493409    0.369764    0.373476    0.430581    0.428148    200         5.653710    2.342849    0.309530    163.713525 
[37m[36mINFO[0m[0m 01/29 22:25:27 | 0.432672    0.443989    0.626325    0.643110    1.004665    0.626325    0.643110    0.462118    0.491525    0.383473    0.384146    0.452425    0.456296    400         11.307420   1.713584    0.227905    158.138136 
[37m[36mINFO[0m[0m 01/29 22:28:53 | 0.436268    0.449089    0.666078    0.674912    0.868299    0.666078    0.674912    0.464000    0.500942    0.384235    0.382622    0.460570    0.463704    600         16.961131   1.494518    0.265089    152.639588 
[37m[36mINFO[0m[0m 01/29 22:32:25 | 0.441710    0.455071    0.745583    0.756184    0.731269    0.745583    0.756184    0.470118    0.508475    0.378522    0.384146    0.476490    0.472593    800         22.614841   1.322114    0.217605    168.945282 
[37m[36mINFO[0m[0m 01/29 22:35:41 | 0.434057    0.446653    0.789753    0.805654    0.604928    0.789753    0.805654    0.471529    0.510358    0.367479    0.367378    0.463162    0.462222    1000        28.268551   1.203750    0.203186    154.481894 
[37m[36mINFO[0m[0m 01/29 22:39:06 | 0.429832    0.433372    0.879859    0.883392    0.480636    0.879859    0.883392    0.482824    0.521657    0.357578    0.339939    0.449093    0.438519    1200        33.922261   1.072074    0.203508    163.523086 
[37m[36mINFO[0m[0m 01/29 22:42:16 | 0.454289    0.449373    0.916961    0.908127    0.370664    0.916961    0.908127    0.543059    0.555556    0.377380    0.367378    0.442429    0.425185    1400        39.575972   0.964626    0.219777    146.295726 
[37m[36mINFO[0m[0m 01/29 22:45:33 | 0.483070    0.461449    0.942580    0.936396    0.292668    0.942580    0.936396    0.584941    0.585687    0.405179    0.373476    0.459089    0.425185    1600        45.229682   0.940263    0.206307    155.263547 
[37m[36mINFO[0m[0m 01/29 22:48:59 | 0.481837    0.463257    0.960247    0.957597    0.238404    0.960247    0.957597    0.570824    0.581921    0.420411    0.384146    0.454276    0.423704    1800        50.883392   0.939732    0.238900    157.521081 
[37m[36mINFO[0m[0m 01/29 22:52:11 | 0.477281    0.450652    0.975265    0.964664    0.207303    0.975265    0.964664    0.557176    0.557439    0.419650    0.384146    0.455017    0.410370    2000        56.537102   0.936166    0.222794    147.309102 
[37m[36mINFO[0m[0m 01/29 22:55:42 | 0.472663    0.447005    0.976148    0.971731    0.181742    0.976148    0.971731    0.547765    0.548023    0.419650    0.382622    0.450574    0.410370    2200        62.190813   0.884747    0.245299    161.858582 
[37m[36mINFO[0m[0m 01/29 22:58:44 | 0.482315    0.460715    0.984099    0.975265    0.158768    0.984099    0.975265    0.549176    0.549906    0.438309    0.408537    0.459459    0.423704    2400        67.844523   0.836201    0.181748    145.131945 
[37m[36mINFO[0m[0m 01/29 23:02:07 | 0.479226    0.456350    0.984099    0.975265    0.141047    0.984099    0.975265    0.538353    0.536723    0.440975    0.411585    0.458349    0.420741    2600        73.498233   0.809315    0.259129    151.202729 
[37m[36mINFO[0m[0m 01/29 23:05:25 | 0.484875    0.460028    0.985866    0.985866    0.128310    0.985866    0.985866    0.528941    0.523540    0.456969    0.429878    0.468715    0.426667    2800        79.151943   0.785875    0.215314    153.857378 
[37m[36mINFO[0m[0m 01/29 23:08:39 | 0.488012    0.464814    0.991166    0.989399    0.114689    0.991166    0.989399    0.519059    0.512241    0.471820    0.446646    0.473158    0.435556    3000        84.805654   0.754935    0.228601    148.449411 
[37m[36mINFO[0m[0m 01/29 23:11:54 | 0.504107    0.477868    0.996466    0.992933    0.099591    0.996466    0.992933    0.521412    0.512241    0.499238    0.469512    0.491670    0.451852    3200        90.459364   0.715390    0.221922    148.847948 
[37m[36mINFO[0m[0m 01/29 23:15:09 | 0.512375    0.490443    0.995583    0.992933    0.093199    0.995583    0.992933    0.517647    0.512241    0.514851    0.493902    0.504628    0.465185    3400        96.113074   0.735194    0.196317    155.813299 
[37m[36mINFO[0m[0m 01/29 23:18:31 | 0.522783    0.499983    0.997350    0.996466    0.086246    0.997350    0.996466    0.517176    0.512241    0.536177    0.510671    0.514994    0.477037    3600        101.766784  0.704311    0.225970    156.339070 
[37m[36mINFO[0m[0m 01/29 23:21:42 | 0.520400    0.495859    0.996466    0.992933    0.086783    0.996466    0.992933    0.505882    0.487759    0.538842    0.519817    0.516475    0.480000    3800        107.420495  0.714717    0.214915    147.768387 
[37m[36mINFO[0m[0m 01/29 23:25:09 | 0.515803    0.494229    0.997350    0.992933    0.082246    0.997350    0.992933    0.501176    0.485876    0.531607    0.518293    0.514624    0.478519    4000        113.074205  0.668836    0.225109    161.739363 
[37m[36mINFO[0m[0m 01/29 23:28:30 | 0.535872    0.519872    0.999117    0.996466    0.069493    0.999117    0.996466    0.503059    0.485876    0.565499    0.567073    0.539060    0.506667    4200        118.727915  0.641096    0.215983    157.134408 
[37m[36mINFO[0m[0m 01/29 23:31:54 | 0.534600    0.518871    0.999117    0.996466    0.067148    0.999117    0.996466    0.501176    0.478343    0.562452    0.570122    0.540170    0.508148    4400        124.381625  0.647624    0.227893    157.718993 
[37m[36mINFO[0m[0m 01/29 23:35:23 | 0.522709    0.503609    0.998233    0.992933    0.068672    0.998233    0.992933    0.492235    0.468927    0.546458    0.541159    0.529434    0.500741    4600        130.035336  0.632202    0.246520    160.153736 
[37m[36mINFO[0m[0m 01/29 23:38:39 | 0.532197    0.520219    0.999117    1.000000    0.062201    0.999117    1.000000    0.495059    0.476460    0.563214    0.570122    0.538319    0.514074    4800        135.689046  0.582499    0.215643    152.658182 
[37m[36mINFO[0m[0m 01/29 23:42:43 | 0.547064    0.537328    1.000000    1.000000    0.053945    1.000000    1.000000    0.502118    0.478343    0.581874    0.589939    0.557201    0.543704    5000        141.342756  0.588296    0.249450    193.743853 
[37m[36mINFO[0m[0m 01/29 23:42:44 | Cumulative gradient change saved at train_output/VLCS/RSC/[1, 2, 3]/250129_22-15-49_resnet50_sgd/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 01/29 23:42:47 | ---
[37m[36mINFO[0m[0m 01/29 23:42:47 | test-domain validation(oracle) = 54.706%
[37m[36mINFO[0m[0m 01/29 23:42:47 | training-domain validation(iid) = 53.220%
[37m[36mINFO[0m[0m 01/29 23:42:47 | last = 54.706%
[37m[36mINFO[0m[0m 01/29 23:42:47 | last (inD) = 100.000%
[37m[36mINFO[0m[0m 01/29 23:42:47 | training-domain validation (iid, inD) = 100.000%
[37m[36mINFO[0m[0m 01/29 23:42:47 | === Summary ===
[37m[36mINFO[0m[0m 01/29 23:42:47 | Command: /jsm0707/Large-scale/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm RSC --test_envs 1 2 3 --dataset VLCS
[37m[36mINFO[0m[0m 01/29 23:42:47 | Unique name: 250129_22-15-49_resnet50_sgd
[37m[36mINFO[0m[0m 01/29 23:42:47 | Out path: train_output/VLCS/RSC/[1, 2, 3]/250129_22-15-49_resnet50_sgd
[37m[36mINFO[0m[0m 01/29 23:42:47 | Algorithm: RSC
[37m[36mINFO[0m[0m 01/29 23:42:47 | Dataset: VLCS
