[37m[36mINFO[0m[0m 02/23 10:31:05 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm RSC --test_envs 0 1 2 --dataset VLCS --trial_seed 0 --hparams_seed 4
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: RSC
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 4
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/VLCS/RSC/[0, 1, 2]/250223_10-31-05_resnet50_GENIE
	out_root: train_output/VLCS/RSC/[0, 1, 2]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 1, 2]
	trial_seed: 0
	unique_name: 250223_10-31-05_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.5
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 2.0793009436922532e-05
	batch_size: 30
	weight_decay: 0.0007980067844361917
	rsc_f_drop_factor: 0.00568084739259922
	rsc_b_drop_factor: 0.21660562421584156
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 02/23 10:31:05 | n_steps = 5001
[37m[36mINFO[0m[0m 02/23 10:31:05 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/23 10:31:05 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/23 10:31:05 | 
[37m[36mINFO[0m[0m 02/23 10:31:05 | Testenv name escaping te_C_L_S -> te_C_L_S
[37m[36mINFO[0m[0m 02/23 10:31:05 | Test envs = [0, 1, 2], name = te_C_L_S
[37m[36mINFO[0m[0m 02/23 10:31:05 | Train environments: [3], Test environments: [0, 1, 2]
[37m[36mINFO[0m[0m 02/23 10:31:05 | Batch sizes for each domain: [0, 0, 0, 30] (total=30)
[37m[36mINFO[0m[0m 02/23 10:31:05 | steps-per-epoch for each domain: 90.03 -> min = 90.03
[37m[36mINFO[0m[0m 02/23 10:31:08 | # of params = 23518277
[37m[36mINFO[0m[0m 02/23 10:33:48 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 02/23 10:33:48 | 0.485229    0.501938    0.443539    0.445926    1.610404    0.611307    0.628975    0.459765    0.489642    0.384615    0.387195    0.443539    0.445926    0           0.000000    1.869976    2.564206    156.740974 
[37m[36mINFO[0m[0m 02/23 10:37:17 | 0.764155    0.757195    0.873380    0.838519    0.494188    0.978799    0.975265    0.572235    0.563089    0.741432    0.733232    0.873380    0.838519    200         2.221399    0.697694    0.207610    168.234924 
[37m[36mINFO[0m[0m 02/23 10:40:53 | 0.789318    0.780182    0.895224    0.835556    0.469754    0.984982    0.975265    0.622118    0.629002    0.760853    0.736280    0.895224    0.835556    400         4.442799    0.386072    0.253705    164.603389 
[37m[36mINFO[0m[0m 02/23 10:44:19 | 0.778339    0.759975    0.904850    0.829630    0.499889    0.975265    0.957597    0.588235    0.587571    0.771516    0.734756    0.904850    0.829630    600         6.664198    0.281699    0.207693    164.358253 
[37m[36mINFO[0m[0m 02/23 10:47:35 | 0.777465    0.763412    0.932247    0.838519    0.505378    0.985866    0.975265    0.570824    0.564972    0.775704    0.750000    0.932247    0.838519    800         8.885598    0.275887    0.198475    156.843577 
[37m[36mINFO[0m[0m 02/23 10:50:54 | 0.764399    0.761625    0.923732    0.838519    0.540697    0.963781    0.968198    0.576941    0.581921    0.752475    0.734756    0.923732    0.838519    1000        11.106997   0.214295    0.219411    154.562634 
[37m[36mINFO[0m[0m 02/23 10:54:24 | 0.777924    0.777965    0.917808    0.829630    0.680278    0.973498    0.982332    0.608941    0.629002    0.751333    0.722561    0.917808    0.829630    1200        13.328397   0.165207    0.267719    156.224495 
[37m[36mINFO[0m[0m 02/23 10:57:56 | 0.770281    0.751533    0.978156    0.837037    0.612445    0.975265    0.954064    0.579294    0.561205    0.756283    0.739329    0.978156    0.837037    1400        15.549796   0.139134    0.247041    162.737344 
[37m[36mINFO[0m[0m 02/23 11:01:20 | 0.746422    0.731160    0.955942    0.802963    0.819606    0.976148    0.975265    0.538824    0.529190    0.724296    0.689024    0.955942    0.802963    1600        17.771196   0.137154    0.222292    159.526385 
[37m[36mINFO[0m[0m 02/23 11:04:39 | 0.773640    0.759586    0.962977    0.850370    0.658961    0.974382    0.957597    0.594824    0.589454    0.751714    0.731707    0.962977    0.850370    1800        19.992595   0.160928    0.241194    150.854038 
[37m[36mINFO[0m[0m 02/23 11:08:05 | 0.754397    0.746924    0.980007    0.829630    0.627256    0.959364    0.961131    0.558588    0.555556    0.745240    0.724085    0.980007    0.829630    2000        22.213995   0.093531    0.243349    157.160758 
[37m[36mINFO[0m[0m 02/23 11:11:21 | 0.765564    0.748629    0.988893    0.841481    0.750477    0.977915    0.978799    0.575059    0.553672    0.743717    0.713415    0.988893    0.841481    2200        24.435394   0.072467    0.210886    154.526272 
[37m[36mINFO[0m[0m 02/23 11:14:41 | 0.747195    0.725528    0.979267    0.817778    0.597196    0.978799    0.971731    0.551059    0.531073    0.711729    0.673780    0.979267    0.817778    2400        26.656794   0.068716    0.224084    154.416907 
[37m[36mINFO[0m[0m 02/23 11:17:42 | 0.769133    0.754117    0.980378    0.823704    0.735280    0.977915    0.975265    0.579294    0.570621    0.750190    0.716463    0.980378    0.823704    2600        28.878193   0.065730    0.212229    139.361600 
[37m[36mINFO[0m[0m 02/23 11:21:00 | 0.776575    0.762761    0.982969    0.845926    0.688625    0.977032    0.968198    0.581176    0.583804    0.771516    0.736280    0.982969    0.845926    2800        31.099593   0.064940    0.281281    141.357583 
[37m[36mINFO[0m[0m 02/23 11:24:21 | 0.775329    0.769152    0.978897    0.838519    0.972167    0.975265    0.975265    0.586824    0.591337    0.763899    0.740854    0.978897    0.838519    3000        33.320992   0.047082    0.216712    157.852433 
[37m[36mINFO[0m[0m 02/23 11:27:36 | 0.751139    0.736306    0.968900    0.832593    0.777386    0.970848    0.968198    0.552941    0.527307    0.729627    0.713415    0.968900    0.832593    3200        35.542392   0.064432    0.201860    154.861569 
[37m[36mINFO[0m[0m 02/23 11:30:51 | 0.786612    0.774407    0.990004    0.862222    0.867780    0.978799    0.982332    0.608000    0.596987    0.773039    0.743902    0.990004    0.862222    3400        37.763791   0.039304    0.225539    149.464979 
[37m[36mINFO[0m[0m 02/23 11:33:54 | 0.771021    0.763353    0.991114    0.845926    0.763322    0.962898    0.957597    0.593882    0.600753    0.756283    0.731707    0.991114    0.845926    3600        39.985191   0.042389    0.210120    140.952380 
[37m[36mINFO[0m[0m 02/23 11:37:03 | 0.771928    0.754768    0.989263    0.823704    0.939728    0.986749    0.982332    0.576941    0.551789    0.752094    0.730183    0.989263    0.823704    3800        42.206590   0.040961    0.265010    135.869514 
[37m[36mINFO[0m[0m 02/23 11:40:17 | 0.768039    0.754463    0.994447    0.841481    0.828129    0.978799    0.971731    0.577412    0.570621    0.747906    0.721037    0.994447    0.841481    4000        44.427990   0.041979    0.214103    150.912757 
[37m[36mINFO[0m[0m 02/23 11:43:25 | 0.776043    0.771202    0.992966    0.838519    1.011113    0.969081    0.954064    0.624471    0.630885    0.734577    0.728659    0.992966    0.838519    4200        46.649389   0.026703    0.191661    150.341779 
[37m[36mINFO[0m[0m 02/23 11:46:25 | 0.750249    0.732330    0.996298    0.842963    0.885819    0.950530    0.950530    0.549647    0.525424    0.750571    0.721037    0.996298    0.842963    4400        48.870789   0.025323    0.199221    140.215131 
[37m[36mINFO[0m[0m 02/23 11:49:32 | 0.758577    0.748156    0.981859    0.823704    0.903374    0.977032    0.971731    0.557647    0.559322    0.741051    0.713415    0.981859    0.823704    4600        51.092188   0.042531    0.234954    139.760423 
[37m[36mINFO[0m[0m 02/23 11:52:43 | 0.760890    0.752334    0.994076    0.838519    0.760312    0.966431    0.961131    0.563765    0.568738    0.752475    0.727134    0.994076    0.838519    4800        53.313588   0.037349    0.211930    148.948292 
[37m[36mINFO[0m[0m 02/23 11:56:01 | 0.774961    0.757247    0.994076    0.841481    0.773165    0.960247    0.929329    0.593882    0.596987    0.770754    0.745427    0.994076    0.841481    5000        55.534987   0.023534    0.223411    153.160822 
[37m[36mINFO[0m[0m 02/23 11:56:01 | Cumulative gradient change saved at train_output/VLCS/RSC/[0, 1, 2]/250223_10-31-05_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/23 11:56:03 | ---
[37m[36mINFO[0m[0m 02/23 11:56:03 | test-domain validation(oracle) = 78.932%
[37m[36mINFO[0m[0m 02/23 11:56:03 | training-domain validation(iid) = 78.661%
[37m[36mINFO[0m[0m 02/23 11:56:03 | last = 77.496%
[37m[36mINFO[0m[0m 02/23 11:56:03 | last (inD) = 84.148%
[37m[36mINFO[0m[0m 02/23 11:56:03 | training-domain validation (iid, inD) = 86.222%
[37m[36mINFO[0m[0m 02/23 11:56:03 | === Summary ===
[37m[36mINFO[0m[0m 02/23 11:56:03 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm RSC --test_envs 0 1 2 --dataset VLCS --trial_seed 0 --hparams_seed 4
[37m[36mINFO[0m[0m 02/23 11:56:03 | Unique name: 250223_10-31-05_resnet50_GENIE
[37m[36mINFO[0m[0m 02/23 11:56:03 | Out path: train_output/VLCS/RSC/[0, 1, 2]/250223_10-31-05_resnet50_GENIE
[37m[36mINFO[0m[0m 02/23 11:56:03 | Algorithm: RSC
[37m[36mINFO[0m[0m 02/23 11:56:03 | Dataset: VLCS
