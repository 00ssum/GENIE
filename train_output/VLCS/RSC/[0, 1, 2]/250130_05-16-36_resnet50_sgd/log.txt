[37m[36mINFO[0m[0m 01/30 05:16:36 | Command :: /jsm0707/Large-scale/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm RSC --test_envs 0 1 2 --dataset VLCS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: RSC
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_sgd.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_sgd
	out_dir: train_output/VLCS/RSC/[0, 1, 2]/250130_05-16-36_resnet50_sgd
	out_root: train_output/VLCS/RSC/[0, 1, 2]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 1, 2]
	trial_seed: 0
	unique_name: 250130_05-16-36_resnet50_sgd
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: sgd
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	rsc_f_drop_factor: 0.3333333333333333
	rsc_b_drop_factor: 0.3333333333333333
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 01/30 05:16:36 | n_steps = 5001
[37m[36mINFO[0m[0m 01/30 05:16:36 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 01/30 05:16:36 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 01/30 05:16:36 | 
[37m[36mINFO[0m[0m 01/30 05:16:36 | Testenv name escaping te_C_L_S -> te_C_L_S
[37m[36mINFO[0m[0m 01/30 05:16:36 | Test envs = [0, 1, 2], name = te_C_L_S
[37m[36mINFO[0m[0m 01/30 05:16:36 | Train environments: [3], Test environments: [0, 1, 2]
[37m[36mINFO[0m[0m 01/30 05:16:36 | Batch sizes for each domain: [0, 0, 0, 32] (total=32)
[37m[36mINFO[0m[0m 01/30 05:16:36 | steps-per-epoch for each domain: 84.41 -> min = 84.41
[37m[36mINFO[0m[0m 01/30 05:16:37 | # of params = 23518277
[37m[36mINFO[0m[0m 01/30 05:19:37 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 01/30 05:19:37 | 0.156389    0.134311    0.132544    0.120000    1.833557    0.091873    0.081272    0.189176    0.160075    0.188119    0.161585    0.132544    0.120000    0           0.000000    3.268955    1.159460    178.767371 
[37m[36mINFO[0m[0m 01/30 05:23:20 | 0.380118    0.386003    0.445020    0.451852    1.482621    0.234099    0.222615    0.476706    0.500942    0.429551    0.434451    0.445020    0.451852    200         2.369493    2.631627    0.247816    173.430231 
[37m[36mINFO[0m[0m 01/30 05:27:36 | 0.477821    0.491360    0.447242    0.447407    1.448137    0.584806    0.586572    0.460235    0.489642    0.388423    0.397866    0.447242    0.447407    400         4.738986    2.031302    0.281810    198.714695 
[37m[36mINFO[0m[0m 01/30 05:31:53 | 0.485229    0.501938    0.443539    0.444444    1.432484    0.611307    0.628975    0.459765    0.489642    0.384615    0.387195    0.443539    0.444444    600         7.108478    1.821357    0.297985    197.361596 
[37m[36mINFO[0m[0m 01/30 05:36:16 | 0.485229    0.501938    0.443539    0.445926    1.423751    0.611307    0.628975    0.459765    0.489642    0.384615    0.387195    0.443539    0.445926    800         9.477971    1.735991    0.304478    201.837437 
[37m[36mINFO[0m[0m 01/30 05:40:29 | 0.485229    0.501938    0.443539    0.445926    1.417546    0.611307    0.628975    0.459765    0.489642    0.384615    0.387195    0.443539    0.445926    1000        11.847464   1.686456    0.307280    191.443115 
[37m[36mINFO[0m[0m 01/30 05:44:53 | 0.485229    0.501938    0.443539    0.445926    1.414912    0.611307    0.628975    0.459765    0.489642    0.384615    0.387195    0.443539    0.445926    1200        14.216957   1.664097    0.292799    205.495831 
[37m[36mINFO[0m[0m 01/30 05:49:09 | 0.485229    0.501938    0.443539    0.445926    1.411786    0.611307    0.628975    0.459765    0.489642    0.384615    0.387195    0.443539    0.445926    1400        16.586449   1.638871    0.303575    195.748777 
[37m[36mINFO[0m[0m 01/30 05:53:26 | 0.485229    0.501938    0.443539    0.445926    1.409097    0.611307    0.628975    0.459765    0.489642    0.384615    0.387195    0.443539    0.445926    1600        18.955942   1.620351    0.332300    190.602233 
[37m[36mINFO[0m[0m 01/30 05:57:43 | 0.485229    0.501938    0.443539    0.445926    1.407690    0.611307    0.628975    0.459765    0.489642    0.384615    0.387195    0.443539    0.445926    1800        21.325435   1.613034    0.352792    186.399524 
[37m[36mINFO[0m[0m 01/30 06:01:36 | 0.485229    0.501938    0.443539    0.445926    1.405150    0.611307    0.628975    0.459765    0.489642    0.384615    0.387195    0.443539    0.445926    2000        23.694928   1.596667    0.301242    172.245630 
[37m[36mINFO[0m[0m 01/30 06:05:24 | 0.485229    0.501938    0.443539    0.445926    1.402861    0.611307    0.628975    0.459765    0.489642    0.384615    0.387195    0.443539    0.445926    2200        26.064421   1.590844    0.310954    166.263728 
[37m[36mINFO[0m[0m 01/30 06:09:11 | 0.485229    0.501938    0.443539    0.445926    1.399510    0.611307    0.628975    0.459765    0.489642    0.384615    0.387195    0.443539    0.445926    2400        28.433913   1.574963    0.309268    164.424636 
[37m[36mINFO[0m[0m 01/30 06:13:04 | 0.485229    0.501938    0.443539    0.445926    1.395873    0.611307    0.628975    0.459765    0.489642    0.384615    0.387195    0.443539    0.445926    2600        30.803406   1.564845    0.290947    175.607275 
[37m[36mINFO[0m[0m 01/30 06:16:52 | 0.485229    0.501938    0.443539    0.445926    1.392328    0.611307    0.628975    0.459765    0.489642    0.384615    0.387195    0.443539    0.445926    2800        33.172899   1.558244    0.313912    165.285471 
[37m[36mINFO[0m[0m 01/30 06:20:46 | 0.485229    0.501938    0.443539    0.445926    1.389151    0.611307    0.628975    0.459765    0.489642    0.384615    0.387195    0.443539    0.445926    3000        35.542392   1.554376    0.337227    165.953068 
[37m[36mINFO[0m[0m 01/30 06:24:30 | 0.485229    0.501938    0.443539    0.445926    1.386055    0.611307    0.628975    0.459765    0.489642    0.384615    0.387195    0.443539    0.445926    3200        37.911884   1.549752    0.316828    160.646054 
[37m[36mINFO[0m[0m 01/30 06:28:23 | 0.485229    0.501938    0.443539    0.445926    1.382432    0.611307    0.628975    0.459765    0.489642    0.384615    0.387195    0.443539    0.445926    3400        40.281377   1.542689    0.306922    172.161369 
[37m[36mINFO[0m[0m 01/30 06:32:12 | 0.485229    0.501938    0.443539    0.445926    1.379458    0.611307    0.628975    0.459765    0.489642    0.384615    0.387195    0.443539    0.445926    3600        42.650870   1.547498    0.292969    169.967114 
[37m[36mINFO[0m[0m 01/30 06:35:54 | 0.485229    0.501938    0.443539    0.445926    1.375232    0.611307    0.628975    0.459765    0.489642    0.384615    0.387195    0.443539    0.445926    3800        45.020363   1.534889    0.272353    167.307342 
[37m[36mINFO[0m[0m 01/30 06:39:34 | 0.485229    0.501938    0.443539    0.445926    1.369757    0.611307    0.628975    0.459765    0.489642    0.384615    0.387195    0.443539    0.445926    4000        47.389856   1.523740    0.291626    161.485839 
[37m[36mINFO[0m[0m 01/30 06:43:25 | 0.485229    0.501938    0.443539    0.445926    1.364761    0.611307    0.628975    0.459765    0.489642    0.384615    0.387195    0.443539    0.445926    4200        49.759348   1.526480    0.270039    177.531401 
[37m[36mINFO[0m[0m 01/30 06:47:20 | 0.485229    0.501938    0.443539    0.445926    1.359664    0.611307    0.628975    0.459765    0.489642    0.384615    0.387195    0.443539    0.445926    4400        52.128841   1.523003    0.271383    180.901945 
[37m[36mINFO[0m[0m 01/30 06:51:10 | 0.485229    0.501938    0.443539    0.445926    1.354600    0.611307    0.628975    0.459765    0.489642    0.384615    0.387195    0.443539    0.445926    4600        54.498334   1.518331    0.297906    170.471051 
[37m[36mINFO[0m[0m 01/30 06:55:07 | 0.485229    0.501938    0.443539    0.445926    1.349580    0.611307    0.628975    0.459765    0.489642    0.384615    0.387195    0.443539    0.445926    4800        56.867827   1.520522    0.290258    179.041215 
[37m[36mINFO[0m[0m 01/30 06:58:52 | 0.485229    0.501938    0.443539    0.445926    1.344103    0.611307    0.628975    0.459765    0.489642    0.384615    0.387195    0.443539    0.445926    5000        59.237320   1.514032    0.246366    174.892379 
[37m[36mINFO[0m[0m 01/30 06:58:52 | Cumulative gradient change saved at train_output/VLCS/RSC/[0, 1, 2]/250130_05-16-36_resnet50_sgd/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 01/30 06:58:53 | ---
[37m[36mINFO[0m[0m 01/30 06:58:53 | test-domain validation(oracle) = 48.523%
[37m[36mINFO[0m[0m 01/30 06:58:53 | training-domain validation(iid) = 38.012%
[37m[36mINFO[0m[0m 01/30 06:58:53 | last = 48.523%
[37m[36mINFO[0m[0m 01/30 06:58:53 | last (inD) = 44.593%
[37m[36mINFO[0m[0m 01/30 06:58:53 | training-domain validation (iid, inD) = 45.185%
[37m[36mINFO[0m[0m 01/30 06:58:53 | === Summary ===
[37m[36mINFO[0m[0m 01/30 06:58:53 | Command: /jsm0707/Large-scale/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm RSC --test_envs 0 1 2 --dataset VLCS
[37m[36mINFO[0m[0m 01/30 06:58:53 | Unique name: 250130_05-16-36_resnet50_sgd
[37m[36mINFO[0m[0m 01/30 06:58:53 | Out path: train_output/VLCS/RSC/[0, 1, 2]/250130_05-16-36_resnet50_sgd
[37m[36mINFO[0m[0m 01/30 06:58:53 | Algorithm: RSC
[37m[36mINFO[0m[0m 01/30 06:58:53 | Dataset: VLCS
