[37m[36mINFO[0m[0m 01/29 07:50:03 | Command :: /jsm0707/Large-scale/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm RSC --test_envs 0 1 2 --dataset VLCS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: RSC
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_adam.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_adam
	out_dir: train_output/VLCS/RSC/[0, 1, 2]/250129_07-50-03_resnet50_adam
	out_root: train_output/VLCS/RSC/[0, 1, 2]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 1, 2]
	trial_seed: 0
	unique_name: 250129_07-50-03_resnet50_adam
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: adam
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	rsc_f_drop_factor: 0.3333333333333333
	rsc_b_drop_factor: 0.3333333333333333
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 01/29 07:50:03 | n_steps = 5001
[37m[36mINFO[0m[0m 01/29 07:50:03 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 01/29 07:50:03 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 01/29 07:50:03 | 
[37m[36mINFO[0m[0m 01/29 07:50:03 | Testenv name escaping te_C_L_S -> te_C_L_S
[37m[36mINFO[0m[0m 01/29 07:50:03 | Test envs = [0, 1, 2], name = te_C_L_S
[37m[36mINFO[0m[0m 01/29 07:50:03 | Train environments: [3], Test environments: [0, 1, 2]
[37m[36mINFO[0m[0m 01/29 07:50:03 | Batch sizes for each domain: [0, 0, 0, 32] (total=32)
[37m[36mINFO[0m[0m 01/29 07:50:03 | steps-per-epoch for each domain: 84.41 -> min = 84.41
[37m[36mINFO[0m[0m 01/29 07:50:05 | # of params = 23518277
[37m[36mINFO[0m[0m 01/29 07:52:40 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 01/29 07:52:40 | 0.327884    0.331817    0.365050    0.317037    1.567931    0.141343    0.137809    0.432941    0.436911    0.409368    0.420732    0.365050    0.317037    0           0.000000    3.268955    1.582965    153.220824 
[37m[36mINFO[0m[0m 01/29 07:56:04 | 0.663612    0.632912    0.707886    0.690370    0.835261    0.818021    0.766784    0.518588    0.508475    0.654227    0.623476    0.707886    0.690370    200         2.369493    1.267273    0.255614    152.453363 
[37m[36mINFO[0m[0m 01/29 07:59:42 | 0.745807    0.738452    0.844502    0.802963    0.586081    0.924912    0.922261    0.590118    0.578154    0.722391    0.714939    0.844502    0.802963    400         4.738986    0.647882    0.304723    156.214609 
[37m[36mINFO[0m[0m 01/29 08:03:11 | 0.736451    0.732009    0.861533    0.788148    0.671203    0.925795    0.925795    0.624000    0.642185    0.659558    0.628049    0.861533    0.788148    600         7.108478    0.421477    0.259439    156.395025 
[37m[36mINFO[0m[0m 01/29 08:06:37 | 0.777618    0.781647    0.917068    0.820741    0.555128    0.964664    0.957597    0.632471    0.664783    0.735720    0.722561    0.917068    0.820741    800         9.477971    0.310818    0.271688    151.982826 
[37m[36mINFO[0m[0m 01/29 08:10:10 | 0.759775    0.753877    0.927805    0.831111    0.681545    0.956714    0.957597    0.589176    0.587571    0.733435    0.716463    0.927805    0.831111    1000        11.847464   0.268800    0.286474    154.678320 
[37m[36mINFO[0m[0m 01/29 08:13:31 | 0.767204    0.757272    0.932988    0.826667    0.666298    0.931095    0.918728    0.620706    0.629002    0.749810    0.724085    0.932988    0.826667    1200        14.216957   0.194986    0.239191    153.905792 
[37m[36mINFO[0m[0m 01/29 08:16:53 | 0.784057    0.776266    0.973713    0.831111    0.648162    0.953180    0.939929    0.628235    0.664783    0.770754    0.724085    0.973713    0.831111    1400        16.586449   0.167844    0.238299    154.501986 
[37m[36mINFO[0m[0m 01/29 08:20:27 | 0.779036    0.771687    0.981118    0.851852    0.630500    0.958481    0.946996    0.627294    0.651601    0.751333    0.716463    0.981118    0.851852    1600        18.955942   0.151056    0.264109    160.018746 
[37m[36mINFO[0m[0m 01/29 08:23:58 | 0.742364    0.727531    0.953721    0.802963    0.712169    0.962014    0.954064    0.567059    0.559322    0.698020    0.669207    0.953721    0.802963    1800        21.325435   0.113779    0.259077    159.076361 
[37m[36mINFO[0m[0m 01/29 08:27:21 | 0.744474    0.731805    0.949648    0.801481    0.881052    0.946113    0.936396    0.587765    0.591337    0.699543    0.667683    0.949648    0.801481    2000        23.694928   0.107424    0.253665    152.191815 
[37m[36mINFO[0m[0m 01/29 08:30:41 | 0.757821    0.751084    0.979267    0.814815    0.733365    0.934629    0.918728    0.602353    0.619586    0.736481    0.714939    0.979267    0.814815    2200        26.064421   0.081516    0.243044    151.355338 
[37m[36mINFO[0m[0m 01/29 08:34:06 | 0.756574    0.735039    0.984820    0.831111    0.675383    0.951413    0.946996    0.582588    0.570621    0.735720    0.687500    0.984820    0.831111    2400        28.433913   0.066430    0.260690    153.475094 
[37m[36mINFO[0m[0m 01/29 08:37:23 | 0.759914    0.749651    0.980748    0.804444    0.701611    0.938163    0.936396    0.636706    0.640301    0.704874    0.672256    0.980748    0.804444    2600        30.803406   0.068897    0.211049    154.873457 
[37m[36mINFO[0m[0m 01/29 08:40:52 | 0.756407    0.757745    0.954832    0.820741    1.002402    0.909894    0.908127    0.649882    0.676083    0.709444    0.689024    0.954832    0.820741    2800        33.172899   0.068708    0.281173    152.364661 
[37m[36mINFO[0m[0m 01/29 08:44:22 | 0.785902    0.775651    0.991485    0.811852    1.013002    0.967314    0.961131    0.639059    0.647834    0.751333    0.717988    0.991485    0.811852    3000        35.542392   0.040974    0.299505    150.028399 
[37m[36mINFO[0m[0m 01/29 08:47:37 | 0.788516    0.774473    0.992225    0.826667    0.979193    0.977915    0.975265    0.630588    0.627119    0.757045    0.721037    0.992225    0.826667    3200        37.911884   0.074959    0.208255    154.024515 
[37m[36mINFO[0m[0m 01/29 08:50:54 | 0.780754    0.780642    0.992595    0.844444    1.113511    0.946113    0.943463    0.643294    0.659134    0.752856    0.739329    0.992595    0.844444    3400        40.281377   0.031358    0.220540    152.176115 
[37m[36mINFO[0m[0m 01/29 08:54:19 | 0.767256    0.764990    0.967790    0.813333    0.964052    0.935512    0.929329    0.610353    0.630885    0.755903    0.734756    0.967790    0.813333    3600        42.650870   0.069100    0.292576    146.855960 
[37m[36mINFO[0m[0m 01/29 08:57:42 | 0.762812    0.757576    0.995187    0.823704    0.953749    0.910777    0.911661    0.612235    0.630885    0.765423    0.730183    0.995187    0.823704    3800        45.020363   0.044838    0.247731    153.002101 
[37m[36mINFO[0m[0m 01/29 09:01:06 | 0.750000    0.751344    0.986672    0.820741    0.842183    0.950530    0.968198    0.581647    0.612053    0.717822    0.673780    0.986672    0.820741    4000        47.389856   0.037572    0.229376    158.255704 
[37m[36mINFO[0m[0m 01/29 09:04:33 | 0.724283    0.717693    0.991114    0.798519    1.168288    0.856890    0.865724    0.588235    0.580038    0.727723    0.707317    0.991114    0.798519    4200        49.759348   0.029336    0.258258    154.834214 
[37m[36mINFO[0m[0m 01/29 09:07:57 | 0.769595    0.761219    0.994817    0.828148    1.133144    0.947880    0.954064    0.620235    0.617702    0.740670    0.711890    0.994817    0.828148    4400        52.128841   0.036540    0.264488    151.638175 
[37m[36mINFO[0m[0m 01/29 09:11:33 | 0.757701    0.745603    0.996668    0.822222    0.968315    0.949647    0.950530    0.573647    0.574388    0.749810    0.711890    0.996668    0.822222    4600        54.498334   0.061259    0.293083    157.472667 
[37m[36mINFO[0m[0m 01/29 09:15:07 | 0.739693    0.733341    0.981859    0.794074    1.022113    0.916961    0.922261    0.599529    0.585687    0.702589    0.692073    0.981859    0.794074    4800        56.867827   0.031945    0.257604    162.618277 
[37m[36mINFO[0m[0m 01/29 09:18:30 | 0.775611    0.770874    0.989263    0.841481    1.142357    0.969081    0.954064    0.629647    0.649718    0.728104    0.708841    0.989263    0.841481    5000        59.237320   0.045959    0.228875    156.532630 
[37m[36mINFO[0m[0m 01/29 09:18:30 | Cumulative gradient change saved at train_output/VLCS/RSC/[0, 1, 2]/250129_07-50-03_resnet50_adam/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 01/29 09:18:31 | ---
[37m[36mINFO[0m[0m 01/29 09:18:31 | test-domain validation(oracle) = 77.762%
[37m[36mINFO[0m[0m 01/29 09:18:31 | training-domain validation(iid) = 77.904%
[37m[36mINFO[0m[0m 01/29 09:18:31 | last = 77.561%
[37m[36mINFO[0m[0m 01/29 09:18:31 | last (inD) = 84.148%
[37m[36mINFO[0m[0m 01/29 09:18:31 | training-domain validation (iid, inD) = 85.185%
[37m[36mINFO[0m[0m 01/29 09:18:31 | === Summary ===
[37m[36mINFO[0m[0m 01/29 09:18:31 | Command: /jsm0707/Large-scale/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm RSC --test_envs 0 1 2 --dataset VLCS
[37m[36mINFO[0m[0m 01/29 09:18:31 | Unique name: 250129_07-50-03_resnet50_adam
[37m[36mINFO[0m[0m 01/29 09:18:31 | Out path: train_output/VLCS/RSC/[0, 1, 2]/250129_07-50-03_resnet50_adam
[37m[36mINFO[0m[0m 01/29 09:18:31 | Algorithm: RSC
[37m[36mINFO[0m[0m 01/29 09:18:31 | Dataset: VLCS
