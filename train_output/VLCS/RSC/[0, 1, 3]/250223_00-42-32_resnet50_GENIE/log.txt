[37m[36mINFO[0m[0m 02/23 00:42:32 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm RSC --test_envs 0 1 3 --dataset VLCS --trial_seed 0 --hparams_seed 18
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: RSC
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 18
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/VLCS/RSC/[0, 1, 3]/250223_00-42-32_resnet50_GENIE
	out_root: train_output/VLCS/RSC/[0, 1, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 1, 3]
	trial_seed: 0
	unique_name: 250223_00-42-32_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.1
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 0.00021894640154701087
	batch_size: 13
	weight_decay: 7.1565884139944e-05
	rsc_f_drop_factor: 0.17180978572145622
	rsc_b_drop_factor: 0.27683104155644905
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 02/23 00:42:32 | n_steps = 5001
[37m[36mINFO[0m[0m 02/23 00:42:32 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/23 00:42:32 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/23 00:42:32 | 
[37m[36mINFO[0m[0m 02/23 00:42:32 | Testenv name escaping te_C_L_V -> te_C_L_V
[37m[36mINFO[0m[0m 02/23 00:42:32 | Test envs = [0, 1, 3], name = te_C_L_V
[37m[36mINFO[0m[0m 02/23 00:42:32 | Train environments: [2], Test environments: [0, 1, 3]
[37m[36mINFO[0m[0m 02/23 00:42:32 | Batch sizes for each domain: [0, 0, 13, 0] (total=13)
[37m[36mINFO[0m[0m 02/23 00:42:32 | steps-per-epoch for each domain: 202.00 -> min = 202.00
[37m[36mINFO[0m[0m 02/23 00:42:34 | # of params = 23518277
[37m[36mINFO[0m[0m 02/23 00:44:58 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 02/23 00:44:58 | 0.306275    0.299533    0.426123    0.431402    1.255636    0.104240    0.081272    0.484706    0.483992    0.426123    0.431402    0.329878    0.333333    0           0.000000    2.520547    1.758462    142.652140 
[37m[36mINFO[0m[0m 02/23 00:48:15 | 0.636290    0.626972    0.753237    0.739329    0.714058    0.708481    0.699647    0.569882    0.564972    0.753237    0.739329    0.630507    0.616296    200         0.990099    1.121007    0.176806    160.848221 
[37m[36mINFO[0m[0m 02/23 00:51:32 | 0.676499    0.678668    0.806931    0.759146    0.638511    0.744700    0.745583    0.625412    0.625235    0.806931    0.759146    0.659385    0.665185    400         1.980198    0.816107    0.167633    164.032807 
[37m[36mINFO[0m[0m 02/23 00:54:23 | 0.629664    0.627803    0.800457    0.772866    0.580845    0.680212    0.681979    0.612706    0.596987    0.800457    0.772866    0.596076    0.604444    600         2.970297    0.701202    0.145823    141.378896 
[37m[36mINFO[0m[0m 02/23 00:57:36 | 0.673793    0.674723    0.806550    0.788110    0.576746    0.732332    0.724382    0.669647    0.676083    0.806550    0.788110    0.619400    0.623704    800         3.960396    0.606916    0.188114    156.192889 
[37m[36mINFO[0m[0m 02/23 01:00:53 | 0.665013    0.663613    0.818355    0.769817    0.572772    0.733216    0.727915    0.640941    0.642185    0.818355    0.769817    0.620881    0.620741    1000        4.950495    0.548346    0.136445    169.099297 
[37m[36mINFO[0m[0m 02/23 01:04:01 | 0.680218    0.684069    0.838919    0.795732    0.573622    0.750883    0.742049    0.657412    0.676083    0.838919    0.795732    0.632358    0.634074    1200        5.940594    0.525296    0.144872    159.451666 
[37m[36mINFO[0m[0m 02/23 01:07:06 | 0.643865    0.639789    0.863671    0.771341    0.628015    0.722615    0.720848    0.563294    0.555556    0.863671    0.771341    0.645687    0.642963    1400        6.930693    0.496820    0.199995    144.528234 
[37m[36mINFO[0m[0m 02/23 01:10:21 | 0.688864    0.696562    0.872049    0.803354    0.556426    0.765018    0.759717    0.665882    0.664783    0.872049    0.803354    0.635690    0.665185    1600        7.920792    0.418004    0.149586    164.897921 
[37m[36mINFO[0m[0m 02/23 01:13:39 | 0.636735    0.637355    0.878142    0.803354    0.618850    0.663428    0.692580    0.615529    0.591337    0.878142    0.803354    0.631248    0.628148    1800        8.910891    0.440285    0.157879    166.651642 
[37m[36mINFO[0m[0m 02/23 01:16:31 | 0.637995    0.649787    0.861767    0.785061    0.690507    0.703180    0.713781    0.634353    0.645951    0.861767    0.785061    0.576453    0.589630    2000        9.900990    0.408658    0.161031    140.006275 
[37m[36mINFO[0m[0m 02/23 01:19:31 | 0.676242    0.677476    0.905941    0.792683    0.584074    0.735866    0.738516    0.637176    0.634652    0.905941    0.792683    0.655683    0.659259    2200        10.891089   0.394859    0.232749    133.552564 
[37m[36mINFO[0m[0m 02/23 01:22:28 | 0.664502    0.672538    0.875476    0.765244    0.780111    0.727915    0.724382    0.616941    0.638418    0.875476    0.765244    0.648649    0.654815    2400        11.881188   0.392408    0.159193    144.790488 
[37m[36mINFO[0m[0m 02/23 01:25:27 | 0.655085    0.676422    0.848439    0.748476    1.004731    0.700530    0.724382    0.659765    0.693032    0.848439    0.748476    0.604961    0.611852    2600        12.871287   0.351124    0.150355    149.019481 
[37m[36mINFO[0m[0m 02/23 01:28:13 | 0.617030    0.632615    0.922315    0.797256    0.807174    0.645760    0.671378    0.600000    0.610169    0.922315    0.797256    0.605331    0.616296    2800        13.861386   0.324465    0.149236    136.629138 
[37m[36mINFO[0m[0m 02/23 01:30:51 | 0.645211    0.636028    0.858340    0.730183    0.858497    0.729682    0.724382    0.564706    0.555556    0.858340    0.730183    0.641244    0.628148    3000        14.851485   0.349003    0.150551    127.225179 
[37m[36mINFO[0m[0m 02/23 01:33:41 | 0.618205    0.610656    0.900228    0.772866    0.769689    0.701413    0.678445    0.570824    0.566855    0.900228    0.772866    0.582377    0.586667    3200        15.841584   0.287027    0.147121    141.249851 
[37m[36mINFO[0m[0m 02/23 01:36:29 | 0.650823    0.650883    0.922696    0.795732    0.644641    0.734982    0.727915    0.596235    0.595104    0.922696    0.795732    0.621251    0.629630    3400        16.831683   0.307537    0.136942    140.118855 
[37m[36mINFO[0m[0m 02/23 01:39:14 | 0.585267    0.599079    0.930312    0.795732    0.845971    0.515901    0.551237    0.597176    0.604520    0.930312    0.795732    0.642725    0.641481    3600        17.821782   0.287180    0.134352    138.487910 
[37m[36mINFO[0m[0m 02/23 01:41:56 | 0.540694    0.538564    0.921173    0.788110    0.825807    0.487633    0.487633    0.573176    0.572505    0.921173    0.788110    0.561274    0.555556    3800        18.811881   0.237723    0.145740    132.952801 
[37m[36mINFO[0m[0m 02/23 01:44:42 | 0.627871    0.622994    0.897182    0.766768    0.899613    0.708481    0.703180    0.553882    0.548023    0.897182    0.766768    0.621251    0.617778    4000        19.801980   0.284945    0.146768    136.695786 
[37m[36mINFO[0m[0m 02/23 01:47:32 | 0.629256    0.619949    0.913557    0.766768    1.002901    0.674028    0.636042    0.604706    0.583804    0.913557    0.766768    0.609034    0.640000    4200        20.792079   0.249777    0.140999    141.047201 
[37m[36mINFO[0m[0m 02/23 01:50:21 | 0.557266    0.567727    0.890327    0.778963    0.816255    0.451413    0.459364    0.620235    0.629002    0.890327    0.778963    0.600148    0.614815    4400        21.782178   0.305279    0.147177    139.754066 
[37m[36mINFO[0m[0m 02/23 01:52:57 | 0.481492    0.487674    0.917746    0.757622    0.750359    0.248233    0.233216    0.626824    0.632768    0.917746    0.757622    0.569419    0.597037    4600        22.772277   0.234402    0.149056    126.655709 
[37m[36mINFO[0m[0m 02/23 01:55:48 | 0.579571    0.587530    0.936405    0.780488    0.892771    0.557420    0.600707    0.579294    0.557439    0.936405    0.780488    0.601999    0.604444    4800        23.762376   0.225062    0.176666    134.814985 
[37m[36mINFO[0m[0m 02/23 01:58:39 | 0.538250    0.555067    0.914318    0.771341    1.167917    0.378975    0.402827    0.638588    0.653484    0.914318    0.771341    0.597186    0.608889    5000        24.752475   0.226819    0.145573    141.959456 
[37m[36mINFO[0m[0m 02/23 01:58:39 | Cumulative gradient change saved at train_output/VLCS/RSC/[0, 1, 3]/250223_00-42-32_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/23 01:58:41 | ---
[37m[36mINFO[0m[0m 02/23 01:58:41 | test-domain validation(oracle) = 68.886%
[37m[36mINFO[0m[0m 02/23 01:58:41 | training-domain validation(iid) = 68.886%
[37m[36mINFO[0m[0m 02/23 01:58:41 | last = 53.825%
[37m[36mINFO[0m[0m 02/23 01:58:41 | last (inD) = 77.134%
[37m[36mINFO[0m[0m 02/23 01:58:41 | training-domain validation (iid, inD) = 80.335%
[37m[36mINFO[0m[0m 02/23 01:58:41 | === Summary ===
[37m[36mINFO[0m[0m 02/23 01:58:41 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm RSC --test_envs 0 1 3 --dataset VLCS --trial_seed 0 --hparams_seed 18
[37m[36mINFO[0m[0m 02/23 01:58:41 | Unique name: 250223_00-42-32_resnet50_GENIE
[37m[36mINFO[0m[0m 02/23 01:58:41 | Out path: train_output/VLCS/RSC/[0, 1, 3]/250223_00-42-32_resnet50_GENIE
[37m[36mINFO[0m[0m 02/23 01:58:41 | Algorithm: RSC
[37m[36mINFO[0m[0m 02/23 01:58:41 | Dataset: VLCS
