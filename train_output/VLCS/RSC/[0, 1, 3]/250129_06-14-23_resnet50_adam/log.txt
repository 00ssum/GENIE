[37m[36mINFO[0m[0m 01/29 06:14:23 | Command :: /jsm0707/Large-scale/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm RSC --test_envs 0 1 3 --dataset VLCS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: RSC
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_adam.yaml']
	data_dir: data
	dataset: VLCS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_adam
	out_dir: train_output/VLCS/RSC/[0, 1, 3]/250129_06-14-23_resnet50_adam
	out_root: train_output/VLCS/RSC/[0, 1, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 1, 3]
	trial_seed: 0
	unique_name: 250129_06-14-23_resnet50_adam
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: adam
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	rsc_f_drop_factor: 0.3333333333333333
	rsc_b_drop_factor: 0.3333333333333333
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: C (#1415)
	env1: L (#2656)
	env2: S (#3282)
	env3: V (#3376)

[37m[36mINFO[0m[0m 01/29 06:14:23 | n_steps = 5001
[37m[36mINFO[0m[0m 01/29 06:14:23 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 01/29 06:14:23 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 01/29 06:14:23 | 
[37m[36mINFO[0m[0m 01/29 06:14:23 | Testenv name escaping te_C_L_V -> te_C_L_V
[37m[36mINFO[0m[0m 01/29 06:14:23 | Test envs = [0, 1, 3], name = te_C_L_V
[37m[36mINFO[0m[0m 01/29 06:14:23 | Train environments: [2], Test environments: [0, 1, 3]
[37m[36mINFO[0m[0m 01/29 06:14:23 | Batch sizes for each domain: [0, 0, 32, 0] (total=32)
[37m[36mINFO[0m[0m 01/29 06:14:23 | steps-per-epoch for each domain: 82.06 -> min = 82.06
[37m[36mINFO[0m[0m 01/29 06:14:24 | # of params = 23518277
[37m[36mINFO[0m[0m 01/29 06:17:02 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 01/29 06:17:02 | 0.270907    0.248356    0.387662    0.373476    1.477991    0.099823    0.060071    0.464471    0.433145    0.387662    0.373476    0.248427    0.251852    0           0.000000    3.109189    1.502321    156.476448 
[37m[36mINFO[0m[0m 01/29 06:20:42 | 0.571022    0.567860    0.701828    0.695122    0.752270    0.685512    0.678445    0.495529    0.485876    0.701828    0.695122    0.532025    0.539259    200         2.437167    1.063167    0.331329    153.139667 
[37m[36mINFO[0m[0m 01/29 06:24:25 | 0.611668    0.603962    0.788652    0.753049    0.607731    0.685512    0.674912    0.576000    0.551789    0.788652    0.753049    0.573491    0.585185    400         4.874334    0.652911    0.321089    158.617889 
[37m[36mINFO[0m[0m 01/29 06:28:00 | 0.655728    0.647561    0.833968    0.763720    0.619384    0.704947    0.674912    0.632471    0.644068    0.833968    0.763720    0.629767    0.623704    600         7.311500    0.520889    0.335412    147.216544 
[37m[36mINFO[0m[0m 01/29 06:31:42 | 0.607202    0.609553    0.886900    0.788110    0.602600    0.575972    0.572438    0.613647    0.617702    0.886900    0.788110    0.631988    0.638519    800         9.748667    0.424393    0.357604    150.150196 
[37m[36mINFO[0m[0m 01/29 06:35:27 | 0.598616    0.604767    0.854532    0.769817    0.665221    0.558304    0.583039    0.650353    0.653484    0.854532    0.769817    0.587190    0.577778    1000        12.185834   0.347636    0.365565    151.316069 
[37m[36mINFO[0m[0m 01/29 06:39:03 | 0.581173    0.584859    0.928789    0.789634    0.622509    0.504417    0.512367    0.616000    0.621469    0.928789    0.789634    0.623103    0.620741    1200        14.623001   0.271593    0.329715    149.972352 
[37m[36mINFO[0m[0m 01/29 06:42:45 | 0.602686    0.628529    0.952399    0.786585    0.701305    0.520318    0.583039    0.613176    0.619586    0.952399    0.786585    0.674565    0.682963    1400        17.060168   0.216056    0.340840    153.317583 
[37m[36mINFO[0m[0m 01/29 06:46:32 | 0.477851    0.484237    0.912414    0.765244    0.756485    0.318905    0.318021    0.556706    0.548023    0.912414    0.765244    0.557942    0.586667    1600        19.497334   0.203814    0.345003    157.636347 
[37m[36mINFO[0m[0m 01/29 06:50:16 | 0.474445    0.482850    0.940975    0.785061    0.799755    0.269435    0.275618    0.551529    0.553672    0.940975    0.785061    0.602369    0.619259    1800        21.934501   0.162336    0.345993    154.927607 
[37m[36mINFO[0m[0m 01/29 06:54:01 | 0.524398    0.532949    0.978294    0.782012    0.942887    0.346290    0.371025    0.600471    0.602637    0.978294    0.782012    0.626435    0.625185    2000        24.371668   0.112522    0.342795    155.905638 
[37m[36mINFO[0m[0m 01/29 06:57:43 | 0.465920    0.469739    0.978294    0.817073    0.862968    0.213781    0.204947    0.584941    0.589454    0.978294    0.817073    0.599037    0.614815    2200        26.808835   0.098738    0.326095    157.044562 
[37m[36mINFO[0m[0m 01/29 07:01:29 | 0.455282    0.465011    0.977152    0.780488    1.046515    0.211131    0.215548    0.595294    0.591337    0.977152    0.780488    0.559422    0.588148    2400        29.246002   0.083422    0.349844    156.507205 
[37m[36mINFO[0m[0m 01/29 07:05:11 | 0.457273    0.464934    0.976009    0.789634    0.964594    0.195230    0.180212    0.624941    0.630885    0.976009    0.789634    0.551648    0.583704    2600        31.683168   0.072916    0.299191    161.298379 
[37m[36mINFO[0m[0m 01/29 07:08:39 | 0.521174    0.526878    0.963823    0.762195    0.853988    0.444346    0.452297    0.567529    0.566855    0.963823    0.762195    0.551648    0.561481    2800        34.120335   0.091338    0.287890    151.068084 
[37m[36mINFO[0m[0m 01/29 07:12:19 | 0.605909    0.606825    0.988957    0.804878    1.197942    0.528269    0.533569    0.638588    0.636535    0.988957    0.804878    0.650870    0.650370    3000        36.557502   0.058497    0.330411    153.206110 
[37m[36mINFO[0m[0m 01/29 07:16:04 | 0.464319    0.475621    0.988576    0.766768    1.132958    0.227032    0.233216    0.568000    0.574388    0.988576    0.766768    0.597927    0.619259    3200        38.994669   0.056583    0.330567    159.188997 
[37m[36mINFO[0m[0m 01/29 07:19:41 | 0.546497    0.574299    0.975248    0.765244    1.197505    0.457597    0.494700    0.609882    0.625235    0.975248    0.765244    0.572010    0.602963    3400        41.431835   0.055729    0.314800    153.402092 
[37m[36mINFO[0m[0m 01/29 07:23:24 | 0.565272    0.566175    0.990099    0.783537    1.272284    0.489399    0.477032    0.592941    0.600753    0.990099    0.783537    0.613476    0.620741    3600        43.869002   0.050316    0.378413    147.436417 
[37m[36mINFO[0m[0m 01/29 07:27:14 | 0.564857    0.563532    0.981340    0.777439    1.164912    0.517668    0.512367    0.616000    0.627119    0.981340    0.777439    0.560903    0.551111    3800        46.306169   0.038389    0.390014    152.707360 
[37m[36mINFO[0m[0m 01/29 07:31:08 | 0.518406    0.518313    0.952399    0.762195    1.330253    0.444346    0.455830    0.585882    0.568738    0.952399    0.762195    0.524991    0.530370    4000        48.743336   0.068609    0.382356    157.090933 
[37m[36mINFO[0m[0m 01/29 07:34:47 | 0.577054    0.579441    0.989718    0.800305    1.567227    0.504417    0.515901    0.618824    0.612053    0.989718    0.800305    0.607923    0.610370    4200        51.180503   0.043536    0.323119    154.253025 
[37m[36mINFO[0m[0m 01/29 07:38:39 | 0.609552    0.605990    0.998096    0.780488    1.329844    0.606890    0.593640    0.592000    0.593220    0.998096    0.780488    0.629767    0.631111    4400        53.617669   0.033648    0.366471    158.363809 
[37m[36mINFO[0m[0m 01/29 07:42:23 | 0.539160    0.554527    0.993907    0.786585    1.181515    0.382509    0.395760    0.584471    0.602637    0.993907    0.786585    0.650500    0.665185    4600        56.054836   0.048464    0.339269    156.247981 
[37m[36mINFO[0m[0m 01/29 07:46:04 | 0.533685    0.547276    0.966870    0.722561    1.320619    0.384276    0.413428    0.570353    0.570621    0.966870    0.722561    0.646427    0.657778    4800        58.492003   0.037521    0.330495    154.833887 
[37m[36mINFO[0m[0m 01/29 07:49:54 | 0.518558    0.537773    0.990861    0.774390    1.188341    0.371025    0.392226    0.586353    0.598870    0.990861    0.774390    0.598297    0.622222    5000        60.929170   0.030263    0.335884    163.444117 
[37m[36mINFO[0m[0m 01/29 07:49:54 | Cumulative gradient change saved at train_output/VLCS/RSC/[0, 1, 3]/250129_06-14-23_resnet50_adam/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 01/29 07:49:56 | ---
[37m[36mINFO[0m[0m 01/29 07:49:56 | test-domain validation(oracle) = 65.573%
[37m[36mINFO[0m[0m 01/29 07:49:56 | training-domain validation(iid) = 46.592%
[37m[36mINFO[0m[0m 01/29 07:49:56 | last = 51.856%
[37m[36mINFO[0m[0m 01/29 07:49:56 | last (inD) = 77.439%
[37m[36mINFO[0m[0m 01/29 07:49:56 | training-domain validation (iid, inD) = 81.707%
[37m[36mINFO[0m[0m 01/29 07:49:56 | === Summary ===
[37m[36mINFO[0m[0m 01/29 07:49:56 | Command: /jsm0707/Large-scale/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm RSC --test_envs 0 1 3 --dataset VLCS
[37m[36mINFO[0m[0m 01/29 07:49:56 | Unique name: 250129_06-14-23_resnet50_adam
[37m[36mINFO[0m[0m 01/29 07:49:56 | Out path: train_output/VLCS/RSC/[0, 1, 3]/250129_06-14-23_resnet50_adam
[37m[36mINFO[0m[0m 01/29 07:49:56 | Algorithm: RSC
[37m[36mINFO[0m[0m 01/29 07:49:56 | Dataset: VLCS
