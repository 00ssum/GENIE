[37m[36mINFO[0m[0m 02/23 18:26:13 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 0 --dataset PACS --trial_seed 0 --hparams_seed 20
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: PACS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 20
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/PACS/CORAL/[0]/250223_18-26-13_resnet50_GENIE
	out_root: train_output/PACS/CORAL/[0]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0]
	trial_seed: 0
	unique_name: 250223_18-26-13_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.5
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 2.6157673767852512e-05
	batch_size: 32
	weight_decay: 1.110622050999988e-05
	mmd_gamma: 0.11123344099864356
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[PACS] #envs=4, #classes=7
	env0: A (#2048)
	env1: C (#2344)
	env2: P (#1670)
	env3: S (#3929)

[37m[36mINFO[0m[0m 02/23 18:26:13 | n_steps = 5001
[37m[36mINFO[0m[0m 02/23 18:26:13 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/23 18:26:13 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/23 18:26:13 | 
[37m[36mINFO[0m[0m 02/23 18:26:13 | Testenv name escaping te_A -> te_A
[37m[36mINFO[0m[0m 02/23 18:26:13 | Test envs = [0], name = te_A
[37m[36mINFO[0m[0m 02/23 18:26:13 | Train environments: [1, 2, 3], Test environments: [0]
[37m[36mINFO[0m[0m 02/23 18:26:13 | Batch sizes for each domain: [0, 32, 32, 32] (total=96)
[37m[36mINFO[0m[0m 02/23 18:26:13 | steps-per-epoch for each domain: 58.62, 41.75, 98.25 -> min = 41.75
[37m[36mINFO[0m[0m 02/23 18:26:15 | # of params = 23522375
[37m[36mINFO[0m[0m 02/23 18:26:53 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 02/23 18:26:53 | 0.202563    0.212714    0.267511    0.262404    1.872847    0.202563    0.212714    0.254264    0.275641    0.353293    0.338323    0.194975    0.173248    0           0.000000    2.081882    0.109830    1.300877    37.196182  
[37m[36mINFO[0m[0m 02/23 18:28:17 | 0.843807    0.841076    0.955917    0.950730    0.136444    0.843807    0.841076    0.940832    0.950855    0.996257    0.979042    0.930662    0.922293    200         4.790419    0.395076    0.202810    0.254156    32.740432  
[37m[36mINFO[0m[0m 02/23 18:30:06 | 0.876754    0.875306    0.974128    0.961522    0.099194    0.876754    0.875306    0.969083    0.963675    0.994012    0.982036    0.959288    0.938854    400         9.580838    0.111492    0.139529    0.370344    34.569931  
[37m[36mINFO[0m[0m 02/23 18:31:31 | 0.869433    0.865526    0.983029    0.967607    0.102396    0.869433    0.865526    0.983475    0.970085    0.995509    0.976048    0.970102    0.956688    600         14.371257   0.071057    0.115709    0.253226    34.431888  
[37m[36mINFO[0m[0m 02/23 18:33:11 | 0.860891    0.877751    0.975493    0.954567    0.137829    0.860891    0.877751    0.975480    0.961538    0.997754    0.976048    0.953244    0.926115    800         19.161677   0.048967    0.099292    0.322566    35.401144  
[37m[36mINFO[0m[0m 02/23 18:34:45 | 0.832825    0.833741    0.995395    0.969476    0.092140    0.832825    0.833741    0.995203    0.970085    0.999251    0.988024    0.991730    0.950318    1000        23.952096   0.036452    0.092519    0.287036    37.210278  
[37m[36mINFO[0m[0m 02/23 18:36:29 | 0.865772    0.882641    0.996636    0.969486    0.091747    0.865772    0.882641    0.996269    0.967949    1.000000    0.994012    0.993639    0.946497    1200        28.742515   0.021240    0.087004    0.346176    35.073207  
[37m[36mINFO[0m[0m 02/23 18:38:12 | 0.870043    0.867971    0.995570    0.972012    0.095309    0.870043    0.867971    0.994136    0.967949    0.999251    0.985030    0.993321    0.963057    1400        33.532934   0.022942    0.077074    0.303428    42.226855  
[37m[36mINFO[0m[0m 02/23 18:39:46 | 0.863941    0.848411    0.996991    0.971186    0.109117    0.863941    0.848411    0.998401    0.972222    0.999251    0.991018    0.993321    0.950318    1600        38.323353   0.017652    0.071562    0.309641    31.947891  
[37m[36mINFO[0m[0m 02/23 18:41:17 | 0.885296    0.897311    0.999009    0.976869    0.083039    0.885296    0.897311    0.998934    0.978632    1.000000    0.994012    0.998092    0.957962    1800        43.113772   0.012993    0.065978    0.264304    38.002976  
[37m[36mINFO[0m[0m 02/23 18:42:57 | 0.874924    0.877751    0.998407    0.970028    0.103977    0.874924    0.877751    0.998401    0.970085    1.000000    0.982036    0.996819    0.957962    2000        47.904192   0.011415    0.061035    0.331962    33.654224  
[37m[36mINFO[0m[0m 02/23 18:44:29 | 0.870653    0.894866    0.998690    0.973609    0.094798    0.870653    0.894866    0.998934    0.976496    1.000000    0.994012    0.997137    0.950318    2200        52.694611   0.010078    0.057632    0.298828    31.563352  
[37m[36mINFO[0m[0m 02/23 18:46:08 | 0.867602    0.875306    0.998126    0.971174    0.109065    0.867602    0.875306    0.999467    0.970085    1.000000    0.988024    0.994911    0.955414    2400        57.485030   0.008806    0.055707    0.338476    31.494340  
[37m[36mINFO[0m[0m 02/23 18:47:40 | 0.865162    0.882641    0.998619    0.973161    0.099843    0.865162    0.882641    0.998401    0.972222    1.000000    0.988024    0.997455    0.959236    2600        62.275449   0.008287    0.053561    0.287055    34.628422  
[37m[36mINFO[0m[0m 02/23 18:49:16 | 0.871263    0.889976    0.998335    0.973296    0.100294    0.871263    0.889976    0.998934    0.965812    0.999251    0.991018    0.996819    0.963057    2800        67.065868   0.007335    0.051310    0.314614    33.700894  
[37m[36mINFO[0m[0m 02/23 18:50:47 | 0.866992    0.870416    0.999115    0.971877    0.101737    0.866992    0.870416    0.998934    0.974359    1.000000    0.982036    0.998410    0.959236    3000        71.856287   0.008307    0.048528    0.295316    31.501229  
[37m[36mINFO[0m[0m 02/23 18:52:18 | 0.877364    0.875306    0.998902    0.976156    0.089861    0.877364    0.875306    0.998934    0.976496    1.000000    0.994012    0.997774    0.957962    3200        76.646707   0.007348    0.048054    0.283550    34.338393  
[37m[36mINFO[0m[0m 02/23 18:53:58 | 0.871263    0.875306    0.999788    0.976855    0.104228    0.871263    0.875306    1.000000    0.972222    1.000000    0.994012    0.999364    0.964331    3400        81.437126   0.004221    0.046301    0.340420    32.041196  
[37m[36mINFO[0m[0m 02/23 18:55:36 | 0.877974    0.877751    0.999433    0.976018    0.090273    0.877974    0.877751    0.998934    0.974359    1.000000    0.997006    0.999364    0.956688    3600        86.227545   0.002913    0.042951    0.284451    40.525961  
[37m[36mINFO[0m[0m 02/23 18:57:12 | 0.873093    0.872861    0.999327    0.976431    0.099127    0.873093    0.872861    0.998934    0.972222    1.000000    0.994012    0.999046    0.963057    3800        91.017964   0.004324    0.040601    0.317911    32.342984  
[37m[36mINFO[0m[0m 02/23 18:58:47 | 0.883466    0.887531    0.999682    0.975720    0.101203    0.883466    0.887531    1.000000    0.974359    1.000000    0.991018    0.999046    0.961783    4000        95.808383   0.002899    0.039681    0.287921    37.860931  
[37m[36mINFO[0m[0m 02/23 19:00:21 | 0.870043    0.885086    0.998937    0.975147    0.096632    0.870043    0.885086    0.999467    0.974359    0.999251    0.988024    0.998092    0.963057    4200        100.598802  0.003208    0.038135    0.289558    36.169627  
[37m[36mINFO[0m[0m 02/23 19:01:57 | 0.881025    0.894866    0.999894    0.975871    0.096439    0.881025    0.894866    1.000000    0.978632    1.000000    0.991018    0.999682    0.957962    4400        105.389222  0.004630    0.037498    0.313015    33.060281  
[37m[36mINFO[0m[0m 02/23 19:03:33 | 0.881025    0.885086    0.999610    0.975149    0.094592    0.881025    0.885086    0.999467    0.978632    1.000000    0.985030    0.999364    0.961783    4600        110.179641  0.003688    0.036514    0.293421    37.734737  
[37m[36mINFO[0m[0m 02/23 19:05:13 | 0.859060    0.877751    0.999504    0.974286    0.109902    0.859060    0.877751    0.999467    0.972222    1.000000    0.985030    0.999046    0.965605    4800        114.970060  0.003340    0.036390    0.337768    32.036350  
[37m[36mINFO[0m[0m 02/23 19:07:00 | 0.870043    0.880196    0.999894    0.972163    0.098872    0.870043    0.880196    1.000000    0.972222    1.000000    0.985030    0.999682    0.959236    5000        119.760479  0.002771    0.035183    0.304815    46.170271  
[37m[36mINFO[0m[0m 02/23 19:07:00 | Cumulative gradient change saved at train_output/PACS/CORAL/[0]/250223_18-26-13_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/23 19:07:02 | ---
[37m[36mINFO[0m[0m 02/23 19:07:02 | test-domain validation(oracle) = 88.530%
[37m[36mINFO[0m[0m 02/23 19:07:02 | training-domain validation(iid) = 88.530%
[37m[36mINFO[0m[0m 02/23 19:07:02 | last = 87.004%
[37m[36mINFO[0m[0m 02/23 19:07:02 | last (inD) = 97.216%
[37m[36mINFO[0m[0m 02/23 19:07:02 | training-domain validation (iid, inD) = 97.687%
[37m[36mINFO[0m[0m 02/23 19:07:02 | === Summary ===
[37m[36mINFO[0m[0m 02/23 19:07:02 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 0 --dataset PACS --trial_seed 0 --hparams_seed 20
[37m[36mINFO[0m[0m 02/23 19:07:02 | Unique name: 250223_18-26-13_resnet50_GENIE
[37m[36mINFO[0m[0m 02/23 19:07:02 | Out path: train_output/PACS/CORAL/[0]/250223_18-26-13_resnet50_GENIE
[37m[36mINFO[0m[0m 02/23 19:07:02 | Algorithm: CORAL
[37m[36mINFO[0m[0m 02/23 19:07:02 | Dataset: PACS
