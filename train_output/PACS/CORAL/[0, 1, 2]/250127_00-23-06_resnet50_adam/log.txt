[37m[36mINFO[0m[0m 01/27 00:23:06 | Command :: /jsm0707/Large-scale/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm CORAL --test_envs 0 1 2 --dataset PACS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_adam.yaml']
	data_dir: data
	dataset: PACS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_adam
	out_dir: train_output/PACS/CORAL/[0, 1, 2]/250127_00-23-06_resnet50_adam
	out_root: train_output/PACS/CORAL/[0, 1, 2]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 1, 2]
	trial_seed: 0
	unique_name: 250127_00-23-06_resnet50_adam
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: adam
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	mmd_gamma: 1.0
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[PACS] #envs=4, #classes=7
	env0: A (#2048)
	env1: C (#2344)
	env2: P (#1670)
	env3: S (#3929)

[37m[36mINFO[0m[0m 01/27 00:23:06 | n_steps = 5001
[37m[36mINFO[0m[0m 01/27 00:23:06 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 01/27 00:23:06 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 01/27 00:23:06 | 
[37m[36mINFO[0m[0m 01/27 00:23:06 | Testenv name escaping te_A_C_P -> te_A_C_P
[37m[36mINFO[0m[0m 01/27 00:23:06 | Test envs = [0, 1, 2], name = te_A_C_P
[37m[36mINFO[0m[0m 01/27 00:23:06 | Train environments: [3], Test environments: [0, 1, 2]
[37m[36mINFO[0m[0m 01/27 00:23:06 | Batch sizes for each domain: [0, 0, 0, 32] (total=32)
[37m[36mINFO[0m[0m 01/27 00:23:06 | steps-per-epoch for each domain: 98.25 -> min = 98.25
[37m[36mINFO[0m[0m 01/27 00:23:07 | # of params = 23522375
[37m[36mINFO[0m[0m 01/27 00:23:32 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 01/27 00:23:32 | 0.170112    0.161019    0.267494    0.214013    1.868191    0.200732    0.183374    0.163646    0.170940    0.145958    0.128743    0.267494    0.214013    0           0.000000    2.123937    0.000000    1.125364    23.593672  
[37m[36mINFO[0m[0m 01/27 00:24:13 | 0.397980    0.387117    0.916667    0.882803    0.348316    0.370348    0.342298    0.527186    0.525641    0.296407    0.293413    0.916667    0.882803    200         2.035623    0.556955    0.000000    0.094914    21.827221  
[37m[36mINFO[0m[0m 01/27 00:24:58 | 0.533026    0.536562    0.964695    0.938854    0.168285    0.479561    0.476773    0.617271    0.623932    0.502246    0.508982    0.964695    0.938854    400         4.071247    0.165100    0.000000    0.094184    25.773759  
[37m[36mINFO[0m[0m 01/27 00:25:42 | 0.407408    0.388564    0.969784    0.914650    0.305466    0.381940    0.376528    0.487740    0.465812    0.352545    0.323353    0.969784    0.914650    600         6.106870    0.110914    0.000000    0.095640    24.793940  
[37m[36mINFO[0m[0m 01/27 00:26:25 | 0.532026    0.553619    0.986323    0.950318    0.199166    0.486882    0.513447    0.635394    0.677350    0.473802    0.470060    0.986323    0.950318    800         8.142494    0.075278    0.000000    0.096202    23.030694  
[37m[36mINFO[0m[0m 01/27 00:27:09 | 0.526977    0.556712    0.968511    0.919745    0.222283    0.509457    0.542787    0.591684    0.630342    0.479790    0.497006    0.968511    0.919745    1000        10.178117   0.073091    0.000000    0.094259    24.780425  
[37m[36mINFO[0m[0m 01/27 00:27:51 | 0.519319    0.510300    0.988868    0.937580    0.246285    0.503356    0.513447    0.620469    0.598291    0.434132    0.419162    0.988868    0.937580    1200        12.213740   0.068838    0.000000    0.095862    23.430061  
[37m[36mINFO[0m[0m 01/27 00:28:35 | 0.444400    0.437589    0.991412    0.940127    0.223036    0.388652    0.366748    0.592751    0.604701    0.351796    0.341317    0.991412    0.940127    1400        14.249364   0.040053    0.000000    0.093677    25.085101  
[37m[36mINFO[0m[0m 01/27 00:29:17 | 0.588533    0.596029    0.993321    0.947771    0.163464    0.525320    0.508557    0.711087    0.728632    0.529192    0.550898    0.993321    0.947771    1600        16.284987   0.049385    0.000000    0.091273    24.206960  
[37m[36mINFO[0m[0m 01/27 00:30:01 | 0.556147    0.559681    0.989186    0.941401    0.245188    0.500305    0.491443    0.663646    0.696581    0.504491    0.491018    0.989186    0.941401    1800        18.320611   0.036340    0.000000    0.091797    24.668062  
[37m[36mINFO[0m[0m 01/27 00:30:43 | 0.583447    0.594690    0.995229    0.943949    0.190709    0.574741    0.589242    0.706290    0.745726    0.469311    0.449102    0.995229    0.943949    2000        20.356234   0.037884    0.000000    0.093721    23.710252  
[37m[36mINFO[0m[0m 01/27 00:31:27 | 0.579997    0.587979    0.995865    0.940127    0.216120    0.528371    0.547677    0.676439    0.692308    0.535180    0.523952    0.995865    0.940127    2200        22.391858   0.030753    0.000000    0.093775    24.791902  
[37m[36mINFO[0m[0m 01/27 00:32:10 | 0.438503    0.441842    0.986959    0.932484    0.282442    0.405735    0.430318    0.528785    0.500000    0.380988    0.395210    0.986959    0.932484    2400        24.427481   0.022613    0.000000    0.101809    22.426744  
[37m[36mINFO[0m[0m 01/27 00:32:54 | 0.456100    0.457516    0.978372    0.936306    0.234881    0.361806    0.376528    0.652452    0.651709    0.354042    0.344311    0.978372    0.936306    2600        26.463104   0.034317    0.000000    0.094314    25.801545  
[37m[36mINFO[0m[0m 01/27 00:33:39 | 0.549944    0.559163    0.993957    0.940127    0.235055    0.493594    0.506112    0.637527    0.662393    0.518713    0.508982    0.993957    0.940127    2800        28.498728   0.038603    0.000000    0.097727    25.719398  
[37m[36mINFO[0m[0m 01/27 00:34:24 | 0.495407    0.498986    0.988232    0.931210    0.245744    0.437462    0.464548    0.607143    0.613248    0.441617    0.419162    0.988232    0.931210    3000        30.534351   0.025666    0.000000    0.092120    26.041985  
[37m[36mINFO[0m[0m 01/27 00:35:09 | 0.509537    0.525781    0.992684    0.949045    0.227780    0.427090    0.454768    0.698827    0.709402    0.402695    0.413174    0.992684    0.949045    3200        32.569975   0.028283    0.000000    0.097064    25.746144  
[37m[36mINFO[0m[0m 01/27 00:35:53 | 0.512317    0.522691    0.997455    0.955414    0.184662    0.455766    0.496333    0.634328    0.634615    0.446856    0.437126    0.997455    0.955414    3400        34.605598   0.031647    0.000000    0.094767    24.802643  
[37m[36mINFO[0m[0m 01/27 00:36:36 | 0.492238    0.508763    0.985687    0.935032    0.201028    0.424039    0.449878    0.656716    0.675214    0.395958    0.401198    0.985687    0.935032    3600        36.641221   0.036173    0.000000    0.093050    24.728003  
[37m[36mINFO[0m[0m 01/27 00:37:20 | 0.479875    0.497695    0.999046    0.954140    0.179277    0.394753    0.420538    0.655650    0.692308    0.389222    0.380240    0.999046    0.954140    3800        38.676845   0.017171    0.000000    0.095795    24.126300  
[37m[36mINFO[0m[0m 01/27 00:38:02 | 0.533197    0.546325    0.996183    0.963057    0.152317    0.485052    0.506112    0.672175    0.683761    0.442365    0.449102    0.996183    0.963057    4000        40.712468   0.015586    0.000000    0.091530    24.141958  
[37m[36mINFO[0m[0m 01/27 00:38:47 | 0.565845    0.557976    0.987277    0.922293    0.336520    0.530201    0.525672    0.682303    0.690171    0.485030    0.458084    0.987277    0.922293    4200        42.748092   0.020232    0.000000    0.094594    25.706513  
[37m[36mINFO[0m[0m 01/27 00:39:31 | 0.502483    0.499535    0.996819    0.933758    0.239941    0.435631    0.430318    0.655650    0.673077    0.416168    0.395210    0.996819    0.933758    4400        44.783715   0.028261    0.000000    0.104285    23.425820  
[37m[36mINFO[0m[0m 01/27 00:40:14 | 0.405269    0.410022    0.990140    0.917197    0.343354    0.266016    0.273839    0.663113    0.668803    0.286677    0.287425    0.990140    0.917197    4600        46.819338   0.017666    0.000000    0.096685    23.954448  
[37m[36mINFO[0m[0m 01/27 00:40:58 | 0.528572    0.535482    0.993957    0.940127    0.246721    0.453325    0.471883    0.674307    0.694444    0.458084    0.440120    0.993957    0.940127    4800        48.854962   0.020431    0.000000    0.093453    25.359900  
[37m[36mINFO[0m[0m 01/27 00:41:44 | 0.485429    0.467848    0.996501    0.949045    0.250794    0.439292    0.415648    0.644989    0.649573    0.372006    0.338323    0.996501    0.949045    5000        50.890585   0.012934    0.000000    0.094977    26.560302  
[37m[36mINFO[0m[0m 01/27 00:41:44 | Cumulative gradient change saved at train_output/PACS/CORAL/[0, 1, 2]/250127_00-23-06_resnet50_adam/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 01/27 00:41:45 | ---
[37m[36mINFO[0m[0m 01/27 00:41:45 | test-domain validation(oracle) = 58.853%
[37m[36mINFO[0m[0m 01/27 00:41:45 | training-domain validation(iid) = 53.320%
[37m[36mINFO[0m[0m 01/27 00:41:45 | last = 48.543%
[37m[36mINFO[0m[0m 01/27 00:41:45 | last (inD) = 94.904%
[37m[36mINFO[0m[0m 01/27 00:41:45 | training-domain validation (iid, inD) = 96.306%
[37m[36mINFO[0m[0m 01/27 00:41:45 | === Summary ===
[37m[36mINFO[0m[0m 01/27 00:41:45 | Command: /jsm0707/Large-scale/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm CORAL --test_envs 0 1 2 --dataset PACS
[37m[36mINFO[0m[0m 01/27 00:41:45 | Unique name: 250127_00-23-06_resnet50_adam
[37m[36mINFO[0m[0m 01/27 00:41:45 | Out path: train_output/PACS/CORAL/[0, 1, 2]/250127_00-23-06_resnet50_adam
[37m[36mINFO[0m[0m 01/27 00:41:45 | Algorithm: CORAL
[37m[36mINFO[0m[0m 01/27 00:41:45 | Dataset: PACS
