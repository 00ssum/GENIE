[37m[36mINFO[0m[0m 01/26 22:58:06 | Command :: /jsm0707/Large-scale/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm CORAL --test_envs 0 1 2 --dataset PACS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_sgd.yaml']
	data_dir: data
	dataset: PACS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_sgd
	out_dir: train_output/PACS/CORAL/[0, 1, 2]/250126_22-58-06_resnet50_sgd
	out_root: train_output/PACS/CORAL/[0, 1, 2]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 1, 2]
	trial_seed: 0
	unique_name: 250126_22-58-06_resnet50_sgd
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: sgd
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	mmd_gamma: 1.0
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[PACS] #envs=4, #classes=7
	env0: A (#2048)
	env1: C (#2344)
	env2: P (#1670)
	env3: S (#3929)

[37m[36mINFO[0m[0m 01/26 22:58:06 | n_steps = 5001
[37m[36mINFO[0m[0m 01/26 22:58:06 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 01/26 22:58:06 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 01/26 22:58:06 | 
[37m[36mINFO[0m[0m 01/26 22:58:06 | Testenv name escaping te_A_C_P -> te_A_C_P
[37m[36mINFO[0m[0m 01/26 22:58:06 | Test envs = [0, 1, 2], name = te_A_C_P
[37m[36mINFO[0m[0m 01/26 22:58:06 | Train environments: [3], Test environments: [0, 1, 2]
[37m[36mINFO[0m[0m 01/26 22:58:06 | Batch sizes for each domain: [0, 0, 0, 32] (total=32)
[37m[36mINFO[0m[0m 01/26 22:58:06 | steps-per-epoch for each domain: 98.25 -> min = 98.25
[37m[36mINFO[0m[0m 01/26 22:58:08 | # of params = 23522375
[37m[36mINFO[0m[0m 01/26 22:58:32 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 01/26 22:58:32 | 0.140180    0.147939    0.045165    0.071338    2.123889    0.226968    0.190709    0.097015    0.115385    0.096557    0.137725    0.045165    0.071338    0           0.000000    2.123937    0.000000    0.902344    23.890903  
[37m[36mINFO[0m[0m 01/26 22:59:16 | 0.176274    0.176904    0.319020    0.307006    1.738333    0.207444    0.222494    0.195629    0.194444    0.125749    0.113772    0.319020    0.307006    200         2.035623    1.895091    0.000000    0.096917    24.383744  
[37m[36mINFO[0m[0m 01/26 23:00:00 | 0.193472    0.195549    0.434160    0.440764    1.529845    0.212935    0.215159    0.226013    0.230769    0.141467    0.140719    0.434160    0.440764    400         4.071247    1.625732    0.000000    0.095045    24.518458  
[37m[36mINFO[0m[0m 01/26 23:00:45 | 0.200992    0.204667    0.535305    0.535032    1.359491    0.211714    0.215159    0.246802    0.252137    0.144461    0.146707    0.535305    0.535032    600         6.106870    1.444300    0.000000    0.097202    24.672680  
[37m[36mINFO[0m[0m 01/26 23:01:28 | 0.206959    0.208796    0.576336    0.575796    1.197460    0.214155    0.215159    0.262260    0.273504    0.144461    0.137725    0.576336    0.575796    800         8.142494    1.280379    0.000000    0.093859    24.053201  
[37m[36mINFO[0m[0m 01/26 23:02:13 | 0.200156    0.213199    0.602417    0.603822    1.058860    0.203783    0.224939    0.257463    0.264957    0.139222    0.149701    0.602417    0.603822    1000        10.178117   1.132304    0.000000    0.095643    26.097153  
[37m[36mINFO[0m[0m 01/26 23:03:00 | 0.214939    0.217575    0.667303    0.638217    0.934101    0.211104    0.227384    0.282516    0.275641    0.151198    0.149701    0.667303    0.638217    1200        12.213740   1.022344    0.000000    0.099256    26.934077  
[37m[36mINFO[0m[0m 01/26 23:03:43 | 0.221377    0.232483    0.676527    0.653503    0.879805    0.220256    0.239609    0.281450    0.284188    0.162425    0.173653    0.676527    0.653503    1400        14.249364   0.871130    0.000000    0.095988    23.645946  
[37m[36mINFO[0m[0m 01/26 23:04:29 | 0.226480    0.228187    0.720738    0.699363    0.765715    0.223917    0.232274    0.284115    0.275641    0.171407    0.176647    0.720738    0.699363    1600        16.284987   0.801368    0.000000    0.098164    25.486278  
[37m[36mINFO[0m[0m 01/26 23:05:15 | 0.233374    0.231505    0.720102    0.710828    0.737781    0.224527    0.229829    0.293710    0.282051    0.181886    0.182635    0.720102    0.710828    1800        18.320611   0.724424    0.000000    0.106513    24.726777  
[37m[36mINFO[0m[0m 01/26 23:05:58 | 0.232559    0.225990    0.778944    0.769427    0.637562    0.226968    0.227384    0.283582    0.264957    0.187126    0.185629    0.778944    0.769427    2000        20.356234   0.668174    0.000000    0.094877    23.994357  
[37m[36mINFO[0m[0m 01/26 23:06:44 | 0.236489    0.227906    0.784987    0.775796    0.607774    0.222087    0.232274    0.286780    0.262821    0.200599    0.188623    0.784987    0.775796    2200        22.391858   0.601609    0.000000    0.099829    25.669639  
[37m[36mINFO[0m[0m 01/26 23:07:30 | 0.245832    0.237500    0.797710    0.802548    0.561450    0.229408    0.246944    0.298507    0.264957    0.209581    0.200599    0.797710    0.802548    2400        24.427481   0.568637    0.000000    0.096836    26.057323  
[37m[36mINFO[0m[0m 01/26 23:08:16 | 0.248633    0.244444    0.800891    0.793631    0.547872    0.230018    0.249389    0.303305    0.271368    0.212575    0.212575    0.800891    0.793631    2600        26.463104   0.517344    0.000000    0.100996    25.363965  
[37m[36mINFO[0m[0m 01/26 23:09:00 | 0.248192    0.240208    0.814249    0.803822    0.514275    0.228798    0.246944    0.301706    0.267094    0.214072    0.206587    0.814249    0.803822    2800        28.498728   0.493232    0.000000    0.095834    24.367184  
[37m[36mINFO[0m[0m 01/26 23:09:43 | 0.249606    0.249193    0.824109    0.806369    0.512915    0.231849    0.264059    0.296908    0.264957    0.220060    0.218563    0.824109    0.806369    3000        30.534351   0.478763    0.000000    0.098088    23.957973  
[37m[36mINFO[0m[0m 01/26 23:10:28 | 0.255025    0.246580    0.843830    0.840764    0.448880    0.233069    0.249389    0.309701    0.277778    0.222305    0.212575    0.843830    0.840764    3200        32.569975   0.452519    0.000000    0.101629    23.897144  
[37m[36mINFO[0m[0m 01/26 23:11:12 | 0.252047    0.251387    0.848601    0.843312    0.450573    0.232459    0.251834    0.304371    0.277778    0.219311    0.224551    0.848601    0.843312    3400        34.605598   0.416833    0.000000    0.099817    23.456811  
[37m[36mINFO[0m[0m 01/26 23:11:57 | 0.256960    0.255177    0.860051    0.838217    0.440991    0.236730    0.264059    0.308102    0.279915    0.226048    0.221557    0.860051    0.838217    3600        36.641221   0.389374    0.000000    0.101155    25.036559  
[37m[36mINFO[0m[0m 01/26 23:12:41 | 0.257406    0.256746    0.836514    0.834395    0.445812    0.239780    0.264059    0.308635    0.275641    0.223802    0.230539    0.836514    0.834395    3800        38.676845   0.377878    0.000000    0.098237    24.350090  
[37m[36mINFO[0m[0m 01/26 23:13:27 | 0.260687    0.261020    0.865140    0.836943    0.456809    0.237340    0.264059    0.313433    0.288462    0.231287    0.230539    0.865140    0.836943    4000        40.712468   0.359718    0.000000    0.100925    25.661354  
[37m[36mINFO[0m[0m 01/26 23:14:11 | 0.259448    0.254362    0.870865    0.864968    0.392867    0.239170    0.261614    0.308635    0.279915    0.230539    0.221557    0.870865    0.864968    4200        42.748092   0.334693    0.000000    0.095909    24.234785  
[37m[36mINFO[0m[0m 01/26 23:14:57 | 0.257459    0.258273    0.882952    0.862420    0.382319    0.236730    0.266504    0.308102    0.277778    0.227545    0.230539    0.882952    0.862420    4400        44.783715   0.350648    0.000000    0.103986    24.913631  
[37m[36mINFO[0m[0m 01/26 23:15:42 | 0.263130    0.269189    0.876272    0.849682    0.412038    0.242221    0.278729    0.316631    0.286325    0.230539    0.242515    0.876272    0.849682    4600        46.819338   0.327546    0.000000    0.098128    25.903183  
[37m[36mINFO[0m[0m 01/26 23:16:26 | 0.259677    0.262817    0.884860    0.862420    0.381902    0.240390    0.276284    0.308102    0.275641    0.230539    0.236527    0.884860    0.862420    4800        48.854962   0.317312    0.000000    0.099632    23.858364  
[37m[36mINFO[0m[0m 01/26 23:17:12 | 0.270584    0.273155    0.896310    0.872611    0.358799    0.251983    0.271394    0.322495    0.305556    0.237275    0.242515    0.896310    0.872611    5000        50.890585   0.294222    0.000000    0.101257    25.417478  
[37m[36mINFO[0m[0m 01/26 23:17:13 | Cumulative gradient change saved at train_output/PACS/CORAL/[0, 1, 2]/250126_22-58-06_resnet50_sgd/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 01/26 23:17:14 | ---
[37m[36mINFO[0m[0m 01/26 23:17:14 | test-domain validation(oracle) = 27.058%
[37m[36mINFO[0m[0m 01/26 23:17:14 | training-domain validation(iid) = 27.058%
[37m[36mINFO[0m[0m 01/26 23:17:14 | last = 27.058%
[37m[36mINFO[0m[0m 01/26 23:17:14 | last (inD) = 87.261%
[37m[36mINFO[0m[0m 01/26 23:17:14 | training-domain validation (iid, inD) = 87.261%
[37m[36mINFO[0m[0m 01/26 23:17:14 | === Summary ===
[37m[36mINFO[0m[0m 01/26 23:17:14 | Command: /jsm0707/Large-scale/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm CORAL --test_envs 0 1 2 --dataset PACS
[37m[36mINFO[0m[0m 01/26 23:17:14 | Unique name: 250126_22-58-06_resnet50_sgd
[37m[36mINFO[0m[0m 01/26 23:17:14 | Out path: train_output/PACS/CORAL/[0, 1, 2]/250126_22-58-06_resnet50_sgd
[37m[36mINFO[0m[0m 01/26 23:17:14 | Algorithm: CORAL
[37m[36mINFO[0m[0m 01/26 23:17:14 | Dataset: PACS
