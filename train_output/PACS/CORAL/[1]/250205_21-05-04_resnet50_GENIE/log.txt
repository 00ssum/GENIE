[37m[36mINFO[0m[0m 02/05 21:05:04 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 1 --dataset PACS --trial_seed 0 --hparams_seed 6
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: PACS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 6
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/PACS/CORAL/[1]/250205_21-05-04_resnet50_GENIE
	out_root: train_output/PACS/CORAL/[1]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [1]
	trial_seed: 0
	unique_name: 250205_21-05-04_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.1
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 1.5764387170443743e-05
	batch_size: 19
	weight_decay: 0.0006024239579587198
	mmd_gamma: 0.6238365410759901
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[PACS] #envs=4, #classes=7
	env0: A (#2048)
	env1: C (#2344)
	env2: P (#1670)
	env3: S (#3929)

[37m[36mINFO[0m[0m 02/05 21:05:04 | n_steps = 5001
[37m[36mINFO[0m[0m 02/05 21:05:04 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/05 21:05:04 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/05 21:05:04 | 
[37m[36mINFO[0m[0m 02/05 21:05:04 | Testenv name escaping te_C -> te_C
[37m[36mINFO[0m[0m 02/05 21:05:04 | Test envs = [1], name = te_C
[37m[36mINFO[0m[0m 02/05 21:05:04 | Train environments: [0, 2, 3], Test environments: [1]
[37m[36mINFO[0m[0m 02/05 21:05:04 | Batch sizes for each domain: [19, 0, 19, 19] (total=57)
[37m[36mINFO[0m[0m 02/05 21:05:04 | steps-per-epoch for each domain: 86.26, 70.32, 165.47 -> min = 70.32
[37m[36mINFO[0m[0m 02/05 21:05:06 | # of params = 23522375
[37m[36mINFO[0m[0m 02/05 21:05:51 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 02/05 21:05:51 | 0.253731    0.279915    0.264660    0.261520    1.867230    0.233679    0.239609    0.253731    0.279915    0.372006    0.374251    0.188295    0.170701    0           0.000000    1.958737    0.091639    1.118273    44.534956  
[37m[36mINFO[0m[0m 02/05 21:07:24 | 0.714819    0.760684    0.954910    0.950970    0.150096    0.951190    0.941320    0.714819    0.760684    0.994012    0.988024    0.919529    0.923567    200         2.844311    0.344572    0.080711    0.273058    37.748880  
[37m[36mINFO[0m[0m 02/05 21:09:00 | 0.795842    0.818376    0.946234    0.929269    0.226832    0.948139    0.921760    0.795842    0.818376    0.985030    0.973054    0.905534    0.892994    400         5.688623    0.123620    0.047981    0.285657    39.033516  
[37m[36mINFO[0m[0m 02/05 21:10:43 | 0.718017    0.741453    0.979290    0.956492    0.126035    0.979256    0.960880    0.718017    0.741453    0.995509    0.985030    0.963104    0.923567    600         8.532934    0.092844    0.038887    0.290088    44.980158  
[37m[36mINFO[0m[0m 02/05 21:12:13 | 0.729211    0.764957    0.983920    0.959119    0.121204    0.981696    0.946210    0.729211    0.764957    0.995509    0.991018    0.974555    0.940127    800         11.377246   0.069390    0.033944    0.251620    39.782495  
[37m[36mINFO[0m[0m 02/05 21:13:49 | 0.810235    0.837607    0.981862    0.951283    0.155832    0.981696    0.946210    0.810235    0.837607    0.992515    0.970060    0.971374    0.937580    1000        14.221557   0.053097    0.030499    0.281421    39.958861  
[37m[36mINFO[0m[0m 02/05 21:15:30 | 0.787313    0.820513    0.993098    0.964319    0.102710    0.993289    0.958435    0.787313    0.820513    1.000000    0.988024    0.986005    0.946497    1200        17.065868   0.038205    0.028301    0.327274    35.594778  
[37m[36mINFO[0m[0m 02/05 21:17:04 | 0.813433    0.837607    0.993138    0.968601    0.104971    0.992678    0.975550    0.813433    0.837607    0.998503    0.985030    0.988232    0.945223    1400        19.910180   0.028626    0.025277    0.287778    36.496569  
[37m[36mINFO[0m[0m 02/05 21:18:37 | 0.802239    0.822650    0.993035    0.961759    0.111927    0.990238    0.948655    0.802239    0.822650    1.000000    0.985030    0.988868    0.951592    1600        22.754491   0.025147    0.023788    0.224477    48.321441  
[37m[36mINFO[0m[0m 02/05 21:20:11 | 0.816631    0.831197    0.989806    0.961784    0.133414    0.988408    0.955990    0.816631    0.831197    0.998503    0.979042    0.982506    0.950318    1800        25.598802   0.018940    0.022633    0.258088    41.955515  
[37m[36mINFO[0m[0m 02/05 21:21:38 | 0.783582    0.799145    0.994923    0.971159    0.092906    0.993899    0.965770    0.783582    0.799145    0.998503    0.991018    0.992366    0.956688    2000        28.443114   0.025429    0.021017    0.255317    36.006484  
[37m[36mINFO[0m[0m 02/05 21:23:11 | 0.800107    0.818376    0.995444    0.962323    0.133366    0.994509    0.958435    0.800107    0.818376    0.998503    0.982036    0.993321    0.946497    2200        31.287425   0.018276    0.019879    0.273842    37.881088  
[37m[36mINFO[0m[0m 02/05 21:24:40 | 0.819296    0.822650    0.997424    0.966569    0.119595    0.996949    0.958435    0.819296    0.822650    0.998503    0.982036    0.996819    0.959236    2400        34.131737   0.015994    0.019144    0.252282    39.173061  
[37m[36mINFO[0m[0m 02/05 21:26:08 | 0.809168    0.820513    0.998418    0.971435    0.105474    0.999390    0.965770    0.809168    0.820513    1.000000    0.988024    0.995865    0.960510    2600        36.976048   0.011960    0.017905    0.227002    41.977640  
[37m[36mINFO[0m[0m 02/05 21:27:35 | 0.800640    0.818376    0.994092    0.963792    0.126779    0.992678    0.953545    0.800640    0.818376    0.998503    0.976048    0.991094    0.961783    2800        39.820359   0.010227    0.017101    0.228998    40.993784  
[37m[36mINFO[0m[0m 02/05 21:29:03 | 0.800107    0.811966    0.997965    0.975451    0.085957    0.998780    0.973105    0.800107    0.811966    0.999251    0.994012    0.995865    0.959236    3000        42.664671   0.018757    0.016627    0.254766    37.096307  
[37m[36mINFO[0m[0m 02/05 21:30:31 | 0.796908    0.814103    0.997817    0.974763    0.093804    0.996949    0.970660    0.796908    0.814103    1.000000    0.988024    0.996501    0.965605    3200        45.508982   0.010353    0.016591    0.260517    36.216371  
[37m[36mINFO[0m[0m 02/05 21:32:02 | 0.797974    0.809829    0.997516    0.970895    0.109111    0.995729    0.963325    0.797974    0.809829    1.000000    0.985030    0.996819    0.964331    3400        48.353293   0.010795    0.015713    0.272014    36.254244  
[37m[36mINFO[0m[0m 02/05 21:33:30 | 0.785714    0.820513    0.998126    0.974843    0.098457    0.997559    0.975550    0.785714    0.820513    1.000000    0.991018    0.996819    0.957962    3600        51.197605   0.010966    0.014780    0.234362    41.085482  
[37m[36mINFO[0m[0m 02/05 21:34:57 | 0.796375    0.805556    0.998602    0.970071    0.104590    0.998780    0.970660    0.796375    0.805556    0.999251    0.979042    0.997774    0.960510    3800        54.041916   0.008966    0.014899    0.224813    42.304272  
[37m[36mINFO[0m[0m 02/05 21:36:29 | 0.806503    0.820513    0.997203    0.967201    0.115659    0.997559    0.963325    0.806503    0.820513    0.998503    0.979042    0.995547    0.959236    4000        56.886228   0.010831    0.014135    0.255056    41.231369  
[37m[36mINFO[0m[0m 02/05 21:38:02 | 0.819296    0.824786    0.998321    0.973765    0.102454    0.998780    0.970660    0.819296    0.824786    1.000000    0.985030    0.996183    0.965605    4200        59.730539   0.009588    0.013659    0.271884    38.230110  
[37m[36mINFO[0m[0m 02/05 21:39:34 | 0.810768    0.826923    0.999364    0.975119    0.091601    1.000000    0.975550    0.810768    0.826923    1.000000    0.988024    0.998092    0.961783    4400        62.574850   0.007755    0.013720    0.250966    42.420479  
[37m[36mINFO[0m[0m 02/05 21:41:07 | 0.817697    0.829060    0.999373    0.971642    0.103026    0.999390    0.970660    0.817697    0.829060    1.000000    0.985030    0.998728    0.959236    4600        65.419162   0.006658    0.012485    0.264015    39.688199  
[37m[36mINFO[0m[0m 02/05 21:42:34 | 0.829957    0.835470    1.000000    0.975544    0.094401    1.000000    0.975550    0.829957    0.835470    1.000000    0.988024    1.000000    0.963057    4800        68.263473   0.004318    0.012636    0.254143    36.133945  
[37m[36mINFO[0m[0m 02/05 21:44:03 | 0.820362    0.833333    0.999788    0.975510    0.097494    1.000000    0.977995    0.820362    0.833333    1.000000    0.988024    0.999364    0.960510    5000        71.107784   0.003775    0.011985    0.264777    36.441701  
[37m[36mINFO[0m[0m 02/05 21:44:03 | Cumulative gradient change saved at train_output/PACS/CORAL/[1]/250205_21-05-04_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/05 21:44:05 | ---
[37m[36mINFO[0m[0m 02/05 21:44:05 | test-domain validation(oracle) = 81.023%
[37m[36mINFO[0m[0m 02/05 21:44:05 | training-domain validation(iid) = 82.996%
[37m[36mINFO[0m[0m 02/05 21:44:05 | last = 82.036%
[37m[36mINFO[0m[0m 02/05 21:44:05 | last (inD) = 97.551%
[37m[36mINFO[0m[0m 02/05 21:44:05 | training-domain validation (iid, inD) = 97.554%
[37m[36mINFO[0m[0m 02/05 21:44:05 | === Summary ===
[37m[36mINFO[0m[0m 02/05 21:44:05 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 1 --dataset PACS --trial_seed 0 --hparams_seed 6
[37m[36mINFO[0m[0m 02/05 21:44:05 | Unique name: 250205_21-05-04_resnet50_GENIE
[37m[36mINFO[0m[0m 02/05 21:44:05 | Out path: train_output/PACS/CORAL/[1]/250205_21-05-04_resnet50_GENIE
[37m[36mINFO[0m[0m 02/05 21:44:05 | Algorithm: CORAL
[37m[36mINFO[0m[0m 02/05 21:44:05 | Dataset: PACS
