[37m[36mINFO[0m[0m 02/06 00:00:47 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 3 --dataset PACS --trial_seed 0 --hparams_seed 6
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: PACS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 6
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/PACS/CORAL/[3]/250206_00-00-47_resnet50_GENIE
	out_root: train_output/PACS/CORAL/[3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [3]
	trial_seed: 0
	unique_name: 250206_00-00-47_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.1
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 1.5764387170443743e-05
	batch_size: 19
	weight_decay: 0.0006024239579587198
	mmd_gamma: 0.6238365410759901
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[PACS] #envs=4, #classes=7
	env0: A (#2048)
	env1: C (#2344)
	env2: P (#1670)
	env3: S (#3929)

[37m[36mINFO[0m[0m 02/06 00:00:48 | n_steps = 5001
[37m[36mINFO[0m[0m 02/06 00:00:48 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 02/06 00:00:48 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 02/06 00:00:48 | 
[37m[36mINFO[0m[0m 02/06 00:00:48 | Testenv name escaping te_S -> te_S
[37m[36mINFO[0m[0m 02/06 00:00:48 | Test envs = [3], name = te_S
[37m[36mINFO[0m[0m 02/06 00:00:48 | Train environments: [0, 1, 2], Test environments: [3]
[37m[36mINFO[0m[0m 02/06 00:00:48 | Batch sizes for each domain: [19, 19, 19, 0] (total=57)
[37m[36mINFO[0m[0m 02/06 00:00:48 | steps-per-epoch for each domain: 86.26, 98.74, 70.32 -> min = 70.32
[37m[36mINFO[0m[0m 02/06 00:00:49 | # of params = 23522375
[37m[36mINFO[0m[0m 02/06 00:01:25 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 02/06 00:01:25 | 0.203244    0.201274    0.260271    0.251009    1.868531    0.239780    0.232274    0.259595    0.239316    0.281437    0.281437    0.203244    0.201274    0           0.000000    1.990902    0.063667    2.435932    33.440603  
[37m[36mINFO[0m[0m 02/06 00:02:55 | 0.774173    0.777070    0.940356    0.938973    0.186791    0.933496    0.924205    0.907783    0.916667    0.979790    0.976048    0.774173    0.777070    200         2.844311    0.334001    0.076407    0.272647    35.665136  
[37m[36mINFO[0m[0m 02/06 00:04:22 | 0.692430    0.699363    0.972275    0.952917    0.153005    0.960342    0.933985    0.963220    0.948718    0.993263    0.976048    0.692430    0.699363    400         5.688623    0.127593    0.045260    0.218239    43.534860  
[37m[36mINFO[0m[0m 02/06 00:05:56 | 0.794529    0.791083    0.983828    0.961045    0.105930    0.975595    0.951100    0.981876    0.952991    0.994012    0.979042    0.794529    0.791083    600         8.532934    0.083602    0.037785    0.245867    44.280538  
[37m[36mINFO[0m[0m 02/06 00:07:30 | 0.751590    0.759236    0.984541    0.974508    0.087243    0.979866    0.973105    0.979744    0.959402    0.994012    0.991018    0.751590    0.759236    800         11.377246   0.049744    0.034351    0.260939    41.738644  
[37m[36mINFO[0m[0m 02/06 00:09:07 | 0.743639    0.752866    0.986415    0.957704    0.135772    0.980476    0.946210    0.984009    0.950855    0.994760    0.976048    0.743639    0.752866    1000        14.221557   0.042893    0.029386    0.266010    43.889714  
[37m[36mINFO[0m[0m 02/06 00:10:40 | 0.760496    0.749045    0.992783    0.965749    0.113500    0.984747    0.951100    0.993603    0.955128    1.000000    0.991018    0.760496    0.749045    1200        17.065868   0.031523    0.027296    0.261045    41.122642  
[37m[36mINFO[0m[0m 02/06 00:12:14 | 0.792303    0.789809    0.994212    0.964628    0.109193    0.990848    0.958435    0.992537    0.959402    0.999251    0.976048    0.792303    0.789809    1400        19.910180   0.031722    0.025922    0.268972    39.928210  
[37m[36mINFO[0m[0m 02/06 00:13:49 | 0.771310    0.778344    0.997169    0.975948    0.075854    0.996949    0.963325    0.996802    0.976496    0.997754    0.988024    0.771310    0.778344    1600        22.754491   0.020376    0.023294    0.292765    37.070100  
[37m[36mINFO[0m[0m 02/06 00:15:23 | 0.821565    0.828025    0.997367    0.969839    0.091345    0.995729    0.953545    0.997868    0.967949    0.998503    0.988024    0.821565    0.828025    1800        25.598802   0.013663    0.021637    0.290474    35.587108  
[37m[36mINFO[0m[0m 02/06 00:16:59 | 0.840649    0.839490    0.994341    0.963003    0.115284    0.993899    0.953545    0.989872    0.944444    0.999251    0.991018    0.840649    0.839490    2000        28.443114   0.013941    0.020292    0.293297    37.459559  
[37m[36mINFO[0m[0m 02/06 00:18:29 | 0.763359    0.782166    0.997361    0.966868    0.113937    0.993899    0.960880    0.998934    0.963675    0.999251    0.976048    0.763359    0.782166    2200        31.287425   0.015363    0.019508    0.268239    36.345050  
[37m[36mINFO[0m[0m 02/06 00:19:56 | 0.792939    0.798726    0.998857    0.976623    0.090408    0.998170    0.965770    0.998401    0.970085    1.000000    0.994012    0.792939    0.798726    2400        34.131737   0.009642    0.018177    0.268609    33.312825  
[37m[36mINFO[0m[0m 02/06 00:21:29 | 0.770992    0.779618    0.997799    0.972753    0.105080    0.997559    0.958435    0.997335    0.965812    0.998503    0.994012    0.770992    0.779618    2600        36.976048   0.011354    0.017353    0.291754    34.196825  
[37m[36mINFO[0m[0m 02/06 00:23:04 | 0.771310    0.792357    0.997519    0.969333    0.104435    0.995119    0.958435    0.998934    0.961538    0.998503    0.988024    0.771310    0.792357    2800        39.820359   0.017259    0.016826    0.279353    39.034758  
[37m[36mINFO[0m[0m 02/06 00:24:40 | 0.791349    0.791083    0.998476    0.978576    0.073856    0.997559    0.968215    0.997868    0.976496    1.000000    0.991018    0.791349    0.791083    3000        42.664671   0.010639    0.016811    0.288757    38.420070  
[37m[36mINFO[0m[0m 02/06 00:26:13 | 0.779262    0.791083    0.999441    0.977335    0.076625    0.999390    0.965770    0.998934    0.972222    1.000000    0.994012    0.779262    0.791083    3200        45.508982   0.007239    0.015429    0.280439    37.138227  
[37m[36mINFO[0m[0m 02/06 00:27:48 | 0.810751    0.814013    0.995224    0.966358    0.107698    0.992068    0.948655    0.993603    0.959402    1.000000    0.991018    0.810751    0.814013    3400        48.353293   0.008167    0.014661    0.293591    36.402722  
[37m[36mINFO[0m[0m 02/06 00:29:26 | 0.804707    0.820382    0.999395    0.978458    0.083730    1.000000    0.975550    0.998934    0.965812    0.999251    0.994012    0.804707    0.820382    3600        51.197605   0.007367    0.014118    0.287070    39.909092  
[37m[36mINFO[0m[0m 02/06 00:30:57 | 0.826336    0.836943    0.999140    0.976440    0.072244    0.998170    0.968215    1.000000    0.970085    0.999251    0.991018    0.826336    0.836943    3800        54.041916   0.003528    0.013491    0.253036    40.378237  
[37m[36mINFO[0m[0m 02/06 00:32:32 | 0.823155    0.828025    0.999573    0.976725    0.095043    1.000000    0.968215    0.999467    0.967949    0.999251    0.994012    0.823155    0.828025    4000        56.886228   0.004385    0.012775    0.277086    39.595310  
[37m[36mINFO[0m[0m 02/06 00:34:02 | 0.786578    0.810191    0.999060    0.975419    0.098125    0.998780    0.960880    0.998401    0.974359    1.000000    0.991018    0.786578    0.810191    4200        59.730539   0.004202    0.012268    0.275362    35.770171  
[37m[36mINFO[0m[0m 02/06 00:35:33 | 0.834606    0.845860    0.999619    0.976542    0.085764    0.999390    0.970660    0.999467    0.967949    1.000000    0.991018    0.834606    0.845860    4400        62.574850   0.003559    0.012159    0.231275    44.760479  
[37m[36mINFO[0m[0m 02/06 00:37:08 | 0.822519    0.824204    0.999619    0.980309    0.080479    0.999390    0.975550    0.999467    0.974359    1.000000    0.991018    0.822519    0.824204    4600        65.419162   0.003974    0.011968    0.263780    41.828612  
[37m[36mINFO[0m[0m 02/06 00:38:43 | 0.819656    0.833121    1.000000    0.979083    0.077300    1.000000    0.963325    1.000000    0.982906    1.000000    0.991018    0.819656    0.833121    4800        68.263473   0.003514    0.011431    0.270044    41.282821  
[37m[36mINFO[0m[0m 02/06 00:40:23 | 0.790394    0.808917    0.999619    0.978759    0.088809    0.999390    0.965770    0.999467    0.976496    1.000000    0.994012    0.790394    0.808917    5000        71.107784   0.004040    0.011117    0.270881    45.778298  
[37m[36mINFO[0m[0m 02/06 00:40:23 | Cumulative gradient change saved at train_output/PACS/CORAL/[3]/250206_00-00-47_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 02/06 00:40:25 | ---
[37m[36mINFO[0m[0m 02/06 00:40:25 | test-domain validation(oracle) = 83.461%
[37m[36mINFO[0m[0m 02/06 00:40:25 | training-domain validation(iid) = 82.252%
[37m[36mINFO[0m[0m 02/06 00:40:25 | last = 79.039%
[37m[36mINFO[0m[0m 02/06 00:40:25 | last (inD) = 97.876%
[37m[36mINFO[0m[0m 02/06 00:40:25 | training-domain validation (iid, inD) = 98.031%
[37m[36mINFO[0m[0m 02/06 00:40:25 | === Summary ===
[37m[36mINFO[0m[0m 02/06 00:40:25 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm CORAL --test_envs 3 --dataset PACS --trial_seed 0 --hparams_seed 6
[37m[36mINFO[0m[0m 02/06 00:40:25 | Unique name: 250206_00-00-47_resnet50_GENIE
[37m[36mINFO[0m[0m 02/06 00:40:25 | Out path: train_output/PACS/CORAL/[3]/250206_00-00-47_resnet50_GENIE
[37m[36mINFO[0m[0m 02/06 00:40:25 | Algorithm: CORAL
[37m[36mINFO[0m[0m 02/06 00:40:25 | Dataset: PACS
