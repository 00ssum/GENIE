[37m[36mINFO[0m[0m 01/26 21:51:14 | Command :: /jsm0707/Large-scale/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm CORAL --test_envs 1 2 3 --dataset PACS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_sgd.yaml']
	data_dir: data
	dataset: PACS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_sgd
	out_dir: train_output/PACS/CORAL/[1, 2, 3]/250126_21-51-14_resnet50_sgd
	out_root: train_output/PACS/CORAL/[1, 2, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [1, 2, 3]
	trial_seed: 0
	unique_name: 250126_21-51-14_resnet50_sgd
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: sgd
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	mmd_gamma: 1.0
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[PACS] #envs=4, #classes=7
	env0: A (#2048)
	env1: C (#2344)
	env2: P (#1670)
	env3: S (#3929)

[37m[36mINFO[0m[0m 01/26 21:51:14 | n_steps = 5001
[37m[36mINFO[0m[0m 01/26 21:51:14 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 01/26 21:51:14 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 01/26 21:51:14 | 
[37m[36mINFO[0m[0m 01/26 21:51:14 | Testenv name escaping te_C_P_S -> te_C_P_S
[37m[36mINFO[0m[0m 01/26 21:51:14 | Test envs = [1, 2, 3], name = te_C_P_S
[37m[36mINFO[0m[0m 01/26 21:51:14 | Train environments: [0], Test environments: [1, 2, 3]
[37m[36mINFO[0m[0m 01/26 21:51:14 | Batch sizes for each domain: [32, 0, 0, 0] (total=32)
[37m[36mINFO[0m[0m 01/26 21:51:14 | steps-per-epoch for each domain: 51.22 -> min = 51.22
[37m[36mINFO[0m[0m 01/26 21:51:15 | # of params = 23522375
[37m[36mINFO[0m[0m 01/26 21:51:42 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 01/26 21:51:42 | 0.085594    0.105738    0.236120    0.190709    1.932743    0.236120    0.190709    0.099680    0.113248    0.097305    0.137725    0.059796    0.066242    0           0.000000    2.096475    0.000000    0.939909    26.000443  
[37m[36mINFO[0m[0m 01/26 21:52:38 | 0.174684    0.187168    0.339231    0.286064    1.836829    0.339231    0.286064    0.144989    0.160256    0.266467    0.290419    0.112595    0.110828    200         3.904820    1.867507    0.000000    0.138184    27.796822  
[37m[36mINFO[0m[0m 01/26 21:53:35 | 0.239001    0.234588    0.410616    0.405868    1.740918    0.410616    0.405868    0.199360    0.196581    0.380240    0.377246    0.137405    0.129936    400         7.809640    1.771642    0.000000    0.158025    25.579757  
[37m[36mINFO[0m[0m 01/26 21:54:29 | 0.302875    0.298632    0.499085    0.518337    1.619202    0.499085    0.518337    0.257996    0.256410    0.484281    0.470060    0.166349    0.169427    600         11.714460   1.671576    0.000000    0.139605    25.528314  
[37m[36mINFO[0m[0m 01/26 21:55:24 | 0.349734    0.344062    0.589994    0.618582    1.450943    0.589994    0.618582    0.315565    0.305556    0.545659    0.541916    0.187977    0.184713    800         15.619280   1.530255    0.000000    0.145018    25.567415  
[37m[36mINFO[0m[0m 01/26 21:56:20 | 0.388136    0.373698    0.661379    0.704156    1.230348    0.661379    0.704156    0.361407    0.339744    0.598802    0.592814    0.204198    0.188535    1000        19.524100   1.332816    0.000000    0.141319    27.464984  
[37m[36mINFO[0m[0m 01/26 21:57:14 | 0.445746    0.430501    0.756559    0.801956    0.983214    0.756559    0.801956    0.386994    0.371795    0.708832    0.700599    0.241412    0.219108    1200        23.428920   1.104847    0.000000    0.142956    25.719304  
[37m[36mINFO[0m[0m 01/26 21:58:06 | 0.487191    0.484586    0.806589    0.855746    0.748085    0.806589    0.855746    0.406183    0.403846    0.805389    0.796407    0.250000    0.253503    1400        27.333740   0.878137    0.000000    0.138805    23.211118  
[37m[36mINFO[0m[0m 01/26 21:59:00 | 0.513609    0.489691    0.844417    0.867971    0.589734    0.844417    0.867971    0.404584    0.378205    0.863024    0.823353    0.273219    0.267516    1600        31.238560   0.671531    0.000000    0.149861    23.768915  
[37m[36mINFO[0m[0m 01/26 21:59:54 | 0.538220    0.522016    0.854179    0.882641    0.472190    0.854179    0.882641    0.431770    0.418803    0.887725    0.868263    0.295165    0.278981    1800        35.143380   0.552243    0.000000    0.135311    26.668734  
[37m[36mINFO[0m[0m 01/26 22:00:47 | 0.547606    0.534813    0.880415    0.875306    0.406241    0.880415    0.875306    0.438166    0.429487    0.903443    0.883234    0.301209    0.291720    2000        39.048200   0.460058    0.000000    0.136195    25.875917  
[37m[36mINFO[0m[0m 01/26 22:01:42 | 0.557923    0.549452    0.887736    0.885086    0.355634    0.887736    0.885086    0.451493    0.450855    0.906437    0.889222    0.315840    0.308280    2200        42.953020   0.394396    0.000000    0.144774    25.563784  
[37m[36mINFO[0m[0m 01/26 22:02:37 | 0.576164    0.574740    0.892617    0.892421    0.319910    0.892617    0.892421    0.465352    0.474359    0.924401    0.907186    0.338740    0.342675    2400        46.857840   0.361095    0.000000    0.142861    26.509444  
[37m[36mINFO[0m[0m 01/26 22:03:31 | 0.581895    0.584142    0.904210    0.897311    0.296570    0.904210    0.897311    0.477079    0.489316    0.931138    0.919162    0.337468    0.343949    2600        50.762660   0.339059    0.000000    0.136915    26.412964  
[37m[36mINFO[0m[0m 01/26 22:04:24 | 0.602199    0.603867    0.913972    0.907090    0.282856    0.913972    0.907090    0.497335    0.512821    0.937126    0.919162    0.372137    0.379618    2800        54.667480   0.301264    0.000000    0.139369    24.751989  
[37m[36mINFO[0m[0m 01/26 22:05:15 | 0.606494    0.606839    0.912142    0.909535    0.271301    0.912142    0.909535    0.494670    0.512821    0.945359    0.919162    0.379453    0.388535    3000        58.572300   0.271330    0.000000    0.130291    24.395973  
[37m[36mINFO[0m[0m 01/26 22:06:08 | 0.608328    0.602180    0.926174    0.911980    0.260912    0.926174    0.911980    0.495736    0.514957    0.955838    0.922156    0.373410    0.369427    3200        62.477120   0.251968    0.000000    0.135436    25.335589  
[37m[36mINFO[0m[0m 01/26 22:07:01 | 0.611623    0.608001    0.922514    0.919315    0.244492    0.922514    0.919315    0.504797    0.523504    0.952844    0.922156    0.377226    0.378344    3400        66.381940   0.241665    0.000000    0.140458    25.278939  
[37m[36mINFO[0m[0m 01/26 22:07:55 | 0.619913    0.614245    0.920073    0.921760    0.235650    0.920073    0.921760    0.518124    0.527778    0.951347    0.925150    0.390267    0.389809    3600        70.286760   0.222175    0.000000    0.134970    26.518284  
[37m[36mINFO[0m[0m 01/26 22:08:47 | 0.621207    0.616836    0.932276    0.924205    0.228167    0.932276    0.924205    0.517591    0.527778    0.959581    0.943114    0.386450    0.379618    3800        74.191580   0.205405    0.000000    0.132741    25.433597  
[37m[36mINFO[0m[0m 01/26 22:09:44 | 0.631189    0.624182    0.937767    0.919315    0.231182    0.937767    0.919315    0.520256    0.527778    0.963323    0.937126    0.409987    0.407643    4000        78.096400   0.202932    0.000000    0.142629    27.606679  
[37m[36mINFO[0m[0m 01/26 22:10:37 | 0.632175    0.625030    0.948749    0.921760    0.222315    0.948749    0.921760    0.517058    0.523504    0.964072    0.940120    0.415394    0.411465    4200        82.001220   0.183970    0.000000    0.136509    25.722080  
[37m[36mINFO[0m[0m 01/26 22:11:32 | 0.643540    0.638530    0.942038    0.924205    0.206906    0.942038    0.924205    0.549041    0.538462    0.963323    0.949102    0.418257    0.428025    4400        85.906040   0.163496    0.000000    0.144488    25.885031  
[37m[36mINFO[0m[0m 01/26 22:12:25 | 0.636078    0.634565    0.946309    0.929095    0.207060    0.946309    0.929095    0.523454    0.527778    0.965569    0.958084    0.419211    0.417834    4600        89.810860   0.173304    0.000000    0.130388    26.476480  
[37m[36mINFO[0m[0m 01/26 22:13:21 | 0.630900    0.627734    0.954240    0.929095    0.213509    0.954240    0.929095    0.511194    0.517094    0.967066    0.952096    0.414440    0.414013    4800        93.715680   0.158497    0.000000    0.137071    28.682067  
[37m[36mINFO[0m[0m 01/26 22:14:15 | 0.639580    0.639651    0.954851    0.936430    0.199172    0.954851    0.936430    0.526119    0.529915    0.964820    0.952096    0.427799    0.436943    5000        97.620500   0.149139    0.000000    0.134603    26.360126  
[37m[36mINFO[0m[0m 01/26 22:14:15 | Cumulative gradient change saved at train_output/PACS/CORAL/[1, 2, 3]/250126_21-51-14_resnet50_sgd/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 01/26 22:14:16 | ---
[37m[36mINFO[0m[0m 01/26 22:14:16 | test-domain validation(oracle) = 63.958%
[37m[36mINFO[0m[0m 01/26 22:14:16 | training-domain validation(iid) = 63.958%
[37m[36mINFO[0m[0m 01/26 22:14:16 | last = 63.958%
[37m[36mINFO[0m[0m 01/26 22:14:16 | last (inD) = 93.643%
[37m[36mINFO[0m[0m 01/26 22:14:16 | training-domain validation (iid, inD) = 93.643%
[37m[36mINFO[0m[0m 01/26 22:14:17 | === Summary ===
[37m[36mINFO[0m[0m 01/26 22:14:17 | Command: /jsm0707/Large-scale/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm CORAL --test_envs 1 2 3 --dataset PACS
[37m[36mINFO[0m[0m 01/26 22:14:17 | Unique name: 250126_21-51-14_resnet50_sgd
[37m[36mINFO[0m[0m 01/26 22:14:17 | Out path: train_output/PACS/CORAL/[1, 2, 3]/250126_21-51-14_resnet50_sgd
[37m[36mINFO[0m[0m 01/26 22:14:17 | Algorithm: CORAL
[37m[36mINFO[0m[0m 01/26 22:14:17 | Dataset: PACS
