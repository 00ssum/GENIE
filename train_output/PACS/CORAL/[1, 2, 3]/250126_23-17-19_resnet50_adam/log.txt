[37m[36mINFO[0m[0m 01/26 23:17:19 | Command :: /jsm0707/Large-scale/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm CORAL --test_envs 1 2 3 --dataset PACS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_adam.yaml']
	data_dir: data
	dataset: PACS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_adam
	out_dir: train_output/PACS/CORAL/[1, 2, 3]/250126_23-17-19_resnet50_adam
	out_root: train_output/PACS/CORAL/[1, 2, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [1, 2, 3]
	trial_seed: 0
	unique_name: 250126_23-17-19_resnet50_adam
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: adam
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	mmd_gamma: 1.0
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[PACS] #envs=4, #classes=7
	env0: A (#2048)
	env1: C (#2344)
	env2: P (#1670)
	env3: S (#3929)

[37m[36mINFO[0m[0m 01/26 23:17:19 | n_steps = 5001
[37m[36mINFO[0m[0m 01/26 23:17:19 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 01/26 23:17:19 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 01/26 23:17:19 | 
[37m[36mINFO[0m[0m 01/26 23:17:19 | Testenv name escaping te_C_P_S -> te_C_P_S
[37m[36mINFO[0m[0m 01/26 23:17:19 | Test envs = [1, 2, 3], name = te_C_P_S
[37m[36mINFO[0m[0m 01/26 23:17:19 | Train environments: [0], Test environments: [1, 2, 3]
[37m[36mINFO[0m[0m 01/26 23:17:19 | Batch sizes for each domain: [32, 0, 0, 0] (total=32)
[37m[36mINFO[0m[0m 01/26 23:17:19 | steps-per-epoch for each domain: 51.22 -> min = 51.22
[37m[36mINFO[0m[0m 01/26 23:17:20 | # of params = 23522375
[37m[36mINFO[0m[0m 01/26 23:17:46 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 01/26 23:17:46 | 0.136786    0.132315    0.261745    0.229829    1.859199    0.261745    0.229829    0.138060    0.128205    0.104042    0.110778    0.168257    0.157962    0           0.000000    2.096475    0.000000    1.267618    24.307949  
[37m[36mINFO[0m[0m 01/26 23:18:41 | 0.725963    0.718000    0.943868    0.904645    0.283556    0.943868    0.904645    0.656716    0.632479    0.958832    0.952096    0.562341    0.569427    200         3.904820    0.321425    0.000000    0.142772    26.667104  
[37m[36mINFO[0m[0m 01/26 23:19:33 | 0.690399    0.697221    0.943868    0.907090    0.408034    0.943868    0.907090    0.641258    0.626068    0.914671    0.910180    0.515267    0.555414    400         7.809640    0.121843    0.000000    0.131866    25.426493  
[37m[36mINFO[0m[0m 01/26 23:20:24 | 0.700591    0.692269    0.945088    0.899756    0.319356    0.945088    0.899756    0.568230    0.566239    0.967066    0.964072    0.566476    0.546497    600         11.714460   0.083838    0.000000    0.129273    24.438564  
[37m[36mINFO[0m[0m 01/26 23:21:19 | 0.678932    0.668058    0.959121    0.907090    0.406631    0.959121    0.907090    0.616738    0.604701    0.899701    0.868263    0.520356    0.531210    800         15.619280   0.086637    0.000000    0.147766    25.488271  
[37m[36mINFO[0m[0m 01/26 23:22:12 | 0.739014    0.729275    0.991458    0.921760    0.180944    0.991458    0.921760    0.647655    0.636752    0.955838    0.928144    0.613550    0.622930    1000        19.524100   0.059368    0.000000    0.138679    25.236981  
[37m[36mINFO[0m[0m 01/26 23:23:04 | 0.725446    0.711246    0.984137    0.941320    0.280107    0.984137    0.941320    0.622068    0.604701    0.961078    0.934132    0.593193    0.594904    1200        23.428920   0.035105    0.000000    0.132201    25.162897  
[37m[36mINFO[0m[0m 01/26 23:23:56 | 0.772984    0.759546    0.994509    0.955990    0.187600    0.994509    0.955990    0.712687    0.694444    0.953593    0.928144    0.652672    0.656051    1400        27.333740   0.061570    0.000000    0.135781    25.533081  
[37m[36mINFO[0m[0m 01/26 23:24:48 | 0.735289    0.729226    0.990238    0.933985    0.286473    0.990238    0.933985    0.689765    0.690171    0.948353    0.919162    0.567748    0.578344    1600        31.238560   0.026330    0.000000    0.135626    24.450407  
[37m[36mINFO[0m[0m 01/26 23:25:39 | 0.768335    0.744113    0.995119    0.943765    0.142366    0.995119    0.943765    0.674307    0.655983    0.934132    0.901198    0.696565    0.675159    1800        35.143380   0.047180    0.000000    0.133238    24.308091  
[37m[36mINFO[0m[0m 01/26 23:26:31 | 0.775359    0.775387    0.986577    0.970660    0.124792    0.986577    0.970660    0.688699    0.698718    0.946856    0.919162    0.690522    0.708280    2000        39.048200   0.045132    0.000000    0.132464    25.195379  
[37m[36mINFO[0m[0m 01/26 23:27:25 | 0.753708    0.749724    0.959732    0.904645    0.489867    0.959732    0.904645    0.690299    0.715812    0.925150    0.886228    0.645674    0.647134    2200        42.953020   0.032168    0.000000    0.134067    26.924557  
[37m[36mINFO[0m[0m 01/26 23:28:17 | 0.792171    0.788477    0.987187    0.943765    0.355489    0.987187    0.943765    0.707889    0.724359    0.955838    0.925150    0.712786    0.715924    2400        46.857840   0.030468    0.000000    0.135964    25.290985  
[37m[36mINFO[0m[0m 01/26 23:29:09 | 0.796750    0.794303    0.994509    0.941320    0.243724    0.994509    0.941320    0.723348    0.741453    0.952844    0.919162    0.714059    0.722293    2600        50.762660   0.057791    0.000000    0.135037    25.212921  
[37m[36mINFO[0m[0m 01/26 23:30:00 | 0.751448    0.748792    0.997559    0.936430    0.248008    0.997559    0.936430    0.632196    0.649573    0.951347    0.910180    0.670802    0.686624    2800        54.667480   0.027821    0.000000    0.132019    24.530859  
[37m[36mINFO[0m[0m 01/26 23:30:52 | 0.716437    0.708080    0.994509    0.921760    0.339341    0.994509    0.921760    0.575693    0.576923    0.967066    0.937126    0.606552    0.610191    3000        58.572300   0.030210    0.000000    0.138288    24.277552  
[37m[36mINFO[0m[0m 01/26 23:31:46 | 0.695552    0.688516    0.957291    0.894866    0.524263    0.957291    0.894866    0.603945    0.611111    0.861527    0.835329    0.621183    0.619108    3200        62.477120   0.030657    0.000000    0.138353    26.065405  
[37m[36mINFO[0m[0m 01/26 23:32:40 | 0.757275    0.753248    0.998780    0.948655    0.198413    0.998780    0.948655    0.647655    0.664530    0.952096    0.925150    0.672074    0.670064    3400        66.381940   0.036224    0.000000    0.134852    26.595464  
[37m[36mINFO[0m[0m 01/26 23:33:34 | 0.774024    0.769051    0.998170    0.943765    0.156076    0.998170    0.943765    0.697228    0.700855    0.956587    0.931138    0.668257    0.675159    3600        70.286760   0.010480    0.000000    0.134245    27.190411  
[37m[36mINFO[0m[0m 01/26 23:34:27 | 0.759821    0.761855    0.996949    0.941320    0.260427    0.996949    0.941320    0.710021    0.728632    0.949850    0.916168    0.619593    0.640764    3800        74.191580   0.020704    0.000000    0.137776    26.062886  
[37m[36mINFO[0m[0m 01/26 23:35:24 | 0.685830    0.674743    0.996949    0.938875    0.286848    0.996949    0.938875    0.577292    0.572650    0.952844    0.910180    0.527354    0.541401    4000        78.096400   0.023361    0.000000    0.136591    29.303270  
[37m[36mINFO[0m[0m 01/26 23:36:16 | 0.779399    0.787169    0.991458    0.941320    0.212069    0.991458    0.941320    0.694030    0.694444    0.934880    0.937126    0.709288    0.729936    4200        82.001220   0.021562    0.000000    0.129042    25.936256  
[37m[36mINFO[0m[0m 01/26 23:37:10 | 0.756052    0.748557    0.998780    0.951100    0.236830    0.998780    0.951100    0.667377    0.692308    0.919162    0.892216    0.681616    0.661146    4400        85.906040   0.035785    0.000000    0.141072    25.535592  
[37m[36mINFO[0m[0m 01/26 23:38:01 | 0.748769    0.758384    0.990238    0.916870    0.265642    0.990238    0.916870    0.683902    0.707265    0.932635    0.904192    0.629771    0.663694    4600        89.810860   0.035761    0.000000    0.128480    25.716142  
[37m[36mINFO[0m[0m 01/26 23:38:52 | 0.747064    0.745588    0.995119    0.946210    0.200338    0.995119    0.946210    0.659382    0.677350    0.945359    0.907186    0.636450    0.652229    4800        93.715680   0.040820    0.000000    0.132180    24.291582  
[37m[36mINFO[0m[0m 01/26 23:39:43 | 0.732076    0.725873    0.988408    0.894866    0.388240    0.988408    0.894866    0.664712    0.675214    0.928144    0.892216    0.603372    0.610191    5000        97.620500   0.030966    0.000000    0.132903    24.466959  
[37m[36mINFO[0m[0m 01/26 23:39:43 | Cumulative gradient change saved at train_output/PACS/CORAL/[1, 2, 3]/250126_23-17-19_resnet50_adam/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 01/26 23:39:45 | ---
[37m[36mINFO[0m[0m 01/26 23:39:45 | test-domain validation(oracle) = 79.675%
[37m[36mINFO[0m[0m 01/26 23:39:45 | training-domain validation(iid) = 77.536%
[37m[36mINFO[0m[0m 01/26 23:39:45 | last = 73.208%
[37m[36mINFO[0m[0m 01/26 23:39:45 | last (inD) = 89.487%
[37m[36mINFO[0m[0m 01/26 23:39:45 | training-domain validation (iid, inD) = 97.066%
[37m[36mINFO[0m[0m 01/26 23:39:45 | === Summary ===
[37m[36mINFO[0m[0m 01/26 23:39:45 | Command: /jsm0707/Large-scale/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm CORAL --test_envs 1 2 3 --dataset PACS
[37m[36mINFO[0m[0m 01/26 23:39:45 | Unique name: 250126_23-17-19_resnet50_adam
[37m[36mINFO[0m[0m 01/26 23:39:45 | Out path: train_output/PACS/CORAL/[1, 2, 3]/250126_23-17-19_resnet50_adam
[37m[36mINFO[0m[0m 01/26 23:39:45 | Algorithm: CORAL
[37m[36mINFO[0m[0m 01/26 23:39:45 | Dataset: PACS
