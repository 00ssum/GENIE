[37m[36mINFO[0m[0m 01/27 00:00:57 | Command :: /jsm0707/Large-scale/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm CORAL --test_envs 0 1 3 --dataset PACS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: CORAL
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_adam.yaml']
	data_dir: data
	dataset: PACS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_adam
	out_dir: train_output/PACS/CORAL/[0, 1, 3]/250127_00-00-57_resnet50_adam
	out_root: train_output/PACS/CORAL/[0, 1, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 1, 3]
	trial_seed: 0
	unique_name: 250127_00-00-57_resnet50_adam
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: adam
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	mmd_gamma: 1.0
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[PACS] #envs=4, #classes=7
	env0: A (#2048)
	env1: C (#2344)
	env2: P (#1670)
	env3: S (#3929)

[37m[36mINFO[0m[0m 01/27 00:00:57 | n_steps = 5001
[37m[36mINFO[0m[0m 01/27 00:00:57 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 01/27 00:00:57 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 01/27 00:00:57 | 
[37m[36mINFO[0m[0m 01/27 00:00:57 | Testenv name escaping te_A_C_S -> te_A_C_S
[37m[36mINFO[0m[0m 01/27 00:00:57 | Test envs = [0, 1, 3], name = te_A_C_S
[37m[36mINFO[0m[0m 01/27 00:00:57 | Train environments: [2], Test environments: [0, 1, 3]
[37m[36mINFO[0m[0m 01/27 00:00:57 | Batch sizes for each domain: [0, 0, 32, 0] (total=32)
[37m[36mINFO[0m[0m 01/27 00:00:57 | steps-per-epoch for each domain: 41.75 -> min = 41.75
[37m[36mINFO[0m[0m 01/27 00:00:59 | # of params = 23522375
[37m[36mINFO[0m[0m 01/27 00:01:22 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        penalty     step_time   eval_time  
[37m[36mINFO[0m[0m 01/27 00:01:22 | 0.157507    0.143911    0.375000    0.335329    1.773910    0.274558    0.246944    0.157249    0.145299    0.375000    0.335329    0.040712    0.039490    0           0.000000    1.968217    0.000000    1.023479    22.558830  
[37m[36mINFO[0m[0m 01/27 00:02:14 | 0.471024    0.476519    0.995509    0.973054    0.090447    0.676022    0.674817    0.420576    0.427350    0.995509    0.973054    0.316476    0.327389    200         4.790419    0.131958    0.000000    0.133192    25.099722  
[37m[36mINFO[0m[0m 01/27 00:03:06 | 0.496698    0.491751    0.999251    0.976048    0.073414    0.676022    0.660147    0.390725    0.371795    0.999251    0.976048    0.423346    0.443312    400         9.580838    0.048425    0.000000    0.134957    24.415779  
[37m[36mINFO[0m[0m 01/27 00:03:58 | 0.544051    0.544519    0.997006    0.988024    0.056426    0.649176    0.657702    0.546908    0.542735    0.997006    0.988024    0.436069    0.433121    600         14.371257   0.012797    0.000000    0.129654    25.816969  
[37m[36mINFO[0m[0m 01/27 00:04:50 | 0.381198    0.395567    0.978293    0.958084    0.151530    0.621721    0.650367    0.332623    0.337607    0.978293    0.958084    0.189249    0.198726    800         19.161677   0.023779    0.000000    0.131548    25.537954  
[37m[36mINFO[0m[0m 01/27 00:05:46 | 0.420396    0.425216    0.999251    0.970060    0.080025    0.604637    0.623472    0.338486    0.324786    0.999251    0.970060    0.318066    0.327389    1000        23.952096   0.028568    0.000000    0.143346    27.125606  
[37m[36mINFO[0m[0m 01/27 00:06:39 | 0.439613    0.442426    0.992515    0.970060    0.110551    0.679683    0.679707    0.356077    0.335470    0.992515    0.970060    0.283079    0.312102    1200        28.742515   0.006113    0.000000    0.137659    25.676959  
[37m[36mINFO[0m[0m 01/27 00:07:31 | 0.440680    0.446200    0.991766    0.946108    0.206777    0.654667    0.667482    0.377932    0.365385    0.991766    0.946108    0.289440    0.305732    1400        33.532934   0.026480    0.000000    0.136250    24.742259  
[37m[36mINFO[0m[0m 01/27 00:08:22 | 0.520012    0.539663    0.996257    0.967066    0.113879    0.670531    0.684597    0.515458    0.566239    0.996257    0.967066    0.374046    0.368153    1600        38.323353   0.028632    0.000000    0.134119    24.273178  
[37m[36mINFO[0m[0m 01/27 00:09:12 | 0.465683    0.463123    0.998503    0.982036    0.060333    0.662599    0.669927    0.371535    0.352564    0.998503    0.982036    0.362913    0.366879    1800        43.113772   0.017586    0.000000    0.135605    23.201356  
[37m[36mINFO[0m[0m 01/27 00:10:03 | 0.461069    0.454199    0.994012    0.967066    0.125186    0.674802    0.672372    0.397655    0.365385    0.994012    0.967066    0.310751    0.324841    2000        47.904192   0.020921    0.000000    0.133602    23.949263  
[37m[36mINFO[0m[0m 01/27 00:10:53 | 0.476392    0.484998    1.000000    0.982036    0.087093    0.682733    0.699267    0.393390    0.382479    1.000000    0.982036    0.353053    0.373248    2200        52.694611   0.001134    0.000000    0.131510    23.263000  
[37m[36mINFO[0m[0m 01/27 00:11:47 | 0.477863    0.484683    0.998503    0.976048    0.093253    0.651007    0.669927    0.390725    0.373932    0.998503    0.976048    0.391858    0.410191    2400        57.485030   0.010805    0.000000    0.137874    26.385619  
[37m[36mINFO[0m[0m 01/27 00:12:38 | 0.448996    0.447276    0.998503    0.973054    0.093770    0.640635    0.645477    0.352345    0.326923    0.998503    0.973054    0.354008    0.369427    2600        62.275449   0.001304    0.000000    0.133834    24.693563  
[37m[36mINFO[0m[0m 01/27 00:13:29 | 0.309956    0.299576    0.981287    0.925150    0.244504    0.525930    0.498778    0.210554    0.192308    0.981287    0.925150    0.193384    0.207643    2800        67.065868   0.045399    0.000000    0.135034    24.251086  
[37m[36mINFO[0m[0m 01/27 00:14:22 | 0.408151    0.402430    0.998503    0.970060    0.114677    0.673581    0.684597    0.304371    0.262821    0.998503    0.970060    0.246501    0.259873    3000        71.856287   0.022689    0.000000    0.136215    25.302230  
[37m[36mINFO[0m[0m 01/27 00:15:15 | 0.416117    0.427140    0.999251    0.985030    0.079557    0.643075    0.669927    0.345416    0.337607    0.999251    0.985030    0.259860    0.273885    3200        76.646707   0.000896    0.000000    0.133492    26.253296  
[37m[36mINFO[0m[0m 01/27 00:16:06 | 0.373544    0.374466    0.997006    0.976048    0.112295    0.664430    0.677262    0.267591    0.243590    0.997006    0.976048    0.188613    0.202548    3400        81.437126   0.020963    0.000000    0.133803    24.084309  
[37m[36mINFO[0m[0m 01/27 00:16:57 | 0.446055    0.463507    0.991018    0.937126    0.241097    0.529591    0.552567    0.355011    0.358974    0.991018    0.937126    0.453562    0.478981    3600        86.227545   0.054469    0.000000    0.136337    24.342119  
[37m[36mINFO[0m[0m 01/27 00:17:49 | 0.469787    0.493313    1.000000    0.967066    0.116548    0.619890    0.621027    0.351812    0.382479    1.000000    0.967066    0.437659    0.476433    3800        91.017964   0.028318    0.000000    0.132371    25.470252  
[37m[36mINFO[0m[0m 01/27 00:18:41 | 0.431839    0.440694    0.996257    0.955090    0.160046    0.586943    0.579462    0.312900    0.324786    0.996257    0.955090    0.395674    0.417834    4000        95.808383   0.005545    0.000000    0.133288    24.764521  
[37m[36mINFO[0m[0m 01/27 00:19:37 | 0.476364    0.468275    1.000000    0.976048    0.145533    0.671751    0.655257    0.312367    0.282051    1.000000    0.976048    0.444975    0.467516    4200        100.598802  0.005606    0.000000    0.142103    27.430297  
[37m[36mINFO[0m[0m 01/27 00:20:28 | 0.477971    0.477925    0.999251    0.970060    0.151412    0.668700    0.662592    0.297974    0.275641    0.999251    0.970060    0.467239    0.495541    4400        105.389222  0.000839    0.000000    0.133752    24.169602  
[37m[36mINFO[0m[0m 01/27 00:21:19 | 0.460966    0.449639    1.000000    0.973054    0.177877    0.636974    0.618582    0.299041    0.262821    1.000000    0.973054    0.446883    0.467516    4600        110.179641  0.000123    0.000000    0.132520    24.883676  
[37m[36mINFO[0m[0m 01/27 00:22:11 | 0.467401    0.457194    1.000000    0.973054    0.177885    0.644905    0.625917    0.304371    0.269231    1.000000    0.973054    0.452926    0.476433    4800        114.970060  0.000009    0.000000    0.136646    24.296894  
[37m[36mINFO[0m[0m 01/27 00:23:00 | 0.479167    0.483903    1.000000    0.976048    0.193980    0.646736    0.645477    0.317164    0.311966    1.000000    0.976048    0.473601    0.494268    5000        119.760479  0.000143    0.000000    0.137937    22.300054  
[37m[36mINFO[0m[0m 01/27 00:23:01 | Cumulative gradient change saved at train_output/PACS/CORAL/[0, 1, 3]/250127_00-00-57_resnet50_adam/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 01/27 00:23:02 | ---
[37m[36mINFO[0m[0m 01/27 00:23:02 | test-domain validation(oracle) = 54.405%
[37m[36mINFO[0m[0m 01/27 00:23:02 | training-domain validation(iid) = 54.405%
[37m[36mINFO[0m[0m 01/27 00:23:02 | last = 47.917%
[37m[36mINFO[0m[0m 01/27 00:23:02 | last (inD) = 97.605%
[37m[36mINFO[0m[0m 01/27 00:23:02 | training-domain validation (iid, inD) = 98.802%
[37m[36mINFO[0m[0m 01/27 00:23:02 | === Summary ===
[37m[36mINFO[0m[0m 01/27 00:23:02 | Command: /jsm0707/Large-scale/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm CORAL --test_envs 0 1 3 --dataset PACS
[37m[36mINFO[0m[0m 01/27 00:23:02 | Unique name: 250127_00-00-57_resnet50_adam
[37m[36mINFO[0m[0m 01/27 00:23:02 | Out path: train_output/PACS/CORAL/[0, 1, 3]/250127_00-00-57_resnet50_adam
[37m[36mINFO[0m[0m 01/27 00:23:02 | Algorithm: CORAL
[37m[36mINFO[0m[0m 01/27 00:23:02 | Dataset: PACS
