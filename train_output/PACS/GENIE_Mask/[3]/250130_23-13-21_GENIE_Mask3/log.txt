[37m[36mINFO[0m[0m 01/30 23:13:21 | Command :: /jsm0707/DomainBed/Large-scale/train_all.py GENIE_Mask3 config/resnet50_sgd.yaml --trial_seed 0 --hparams_seed 18 --algorithm GENIE_Mask --test_envs 3 --dataset PACS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 9.4.0
Args:
	algorithm: GENIE_Mask
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_sgd.yaml']
	data_dir: data
	dataset: PACS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 18
	in_domain: False
	model_save: None
	mpa: False
	name: GENIE_Mask3
	out_dir: train_output/PACS/GENIE_Mask/[3]/250130_23-13-21_GENIE_Mask3
	out_root: train_output/PACS/GENIE_Mask/[3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [3]
	trial_seed: 0
	unique_name: 250130_23-13-21_GENIE_Mask3
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.1
	class_balanced: False
	optimizer: sgd
	freeze_bn: False
	pretrained: True
	lr: 0.00021894640154701087
	batch_size: 13
	weight_decay: 7.1565884139944e-05
	momentum: 0.8683802947171396
	convergence_rate: 0.012803366168469622
	moving_avg: 0.9263892108829195
	p: 0.24651630496904078
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[PACS] #envs=4, #classes=7
	env0: A (#2048)
	env1: C (#2344)
	env2: P (#1670)
	env3: S (#3929)

[37m[36mINFO[0m[0m 01/30 23:13:21 | n_steps = 5001
[37m[36mINFO[0m[0m 01/30 23:13:21 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 01/30 23:13:21 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 01/30 23:13:21 | Target test envs = [[3]]
[37m[36mINFO[0m[0m 01/30 23:13:21 | 
[37m[36mINFO[0m[0m 01/30 23:13:21 | Testenv name escaping te_S -> te_S
[37m[36mINFO[0m[0m 01/30 23:13:21 | Test envs = [3], name = te_S
[37m[36mINFO[0m[0m 01/30 23:13:21 | Batch sizes for each domain: [13, 13, 13, 0] (total=39)
[37m[36mINFO[0m[0m 01/30 23:13:21 | steps-per-epoch for each domain: 126.08, 144.31, 102.77 -> min = 102.77
[37m[36mINFO[0m[0m 01/30 23:13:22 | # of params = 23522375
[37m[36mINFO[0m[0m 01/30 23:13:57 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 01/30 23:13:57 | 0.197519    0.200000    0.212310    0.203318    1.931755    0.220866    0.202934    0.213220    0.194444    0.202844    0.212575    0.197519    0.200000    0           0.000000    2.002535    0.965427    33.737782  
[37m[36mINFO[0m[0m 01/30 23:15:07 | 0.626272    0.639490    0.927707    0.926412    0.194325    0.924344    0.916870    0.882729    0.895299    0.976048    0.967066    0.626272    0.639490    200         1.946108    0.405225    0.181180    33.806094  
[37m[36mINFO[0m[0m 01/30 23:16:04 | 0.666667    0.690446    0.944009    0.926885    0.252925    0.918243    0.887531    0.939232    0.938034    0.974551    0.955090    0.666667    0.690446    400         3.892216    0.168070    0.121254    32.663980  
[37m[36mINFO[0m[0m 01/30 23:17:27 | 0.699109    0.724841    0.967155    0.959986    0.125653    0.955461    0.946210    0.963220    0.948718    0.982784    0.985030    0.699109    0.724841    600         5.838323    0.117373    0.209247    40.342214  
[37m[36mINFO[0m[0m 01/30 23:18:28 | 0.760178    0.770701    0.982929    0.960774    0.121381    0.971934    0.941320    0.981343    0.967949    0.995509    0.973054    0.760178    0.770701    800         7.784431    0.097354    0.143168    32.377081  
[37m[36mINFO[0m[0m 01/30 23:19:25 | 0.760814    0.757962    0.985819    0.968556    0.095357    0.982306    0.953545    0.978145    0.970085    0.997006    0.982036    0.760814    0.757962    1000        9.730539    0.065233    0.117543    32.609680  
[37m[36mINFO[0m[0m 01/30 23:20:39 | 0.774491    0.780892    0.982260    0.953180    0.154958    0.971324    0.926650    0.982942    0.950855    0.992515    0.982036    0.774491    0.780892    1200        11.676647   0.059863    0.176979    38.342101  
[37m[36mINFO[0m[0m 01/30 23:21:45 | 0.686705    0.696815    0.969466    0.955934    0.143748    0.960342    0.941320    0.956290    0.944444    0.991766    0.982036    0.686705    0.696815    1400        13.622754   0.064811    0.170193    32.315352  
[37m[36mINFO[0m[0m 01/30 23:22:44 | 0.792939    0.794904    0.990489    0.959049    0.129270    0.990238    0.951100    0.983475    0.952991    0.997754    0.973054    0.792939    0.794904    1600        15.568862   0.035950    0.119875    34.933807  
[37m[36mINFO[0m[0m 01/30 23:24:03 | 0.722964    0.715924    0.989568    0.954791    0.138196    0.983527    0.941320    0.986674    0.952991    0.998503    0.970060    0.722964    0.715924    1800        17.514970   0.040086    0.171281    45.005618  
[37m[36mINFO[0m[0m 01/30 23:25:09 | 0.683206    0.677707    0.984393    0.949597    0.156756    0.973764    0.919315    0.982409    0.944444    0.997006    0.985030    0.683206    0.677707    2000        19.461078   0.027727    0.157800    33.905943  
[37m[36mINFO[0m[0m 01/30 23:26:26 | 0.761450    0.756688    0.994599    0.969839    0.104871    0.993289    0.953545    0.992004    0.967949    0.998503    0.988024    0.761450    0.756688    2200        21.407186   0.039725    0.164457    44.525778  
[37m[36mINFO[0m[0m 01/30 23:27:35 | 0.803435    0.791083    0.993198    0.968357    0.111899    0.992068    0.965770    0.988273    0.957265    0.999251    0.982036    0.803435    0.791083    2400        23.353293   0.024797    0.136118    40.738213  
[37m[36mINFO[0m[0m 01/30 23:28:37 | 0.801209    0.794904    0.994851    0.965767    0.117231    0.990848    0.958435    0.995203    0.965812    0.998503    0.973054    0.801209    0.794904    2600        25.299401   0.018114    0.137735    35.281822  
[37m[36mINFO[0m[0m 01/30 23:29:58 | 0.789758    0.775796    0.997338    0.973914    0.088447    0.997559    0.965770    0.995203    0.967949    0.999251    0.988024    0.789758    0.775796    2800        27.245509   0.027119    0.235274    33.872059  
[37m[36mINFO[0m[0m 01/30 23:31:00 | 0.783715    0.774522    0.998129    0.973019    0.109556    0.996949    0.968215    0.998934    0.965812    0.998503    0.985030    0.783715    0.774522    3000        29.191617   0.016333    0.133465    34.861391  
[37m[36mINFO[0m[0m 01/30 23:32:08 | 0.681616    0.654777    0.996017    0.974261    0.092525    0.995729    0.970660    0.993070    0.970085    0.999251    0.982036    0.681616    0.654777    3200        31.137725   0.022728    0.143672    39.466156  
[37m[36mINFO[0m[0m 01/30 23:33:18 | 0.692748    0.709554    0.988635    0.947052    0.228347    0.985967    0.926650    0.986674    0.944444    0.993263    0.970060    0.692748    0.709554    3400        33.083832   0.012392    0.182111    33.047721  
[37m[36mINFO[0m[0m 01/30 23:34:15 | 0.781807    0.798726    0.993192    0.960310    0.126641    0.990238    0.943765    0.989339    0.955128    1.000000    0.982036    0.781807    0.798726    3600        35.029940   0.022444    0.122940    32.073701  
[37m[36mINFO[0m[0m 01/30 23:35:35 | 0.764631    0.751592    0.988978    0.955708    0.162838    0.980476    0.946210    0.987207    0.950855    0.999251    0.970060    0.764631    0.751592    3800        36.976048   0.014530    0.175624    45.405270  
[37m[36mINFO[0m[0m 01/30 23:36:40 | 0.784669    0.792357    0.989045    0.965928    0.151109    0.984747    0.948655    0.989872    0.970085    0.992515    0.979042    0.784669    0.792357    4000        38.922156   0.027148    0.147708    35.221065  
[37m[36mINFO[0m[0m 01/30 23:37:50 | 0.763995    0.770701    0.997464    0.964488    0.157863    0.996339    0.958435    0.996802    0.952991    0.999251    0.982036    0.763995    0.770701    4200        40.868263   0.011934    0.178646    34.029204  
[37m[36mINFO[0m[0m 01/30 23:39:14 | 0.789758    0.775796    0.989521    0.958374    0.200185    0.981696    0.948655    0.993603    0.959402    0.993263    0.967066    0.789758    0.775796    4400        42.814371   0.005203    0.192907    45.916532  
[37m[36mINFO[0m[0m 01/30 23:40:13 | 0.774173    0.787261    0.996499    0.974341    0.088719    0.994509    0.965770    0.995736    0.972222    0.999251    0.985030    0.774173    0.787261    4600        44.760479   0.023782    0.127512    32.702144  
[37m[36mINFO[0m[0m 01/30 23:41:18 | 0.750954    0.764331    0.997840    0.965113    0.138670    0.995119    0.946210    0.998401    0.970085    1.000000    0.979042    0.750954    0.764331    4800        46.706587   0.012381    0.148697    35.214551  
[37m[36mINFO[0m[0m 01/30 23:42:38 | 0.753817    0.780892    0.998501    0.958660    0.144770    0.998170    0.948655    0.997335    0.957265    1.000000    0.970060    0.753817    0.780892    5000        48.652695   0.011522    0.197748    40.901934  
[37m[36mINFO[0m[0m 01/30 23:42:38 | Cumulative gradient change saved at train_output/PACS/GENIE_Mask/[3]/250130_23-13-21_GENIE_Mask3/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 01/30 23:42:40 | ---
[37m[36mINFO[0m[0m 01/30 23:42:40 | test-domain validation(oracle) = 78.181%
[37m[36mINFO[0m[0m 01/30 23:42:40 | training-domain validation(iid) = 77.417%
[37m[36mINFO[0m[0m 01/30 23:42:40 | last = 75.382%
[37m[36mINFO[0m[0m 01/30 23:42:40 | last (inD) = 95.866%
[37m[36mINFO[0m[0m 01/30 23:42:40 | training-domain validation (iid, inD) = 97.434%
[37m[36mINFO[0m[0m 01/30 23:42:40 | === Summary ===
[37m[36mINFO[0m[0m 01/30 23:42:40 | Command: /jsm0707/DomainBed/Large-scale/train_all.py GENIE_Mask3 config/resnet50_sgd.yaml --trial_seed 0 --hparams_seed 18 --algorithm GENIE_Mask --test_envs 3 --dataset PACS
[37m[36mINFO[0m[0m 01/30 23:42:40 | Unique name: 250130_23-13-21_GENIE_Mask3
[37m[36mINFO[0m[0m 01/30 23:42:40 | Out path: train_output/PACS/GENIE_Mask/[3]/250130_23-13-21_GENIE_Mask3
[37m[36mINFO[0m[0m 01/30 23:42:40 | Algorithm: GENIE_Mask
[37m[36mINFO[0m[0m 01/30 23:42:40 | Dataset: PACS
[37m[36mINFO[0m[0m 01/30 23:42:40 | Max test_in: 0.8034
