[37m[36mINFO[0m[0m 01/30 22:41:30 | Command :: /jsm0707/DomainBed/Large-scale/train_all.py GENIE_Mask2 config/resnet50_sgd.yaml --trial_seed 0 --hparams_seed 16 --algorithm GENIE_Mask --test_envs 2 --dataset PACS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 9.4.0
Args:
	algorithm: GENIE_Mask
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_sgd.yaml']
	data_dir: data
	dataset: PACS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 16
	in_domain: False
	model_save: None
	mpa: False
	name: GENIE_Mask2
	out_dir: train_output/PACS/GENIE_Mask/[2]/250130_22-41-30_GENIE_Mask2
	out_root: train_output/PACS/GENIE_Mask/[2]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [2]
	trial_seed: 0
	unique_name: 250130_22-41-30_GENIE_Mask2
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: sgd
	freeze_bn: False
	pretrained: True
	lr: 4.249952708249365e-05
	batch_size: 17
	weight_decay: 9.786966598736845e-06
	momentum: 0.8998816091103917
	convergence_rate: 0.002532172972034822
	moving_avg: 0.9428040906106079
	p: 0.1602194197192816
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[PACS] #envs=4, #classes=7
	env0: A (#2048)
	env1: C (#2344)
	env2: P (#1670)
	env3: S (#3929)

[37m[36mINFO[0m[0m 01/30 22:41:30 | n_steps = 5001
[37m[36mINFO[0m[0m 01/30 22:41:30 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 01/30 22:41:30 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 01/30 22:41:30 | Target test envs = [[2]]
[37m[36mINFO[0m[0m 01/30 22:41:30 | 
[37m[36mINFO[0m[0m 01/30 22:41:30 | Testenv name escaping te_P -> te_P
[37m[36mINFO[0m[0m 01/30 22:41:30 | Test envs = [2], name = te_P
[37m[36mINFO[0m[0m 01/30 22:41:30 | Batch sizes for each domain: [17, 17, 0, 17] (total=51)
[37m[36mINFO[0m[0m 01/30 22:41:30 | steps-per-epoch for each domain: 96.41, 110.35, 184.94 -> min = 96.41
[37m[36mINFO[0m[0m 01/30 22:41:32 | # of params = 23522375
[37m[36mINFO[0m[0m 01/30 22:42:06 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 01/30 22:42:06 | 0.083084    0.095808    0.182943    0.183408    1.944213    0.194631    0.200489    0.207889    0.175214    0.083084    0.095808    0.146310    0.174522    0           0.000000    1.973117    0.960765    33.639558  
[37m[36mINFO[0m[0m 01/30 22:43:59 | 0.970808    0.961078    0.862707    0.873984    0.337958    0.895668    0.902200    0.850213    0.867521    0.970808    0.961078    0.842239    0.852229    200         2.074436    0.847667    0.278767    56.822288  
[37m[36mINFO[0m[0m 01/30 22:45:00 | 0.977545    0.982036    0.916744    0.908926    0.254822    0.938377    0.921760    0.912047    0.920940    0.977545    0.982036    0.899809    0.884076    400         4.148871    0.290011    0.140758    32.180660  
[37m[36mINFO[0m[0m 01/30 22:46:03 | 0.977545    0.961078    0.931161    0.931280    0.196363    0.946309    0.936430    0.933369    0.946581    0.977545    0.961078    0.913804    0.910828    600         6.223307    0.210286    0.152524    32.072599  
[37m[36mINFO[0m[0m 01/30 22:47:26 | 0.975299    0.979042    0.941249    0.940060    0.189616    0.967663    0.955990    0.915245    0.944444    0.975299    0.979042    0.940840    0.919745    800         8.297743    0.153714    0.163805    49.689284  
[37m[36mINFO[0m[0m 01/30 22:48:41 | 0.977545    0.982036    0.967573    0.937375    0.180608    0.974375    0.936430    0.964286    0.950855    0.977545    0.982036    0.964059    0.924841    1000        10.372178   0.121422    0.206565    33.381573  
[37m[36mINFO[0m[0m 01/30 22:50:06 | 0.986527    0.988024    0.973948    0.938567    0.179400    0.982306    0.931540    0.975480    0.946581    0.986527    0.988024    0.964059    0.937580    1200        12.446614   0.098111    0.217357    42.042947  
[37m[36mINFO[0m[0m 01/30 22:51:15 | 0.979042    0.976048    0.979668    0.954504    0.141794    0.983527    0.958435    0.981876    0.963675    0.979042    0.976048    0.973601    0.941401    1400        14.521049   0.082672    0.146975    39.458798  
[37m[36mINFO[0m[0m 01/30 22:52:41 | 0.978293    0.970060    0.984576    0.951621    0.152007    0.989628    0.960880    0.988273    0.955128    0.978293    0.970060    0.975827    0.938854    1600        16.595485   0.069854    0.241403    36.929060  
[37m[36mINFO[0m[0m 01/30 22:53:49 | 0.978293    0.973054    0.978613    0.952853    0.160517    0.984747    0.955990    0.974947    0.970085    0.978293    0.973054    0.976145    0.932484    1800        18.669921   0.054783    0.163427    35.217792  
[37m[36mINFO[0m[0m 01/30 22:54:59 | 0.982036    0.982036    0.975238    0.957798    0.171390    0.981086    0.965770    0.975480    0.963675    0.982036    0.982036    0.969148    0.943949    2000        20.744356   0.051920    0.162839    37.630442  
[37m[36mINFO[0m[0m 01/30 22:56:25 | 0.985030    0.982036    0.989837    0.951244    0.167767    0.992678    0.948655    0.989872    0.963675    0.985030    0.982036    0.986959    0.941401    2200        22.818792   0.040997    0.236153    38.296144  
[37m[36mINFO[0m[0m 01/30 22:57:31 | 0.986527    0.985030    0.988407    0.948799    0.162930    0.991458    0.951100    0.990938    0.961538    0.986527    0.985030    0.982824    0.933758    2400        24.893228   0.038337    0.166635    33.182601  
[37m[36mINFO[0m[0m 01/30 22:58:42 | 0.983533    0.982036    0.990713    0.953299    0.154705    0.993289    0.953545    0.990938    0.963675    0.983533    0.982036    0.987913    0.942675    2600        26.967663   0.036597    0.172877    35.935172  
[37m[36mINFO[0m[0m 01/30 22:59:50 | 0.987275    0.982036    0.991780    0.947580    0.180206    0.990848    0.946210    0.994670    0.955128    0.987275    0.982036    0.989822    0.941401    2800        29.042099   0.024458    0.180296    31.816274  
[37m[36mINFO[0m[0m 01/30 23:01:07 | 0.982784    0.982036    0.992533    0.961428    0.144212    0.995119    0.960880    0.995203    0.974359    0.982784    0.982036    0.987277    0.949045    3000        31.116534   0.033334    0.217916    33.327624  
[37m[36mINFO[0m[0m 01/30 23:02:33 | 0.982784    0.982036    0.991903    0.953655    0.160392    0.992068    0.948655    0.994136    0.965812    0.982784    0.982036    0.989504    0.946497    3200        33.190970   0.026485    0.233068    39.255358  
[37m[36mINFO[0m[0m 01/30 23:03:36 | 0.978293    0.985030    0.991215    0.954826    0.166143    0.993289    0.955990    0.994670    0.965812    0.978293    0.985030    0.985687    0.942675    3400        35.265406   0.023601    0.151076    33.348366  
[37m[36mINFO[0m[0m 01/30 23:04:43 | 0.982784    0.979042    0.993619    0.956880    0.160086    0.993289    0.960880    0.995203    0.965812    0.982784    0.979042    0.992366    0.943949    3600        37.339841   0.022209    0.151215    36.269355  
[37m[36mINFO[0m[0m 01/30 23:06:11 | 0.983533    0.979042    0.996508    0.960853    0.139394    0.994509    0.960880    0.999467    0.970085    0.983533    0.979042    0.995547    0.951592    3800        39.414277   0.024586    0.265599    34.701943  
[37m[36mINFO[0m[0m 01/30 23:07:10 | 0.986527    0.982036    0.996203    0.959866    0.141263    0.998170    0.960880    0.996802    0.972222    0.986527    0.982036    0.993639    0.946497    4000        41.488713   0.021113    0.134720    31.935917  
[37m[36mINFO[0m[0m 01/30 23:08:23 | 0.986527    0.976048    0.986573    0.955387    0.202459    0.990848    0.955990    0.988273    0.963675    0.986527    0.976048    0.980598    0.946497    4200        43.563148   0.022146    0.160826    41.399482  
[37m[36mINFO[0m[0m 01/30 23:09:35 | 0.982784    0.988024    0.994860    0.957846    0.162653    0.995729    0.953545    0.996802    0.972222    0.982784    0.988024    0.992048    0.947771    4400        45.637584   0.018630    0.147578    42.027258  
[37m[36mINFO[0m[0m 01/30 23:10:34 | 0.990269    0.988024    0.992802    0.954470    0.171465    0.995729    0.951100    0.992537    0.965812    0.990269    0.988024    0.990140    0.946497    4600        47.712020   0.017571    0.133096    32.470673  
[37m[36mINFO[0m[0m 01/30 23:11:56 | 0.981287    0.976048    0.995177    0.957764    0.154671    0.998170    0.948655    0.996269    0.967949    0.981287    0.976048    0.991094    0.956688    4800        49.786455   0.017146    0.220216    37.658276  
[37m[36mINFO[0m[0m 01/30 23:13:16 | 0.985030    0.976048    0.996610    0.960223    0.165404    0.996949    0.955990    0.997335    0.974359    0.985030    0.976048    0.995547    0.950318    5000        51.860891   0.016920    0.218756    36.482060  
[37m[36mINFO[0m[0m 01/30 23:13:16 | Cumulative gradient change saved at train_output/PACS/GENIE_Mask/[2]/250130_22-41-30_GENIE_Mask2/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 01/30 23:13:17 | ---
[37m[36mINFO[0m[0m 01/30 23:13:17 | test-domain validation(oracle) = 98.653%
[37m[36mINFO[0m[0m 01/30 23:13:17 | training-domain validation(iid) = 98.278%
[37m[36mINFO[0m[0m 01/30 23:13:17 | last = 98.503%
[37m[36mINFO[0m[0m 01/30 23:13:17 | last (inD) = 96.022%
[37m[36mINFO[0m[0m 01/30 23:13:17 | training-domain validation (iid, inD) = 96.143%
[37m[36mINFO[0m[0m 01/30 23:13:17 | === Summary ===
[37m[36mINFO[0m[0m 01/30 23:13:17 | Command: /jsm0707/DomainBed/Large-scale/train_all.py GENIE_Mask2 config/resnet50_sgd.yaml --trial_seed 0 --hparams_seed 16 --algorithm GENIE_Mask --test_envs 2 --dataset PACS
[37m[36mINFO[0m[0m 01/30 23:13:17 | Unique name: 250130_22-41-30_GENIE_Mask2
[37m[36mINFO[0m[0m 01/30 23:13:17 | Out path: train_output/PACS/GENIE_Mask/[2]/250130_22-41-30_GENIE_Mask2
[37m[36mINFO[0m[0m 01/30 23:13:17 | Algorithm: GENIE_Mask
[37m[36mINFO[0m[0m 01/30 23:13:17 | Dataset: PACS
[37m[36mINFO[0m[0m 01/30 23:13:17 | Max test_in: 0.9903
