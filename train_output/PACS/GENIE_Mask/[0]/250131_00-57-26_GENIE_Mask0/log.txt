[37m[36mINFO[0m[0m 01/31 00:57:26 | Command :: /jsm0707/DomainBed/Large-scale/train_all.py GENIE_Mask0 config/resnet50_sgd.yaml --trial_seed 2 --hparams_seed 9 --algorithm GENIE_Mask --test_envs 0 --dataset PACS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 9.4.0
Args:
	algorithm: GENIE_Mask
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_sgd.yaml']
	data_dir: data
	dataset: PACS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 9
	in_domain: False
	model_save: None
	mpa: False
	name: GENIE_Mask0
	out_dir: train_output/PACS/GENIE_Mask/[0]/250131_00-57-26_GENIE_Mask0
	out_root: train_output/PACS/GENIE_Mask/[0]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0]
	trial_seed: 2
	unique_name: 250131_00-57-26_GENIE_Mask0
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: sgd
	freeze_bn: False
	pretrained: True
	lr: 2.716671579524612e-05
	batch_size: 29
	weight_decay: 1.71368232883332e-06
	momentum: 0.9092933546128503
	convergence_rate: 0.02426611940613899
	moving_avg: 0.947722940872739
	p: 0.5933807106679234
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[PACS] #envs=4, #classes=7
	env0: A (#2048)
	env1: C (#2344)
	env2: P (#1670)
	env3: S (#3929)

[37m[36mINFO[0m[0m 01/31 00:57:26 | n_steps = 5001
[37m[36mINFO[0m[0m 01/31 00:57:26 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 01/31 00:57:26 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 01/31 00:57:26 | Target test envs = [[0]]
[37m[36mINFO[0m[0m 01/31 00:57:26 | 
[37m[36mINFO[0m[0m 01/31 00:57:26 | Testenv name escaping te_A -> te_A
[37m[36mINFO[0m[0m 01/31 00:57:26 | Test envs = [0], name = te_A
[37m[36mINFO[0m[0m 01/31 00:57:26 | Batch sizes for each domain: [0, 29, 29, 29] (total=87)
[37m[36mINFO[0m[0m 01/31 00:57:26 | steps-per-epoch for each domain: 64.69, 46.07, 108.41 -> min = 46.07
[37m[36mINFO[0m[0m 01/31 00:57:27 | # of params = 23522375
[37m[36mINFO[0m[0m 01/31 00:58:09 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 01/31 00:58:09 | 0.212325    0.215159    0.198771    0.204327    1.876258    0.212325    0.215159    0.230810    0.247863    0.167665    0.167665    0.197837    0.197452    0           0.000000    1.997630    2.084028    39.775743  
[37m[36mINFO[0m[0m 01/31 00:59:30 | 0.798658    0.819071    0.962850    0.953450    0.132359    0.798658    0.819071    0.953625    0.955128    0.990269    0.988024    0.944656    0.917197    200         4.341317    0.313571    0.248170    30.719208  
[37m[36mINFO[0m[0m 01/31 01:01:03 | 0.861501    0.865526    0.976881    0.961385    0.109554    0.861501    0.865526    0.970682    0.965812    0.991766    0.982036    0.968193    0.936306    400         8.682635    0.104850    0.215989    50.170082  
[37m[36mINFO[0m[0m 01/31 01:02:31 | 0.813301    0.811736    0.981747    0.953714    0.138475    0.813301    0.811736    0.986141    0.952991    0.990269    0.982036    0.968830    0.926115    600         13.023952   0.059272    0.282882    30.938877  
[37m[36mINFO[0m[0m 01/31 01:03:49 | 0.837096    0.838631    0.976879    0.952716    0.155798    0.837096    0.838631    0.960554    0.952991    0.997754    0.979042    0.972328    0.926115    800         17.365269   0.037572    0.226735    32.641708  
[37m[36mINFO[0m[0m 01/31 01:05:32 | 0.852349    0.841076    0.990861    0.967075    0.130566    0.852349    0.841076    0.990938    0.965812    0.998503    0.994012    0.983142    0.941401    1000        21.706587   0.027172    0.341742    34.527465  
[37m[36mINFO[0m[0m 01/31 01:06:52 | 0.882245    0.885086    0.992417    0.970210    0.101328    0.882245    0.885086    0.990405    0.972222    0.999251    0.997006    0.987595    0.941401    1200        26.047904   0.025793    0.238016    31.600973  
[37m[36mINFO[0m[0m 01/31 01:08:27 | 0.884686    0.865526    0.992781    0.972898    0.111009    0.884686    0.865526    0.998401    0.978632    0.997754    0.991018    0.982188    0.949045    1400        30.389222   0.024509    0.230670    48.944461  
[37m[36mINFO[0m[0m 01/31 01:09:57 | 0.829774    0.823961    0.991902    0.968343    0.111504    0.829774    0.823961    0.992004    0.976496    0.991018    0.982036    0.992684    0.946497    1600        34.730539   0.021214    0.285338    31.859365  
[37m[36mINFO[0m[0m 01/31 01:11:17 | 0.849298    0.855746    0.996991    0.978581    0.093898    0.849298    0.855746    0.999467    0.985043    0.998503    0.994012    0.993003    0.956688    1800        39.071856   0.013204    0.209665    37.921031  
[37m[36mINFO[0m[0m 01/31 01:13:06 | 0.865162    0.860636    0.995635    0.969051    0.096270    0.865162    0.860636    0.993603    0.970085    0.997754    0.988024    0.995547    0.949045    2000        43.413174   0.015355    0.377739    32.660001  
[37m[36mINFO[0m[0m 01/31 01:14:21 | 0.893228    0.882641    0.997128    0.972035    0.109389    0.893228    0.882641    0.998401    0.972222    0.997754    0.991018    0.995229    0.952866    2200        47.754491   0.010343    0.210817    33.020436  
[37m[36mINFO[0m[0m 01/31 01:16:25 | 0.871873    0.875306    0.998937    0.975470    0.087425    0.871873    0.875306    0.998401    0.982906    1.000000    0.997006    0.998410    0.946497    2400        52.095808   0.017729    0.359043    52.164188  
[37m[36mINFO[0m[0m 01/31 01:17:39 | 0.876144    0.860636    0.995357    0.969478    0.139377    0.876144    0.860636    0.996269    0.974359    0.997754    0.985030    0.992048    0.949045    2600        56.437126   0.008672    0.211005    31.695791  
[37m[36mINFO[0m[0m 01/31 01:19:13 | 0.871263    0.860636    0.995822    0.970912    0.123911    0.871263    0.860636    0.996802    0.976496    0.999251    0.991018    0.991412    0.945223    2800        60.778443   0.010702    0.277485    38.641393  
[37m[36mINFO[0m[0m 01/31 01:20:40 | 0.870653    0.872861    0.997128    0.968775    0.103924    0.870653    0.872861    0.998401    0.970085    0.997754    0.991018    0.995229    0.945223    3000        65.119760   0.010260    0.279371    31.701431  
[37m[36mINFO[0m[0m 01/31 01:21:59 | 0.852349    0.853301    0.998619    0.975595    0.086227    0.852349    0.853301    0.999467    0.978632    0.999251    0.994012    0.997137    0.954140    3200        69.461078   0.012306    0.231377    31.974779  
[37m[36mINFO[0m[0m 01/31 01:23:53 | 0.854790    0.865526    0.999111    0.969762    0.129351    0.854790    0.865526    0.998401    0.967949    0.999251    0.991018    0.999682    0.950318    3400        73.802395   0.004839    0.359624    42.285362  
[37m[36mINFO[0m[0m 01/31 01:25:12 | 0.859060    0.863081    0.999077    0.976456    0.107450    0.859060    0.863081    0.998934    0.980769    0.999251    0.997006    0.999046    0.951592    3600        78.143713   0.005379    0.233532    32.236876  
[37m[36mINFO[0m[0m 01/31 01:26:45 | 0.840146    0.848411    0.998581    0.973599    0.106806    0.840146    0.848411    0.999467    0.978632    0.998503    0.988024    0.997774    0.954140    3800        82.485030   0.009272    0.259188    41.274602  
[37m[36mINFO[0m[0m 01/31 01:28:01 | 0.873093    0.865526    0.998687    0.973035    0.100967    0.873093    0.865526    0.997335    0.976496    1.000000    0.991018    0.998728    0.951592    4000        86.826347   0.007958    0.222482    31.284344  
[37m[36mINFO[0m[0m 01/31 01:29:24 | 0.865162    0.860636    0.999538    0.974736    0.102397    0.865162    0.860636    1.000000    0.980769    0.999251    0.988024    0.999364    0.955414    4200        91.167665   0.009639    0.249740    32.928640  
[37m[36mINFO[0m[0m 01/31 01:31:15 | 0.882245    0.892421    0.997908    0.973757    0.107218    0.882245    0.892421    0.997335    0.976496    0.999251    0.997006    0.997137    0.947771    4400        95.508982   0.004916    0.333672    44.233141  
[37m[36mINFO[0m[0m 01/31 01:32:34 | 0.866382    0.860636    0.998195    0.974333    0.126148    0.866382    0.860636    0.999467    0.980769    0.999251    0.997006    0.995865    0.945223    4600        99.850299   0.005242    0.235869    31.851618  
[37m[36mINFO[0m[0m 01/31 01:34:06 | 0.846248    0.843521    0.999682    0.980704    0.097740    0.846248    0.843521    1.000000    0.985043    1.000000    0.994012    0.999046    0.963057    4800        104.191617  0.004654    0.264729    39.782109  
[37m[36mINFO[0m[0m 01/31 01:35:31 | 0.881635    0.877751    0.997908    0.976182    0.092318    0.881635    0.877751    0.997335    0.985043    0.999251    0.997006    0.997137    0.946497    5000        108.532934  0.002043    0.255775    33.607226  
[37m[36mINFO[0m[0m 01/31 01:35:32 | Cumulative gradient change saved at train_output/PACS/GENIE_Mask/[0]/250131_00-57-26_GENIE_Mask0/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 01/31 01:35:33 | ---
[37m[36mINFO[0m[0m 01/31 01:35:33 | test-domain validation(oracle) = 88.225%
[37m[36mINFO[0m[0m 01/31 01:35:33 | training-domain validation(iid) = 84.625%
[37m[36mINFO[0m[0m 01/31 01:35:33 | last = 88.164%
[37m[36mINFO[0m[0m 01/31 01:35:33 | last (inD) = 97.618%
[37m[36mINFO[0m[0m 01/31 01:35:33 | training-domain validation (iid, inD) = 98.070%
[37m[36mINFO[0m[0m 01/31 01:35:33 | === Summary ===
[37m[36mINFO[0m[0m 01/31 01:35:33 | Command: /jsm0707/DomainBed/Large-scale/train_all.py GENIE_Mask0 config/resnet50_sgd.yaml --trial_seed 2 --hparams_seed 9 --algorithm GENIE_Mask --test_envs 0 --dataset PACS
[37m[36mINFO[0m[0m 01/31 01:35:33 | Unique name: 250131_00-57-26_GENIE_Mask0
[37m[36mINFO[0m[0m 01/31 01:35:33 | Out path: train_output/PACS/GENIE_Mask/[0]/250131_00-57-26_GENIE_Mask0
[37m[36mINFO[0m[0m 01/31 01:35:33 | Algorithm: GENIE_Mask
[37m[36mINFO[0m[0m 01/31 01:35:33 | Dataset: PACS
[37m[36mINFO[0m[0m 01/31 01:35:33 | Max test_in: 0.8932
