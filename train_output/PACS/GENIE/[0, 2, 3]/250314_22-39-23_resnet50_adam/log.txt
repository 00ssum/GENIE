[37m[36mINFO[0m[0m 03/14 22:39:23 | Command :: /jsm0707/GENIE/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm GENIE --test_envs 0 2 3 --dataset PACS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: GENIE
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_adam.yaml']
	data_dir: data
	dataset: PACS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_adam
	out_dir: train_output/PACS/GENIE/[0, 2, 3]/250314_22-39-23_resnet50_adam
	out_root: train_output/PACS/GENIE/[0, 2, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 2, 3]
	trial_seed: 0
	unique_name: 250314_22-39-23_resnet50_adam
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: adam
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	momentum: 0.9
	convergence_rate: 0.015
	moving_avg: 0.95
	p: 0.4
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[PACS] #envs=4, #classes=7
	env0: A (#2048)
	env1: C (#2344)
	env2: P (#1670)
	env3: S (#3929)

[37m[36mINFO[0m[0m 03/14 22:39:23 | n_steps = 5001
[37m[36mINFO[0m[0m 03/14 22:39:23 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/14 22:39:23 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/14 22:39:23 | 
[37m[36mINFO[0m[0m 03/14 22:39:23 | Testenv name escaping te_A_P_S -> te_A_P_S
[37m[36mINFO[0m[0m 03/14 22:39:23 | Test envs = [0, 2, 3], name = te_A_P_S
[37m[36mINFO[0m[0m 03/14 22:39:23 | Train environments: [1], Test environments: [0, 2, 3]
[37m[36mINFO[0m[0m 03/14 22:39:23 | Batch sizes for each domain: [0, 32, 0, 0] (total=32)
[37m[36mINFO[0m[0m 03/14 22:39:23 | steps-per-epoch for each domain: 58.62 -> min = 58.62
[37m[36mINFO[0m[0m 03/14 22:39:24 | # of params = 23522375
[37m[36mINFO[0m[0m 03/14 22:39:49 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/14 22:39:49 | 0.147939    0.146595    0.201493    0.168803    1.900370    0.143380    0.141809    0.201493    0.168803    0.096557    0.101796    0.203880    0.196178    0           0.000000    2.070246    0.961860    23.054341  
[37m[36mINFO[0m[0m 03/14 22:41:08 | 0.712810    0.698843    0.942431    0.946581    0.172478    0.727273    0.701711    0.942431    0.946581    0.825599    0.811377    0.585560    0.583439    200         3.411514    0.421262    0.286104    22.239378  
[37m[36mINFO[0m[0m 03/14 22:42:17 | 0.789896    0.792894    0.986141    0.959402    0.142798    0.793777    0.775061    0.986141    0.959402    0.912425    0.913174    0.663486    0.690446    400         6.823028    0.097915    0.225051    23.950575  
[37m[36mINFO[0m[0m 03/14 22:43:11 | 0.747630    0.739802    0.970149    0.944444    0.183290    0.726052    0.753056    0.970149    0.944444    0.860030    0.838323    0.656807    0.628025    600         10.234542   0.061793    0.146658    25.185505  
[37m[36mINFO[0m[0m 03/14 22:44:23 | 0.813821    0.814276    0.992537    0.972222    0.116078    0.791946    0.794621    0.992537    0.972222    0.915419    0.913174    0.734097    0.735032    800         13.646055   0.042914    0.242302    22.618324  
[37m[36mINFO[0m[0m 03/14 22:45:43 | 0.757759    0.763916    0.988273    0.961538    0.206223    0.723002    0.738386    0.988273    0.961538    0.889970    0.892216    0.660305    0.661146    1000        17.057569   0.039059    0.290293    22.683809  
[37m[36mINFO[0m[0m 03/14 22:46:34 | 0.706068    0.710995    0.973348    0.955128    0.150642    0.701037    0.716381    0.973348    0.955128    0.846557    0.829341    0.570611    0.587261    1200        20.469083   0.039461    0.139346    22.410777  
[37m[36mINFO[0m[0m 03/14 22:47:59 | 0.803526    0.798743    0.998401    0.980769    0.123481    0.775473    0.772616    0.998401    0.980769    0.878743    0.859281    0.756361    0.764331    1400        23.880597   0.029406    0.314334    22.417452  
[37m[36mINFO[0m[0m 03/14 22:49:15 | 0.773085    0.777847    0.995736    0.972222    0.143226    0.734594    0.713936    0.995736    0.972222    0.869012    0.892216    0.715649    0.727389    1600        27.292111   0.012336    0.271229    22.327660  
[37m[36mINFO[0m[0m 03/14 22:50:06 | 0.770035    0.763025    0.997868    0.976496    0.144642    0.736425    0.726161    0.997868    0.976496    0.874251    0.862275    0.699427    0.700637    1800        30.703625   0.018213    0.140284    22.391762  
[37m[36mINFO[0m[0m 03/14 22:51:21 | 0.811339    0.821380    0.998934    0.978632    0.135348    0.773032    0.792176    0.998934    0.978632    0.904940    0.910180    0.756043    0.761783    2000        34.115139   0.006705    0.259264    23.348367  
[37m[36mINFO[0m[0m 03/14 22:52:49 | 0.773272    0.773017    0.992004    0.961538    0.141496    0.728493    0.723716    0.992004    0.961538    0.879491    0.883234    0.711832    0.712102    2200        37.526652   0.010789    0.319096    23.911026  
[37m[36mINFO[0m[0m 03/14 22:54:07 | 0.801087    0.804727    0.996802    0.961538    0.238922    0.760220    0.777506    0.996802    0.961538    0.901946    0.904192    0.741094    0.732484    2400        40.938166   0.003380    0.275216    22.746722  
[37m[36mINFO[0m[0m 03/14 22:55:03 | 0.790876    0.781145    0.997868    0.963675    0.133913    0.769982    0.760391    0.997868    0.963675    0.901946    0.886228    0.700700    0.696815    2600        44.349680   0.010364    0.163914    23.116321  
[37m[36mINFO[0m[0m 03/14 22:56:16 | 0.770345    0.771699    0.998401    0.965812    0.151156    0.715070    0.735941    0.998401    0.965812    0.889222    0.877246    0.706743    0.701911    2800        47.761194   0.003670    0.246247    23.769291  
[37m[36mINFO[0m[0m 03/14 22:57:40 | 0.730973    0.732176    0.993603    0.961538    0.152958    0.671141    0.682152    0.993603    0.961538    0.867515    0.844311    0.654262    0.670064    3000        51.172708   0.019723    0.309547    22.712864  
[37m[36mINFO[0m[0m 03/14 22:58:59 | 0.794041    0.803223    0.997868    0.967949    0.158038    0.739475    0.753056    0.997868    0.967949    0.905689    0.901198    0.736959    0.755414    3200        54.584222   0.012340    0.280196    22.713954  
[37m[36mINFO[0m[0m 03/14 22:59:52 | 0.767741    0.783898    0.998401    0.970085    0.178897    0.720561    0.745721    0.998401    0.970085    0.883234    0.886228    0.699427    0.719745    3400        57.995736   0.003060    0.154639    21.681969  
[37m[36mINFO[0m[0m 03/14 23:01:09 | 0.746737    0.742999    0.996802    0.970085    0.158757    0.693106    0.687042    0.996802    0.970085    0.841317    0.841317    0.705789    0.700637    3600        61.407249   0.007027    0.265017    24.131588  
[37m[36mINFO[0m[0m 03/14 23:02:35 | 0.772951    0.772851    0.997868    0.967949    0.124774    0.740085    0.750611    0.997868    0.967949    0.861527    0.853293    0.717239    0.714650    3800        64.818763   0.007950    0.317943    23.023014  
[37m[36mINFO[0m[0m 03/14 23:03:57 | 0.814063    0.805360    1.000000    0.970085    0.124908    0.777913    0.770171    1.000000    0.970085    0.905689    0.889222    0.758588    0.756688    4000        68.230277   0.005427    0.293607    22.986844  
[37m[36mINFO[0m[0m 03/14 23:04:54 | 0.805788    0.794560    0.999467    0.978632    0.122058    0.762050    0.753056    0.999467    0.978632    0.898952    0.889222    0.756361    0.741401    4200        71.641791   0.000606    0.168529    23.627473  
[37m[36mINFO[0m[0m 03/14 23:06:03 | 0.815045    0.806645    1.000000    0.980769    0.118842    0.755339    0.748166    1.000000    0.980769    0.901946    0.883234    0.787850    0.788535    4400        75.053305   0.001826    0.222849    23.717168  
[37m[36mINFO[0m[0m 03/14 23:07:27 | 0.810188    0.803086    1.000000    0.978632    0.129595    0.759610    0.762836    1.000000    0.978632    0.905689    0.901198    0.765267    0.745223    4600        78.464819   0.001453    0.305399    23.020051  
[37m[36mINFO[0m[0m 03/14 23:08:42 | 0.812932    0.799311    0.999467    0.980769    0.135348    0.767541    0.757946    0.999467    0.980769    0.903443    0.892216    0.767812    0.747771    4800        81.876333   0.000732    0.263889    22.836660  
[37m[36mINFO[0m[0m 03/14 23:09:36 | 0.799898    0.805848    1.000000    0.970085    0.161352    0.766931    0.801956    1.000000    0.970085    0.865269    0.865269    0.767494    0.750318    5000        85.287846   0.005818    0.147296    24.188346  
[37m[36mINFO[0m[0m 03/14 23:09:36 | Cumulative gradient change saved at train_output/PACS/GENIE/[0, 2, 3]/250314_22-39-23_resnet50_adam/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/14 23:09:37 | ---
[37m[36mINFO[0m[0m 03/14 23:09:37 | test-domain validation(oracle) = 81.134%
[37m[36mINFO[0m[0m 03/14 23:09:37 | training-domain validation(iid) = 80.353%
[37m[36mINFO[0m[0m 03/14 23:09:37 | last = 79.990%
[37m[36mINFO[0m[0m 03/14 23:09:37 | last (inD) = 97.009%
[37m[36mINFO[0m[0m 03/14 23:09:37 | training-domain validation (iid, inD) = 98.077%
[37m[36mINFO[0m[0m 03/14 23:09:38 | === Summary ===
[37m[36mINFO[0m[0m 03/14 23:09:38 | Command: /jsm0707/GENIE/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm GENIE --test_envs 0 2 3 --dataset PACS
[37m[36mINFO[0m[0m 03/14 23:09:38 | Unique name: 250314_22-39-23_resnet50_adam
[37m[36mINFO[0m[0m 03/14 23:09:38 | Out path: train_output/PACS/GENIE/[0, 2, 3]/250314_22-39-23_resnet50_adam
[37m[36mINFO[0m[0m 03/14 23:09:38 | Algorithm: GENIE
[37m[36mINFO[0m[0m 03/14 23:09:38 | Dataset: PACS
