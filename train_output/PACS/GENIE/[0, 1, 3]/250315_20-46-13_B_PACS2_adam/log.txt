[37m[36mINFO[0m[0m 03/15 20:46:13 | Command :: /jsm0707/GENIE/train_all.py B_PACS2_adam config/resnet50_adam.yaml --trial_seed 0 --hparams_seed 5 --algorithm GENIE --test_envs 0 1 3 --dataset PACS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: GENIE
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_adam.yaml']
	data_dir: data
	dataset: PACS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 5
	in_domain: False
	model_save: None
	mpa: False
	name: B_PACS2_adam
	out_dir: train_output/PACS/GENIE/[0, 1, 3]/250315_20-46-13_B_PACS2_adam
	out_root: train_output/PACS/GENIE/[0, 1, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 1, 3]
	trial_seed: 0
	unique_name: 250315_20-46-13_B_PACS2_adam
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: adam
	freeze_bn: False
	pretrained: True
	lr: 1.6343540304927548e-05
	batch_size: 23
	weight_decay: 3.844578840738432e-05
	momentum: 0.8831874982931204
	convergence_rate: 0.038025503673057105
	moving_avg: 0.9556218694240625
	p: 0.22529679702233638
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[PACS] #envs=4, #classes=7
	env0: A (#2048)
	env1: C (#2344)
	env2: P (#1670)
	env3: S (#3929)

[37m[36mINFO[0m[0m 03/15 20:46:13 | n_steps = 5001
[37m[36mINFO[0m[0m 03/15 20:46:13 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/15 20:46:13 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/15 20:46:13 | 
[37m[36mINFO[0m[0m 03/15 20:46:13 | Testenv name escaping te_A_C_S -> te_A_C_S
[37m[36mINFO[0m[0m 03/15 20:46:13 | Test envs = [0, 1, 3], name = te_A_C_S
[37m[36mINFO[0m[0m 03/15 20:46:13 | Train environments: [2], Test environments: [0, 1, 3]
[37m[36mINFO[0m[0m 03/15 20:46:13 | Batch sizes for each domain: [0, 0, 23, 0] (total=23)
[37m[36mINFO[0m[0m 03/15 20:46:13 | steps-per-epoch for each domain: 58.09 -> min = 58.09
[37m[36mINFO[0m[0m 03/15 20:46:14 | # of params = 23522375
[37m[36mINFO[0m[0m 03/15 20:46:39 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/15 20:46:39 | 0.194858    0.183654    0.404192    0.410180    2.098591    0.322758    0.308068    0.220149    0.200855    0.404192    0.410180    0.041667    0.042038    0           0.000000    2.040825    0.865197    24.205714  
[37m[36mINFO[0m[0m 03/15 20:47:28 | 0.481725    0.488381    0.961078    0.925150    0.235120    0.525320    0.528117    0.481876    0.446581    0.961078    0.925150    0.437977    0.490446    200         3.443114    0.290093    0.128215    23.344780  
[37m[36mINFO[0m[0m 03/15 20:48:14 | 0.273165    0.287434    0.957335    0.934132    0.207518    0.456986    0.511002    0.176439    0.153846    0.957335    0.934132    0.186069    0.197452    400         6.886228    0.162815    0.117967    22.884281  
[37m[36mINFO[0m[0m 03/15 20:49:01 | 0.462829    0.459426    0.976048    0.940120    0.160573    0.562538    0.577017    0.372068    0.331197    0.976048    0.940120    0.453880    0.470064    600         10.329341   0.111938    0.111774    24.716628  
[37m[36mINFO[0m[0m 03/15 20:49:48 | 0.359728    0.369625    0.958084    0.934132    0.227020    0.596095    0.635697    0.240405    0.222222    0.958084    0.934132    0.242684    0.250955    800         13.772455   0.092461    0.116535    23.816962  
[37m[36mINFO[0m[0m 03/15 20:50:33 | 0.422399    0.431742    0.993263    0.937126    0.199923    0.568029    0.586797    0.356610    0.356838    0.993263    0.937126    0.342557    0.351592    1000        17.215569   0.051759    0.111664    21.998507  
[37m[36mINFO[0m[0m 03/15 20:51:20 | 0.436127    0.442468    0.987275    0.940120    0.178699    0.547895    0.567237    0.363539    0.346154    0.987275    0.940120    0.396947    0.414013    1200        20.658683   0.074092    0.113574    24.822207  
[37m[36mINFO[0m[0m 03/15 20:52:08 | 0.496964    0.495114    0.988772    0.943114    0.163945    0.626602    0.618582    0.441898    0.414530    0.988772    0.943114    0.422392    0.452229    1400        24.101796   0.041563    0.115829    24.127412  
[37m[36mINFO[0m[0m 03/15 20:52:54 | 0.532551    0.532563    0.997754    0.967066    0.161361    0.654667    0.647922    0.465885    0.446581    0.997754    0.967066    0.477099    0.503185    1600        27.544910   0.018339    0.116197    22.877565  
[37m[36mINFO[0m[0m 03/15 20:53:41 | 0.461798    0.467547    0.999251    0.976048    0.115511    0.660769    0.660147    0.377932    0.371795    0.999251    0.976048    0.346692    0.370701    1800        30.988024   0.008960    0.115117    23.935256  
[37m[36mINFO[0m[0m 03/15 20:54:26 | 0.388969    0.387774    0.994760    0.955090    0.180076    0.610738    0.601467    0.303305    0.277778    0.994760    0.955090    0.252863    0.284076    2000        34.431138   0.008596    0.113662    22.390866  
[37m[36mINFO[0m[0m 03/15 20:55:13 | 0.439016    0.452139    0.994012    0.946108    0.216827    0.533862    0.542787    0.346482    0.339744    0.994012    0.946108    0.436705    0.473885    2200        37.874251   0.033378    0.117003    23.451974  
