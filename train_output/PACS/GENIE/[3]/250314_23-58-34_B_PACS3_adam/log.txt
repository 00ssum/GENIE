[37m[36mINFO[0m[0m 03/14 23:58:34 | Command :: /jsm0707/GENIE/train_all.py B_PACS3_adam config/resnet50_adam.yaml --trial_seed 0 --hparams_seed 18 --algorithm GENIE --test_envs 3 --dataset PACS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: GENIE
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_adam.yaml']
	data_dir: data
	dataset: PACS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 18
	in_domain: False
	model_save: None
	mpa: False
	name: B_PACS3_adam
	out_dir: train_output/PACS/GENIE/[3]/250314_23-58-34_B_PACS3_adam
	out_root: train_output/PACS/GENIE/[3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [3]
	trial_seed: 0
	unique_name: 250314_23-58-34_B_PACS3_adam
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.1
	class_balanced: False
	optimizer: adam
	freeze_bn: False
	pretrained: True
	lr: 0.00021894640154701087
	batch_size: 13
	weight_decay: 7.1565884139944e-05
	momentum: 0.8683802947171396
	convergence_rate: 0.012803366168469622
	moving_avg: 0.9263892108829195
	p: 0.24651630496904078
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[PACS] #envs=4, #classes=7
	env0: A (#2048)
	env1: C (#2344)
	env2: P (#1670)
	env3: S (#3929)

[37m[36mINFO[0m[0m 03/14 23:58:34 | n_steps = 5001
[37m[36mINFO[0m[0m 03/14 23:58:34 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/14 23:58:34 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/14 23:58:34 | 
[37m[36mINFO[0m[0m 03/14 23:58:34 | Testenv name escaping te_S -> te_S
[37m[36mINFO[0m[0m 03/14 23:58:34 | Test envs = [3], name = te_S
[37m[36mINFO[0m[0m 03/14 23:58:34 | Train environments: [0, 1, 2], Test environments: [3]
[37m[36mINFO[0m[0m 03/14 23:58:34 | Batch sizes for each domain: [13, 13, 13, 0] (total=39)
[37m[36mINFO[0m[0m 03/14 23:58:34 | steps-per-epoch for each domain: 126.08, 144.31, 102.77 -> min = 102.77
[37m[36mINFO[0m[0m 03/14 23:58:35 | # of params = 23522375
[37m[36mINFO[0m[0m 03/14 23:59:07 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/14 23:59:07 | 0.198791    0.200000    0.215060    0.204316    1.934378    0.222697    0.202934    0.212154    0.194444    0.210329    0.215569    0.198791    0.200000    0           0.000000    2.002535    1.441103    30.464207  
[37m[36mINFO[0m[0m 03/15 00:00:18 | 0.543893    0.554140    0.893194    0.889844    0.314652    0.889567    0.887531    0.849147    0.841880    0.940868    0.940120    0.543893    0.554140    200         1.946108    0.409173    0.197717    31.213098  
[37m[36mINFO[0m[0m 03/15 00:01:33 | 0.754135    0.737580    0.942552    0.938417    0.207732    0.916412    0.914425    0.930704    0.933761    0.980539    0.967066    0.754135    0.737580    400         3.892216    0.170566    0.214235    32.400331  
[37m[36mINFO[0m[0m 03/15 00:02:47 | 0.725827    0.743949    0.975595    0.958070    0.126980    0.965833    0.941320    0.970682    0.950855    0.990269    0.982036    0.725827    0.743949    600         5.838323    0.112080    0.203775    32.940698  
[37m[36mINFO[0m[0m 03/15 00:03:55 | 0.742048    0.756688    0.977618    0.958291    0.158059    0.968273    0.936430    0.972814    0.959402    0.991766    0.979042    0.742048    0.756688    800         7.784431    0.091183    0.179489    31.682600  
[37m[36mINFO[0m[0m 03/15 00:04:56 | 0.573473    0.574522    0.964664    0.947822    0.221419    0.934106    0.914425    0.969616    0.952991    0.990269    0.976048    0.573473    0.574522    1000        9.730539    0.069006    0.154670    30.536522  
[37m[36mINFO[0m[0m 03/15 00:05:54 | 0.675573    0.684076    0.979410    0.952654    0.138662    0.965223    0.941320    0.979744    0.946581    0.993263    0.970060    0.675573    0.684076    1200        11.676647   0.062727    0.132981    31.026497  
[37m[36mINFO[0m[0m 03/15 00:06:52 | 0.727735    0.728662    0.974213    0.941860    0.181900    0.961562    0.921760    0.964819    0.933761    0.996257    0.970060    0.727735    0.728662    1400        13.622754   0.048216    0.135395    31.150085  
[37m[36mINFO[0m[0m 03/15 00:07:52 | 0.763359    0.773248    0.988072    0.965280    0.145771    0.979256    0.953545    0.987207    0.957265    0.997754    0.985030    0.763359    0.773248    1600        15.568862   0.037112    0.139091    32.146863  
[37m[36mINFO[0m[0m 03/15 00:08:53 | 0.746819    0.756688    0.990601    0.971001    0.112413    0.985357    0.960880    0.990938    0.970085    0.995509    0.982036    0.746819    0.756688    1800        17.514970   0.047677    0.143735    31.872572  
[37m[36mINFO[0m[0m 03/15 00:10:06 | 0.805344    0.806369    0.990456    0.961225    0.126011    0.983527    0.931540    0.989339    0.955128    0.998503    0.997006    0.805344    0.806369    2000        19.461078   0.037358    0.212220    30.661529  
[37m[36mINFO[0m[0m 03/15 00:11:09 | 0.784351    0.794904    0.992312    0.965280    0.116255    0.989628    0.953545    0.988806    0.957265    0.998503    0.985030    0.784351    0.794904    2200        21.407186   0.030203    0.131698    36.666384  
[37m[36mINFO[0m[0m 03/15 00:12:16 | 0.741412    0.740127    0.993971    0.963711    0.132973    0.990238    0.953545    0.994670    0.961538    0.997006    0.976048    0.741412    0.740127    2400        23.353293   0.033915    0.161133    34.600500  
[37m[36mINFO[0m[0m 03/15 00:13:15 | 0.705471    0.689172    0.977236    0.946625    0.184055    0.974375    0.926650    0.964819    0.940171    0.992515    0.973054    0.705471    0.689172    2600        25.299401   0.029885    0.143037    30.702715  
[37m[36mINFO[0m[0m 03/15 00:14:16 | 0.758588    0.756688    0.994048    0.964724    0.137606    0.992068    0.943765    0.993070    0.974359    0.997006    0.976048    0.758588    0.756688    2800        27.245509   0.019310    0.153515    30.702768  
[37m[36mINFO[0m[0m 03/15 00:15:28 | 0.786260    0.793631    0.997109    0.975522    0.100736    0.996339    0.963325    0.995736    0.972222    0.999251    0.991018    0.786260    0.793631    3000        29.191617   0.023685    0.198231    31.878789  
[37m[36mINFO[0m[0m 03/15 00:16:25 | 0.761450    0.780892    0.982685    0.948396    0.215313    0.967053    0.931540    0.987740    0.946581    0.993263    0.967066    0.761450    0.780892    3200        31.137725   0.018189    0.128863    30.945431  
[37m[36mINFO[0m[0m 03/15 00:17:28 | 0.717875    0.731210    0.986256    0.952163    0.252389    0.983527    0.936430    0.983475    0.952991    0.991766    0.967066    0.717875    0.731210    3400        33.083832   0.027485    0.148856    34.199899  
[37m[36mINFO[0m[0m 03/15 00:18:28 | 0.742366    0.769427    0.994568    0.965524    0.130186    0.990848    0.955990    0.993603    0.961538    0.999251    0.979042    0.742366    0.769427    3600        35.029940   0.017225    0.137747    32.259606  
[37m[36mINFO[0m[0m 03/15 00:19:28 | 0.750954    0.746497    0.998739    0.974055    0.121308    0.998780    0.965770    0.998934    0.974359    0.998503    0.982036    0.750954    0.746497    3800        36.976048   0.013558    0.145137    31.100567  
[37m[36mINFO[0m[0m 03/15 00:20:39 | 0.798664    0.798726    0.998049    0.967256    0.147282    0.997559    0.963325    0.997335    0.959402    0.999251    0.979042    0.798664    0.798726    4000        38.922156   0.010847    0.196097    31.051282  
[37m[36mINFO[0m[0m 03/15 00:21:37 | 0.779580    0.771975    0.996702    0.963528    0.138376    0.995119    0.955990    0.995736    0.961538    0.999251    0.973054    0.779580    0.771975    4200        40.868263   0.024675    0.137886    30.935505  
[37m[36mINFO[0m[0m 03/15 00:22:40 | 0.772901    0.771975    0.997485    0.965158    0.132769    0.995119    0.960880    0.997335    0.961538    1.000000    0.973054    0.772901    0.771975    4400        42.814371   0.010169    0.140538    34.409258  
[37m[36mINFO[0m[0m 03/15 00:23:43 | 0.752226    0.749045    0.994819    0.972512    0.134374    0.995119    0.973105    0.989339    0.959402    1.000000    0.985030    0.752226    0.749045    4600        44.760479   0.007971    0.140398    34.741414  
[37m[36mINFO[0m[0m 03/15 00:24:44 | 0.786578    0.771975    0.996960    0.960676    0.137521    0.994509    0.938875    0.997868    0.955128    0.998503    0.988024    0.786578    0.771975    4800        46.706587   0.032624    0.141469    32.763060  
[37m[36mINFO[0m[0m 03/15 00:25:57 | 0.816158    0.815287    0.999619    0.979208    0.101639    0.999390    0.973105    0.999467    0.976496    1.000000    0.988024    0.816158    0.815287    5000        48.652695   0.002304    0.198664    33.889648  
[37m[36mINFO[0m[0m 03/15 00:25:57 | Cumulative gradient change saved at train_output/PACS/GENIE/[3]/250314_23-58-34_B_PACS3_adam/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/15 00:25:59 | ---
[37m[36mINFO[0m[0m 03/15 00:25:59 | test-domain validation(oracle) = 81.616%
[37m[36mINFO[0m[0m 03/15 00:25:59 | training-domain validation(iid) = 81.616%
[37m[36mINFO[0m[0m 03/15 00:25:59 | last = 81.616%
[37m[36mINFO[0m[0m 03/15 00:25:59 | last (inD) = 97.921%
[37m[36mINFO[0m[0m 03/15 00:25:59 | training-domain validation (iid, inD) = 97.921%
[37m[36mINFO[0m[0m 03/15 00:25:59 | === Summary ===
[37m[36mINFO[0m[0m 03/15 00:25:59 | Command: /jsm0707/GENIE/train_all.py B_PACS3_adam config/resnet50_adam.yaml --trial_seed 0 --hparams_seed 18 --algorithm GENIE --test_envs 3 --dataset PACS
[37m[36mINFO[0m[0m 03/15 00:25:59 | Unique name: 250314_23-58-34_B_PACS3_adam
[37m[36mINFO[0m[0m 03/15 00:25:59 | Out path: train_output/PACS/GENIE/[3]/250314_23-58-34_B_PACS3_adam
[37m[36mINFO[0m[0m 03/15 00:25:59 | Algorithm: GENIE
[37m[36mINFO[0m[0m 03/15 00:25:59 | Dataset: PACS
