[37m[36mINFO[0m[0m 03/30 00:59:20 | Command :: /jsm0707/GENIE/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm GENIE --test_envs 3 --dataset PACS --trial_seed 0 --hparams_seed 18
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.22.4
	PIL: 9.4.0
Args:
	algorithm: GENIE
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_sgd.yaml']
	data_dir: data
	dataset: PACS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 18
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_sgd
	out_dir: train_output/PACS/GENIE/[3]/250330_00-59-20_resnet50_sgd
	out_root: train_output/PACS/GENIE/[3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [3]
	trial_seed: 0
	unique_name: 250330_00-59-20_resnet50_sgd
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.1
	class_balanced: False
	optimizer: sgd
	freeze_bn: False
	pretrained: True
	lr: 0.00021894640154701087
	batch_size: 13
	weight_decay: 7.1565884139944e-05
	momentum: 0.8683802947171396
	convergence_rate: 0.012803366168469622
	moving_avg: 0.9263892108829195
	p: 0.24651630496904078
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[PACS] #envs=4, #classes=7
	env0: A (#2048)
	env1: C (#2344)
	env2: P (#1670)
	env3: S (#3929)

[37m[36mINFO[0m[0m 03/30 00:59:20 | n_steps = 5001
[37m[36mINFO[0m[0m 03/30 00:59:20 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/30 00:59:20 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/30 00:59:20 | 
[37m[36mINFO[0m[0m 03/30 00:59:20 | Testenv name escaping te_S -> te_S
[37m[36mINFO[0m[0m 03/30 00:59:20 | Test envs = [3], name = te_S
[37m[36mINFO[0m[0m 03/30 00:59:20 | Train environments: [0, 1, 2], Test environments: [3]
[37m[36mINFO[0m[0m 03/30 00:59:20 | Batch sizes for each domain: [13, 13, 13, 0] (total=39)
[37m[36mINFO[0m[0m 03/30 00:59:20 | steps-per-epoch for each domain: 126.08, 144.31, 102.77 -> min = 102.77
[37m[36mINFO[0m[0m 03/30 00:59:21 | # of params = 23522375
[37m[36mINFO[0m[0m 03/30 00:59:21 | Extracting features BEFORE training...
[37m[36mINFO[0m[0m 03/30 01:00:01 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/30 01:00:01 | 0.199109    0.200000    0.208613    0.213446    1.924718    0.214765    0.220049    0.201493    0.183761    0.209581    0.236527    0.199109    0.200000    0           0.000000    2.021235    7.210364    32.867193  
[37m[36mINFO[0m[0m 03/30 01:01:21 | 0.539758    0.538854    0.937148    0.928682    0.209248    0.923124    0.899756    0.907783    0.925214    0.980539    0.961078    0.539758    0.538854    200         1.946108    0.396299    0.125914    33.240196  
[37m[36mINFO[0m[0m 03/30 01:02:41 | 0.731870    0.742675    0.958866    0.946500    0.170069    0.945088    0.916870    0.947228    0.946581    0.984281    0.976048    0.731870    0.742675    400         3.892216    0.158432    0.132954    31.819013  
[37m[36mINFO[0m[0m 03/30 01:03:58 | 0.717557    0.713376    0.970235    0.947219    0.145885    0.959121    0.933985    0.956823    0.931624    0.994760    0.976048    0.717557    0.713376    600         5.838323    0.119690    0.124658    31.286764  
[37m[36mINFO[0m[0m 03/30 01:05:18 | 0.721056    0.722293    0.974693    0.950392    0.146357    0.964613    0.931540    0.966951    0.946581    0.992515    0.973054    0.721056    0.722293    800         7.784431    0.095360    0.130453    32.677710  
[37m[36mINFO[0m[0m 03/30 01:06:36 | 0.751272    0.742675    0.982861    0.948666    0.149787    0.980476    0.941320    0.973348    0.931624    0.994760    0.973054    0.751272    0.742675    1000        9.730539    0.066668    0.126199    30.685046  
[37m[36mINFO[0m[0m 03/30 01:07:57 | 0.725827    0.749045    0.982223    0.948579    0.155130    0.973764    0.929095    0.978145    0.946581    0.994760    0.970060    0.725827    0.749045    1200        11.676647   0.050163    0.132359    33.617642  
[37m[36mINFO[0m[0m 03/30 01:09:15 | 0.704517    0.723567    0.933343    0.906859    0.347326    0.903600    0.875306    0.913646    0.878205    0.982784    0.967066    0.704517    0.723567    1400        13.622754   0.047247    0.125799    31.127065  
[37m[36mINFO[0m[0m 03/30 01:10:33 | 0.729326    0.733758    0.985417    0.947927    0.178486    0.980476    0.933985    0.984009    0.948718    0.991766    0.961078    0.729326    0.733758    1600        15.568862   0.044511    0.133477    30.513529  
[37m[36mINFO[0m[0m 03/30 01:11:51 | 0.806298    0.807643    0.993951    0.963181    0.125226    0.991458    0.951100    0.994136    0.959402    0.996257    0.979042    0.806298    0.807643    1800        17.514970   0.036544    0.127678    31.695448  
[37m[36mINFO[0m[0m 03/30 01:13:11 | 0.739504    0.743949    0.993512    0.957015    0.170387    0.994509    0.953545    0.988273    0.944444    0.997754    0.973054    0.739504    0.743949    2000        19.461078   0.031536    0.127779    32.760135  
[37m[36mINFO[0m[0m 03/30 01:14:33 | 0.751590    0.747771    0.994390    0.965322    0.119304    0.990848    0.951100    0.993070    0.950855    0.999251    0.994012    0.751590    0.747771    2200        21.407186   0.033929    0.130829    33.916209  
[37m[36mINFO[0m[0m 03/30 01:15:51 | 0.765585    0.784713    0.986611    0.953321    0.157794    0.974985    0.926650    0.989339    0.957265    0.995509    0.976048    0.765585    0.784713    2400        23.353293   0.023008    0.130859    31.107079  
[37m[36mINFO[0m[0m 03/30 01:17:09 | 0.678435    0.681529    0.980997    0.939255    0.223260    0.974985    0.924205    0.971748    0.929487    0.996257    0.964072    0.678435    0.681529    2600        25.299401   0.030972    0.130071    30.488510  
[37m[36mINFO[0m[0m 03/30 01:18:28 | 0.779580    0.800000    0.996625    0.958394    0.139205    0.993289    0.938875    0.997335    0.957265    0.999251    0.979042    0.779580    0.800000    2800        27.245509   0.034730    0.129389    31.279798  
[37m[36mINFO[0m[0m 03/30 01:19:48 | 0.810751    0.829299    0.994810    0.957396    0.163754    0.993289    0.938875    0.994136    0.957265    0.997006    0.976048    0.810751    0.829299    3000        29.191617   0.015974    0.130575    33.547453  
[37m[36mINFO[0m[0m 03/30 01:21:07 | 0.809160    0.811465    0.994785    0.961288    0.128615    0.992678    0.953545    0.994670    0.957265    0.997006    0.973054    0.809160    0.811465    3200        31.137725   0.024064    0.130317    31.652482  
[37m[36mINFO[0m[0m 03/30 01:22:25 | 0.791349    0.789809    0.993963    0.952712    0.179848    0.990848    0.929095    0.992537    0.952991    0.998503    0.976048    0.791349    0.789809    3400        33.083832   0.012678    0.126183    30.883652  
[37m[36mINFO[0m[0m 03/30 01:23:42 | 0.762405    0.765605    0.993891    0.957499    0.142981    0.990848    0.941320    0.993070    0.955128    0.997754    0.976048    0.762405    0.765605    3600        35.029940   0.018411    0.126743    30.704970  
[37m[36mINFO[0m[0m 03/30 01:25:00 | 0.802799    0.803822    0.998883    0.963505    0.139323    0.998780    0.948655    0.997868    0.965812    1.000000    0.976048    0.802799    0.803822    3800        36.976048   0.023703    0.130141    30.376547  
[37m[36mINFO[0m[0m 03/30 01:26:18 | 0.805344    0.817834    0.996625    0.965684    0.124960    0.993289    0.946210    0.997335    0.965812    0.999251    0.985030    0.805344    0.817834    4000        38.922156   0.011112    0.130169    30.307133  
[37m[36mINFO[0m[0m 03/30 01:27:36 | 0.791349    0.798726    0.996393    0.966971    0.140999    0.994509    0.963325    0.994670    0.961538    1.000000    0.976048    0.791349    0.798726    4200        40.868263   0.011778    0.127462    31.888000  
[37m[36mINFO[0m[0m 03/30 01:28:55 | 0.766539    0.779618    0.996625    0.962690    0.107458    0.993289    0.946210    0.997335    0.965812    0.999251    0.976048    0.766539    0.779618    4400        42.814371   0.021620    0.126375    32.072503  
[37m[36mINFO[0m[0m 03/30 01:30:13 | 0.703880    0.726115    0.994453    0.963630    0.132666    0.989018    0.958435    0.997335    0.959402    0.997006    0.973054    0.703880    0.726115    4600        44.760479   0.015753    0.126290    30.914599  
[37m[36mINFO[0m[0m 03/30 01:31:30 | 0.781807    0.774522    0.992980    0.960797    0.155616    0.987797    0.948655    0.994136    0.963675    0.997006    0.970060    0.781807    0.774522    4800        46.706587   0.012425    0.125569    31.534933  
[37m[36mINFO[0m[0m 03/30 01:32:49 | 0.703244    0.710828    0.997232    0.960187    0.157644    0.997559    0.951100    0.994136    0.959402    1.000000    0.970060    0.703244    0.710828    5000        48.652695   0.018321    0.130888    30.556094  
[37m[36mINFO[0m[0m 03/30 01:33:10 | Extracting features AFTER training...
[37m[36mINFO[0m[0m 03/30 01:33:16 | Feature representations saved to disk.
[37m[36mINFO[0m[0m 03/30 01:33:16 | Cumulative gradient change saved at train_output/PACS/GENIE/[3]/250330_00-59-20_resnet50_sgd/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/30 01:33:18 | ---
[37m[36mINFO[0m[0m 03/30 01:33:18 | test-domain validation(oracle) = 81.075%
[37m[36mINFO[0m[0m 03/30 01:33:18 | training-domain validation(iid) = 79.135%
[37m[36mINFO[0m[0m 03/30 01:33:18 | last = 70.324%
[37m[36mINFO[0m[0m 03/30 01:33:18 | last (inD) = 96.019%
[37m[36mINFO[0m[0m 03/30 01:33:18 | training-domain validation (iid, inD) = 96.697%
[37m[36mINFO[0m[0m 03/30 01:33:18 | === Summary ===
[37m[36mINFO[0m[0m 03/30 01:33:18 | Command: /jsm0707/GENIE/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm GENIE --test_envs 3 --dataset PACS --trial_seed 0 --hparams_seed 18
[37m[36mINFO[0m[0m 03/30 01:33:18 | Unique name: 250330_00-59-20_resnet50_sgd
[37m[36mINFO[0m[0m 03/30 01:33:18 | Out path: train_output/PACS/GENIE/[3]/250330_00-59-20_resnet50_sgd
[37m[36mINFO[0m[0m 03/30 01:33:18 | Algorithm: GENIE
[37m[36mINFO[0m[0m 03/30 01:33:18 | Dataset: PACS
