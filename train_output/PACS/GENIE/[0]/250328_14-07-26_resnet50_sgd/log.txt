[37m[36mINFO[0m[0m 03/28 14:07:26 | Command :: /jsm0707/GENIE/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm GENIE --test_envs 0 --dataset PACS --trial_seed 2 --hparams_seed 9
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.22.4
	PIL: 9.4.0
Args:
	algorithm: GENIE
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_sgd.yaml']
	data_dir: data
	dataset: PACS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 9
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_sgd
	out_dir: train_output/PACS/GENIE/[0]/250328_14-07-26_resnet50_sgd
	out_root: train_output/PACS/GENIE/[0]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0]
	trial_seed: 2
	unique_name: 250328_14-07-26_resnet50_sgd
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: sgd
	freeze_bn: False
	pretrained: True
	lr: 2.716671579524612e-05
	batch_size: 29
	weight_decay: 1.71368232883332e-06
	momentum: 0.9092933546128503
	convergence_rate: 0.02426611940613899
	moving_avg: 0.947722940872739
	p: 0.5933807106679234
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[PACS] #envs=4, #classes=7
	env0: A (#2048)
	env1: C (#2344)
	env2: P (#1670)
	env3: S (#3929)

[37m[36mINFO[0m[0m 03/28 14:07:26 | n_steps = 5001
[37m[36mINFO[0m[0m 03/28 14:07:26 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/28 14:07:26 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/28 14:07:26 | 
[37m[36mINFO[0m[0m 03/28 14:07:26 | Testenv name escaping te_A -> te_A
[37m[36mINFO[0m[0m 03/28 14:07:26 | Test envs = [0], name = te_A
[37m[36mINFO[0m[0m 03/28 14:07:26 | Train environments: [1, 2, 3], Test environments: [0]
[37m[36mINFO[0m[0m 03/28 14:07:26 | Batch sizes for each domain: [0, 29, 29, 29] (total=87)
[37m[36mINFO[0m[0m 03/28 14:07:26 | steps-per-epoch for each domain: 64.69, 46.07, 108.41 -> min = 46.07
[37m[36mINFO[0m[0m 03/28 14:07:27 | # of params = 23522375
[37m[36mINFO[0m[0m 03/28 14:07:27 | Extracting features BEFORE training...
[37m[36mINFO[0m[0m 03/28 14:08:01 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/28 14:08:01 | 0.206833    0.217604    0.196310    0.207606    1.874971    0.206833    0.217604    0.232409    0.245726    0.158683    0.179641    0.197837    0.197452    0           0.000000    1.997630    3.499738    30.611619  
[37m[36mINFO[0m[0m 03/28 14:09:15 | 0.883466    0.899756    0.959440    0.951311    0.138690    0.883466    0.899756    0.941898    0.944444    0.991766    0.991018    0.944656    0.918471    200         4.341317    0.310677    0.214430    31.131713  
[37m[36mINFO[0m[0m 03/28 14:10:28 | 0.859671    0.838631    0.975354    0.954012    0.127150    0.859671    0.838631    0.964286    0.952991    0.993263    0.988024    0.968511    0.921019    400         8.682635    0.090194    0.212786    30.589896  
[37m[36mINFO[0m[0m 03/28 14:11:42 | 0.866992    0.855746    0.986954    0.969049    0.107321    0.866992    0.855746    0.987207    0.965812    0.994012    0.991018    0.979644    0.950318    600         13.023952   0.062330    0.212503    30.679772  
[37m[36mINFO[0m[0m 03/28 14:12:56 | 0.802318    0.794621    0.983758    0.958813    0.136534    0.802318    0.794621    0.984542    0.961538    0.990269    0.976048    0.976463    0.938854    800         17.365269   0.042988    0.210828    31.952502  
[37m[36mINFO[0m[0m 03/28 14:14:08 | 0.870043    0.858191    0.989520    0.961968    0.123664    0.870043    0.858191    0.990938    0.963675    0.999251    0.991018    0.978372    0.931210    1000        21.706587   0.047075    0.210900    29.704899  
[37m[36mINFO[0m[0m 03/28 14:15:21 | 0.837096    0.814181    0.992414    0.963222    0.122906    0.837096    0.814181    0.990938    0.967949    0.997754    0.979042    0.988550    0.942675    1200        26.047904   0.023596    0.211932    30.899446  
[37m[36mINFO[0m[0m 03/28 14:16:34 | 0.874314    0.860636    0.996034    0.967650    0.101901    0.874314    0.860636    0.997868    0.970085    0.998503    0.994012    0.991730    0.938854    1400        30.389222   0.027374    0.211980    31.197175  
[37m[36mINFO[0m[0m 03/28 14:17:47 | 0.848078    0.836186    0.996065    0.968488    0.101595    0.848078    0.836186    0.995736    0.967949    0.998503    0.991018    0.993957    0.946497    1600        34.730539   0.023628    0.211235    29.968683  
[37m[36mINFO[0m[0m 03/28 14:19:01 | 0.852959    0.843521    0.996171    0.969787    0.103372    0.852959    0.843521    0.994670    0.976496    0.999251    0.994012    0.994593    0.938854    1800        39.071856   0.016786    0.213273    31.544570  
[37m[36mINFO[0m[0m 03/28 14:20:13 | 0.876754    0.872861    0.994864    0.970936    0.113472    0.876754    0.872861    0.997335    0.980769    0.997754    0.997006    0.989504    0.935032    2000        43.413174   0.013932    0.213560    29.607853  
[37m[36mINFO[0m[0m 03/28 14:21:26 | 0.861501    0.860636    0.996455    0.966065    0.108787    0.861501    0.860636    0.996269    0.963675    0.998503    0.988024    0.994593    0.946497    2200        47.754491   0.017606    0.210568    30.997779  
[37m[36mINFO[0m[0m 03/28 14:22:38 | 0.877364    0.887531    0.996427    0.966920    0.108763    0.877364    0.887531    0.998934    0.976496    0.999251    0.979042    0.991094    0.945223    2400        52.095808   0.012651    0.209663    30.180250  
[37m[36mINFO[0m[0m 03/28 14:23:51 | 0.893838    0.894866    0.997948    0.974458    0.124944    0.893838    0.894866    1.000000    0.976496    0.999251    0.994012    0.994593    0.952866    2600        56.437126   0.007196    0.211261    30.101187  
[37m[36mINFO[0m[0m 03/28 14:25:04 | 0.830995    0.831296    0.993540    0.959520    0.162029    0.830995    0.831296    0.988273    0.950855    0.997754    0.985030    0.994593    0.942675    2800        60.778443   0.007476    0.210954    30.969459  
[37m[36mINFO[0m[0m 03/28 14:26:17 | 0.850519    0.865526    0.994397    0.963678    0.163222    0.850519    0.865526    0.990938    0.965812    0.999251    0.994012    0.993003    0.931210    3000        65.119760   0.009092    0.214095    29.790012  
[37m[36mINFO[0m[0m 03/28 14:27:30 | 0.841367    0.841076    0.998759    0.967077    0.132882    0.841367    0.841076    1.000000    0.970085    0.998503    0.991018    0.997774    0.940127    3200        69.461078   0.007020    0.209961    31.329030  
[37m[36mINFO[0m[0m 03/28 14:28:43 | 0.881025    0.877751    0.997128    0.969337    0.134246    0.881025    0.877751    0.996269    0.967949    0.999251    0.991018    0.995865    0.949045    3400        73.802395   0.007461    0.211916    30.893444  
[37m[36mINFO[0m[0m 03/28 14:29:56 | 0.824893    0.819071    0.996913    0.966938    0.142135    0.824893    0.819071    0.998934    0.967949    0.996257    0.994012    0.995547    0.938854    3600        78.143713   0.010981    0.213617    29.675088  
[37m[36mINFO[0m[0m 03/28 14:31:07 | 0.839536    0.850856    0.996848    0.963932    0.119444    0.839536    0.850856    0.996269    0.965812    1.000000    0.982036    0.994275    0.943949    3800        82.485030   0.007948    0.212002    29.249052  
[37m[36mINFO[0m[0m 03/28 14:32:21 | 0.887736    0.897311    0.997945    0.971897    0.123823    0.887736    0.897311    0.998401    0.970085    0.999251    0.994012    0.996183    0.951592    4000        86.826347   0.004020    0.211314    31.131152  
[37m[36mINFO[0m[0m 03/28 14:33:34 | 0.824283    0.823961    0.991693    0.963640    0.147632    0.824283    0.823961    0.994670    0.978632    0.990269    0.967066    0.990140    0.945223    4200        91.167665   0.008213    0.212453    30.409745  
[37m[36mINFO[0m[0m 03/28 14:34:48 | 0.835876    0.836186    0.997235    0.967615    0.127535    0.835876    0.836186    0.995203    0.963675    1.000000    0.985030    0.996501    0.954140    4400        95.508982   0.007880    0.214107    31.150066  
[37m[36mINFO[0m[0m 03/28 14:36:04 | 0.833435    0.833741    0.999504    0.966365    0.147889    0.833435    0.833741    0.999467    0.967949    1.000000    0.991018    0.999046    0.940127    4600        99.850299   0.002972    0.215368    33.148677  
[37m[36mINFO[0m[0m 03/28 14:37:16 | 0.840757    0.848411    0.999292    0.969204    0.144488    0.840757    0.848411    0.999467    0.978632    1.000000    0.985030    0.998410    0.943949    4800        104.191617  0.002189    0.209559    30.231556  
[37m[36mINFO[0m[0m 03/28 14:38:30 | 0.856010    0.865526    0.999432    0.972472    0.101203    0.856010    0.865526    1.000000    0.974359    0.999251    0.994012    0.999046    0.949045    5000        108.532934  0.007637    0.211319    31.429676  
[37m[36mINFO[0m[0m 03/28 14:38:30 | Extracting features AFTER training...
[37m[36mINFO[0m[0m 03/28 14:38:33 | Feature representations saved to disk.
[37m[36mINFO[0m[0m 03/28 14:38:33 | Cumulative gradient change saved at train_output/PACS/GENIE/[0]/250328_14-07-26_resnet50_sgd/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/28 14:38:35 | ---
[37m[36mINFO[0m[0m 03/28 14:38:35 | test-domain validation(oracle) = 88.347%
[37m[36mINFO[0m[0m 03/28 14:38:35 | training-domain validation(iid) = 89.384%
[37m[36mINFO[0m[0m 03/28 14:38:35 | last = 85.601%
[37m[36mINFO[0m[0m 03/28 14:38:35 | last (inD) = 97.247%
[37m[36mINFO[0m[0m 03/28 14:38:35 | training-domain validation (iid, inD) = 97.446%
[37m[36mINFO[0m[0m 03/28 14:38:35 | === Summary ===
[37m[36mINFO[0m[0m 03/28 14:38:35 | Command: /jsm0707/GENIE/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm GENIE --test_envs 0 --dataset PACS --trial_seed 2 --hparams_seed 9
[37m[36mINFO[0m[0m 03/28 14:38:35 | Unique name: 250328_14-07-26_resnet50_sgd
[37m[36mINFO[0m[0m 03/28 14:38:35 | Out path: train_output/PACS/GENIE/[0]/250328_14-07-26_resnet50_sgd
[37m[36mINFO[0m[0m 03/28 14:38:35 | Algorithm: GENIE
[37m[36mINFO[0m[0m 03/28 14:38:35 | Dataset: PACS
