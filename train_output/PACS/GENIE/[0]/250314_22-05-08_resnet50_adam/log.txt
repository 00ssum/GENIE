[37m[36mINFO[0m[0m 03/14 22:05:08 | Command :: /jsm0707/GENIE/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm GENIE --test_envs 0 --dataset PACS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: GENIE
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_adam.yaml']
	data_dir: data
	dataset: PACS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_adam
	out_dir: train_output/PACS/GENIE/[0]/250314_22-05-08_resnet50_adam
	out_root: train_output/PACS/GENIE/[0]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0]
	trial_seed: 0
	unique_name: 250314_22-05-08_resnet50_adam
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: adam
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	momentum: 0.9
	convergence_rate: 0.015
	moving_avg: 0.95
	p: 0.4
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[PACS] #envs=4, #classes=7
	env0: A (#2048)
	env1: C (#2344)
	env2: P (#1670)
	env3: S (#3929)

[37m[36mINFO[0m[0m 03/14 22:05:08 | n_steps = 5001
[37m[36mINFO[0m[0m 03/14 22:05:08 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/14 22:05:08 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/14 22:05:08 | 
[37m[36mINFO[0m[0m 03/14 22:05:08 | Testenv name escaping te_A -> te_A
[37m[36mINFO[0m[0m 03/14 22:05:08 | Test envs = [0], name = te_A
[37m[36mINFO[0m[0m 03/14 22:05:08 | Train environments: [1, 2, 3], Test environments: [0]
[37m[36mINFO[0m[0m 03/14 22:05:08 | Batch sizes for each domain: [0, 32, 32, 32] (total=96)
[37m[36mINFO[0m[0m 03/14 22:05:08 | steps-per-epoch for each domain: 58.62, 41.75, 98.25 -> min = 41.75
[37m[36mINFO[0m[0m 03/14 22:05:09 | # of params = 23522375
[37m[36mINFO[0m[0m 03/14 22:05:43 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/14 22:05:43 | 0.212935    0.217604    0.267092    0.262549    1.862266    0.212935    0.217604    0.242004    0.290598    0.363024    0.326347    0.196247    0.170701    0           0.000000    1.997718    0.987622    32.907136  
[37m[36mINFO[0m[0m 03/14 22:07:04 | 0.845638    0.872861    0.952453    0.954849    0.127722    0.845638    0.872861    0.930704    0.950855    0.990269    0.985030    0.936387    0.928662    200         4.790419    0.337703    0.245072    31.909671  
[37m[36mINFO[0m[0m 03/14 22:08:44 | 0.877974    0.872861    0.970284    0.961670    0.119135    0.877974    0.872861    0.956823    0.963675    0.992515    0.985030    0.961514    0.936306    400         9.580838    0.091969    0.339438    31.557741  
[37m[36mINFO[0m[0m 03/14 22:10:13 | 0.846248    0.838631    0.986992    0.968889    0.102358    0.846248    0.838631    0.984009    0.963675    0.997006    0.985030    0.979962    0.957962    600         14.371257   0.065522    0.292639    30.751144  
[37m[36mINFO[0m[0m 03/14 22:11:32 | 0.849298    0.855746    0.981046    0.961097    0.131600    0.849298    0.855746    0.979211    0.963675    0.997006    0.982036    0.966921    0.937580    800         19.161677   0.039263    0.243612    30.203174  
[37m[36mINFO[0m[0m 03/14 22:13:18 | 0.867602    0.877751    0.995467    0.971029    0.098358    0.867602    0.877751    0.994670    0.978632    1.000000    0.979042    0.991730    0.955414    1000        23.952096   0.033185    0.382745    30.166636  
[37m[36mINFO[0m[0m 03/14 22:14:40 | 0.848078    0.865526    0.992059    0.966054    0.107823    0.848078    0.865526    0.989872    0.961538    0.997754    0.985030    0.988550    0.951592    1200        28.742515   0.021071    0.239572    33.994746  
[37m[36mINFO[0m[0m 03/14 22:16:19 | 0.835265    0.845966    0.997163    0.975282    0.093590    0.835265    0.845966    0.995736    0.967949    0.999251    0.991018    0.996501    0.966879    1400        33.532934   0.018022    0.336481    31.677430  
[37m[36mINFO[0m[0m 03/14 22:17:50 | 0.854790    0.887531    0.995638    0.976698    0.086465    0.854790    0.887531    0.993070    0.978632    0.999251    0.982036    0.994593    0.969427    1600        38.323353   0.019514    0.297031    30.795711  
[37m[36mINFO[0m[0m 03/14 22:19:11 | 0.818792    0.821516    0.996489    0.974564    0.111570    0.818792    0.821516    0.994670    0.976496    0.999251    0.979042    0.995547    0.968153    1800        43.113772   0.013727    0.245145    32.184663  
[37m[36mINFO[0m[0m 03/14 22:20:56 | 0.870043    0.880196    0.997166    0.970578    0.119339    0.870043    0.880196    0.996269    0.965812    1.000000    0.979042    0.995229    0.966879    2000        47.904192   0.010367    0.366700    31.731509  
[37m[36mINFO[0m[0m 03/14 22:22:17 | 0.861501    0.897311    0.995211    0.969754    0.119986    0.861501    0.897311    0.993603    0.974359    0.997754    0.982036    0.994275    0.952866    2200        52.694611   0.012675    0.242905    32.616456  
[37m[36mINFO[0m[0m 03/14 22:23:51 | 0.849298    0.863081    0.998263    0.971750    0.120252    0.849298    0.863081    0.999467    0.974359    0.998503    0.988024    0.996819    0.952866    2400        57.485030   0.008323    0.318757    30.462809  
[37m[36mINFO[0m[0m 03/14 22:25:23 | 0.864552    0.880196    0.998195    0.968601    0.113282    0.864552    0.880196    0.998401    0.961538    1.000000    0.985030    0.996183    0.959236    2600        62.275449   0.008283    0.305688    30.720994  
[37m[36mINFO[0m[0m 03/14 22:26:47 | 0.849298    0.838631    0.998263    0.978839    0.114653    0.849298    0.838631    0.998401    0.970085    0.999251    0.997006    0.997137    0.969427    2800        67.065868   0.007299    0.252580    33.000253  
[37m[36mINFO[0m[0m 03/14 22:28:32 | 0.800488    0.792176    0.992336    0.968754    0.141456    0.800488    0.792176    0.989339    0.970085    0.996257    0.982036    0.991412    0.954140    3000        71.856287   0.009962    0.374880    30.574286  
[37m[36mINFO[0m[0m 03/14 22:29:52 | 0.873703    0.887531    0.997627    0.971472    0.123441    0.873703    0.887531    0.997335    0.970085    1.000000    0.994012    0.995547    0.950318    3200        76.646707   0.012593    0.241834    31.689873  
[37m[36mINFO[0m[0m 03/14 22:31:33 | 0.854790    0.858191    0.999292    0.973172    0.114691    0.854790    0.858191    0.999467    0.974359    1.000000    0.991018    0.998410    0.954140    3400        81.437126   0.006843    0.339787    32.490458  
[37m[36mINFO[0m[0m 03/14 22:33:01 | 0.860281    0.863081    0.996140    0.965228    0.135052    0.860281    0.863081    0.998934    0.965812    0.997754    0.991018    0.991730    0.938854    3600        86.227545   0.005042    0.289402    30.785740  
[37m[36mINFO[0m[0m 03/14 22:34:21 | 0.873703    0.872861    0.998444    0.972611    0.134148    0.873703    0.872861    0.999467    0.976496    1.000000    0.991018    0.995865    0.950318    3800        91.017964   0.003442    0.240506    31.739882  
[37m[36mINFO[0m[0m 03/14 22:36:09 | 0.868822    0.875306    0.997696    0.964230    0.170164    0.868822    0.875306    0.999467    0.965812    0.997754    0.988024    0.995865    0.938854    4000        95.808383   0.004226    0.376167    32.439876  
[37m[36mINFO[0m[0m 03/14 22:37:27 | 0.881025    0.865526    0.997518    0.969742    0.138926    0.881025    0.865526    0.996802    0.972222    0.999251    0.979042    0.996501    0.957962    4200        100.598802  0.004478    0.238126    30.692310  
[37m[36mINFO[0m[0m 03/14 22:39:13 | 0.888347    0.887531    0.999258    0.971885    0.131657    0.888347    0.887531    1.000000    0.967949    1.000000    0.991018    0.997774    0.956688    4400        105.389222  0.003934    0.363898    33.015058  
[37m[36mINFO[0m[0m 03/14 22:40:37 | 0.872483    0.887531    0.999292    0.974022    0.108509    0.872483    0.887531    0.999467    0.974359    1.000000    0.991018    0.998410    0.956688    4600        110.179641  0.005187    0.264256    30.662761  
[37m[36mINFO[0m[0m 03/14 22:42:01 | 0.846248    0.831296    0.998475    0.967433    0.147058    0.846248    0.831296    0.999467    0.961538    0.998503    0.970060    0.997455    0.970701    4800        114.970060  0.006037    0.258444    33.210008  
[37m[36mINFO[0m[0m 03/14 22:43:42 | 0.865772    0.860636    0.999326    0.970728    0.140024    0.865772    0.860636    1.000000    0.970085    0.999251    0.979042    0.998728    0.963057    5000        119.760479  0.003131    0.356130    29.480679  
[37m[36mINFO[0m[0m 03/14 22:43:42 | Cumulative gradient change saved at train_output/PACS/GENIE/[0]/250314_22-05-08_resnet50_adam/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/14 22:43:44 | ---
[37m[36mINFO[0m[0m 03/14 22:43:44 | test-domain validation(oracle) = 86.150%
[37m[36mINFO[0m[0m 03/14 22:43:44 | training-domain validation(iid) = 84.930%
[37m[36mINFO[0m[0m 03/14 22:43:44 | last = 86.577%
[37m[36mINFO[0m[0m 03/14 22:43:44 | last (inD) = 97.073%
[37m[36mINFO[0m[0m 03/14 22:43:44 | training-domain validation (iid, inD) = 97.884%
[37m[36mINFO[0m[0m 03/14 22:43:44 | === Summary ===
[37m[36mINFO[0m[0m 03/14 22:43:44 | Command: /jsm0707/GENIE/train_all.py resnet50_adam config/resnet50_adam.yaml --algorithm GENIE --test_envs 0 --dataset PACS
[37m[36mINFO[0m[0m 03/14 22:43:44 | Unique name: 250314_22-05-08_resnet50_adam
[37m[36mINFO[0m[0m 03/14 22:43:44 | Out path: train_output/PACS/GENIE/[0]/250314_22-05-08_resnet50_adam
[37m[36mINFO[0m[0m 03/14 22:43:44 | Algorithm: GENIE
[37m[36mINFO[0m[0m 03/14 22:43:44 | Dataset: PACS
