[37m[36mINFO[0m[0m 03/07 02:24:35 | Command :: /jsm0707/GENIE/train_all.py clip_vitb16_GENIE config/clip_vitb16_GENIE.yaml --algorithm ERM --test_envs 0 --dataset PACS --trial_seed 1 --hparams_seed 15
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: ERM
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/clip_vitb16_GENIE.yaml']
	data_dir: data
	dataset: PACS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 15
	in_domain: False
	model_save: None
	mpa: False
	name: clip_vitb16_GENIE
	out_dir: train_output/PACS/ERM/[0]/250307_02-24-35_clip_vitb16_GENIE
	out_root: train_output/PACS/ERM/[0]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0]
	trial_seed: 1
	unique_name: 250307_02-24-35_clip_vitb16_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 1.7812453400894684e-05
	batch_size: 36
	weight_decay: 3.1651536009272826e-06
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: openclip_vit-b16
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[PACS] #envs=4, #classes=7
	env0: A (#2048)
	env1: C (#2344)
	env2: P (#1670)
	env3: S (#3929)

[37m[36mINFO[0m[0m 03/07 02:24:35 | n_steps = 5001
[37m[36mINFO[0m[0m 03/07 02:24:35 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/07 02:24:35 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/07 02:24:35 | 
[37m[36mINFO[0m[0m 03/07 02:24:35 | Testenv name escaping te_A -> te_A
[37m[36mINFO[0m[0m 03/07 02:24:35 | Test envs = [0], name = te_A
[37m[36mINFO[0m[0m 03/07 02:24:35 | Train environments: [1, 2, 3], Test environments: [0]
[37m[36mINFO[0m[0m 03/07 02:24:35 | Batch sizes for each domain: [0, 36, 36, 36] (total=108)
[37m[36mINFO[0m[0m 03/07 02:24:35 | steps-per-epoch for each domain: 52.11, 37.11, 87.33 -> min = 37.11
[37m[36mINFO[0m[0m 03/07 02:24:37 | # of params = 86196231
[37m[36mINFO[0m[0m 03/07 02:25:09 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/07 02:25:09 | 0.117755    0.129584    0.162151    0.163681    1.962238    0.117755    0.129584    0.148721    0.215812    0.130988    0.068862    0.206743    0.206369    0           0.000000    1.934025    1.153881    30.830380  
[37m[36mINFO[0m[0m 03/07 02:27:03 | 0.569250    0.533007    0.786853    0.827675    0.483185    0.569250    0.533007    0.804371    0.846154    0.886976    0.931138    0.669211    0.705732    200         5.389222    0.985020    0.422664    29.695423  
[37m[36mINFO[0m[0m 03/07 02:28:58 | 0.505186    0.496333    0.872249    0.856389    0.406775    0.505186    0.496333    0.897122    0.886752    0.943862    0.946108    0.775763    0.736306    400         10.778443   0.403624    0.423805    30.625059  
[37m[36mINFO[0m[0m 03/07 02:30:53 | 0.620500    0.591687    0.913239    0.904002    0.275709    0.620500    0.591687    0.940832    0.931624    0.976048    0.988024    0.822837    0.792357    600         16.167665   0.310439    0.423321    29.616055  
[37m[36mINFO[0m[0m 03/07 02:32:48 | 0.569860    0.523227    0.926463    0.900268    0.289499    0.569860    0.523227    0.952026    0.916667    0.983533    0.979042    0.843830    0.805096    800         21.556886   0.242991    0.423543    30.259771  
[37m[36mINFO[0m[0m 03/07 02:34:43 | 0.568639    0.550122    0.920699    0.886120    0.329706    0.568639    0.550122    0.964819    0.923077    0.986527    0.976048    0.810751    0.759236    1000        26.946108   0.201979    0.423845    30.419921  
[37m[36mINFO[0m[0m 03/07 02:36:37 | 0.605247    0.589242    0.942120    0.916895    0.262740    0.605247    0.589242    0.979744    0.944444    0.991018    0.982036    0.855598    0.824204    1200        32.335329   0.180235    0.423974    29.322404  
[37m[36mINFO[0m[0m 03/07 02:38:31 | 0.582672    0.555012    0.951010    0.918441    0.250397    0.582672    0.555012    0.986674    0.935897    0.993263    0.985030    0.873092    0.834395    1400        37.724551   0.164135    0.424023    29.221075  
[37m[36mINFO[0m[0m 03/07 02:40:27 | 0.568029    0.564792    0.950456    0.913202    0.246640    0.568029    0.564792    0.977079    0.948718    0.991018    0.973054    0.883270    0.817834    1600        43.113772   0.153795    0.423928    30.854202  
[37m[36mINFO[0m[0m 03/07 02:42:21 | 0.574741    0.547677    0.951830    0.906228    0.267737    0.574741    0.547677    0.986141    0.927350    0.996257    0.976048    0.873092    0.815287    1800        48.502994   0.135762    0.423674    29.598812  
[37m[36mINFO[0m[0m 03/07 02:44:16 | 0.601586    0.569682    0.955872    0.914012    0.273192    0.601586    0.569682    0.978678    0.933761    0.993263    0.970060    0.895674    0.838217    2000        53.892216   0.123619    0.424118    29.934811  
[37m[36mINFO[0m[0m 03/07 02:46:09 | 0.579012    0.574572    0.971387    0.925258    0.232937    0.579012    0.574572    0.992537    0.940171    0.997006    0.991018    0.924618    0.844586    2200        59.281437   0.104738    0.422849    29.025003  
[37m[36mINFO[0m[0m 03/07 02:48:03 | 0.574131    0.545232    0.963895    0.916592    0.253500    0.574131    0.545232    0.987740    0.931624    1.000000    0.985030    0.903944    0.833121    2400        64.670659   0.094202    0.423082    29.639722  
[37m[36mINFO[0m[0m 03/07 02:49:58 | 0.660769    0.667482    0.972694    0.927397    0.216120    0.660769    0.667482    0.990938    0.950855    0.997754    0.988024    0.929389    0.843312    2600        70.059880   0.091933    0.422865    29.736230  
[37m[36mINFO[0m[0m 03/07 02:51:52 | 0.593045    0.550122    0.971180    0.915961    0.261408    0.593045    0.550122    0.977079    0.925214    0.996257    0.964072    0.940204    0.858599    2800        75.449102   0.080207    0.422701    29.896295  
[37m[36mINFO[0m[0m 03/07 02:53:46 | 0.599146    0.564792    0.977178    0.924391    0.240613    0.599146    0.564792    0.993070    0.948718    0.994760    0.976048    0.943702    0.848408    3000        80.838323   0.083131    0.422444    29.711757  
[37m[36mINFO[0m[0m 03/07 02:55:41 | 0.588164    0.589242    0.971725    0.920523    0.277886    0.588164    0.589242    0.986141    0.940171    0.995509    0.964072    0.933524    0.857325    3200        86.227545   0.067520    0.423272    29.861237  
[37m[36mINFO[0m[0m 03/07 02:57:35 | 0.583282    0.574572    0.978142    0.913036    0.282131    0.583282    0.574572    0.992537    0.933761    0.998503    0.976048    0.943384    0.829299    3400        91.616766   0.067571    0.424007    29.485570  
[37m[36mINFO[0m[0m 03/07 02:59:29 | 0.591824    0.537897    0.979798    0.925086    0.247254    0.591824    0.537897    0.988806    0.959402    0.999251    0.961078    0.951336    0.854777    3600        97.005988   0.062001    0.422853    29.585695  
[37m[36mINFO[0m[0m 03/07 03:01:23 | 0.635754    0.625917    0.976903    0.914041    0.290905    0.635754    0.625917    0.994136    0.950855    0.997006    0.967066    0.939567    0.824204    3800        102.395210  0.058936    0.423807    29.324743  
[37m[36mINFO[0m[0m 03/07 03:03:18 | 0.572910    0.572127    0.979413    0.923219    0.263599    0.572910    0.572127    0.995736    0.940171    0.996257    0.967066    0.946247    0.862420    4000        107.784431  0.056642    0.423318    29.784023  
[37m[36mINFO[0m[0m 03/07 03:05:13 | 0.618670    0.633252    0.979205    0.917450    0.299212    0.618670    0.633252    0.994136    0.952991    0.998503    0.970060    0.944975    0.829299    4200        113.173653  0.051582    0.425198    29.566063  
[37m[36mINFO[0m[0m 03/07 03:07:07 | 0.646126    0.628362    0.984042    0.922117    0.257480    0.646126    0.628362    0.990405    0.944444    0.999251    0.976048    0.962468    0.845860    4400        118.562874  0.051909    0.422953    29.570811  
[37m[36mINFO[0m[0m 03/07 03:09:01 | 0.645516    0.652812    0.988756    0.932494    0.221460    0.645516    0.652812    0.997868    0.955128    0.999251    0.985030    0.969148    0.857325    4600        123.952096  0.048307    0.423065    29.921334  
[37m[36mINFO[0m[0m 03/07 03:10:55 | 0.647956    0.665037    0.982460    0.924828    0.249788    0.647956    0.665037    0.996269    0.950855    0.998503    0.979042    0.952608    0.844586    4800        129.341317  0.041620    0.422496    29.696782  
[37m[36mINFO[0m[0m 03/07 03:12:49 | 0.619890    0.616137    0.985737    0.924256    0.270348    0.619890    0.616137    0.994670    0.955128    0.996257    0.973054    0.966285    0.844586    5000        134.730539  0.045252    0.422564    29.308041  
[37m[36mINFO[0m[0m 03/07 03:12:50 | Cumulative gradient change saved at train_output/PACS/ERM/[0]/250307_02-24-35_clip_vitb16_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/07 03:12:53 | ---
[37m[36mINFO[0m[0m 03/07 03:12:53 | test-domain validation(oracle) = 66.077%
[37m[36mINFO[0m[0m 03/07 03:12:53 | training-domain validation(iid) = 64.552%
[37m[36mINFO[0m[0m 03/07 03:12:53 | last = 61.989%
[37m[36mINFO[0m[0m 03/07 03:12:53 | last (inD) = 92.426%
[37m[36mINFO[0m[0m 03/07 03:12:53 | training-domain validation (iid, inD) = 93.249%
[37m[36mINFO[0m[0m 03/07 03:12:53 | === Summary ===
[37m[36mINFO[0m[0m 03/07 03:12:53 | Command: /jsm0707/GENIE/train_all.py clip_vitb16_GENIE config/clip_vitb16_GENIE.yaml --algorithm ERM --test_envs 0 --dataset PACS --trial_seed 1 --hparams_seed 15
[37m[36mINFO[0m[0m 03/07 03:12:53 | Unique name: 250307_02-24-35_clip_vitb16_GENIE
[37m[36mINFO[0m[0m 03/07 03:12:53 | Out path: train_output/PACS/ERM/[0]/250307_02-24-35_clip_vitb16_GENIE
[37m[36mINFO[0m[0m 03/07 03:12:53 | Algorithm: ERM
[37m[36mINFO[0m[0m 03/07 03:12:53 | Dataset: PACS
