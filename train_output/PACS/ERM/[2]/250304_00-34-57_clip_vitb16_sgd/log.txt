[37m[36mINFO[0m[0m 03/04 00:34:57 | Command :: /jsm0707/GENIE/train_all.py clip_vitb16_sgd config/clip_vitb16_sgd.yaml --algorithm ERM --test_envs 2 --dataset PACS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: ERM
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/clip_vitb16_sgd.yaml']
	data_dir: data
	dataset: PACS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: clip_vitb16_sgd
	out_dir: train_output/PACS/ERM/[2]/250304_00-34-57_clip_vitb16_sgd
	out_root: train_output/PACS/ERM/[2]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [2]
	trial_seed: 0
	unique_name: 250304_00-34-57_clip_vitb16_sgd
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: sgd
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: clip_vit-b16
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[PACS] #envs=4, #classes=7
	env0: A (#2048)
	env1: C (#2344)
	env2: P (#1670)
	env3: S (#3929)

[37m[36mINFO[0m[0m 03/04 00:34:57 | n_steps = 5001
[37m[36mINFO[0m[0m 03/04 00:34:57 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/04 00:34:57 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/04 00:34:57 | 
[37m[36mINFO[0m[0m 03/04 00:34:57 | Testenv name escaping te_P -> te_P
[37m[36mINFO[0m[0m 03/04 00:34:57 | Test envs = [2], name = te_P
[37m[36mINFO[0m[0m 03/04 00:34:57 | Train environments: [0, 1, 3], Test environments: [2]
[37m[36mINFO[0m[0m 03/04 00:34:57 | Batch sizes for each domain: [32, 32, 0, 32] (total=96)
[37m[36mINFO[0m[0m 03/04 00:34:57 | steps-per-epoch for each domain: 51.22, 58.62, 98.25 -> min = 51.22
[37m[36mINFO[0m[0m 03/04 00:34:59 | # of params = 86196231
[37m[36mINFO[0m[0m 03/04 00:35:32 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/04 00:35:32 | 0.176647    0.185629    0.116549    0.109456    1.947039    0.104332    0.097800    0.131130    0.132479    0.176647    0.185629    0.114186    0.098089    0           0.000000    1.930308    1.091122    31.704653  
[37m[36mINFO[0m[0m 03/04 00:37:27 | 0.368263    0.377246    0.437570    0.432874    1.750246    0.353874    0.290954    0.398721    0.403846    0.368263    0.377246    0.560115    0.603822    200         3.904820    1.855951    0.412962    32.701218  
[37m[36mINFO[0m[0m 03/04 00:39:23 | 0.634731    0.619760    0.745168    0.768611    1.519839    0.673581    0.731051    0.712687    0.707265    0.634731    0.619760    0.849237    0.867516    400         7.809640    1.649576    0.415311    31.995529  
[37m[36mINFO[0m[0m 03/04 00:41:19 | 0.819611    0.811377    0.889518    0.888517    1.260833    0.892617    0.887531    0.877399    0.882479    0.819611    0.811377    0.898537    0.895541    600         11.714460   1.396553    0.420648    32.278921  
[37m[36mINFO[0m[0m 03/04 00:43:13 | 0.925898    0.916168    0.943946    0.951347    1.000983    0.956681    0.960880    0.951493    0.959402    0.925898    0.916168    0.923664    0.933758    800         15.619280   1.136288    0.411618    31.793300  
[37m[36mINFO[0m[0m 03/04 00:45:08 | 0.985778    0.979042    0.961281    0.970153    0.778841    0.970714    0.975550    0.973881    0.980769    0.985778    0.979042    0.939249    0.954140    1000        19.524100   0.888578    0.417779    31.691192  
[37m[36mINFO[0m[0m 03/04 00:47:03 | 0.995509    0.994012    0.970352    0.977673    0.608494    0.981696    0.985330    0.975480    0.987179    0.995509    0.994012    0.953880    0.960510    1200        23.428920   0.696046    0.415607    31.854514  
[37m[36mINFO[0m[0m 03/04 00:48:59 | 0.997754    1.000000    0.973000    0.977858    0.486220    0.979866    0.982885    0.979211    0.991453    0.997754    1.000000    0.959924    0.959236    1400        27.333740   0.546131    0.422509    31.327111  
[37m[36mINFO[0m[0m 03/04 00:50:55 | 0.997754    1.000000    0.976432    0.978248    0.395816    0.984747    0.985330    0.980810    0.991453    0.997754    1.000000    0.963740    0.957962    1600        31.238560   0.439100    0.420434    31.670098  
[37m[36mINFO[0m[0m 03/04 00:52:48 | 0.998503    1.000000    0.977390    0.980166    0.331842    0.984747    0.980440    0.982409    0.995726    0.998503    1.000000    0.965013    0.964331    1800        35.143380   0.356003    0.411281    31.247059  
[37m[36mINFO[0m[0m 03/04 00:54:43 | 0.686377    0.649701    0.701490    0.705401    1.046407    0.608908    0.665037    0.791045    0.833333    0.686377    0.649701    0.704517    0.617834    2000        39.048200   1.042634    0.417538    31.453085  
[37m[36mINFO[0m[0m 03/04 00:56:39 | 0.997006    1.000000    0.982977    0.978077    0.264015    0.987797    0.977995    0.988806    0.995726    0.997006    1.000000    0.972328    0.960510    2200        42.953020   0.285103    0.418958    31.395475  
[37m[36mINFO[0m[0m 03/04 00:58:33 | 0.997754    1.000000    0.982255    0.980371    0.233134    0.986577    0.985330    0.990405    0.991453    0.997754    1.000000    0.969784    0.964331    2400        46.857840   0.242656    0.417351    31.190391  
[37m[36mINFO[0m[0m 03/04 01:00:28 | 0.997754    1.000000    0.986074    0.981830    0.208132    0.991458    0.982885    0.990938    0.995726    0.997754    1.000000    0.975827    0.966879    2600        50.762660   0.209750    0.415248    31.259351  
[37m[36mINFO[0m[0m 03/04 01:02:22 | 0.998503    1.000000    0.986464    0.981255    0.188480    0.989018    0.982885    0.992004    0.991453    0.998503    1.000000    0.978372    0.969427    2800        54.667480   0.186789    0.414698    31.417179  
[37m[36mINFO[0m[0m 03/04 01:04:17 | 0.997006    1.000000    0.987152    0.985446    0.169984    0.992678    0.987775    0.990405    0.997863    0.997006    1.000000    0.978372    0.970701    3000        58.572300   0.165434    0.419565    31.220052  
[37m[36mINFO[0m[0m 03/04 01:06:11 | 0.997006    1.000000    0.988576    0.984309    0.159084    0.992068    0.987775    0.991471    0.995726    0.997006    1.000000    0.982188    0.969427    3200        62.477120   0.151405    0.413961    31.110750  
[37m[36mINFO[0m[0m 03/04 01:08:05 | 0.997754    1.000000    0.989401    0.985549    0.146930    0.991458    0.990220    0.993603    0.995726    0.997754    1.000000    0.983142    0.970701    3400        66.381940   0.136939    0.415105    31.223545  
[37m[36mINFO[0m[0m 03/04 01:09:59 | 0.997006    1.000000    0.989702    0.984734    0.137420    0.992678    0.987775    0.993603    0.995726    0.997006    1.000000    0.982824    0.970701    3600        70.286760   0.120854    0.414371    31.124747  
[37m[36mINFO[0m[0m 03/04 01:11:53 | 0.994760    1.000000    0.990410    0.985905    0.128035    0.995119    0.985330    0.993603    0.997863    0.994760    1.000000    0.982506    0.974522    3800        74.191580   0.114711    0.413331    31.368266  
[37m[36mINFO[0m[0m 03/04 01:13:48 | 0.995509    1.000000    0.992350    0.986398    0.121240    0.995729    0.990220    0.996269    0.995726    0.995509    1.000000    0.985051    0.973248    4000        78.096400   0.104613    0.415206    31.476081  
[37m[36mINFO[0m[0m 03/04 01:15:42 | 0.993263    1.000000    0.988418    0.982714    0.122362    0.993289    0.980440    0.992004    0.995726    0.993263    1.000000    0.979962    0.971975    4200        82.001220   0.411824    0.414811    31.338767  
[37m[36mINFO[0m[0m 03/04 01:17:37 | 0.994012    1.000000    0.992301    0.985193    0.113577    0.996339    0.985330    0.993603    0.995726    0.994012    1.000000    0.986959    0.974522    4400        85.906040   0.093233    0.416338    31.650282  
[37m[36mINFO[0m[0m 03/04 01:19:31 | 0.994760    1.000000    0.993828    0.986433    0.105096    0.996339    0.987775    0.997868    0.995726    0.994760    1.000000    0.987277    0.975796    4600        89.810860   0.086622    0.417219    30.974077  
[37m[36mINFO[0m[0m 03/04 01:21:25 | 0.995509    1.000000    0.993049    0.985159    0.102863    0.993899    0.987775    0.997335    0.995726    0.995509    1.000000    0.987913    0.971975    4800        93.715680   0.079445    0.411113    31.141041  
[37m[36mINFO[0m[0m 03/04 01:23:19 | 0.994760    1.000000    0.995169    0.984378    0.100730    0.996339    0.982885    0.996802    0.995726    0.994760    1.000000    0.992366    0.974522    5000        97.620500   0.075678    0.413840    31.090204  
[37m[36mINFO[0m[0m 03/04 01:23:19 | Cumulative gradient change saved at train_output/PACS/ERM/[2]/250304_00-34-57_clip_vitb16_sgd/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/04 01:23:22 | ---
[37m[36mINFO[0m[0m 03/04 01:23:22 | test-domain validation(oracle) = 99.775%
[37m[36mINFO[0m[0m 03/04 01:23:22 | training-domain validation(iid) = 99.476%
[37m[36mINFO[0m[0m 03/04 01:23:22 | last = 99.476%
[37m[36mINFO[0m[0m 03/04 01:23:22 | last (inD) = 98.438%
[37m[36mINFO[0m[0m 03/04 01:23:22 | training-domain validation (iid, inD) = 98.643%
[37m[36mINFO[0m[0m 03/04 01:23:22 | === Summary ===
[37m[36mINFO[0m[0m 03/04 01:23:22 | Command: /jsm0707/GENIE/train_all.py clip_vitb16_sgd config/clip_vitb16_sgd.yaml --algorithm ERM --test_envs 2 --dataset PACS
[37m[36mINFO[0m[0m 03/04 01:23:22 | Unique name: 250304_00-34-57_clip_vitb16_sgd
[37m[36mINFO[0m[0m 03/04 01:23:22 | Out path: train_output/PACS/ERM/[2]/250304_00-34-57_clip_vitb16_sgd
[37m[36mINFO[0m[0m 03/04 01:23:22 | Algorithm: ERM
[37m[36mINFO[0m[0m 03/04 01:23:22 | Dataset: PACS
