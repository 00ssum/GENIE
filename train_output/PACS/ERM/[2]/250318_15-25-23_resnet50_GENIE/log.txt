[37m[36mINFO[0m[0m 03/18 15:25:23 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm ERM --test_envs 2 --dataset PACS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: ERM
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: PACS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/PACS/ERM/[2]/250318_15-25-23_resnet50_GENIE
	out_root: train_output/PACS/ERM/[2]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [2]
	trial_seed: 0
	unique_name: 250318_15-25-23_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[PACS] #envs=4, #classes=7
	env0: A (#2048)
	env1: C (#2344)
	env2: P (#1670)
	env3: S (#3929)

[37m[36mINFO[0m[0m 03/18 15:25:23 | n_steps = 5001
[37m[36mINFO[0m[0m 03/18 15:25:23 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/18 15:25:23 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/18 15:25:23 | 
[37m[36mINFO[0m[0m 03/18 15:25:23 | Testenv name escaping te_P -> te_P
[37m[36mINFO[0m[0m 03/18 15:25:23 | Test envs = [2], name = te_P
[37m[36mINFO[0m[0m 03/18 15:25:23 | Train environments: [0, 1, 3], Test environments: [2]
[37m[36mINFO[0m[0m 03/18 15:25:23 | Batch sizes for each domain: [32, 32, 0, 32] (total=96)
[37m[36mINFO[0m[0m 03/18 15:25:23 | steps-per-epoch for each domain: 51.22, 58.62, 98.25 -> min = 51.22
[37m[36mINFO[0m[0m 03/18 15:25:24 | # of params = 23522375
[37m[36mINFO[0m[0m 03/18 15:25:58 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/18 15:25:58 | 0.167665    0.185629    0.201773    0.206748    1.881724    0.213545    0.229829    0.215885    0.228632    0.167665    0.185629    0.175891    0.161783    0           0.000000    1.977479    1.019309    32.696517  
[37m[36mINFO[0m[0m 03/18 15:27:31 | 0.977545    0.979042    0.940177    0.937122    0.186425    0.953630    0.943765    0.934968    0.946581    0.977545    0.979042    0.931934    0.921019    200         3.904820    0.436651    0.312525    30.408410  
[37m[36mINFO[0m[0m 03/18 15:28:47 | 0.972305    0.964072    0.972275    0.939855    0.152786    0.979866    0.941320    0.969083    0.950855    0.972305    0.964072    0.967875    0.927389    400         7.809640    0.125732    0.230824    30.706017  
[37m[36mINFO[0m[0m 03/18 15:30:13 | 0.973802    0.973054    0.983900    0.963243    0.149678    0.987187    0.963325    0.986141    0.978632    0.973802    0.973054    0.978372    0.947771    600         11.714460   0.076497    0.264364    32.530397  
[37m[36mINFO[0m[0m 03/18 15:31:41 | 0.976048    0.967066    0.991161    0.966660    0.130338    0.992068    0.970660    0.994136    0.970085    0.976048    0.967066    0.987277    0.959236    800         15.619280   0.053185    0.285758    30.764190  
[37m[36mINFO[0m[0m 03/18 15:32:55 | 0.976048    0.970060    0.982694    0.947847    0.169011    0.985967    0.938875    0.993603    0.965812    0.976048    0.970060    0.968511    0.938854    1000        19.524100   0.043406    0.220005    30.646811  
[37m[36mINFO[0m[0m 03/18 15:34:28 | 0.967814    0.955090    0.977352    0.944231    0.193747    0.984747    0.933985    0.981343    0.963675    0.967814    0.955090    0.965967    0.935032    1200        23.428920   0.034146    0.306640    31.189539  
[37m[36mINFO[0m[0m 03/18 15:35:50 | 0.974551    0.973054    0.991719    0.956168    0.160742    0.995119    0.951100    0.994670    0.965812    0.974551    0.973054    0.985369    0.951592    1400        27.333740   0.029411    0.254733    31.417741  
[37m[36mINFO[0m[0m 03/18 15:37:06 | 0.975299    0.967066    0.994155    0.960223    0.154275    0.995119    0.946210    0.993070    0.976496    0.975299    0.967066    0.994275    0.957962    1600        31.238560   0.021375    0.223134    31.214268  
[37m[36mINFO[0m[0m 03/18 15:38:41 | 0.966317    0.967066    0.987892    0.943526    0.195870    0.985357    0.931540    0.990405    0.948718    0.966317    0.967066    0.987913    0.950318    1800        35.143380   0.020392    0.311756    32.236394  
[37m[36mINFO[0m[0m 03/18 15:39:58 | 0.968563    0.946108    0.986199    0.956079    0.192713    0.982306    0.948655    0.987740    0.974359    0.968563    0.946108    0.988550    0.945223    2000        39.048200   0.018464    0.230739    31.164891  
[37m[36mINFO[0m[0m 03/18 15:41:22 | 0.979042    0.976048    0.995421    0.962675    0.156318    0.995729    0.960880    0.994670    0.961538    0.979042    0.976048    0.995865    0.965605    2200        42.953020   0.015185    0.261188    31.457073  
[37m[36mINFO[0m[0m 03/18 15:42:53 | 0.973054    0.973054    0.996221    0.963983    0.147934    0.996949    0.968215    0.996802    0.959402    0.973054    0.973054    0.994911    0.964331    2400        46.857840   0.014498    0.292188    32.446259  
[37m[36mINFO[0m[0m 03/18 15:44:09 | 0.982036    0.991018    0.996275    0.960483    0.170720    0.997559    0.955990    0.992537    0.963675    0.982036    0.991018    0.998728    0.961783    2600        50.762660   0.009801    0.221449    31.835478  
[37m[36mINFO[0m[0m 03/18 15:45:42 | 0.969311    0.967066    0.997547    0.963298    0.144258    0.998170    0.958435    0.997335    0.972222    0.969311    0.967066    0.997137    0.959236    2800        54.667480   0.009761    0.304253    32.096419  
[37m[36mINFO[0m[0m 03/18 15:47:05 | 0.972305    0.958084    0.993931    0.961312    0.175762    0.996339    0.968215    0.996269    0.967949    0.972305    0.958084    0.989186    0.947771    3000        58.572300   0.008952    0.255259    32.106020  
[37m[36mINFO[0m[0m 03/18 15:48:21 | 0.976796    0.976048    0.997851    0.966660    0.143181    0.999390    0.960880    0.998934    0.972222    0.976796    0.976048    0.995229    0.966879    3200        62.477120   0.007643    0.223300    31.767471  
[37m[36mINFO[0m[0m 03/18 15:49:56 | 0.979790    0.985030    0.993982    0.962558    0.202042    0.996949    0.968215    0.990405    0.955128    0.979790    0.985030    0.994593    0.964331    3400        66.381940   0.005631    0.309596    33.208336  
[37m[36mINFO[0m[0m 03/18 15:51:15 | 0.978293    0.967066    0.997436    0.968557    0.131150    0.998780    0.968215    0.998934    0.980769    0.978293    0.967066    0.994593    0.956688    3600        70.286760   0.010374    0.231597    32.578194  
[37m[36mINFO[0m[0m 03/18 15:52:31 | 0.976796    0.976048    0.994900    0.961620    0.184568    0.990238    0.955990    0.995736    0.965812    0.976796    0.976048    0.998728    0.963057    3800        74.191580   0.005747    0.226939    30.471179  
[37m[36mINFO[0m[0m 03/18 15:53:47 | 0.969311    0.958084    0.998424    0.966777    0.133703    0.998780    0.963325    0.998401    0.976496    0.969311    0.958084    0.998092    0.960510    4000        78.096400   0.010273    0.221597    31.698187  
[37m[36mINFO[0m[0m 03/18 15:55:21 | 0.976048    0.961078    0.997991    0.961791    0.143469    0.999390    0.963325    0.998401    0.961538    0.976048    0.961078    0.996183    0.960510    4200        82.001220   0.016013    0.307568    32.474225  
[37m[36mINFO[0m[0m 03/18 15:56:43 | 0.970808    0.967066    0.999123    0.966386    0.164706    0.999390    0.960880    0.998934    0.976496    0.970808    0.967066    0.999046    0.961783    4400        85.906040   0.005700    0.251431    31.554806  
[37m[36mINFO[0m[0m 03/18 15:57:59 | 0.964820    0.967066    0.996275    0.960325    0.180556    0.995729    0.948655    0.997868    0.974359    0.964820    0.967066    0.995229    0.957962    4600        89.810860   0.004621    0.225336    30.370204  
[37m[36mINFO[0m[0m 03/18 15:59:31 | 0.975299    0.958084    0.999169    0.969852    0.144676    0.998780    0.975550    1.000000    0.972222    0.975299    0.958084    0.998728    0.961783    4800        93.715680   0.006733    0.302050    32.023979  
[37m[36mINFO[0m[0m 03/18 16:00:49 | 0.974551    0.967066    0.998762    0.967188    0.144469    1.000000    0.973105    0.999467    0.967949    0.974551    0.967066    0.996819    0.960510    5000        97.620500   0.007393    0.237215    31.059155  
[37m[36mINFO[0m[0m 03/18 16:00:50 | Cumulative gradient change saved at train_output/PACS/ERM/[2]/250318_15-25-23_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/18 16:00:51 | ---
[37m[36mINFO[0m[0m 03/18 16:00:51 | test-domain validation(oracle) = 98.204%
[37m[36mINFO[0m[0m 03/18 16:00:51 | training-domain validation(iid) = 97.530%
[37m[36mINFO[0m[0m 03/18 16:00:51 | last = 97.455%
[37m[36mINFO[0m[0m 03/18 16:00:51 | last (inD) = 96.719%
[37m[36mINFO[0m[0m 03/18 16:00:51 | training-domain validation (iid, inD) = 96.985%
[37m[36mINFO[0m[0m 03/18 16:00:51 | === Summary ===
[37m[36mINFO[0m[0m 03/18 16:00:51 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm ERM --test_envs 2 --dataset PACS
[37m[36mINFO[0m[0m 03/18 16:00:51 | Unique name: 250318_15-25-23_resnet50_GENIE
[37m[36mINFO[0m[0m 03/18 16:00:51 | Out path: train_output/PACS/ERM/[2]/250318_15-25-23_resnet50_GENIE
[37m[36mINFO[0m[0m 03/18 16:00:51 | Algorithm: ERM
[37m[36mINFO[0m[0m 03/18 16:00:51 | Dataset: PACS
