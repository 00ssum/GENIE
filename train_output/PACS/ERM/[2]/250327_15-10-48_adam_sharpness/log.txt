[37m[36mINFO[0m[0m 03/27 15:10:48 | Command :: /jsm0707/GENIE/train_all.py adam_sharpness config/resnet50_adam.yaml --algorithm ERM --test_envs 2 --dataset PACS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: ERM
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_adam.yaml']
	data_dir: data
	dataset: PACS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: adam_sharpness
	out_dir: train_output/PACS/ERM/[2]/250327_15-10-48_adam_sharpness
	out_root: train_output/PACS/ERM/[2]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [2]
	trial_seed: 0
	unique_name: 250327_15-10-48_adam_sharpness
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: adam
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[PACS] #envs=4, #classes=7
	env0: A (#2048)
	env1: C (#2344)
	env2: P (#1670)
	env3: S (#3929)

[37m[36mINFO[0m[0m 03/27 15:10:48 | n_steps = 5001
[37m[36mINFO[0m[0m 03/27 15:10:48 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/27 15:10:48 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/27 15:10:48 | 
[37m[36mINFO[0m[0m 03/27 15:10:48 | Testenv name escaping te_P -> te_P
[37m[36mINFO[0m[0m 03/27 15:10:48 | Test envs = [2], name = te_P
[37m[36mINFO[0m[0m 03/27 15:10:48 | Train environments: [0, 1, 3], Test environments: [2]
[37m[36mINFO[0m[0m 03/27 15:10:48 | Batch sizes for each domain: [32, 32, 0, 32] (total=96)
[37m[36mINFO[0m[0m 03/27 15:10:48 | steps-per-epoch for each domain: 51.22, 58.62, 98.25 -> min = 51.22
[37m[36mINFO[0m[0m 03/27 15:10:49 | # of params = 23522375
[37m[36mINFO[0m[0m 03/27 15:11:25 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/27 15:11:25 | 0.169162    0.167665    0.218547    0.220459    1.863360    0.224527    0.244499    0.236141    0.250000    0.169162    0.167665    0.194975    0.166879    0           0.000000    1.977479    0.934792    34.776850  
[37m[36mINFO[0m[0m 03/27 15:12:55 | 0.944611    0.925150    0.921855    0.923808    0.221756    0.928615    0.914425    0.925373    0.948718    0.944611    0.925150    0.911578    0.908280    200         3.904820    0.341997    0.178965    32.998363  
[37m[36mINFO[0m[0m 03/27 15:14:24 | 0.975299    0.952096    0.972104    0.943060    0.178834    0.975595    0.936430    0.977612    0.961538    0.975299    0.952096    0.963104    0.931210    400         7.809640    0.111629    0.178880    32.216094  
[37m[36mINFO[0m[0m 03/27 15:15:55 | 0.976048    0.955090    0.984753    0.960017    0.140862    0.992068    0.960880    0.988273    0.976496    0.976048    0.955090    0.973919    0.942675    600         11.714460   0.068044    0.178460    33.556456  
[37m[36mINFO[0m[0m 03/27 15:17:23 | 0.964820    0.943114    0.987046    0.942149    0.214986    0.989628    0.919315    0.986141    0.952991    0.964820    0.943114    0.985369    0.954140    800         15.619280   0.058324    0.177560    31.371921  
[37m[36mINFO[0m[0m 03/27 15:18:52 | 0.955838    0.958084    0.992264    0.950484    0.148952    0.993899    0.941320    0.993070    0.957265    0.955838    0.958084    0.989822    0.952866    1000        19.524100   0.043423    0.178321    32.205884  
[37m[36mINFO[0m[0m 03/27 15:20:23 | 0.971557    0.955090    0.995585    0.957627    0.140534    0.996949    0.948655    0.996802    0.970085    0.971557    0.955090    0.993003    0.954140    1200        23.428920   0.035843    0.178279    34.366549  
[37m[36mINFO[0m[0m 03/27 15:21:51 | 0.965569    0.937126    0.989037    0.945560    0.222557    0.989018    0.929095    0.988273    0.957265    0.965569    0.937126    0.989822    0.950318    1400        27.333740   0.029825    0.177608    31.360605  
[37m[36mINFO[0m[0m 03/27 15:23:18 | 0.952096    0.940120    0.988616    0.946662    0.197585    0.991458    0.941320    0.989339    0.957265    0.952096    0.940120    0.985051    0.941401    1600        31.238560   0.034766    0.177575    30.458094  
[37m[36mINFO[0m[0m 03/27 15:24:47 | 0.962575    0.946108    0.996289    0.958613    0.161790    0.996949    0.948655    0.995736    0.967949    0.962575    0.946108    0.996183    0.959236    1800        35.143380   0.026538    0.179200    31.393099  
[37m[36mINFO[0m[0m 03/27 15:26:14 | 0.963323    0.955090    0.992580    0.953757    0.159193    0.989628    0.941320    0.997335    0.965812    0.963323    0.955090    0.990776    0.954140    2000        39.048200   0.025730    0.177463    30.820479  
[37m[36mINFO[0m[0m 03/27 15:27:44 | 0.950599    0.949102    0.995353    0.956113    0.144481    0.993289    0.936430    0.996269    0.976496    0.950599    0.949102    0.996501    0.955414    2200        42.953020   0.029075    0.179026    32.165203  
[37m[36mINFO[0m[0m 03/27 15:29:12 | 0.953593    0.928144    0.992616    0.958319    0.186727    0.996949    0.960880    0.996802    0.976496    0.953593    0.928144    0.984097    0.937580    2400        46.857840   0.026790    0.178053    31.371641  
[37m[36mINFO[0m[0m 03/27 15:30:41 | 0.960329    0.970060    0.987507    0.936971    0.263193    0.973154    0.894866    0.994136    0.952991    0.960329    0.970060    0.995229    0.963057    2600        50.762660   0.016338    0.178531    31.986207  
[37m[36mINFO[0m[0m 03/27 15:32:11 | 0.955090    0.946108    0.986692    0.948210    0.220019    0.982916    0.941320    0.991471    0.952991    0.955090    0.946108    0.985687    0.950318    2800        54.667480   0.017794    0.178490    32.928787  
[37m[36mINFO[0m[0m 03/27 15:33:41 | 0.946856    0.940120    0.989145    0.948950    0.169857    0.979866    0.921760    0.995203    0.972222    0.946856    0.940120    0.992366    0.952866    3000        58.572300   0.022074    0.179758    33.212570  
[37m[36mINFO[0m[0m 03/27 15:35:11 | 0.949850    0.931138    0.980736    0.936396    0.218518    0.987797    0.924205    0.980810    0.942308    0.949850    0.931138    0.973601    0.942675    3200        62.477120   0.033374    0.178734    32.785583  
[37m[36mINFO[0m[0m 03/27 15:36:41 | 0.962575    0.913174    0.995175    0.952518    0.203759    0.993289    0.938875    0.995736    0.965812    0.962575    0.913174    0.996501    0.952866    3400        66.381940   0.018961    0.179131    32.745938  
[37m[36mINFO[0m[0m 03/27 15:38:12 | 0.943114    0.913174    0.994192    0.948313    0.230220    0.995119    0.943765    0.994136    0.950855    0.943114    0.913174    0.993321    0.950318    3600        70.286760   0.011126    0.178535    33.623109  
[37m[36mINFO[0m[0m 03/27 15:39:40 | 0.955090    0.922156    0.997886    0.967338    0.134651    0.996949    0.963325    0.998934    0.974359    0.955090    0.922156    0.997774    0.964331    3800        74.191580   0.019334    0.177801    31.855173  
[37m[36mINFO[0m[0m 03/27 15:41:11 | 0.942365    0.919162    0.991771    0.953908    0.218837    0.993899    0.951100    0.994136    0.967949    0.942365    0.919162    0.987277    0.942675    4000        78.096400   0.010527    0.178358    33.587318  
[37m[36mINFO[0m[0m 03/27 15:42:40 | 0.946856    0.925150    0.995596    0.953799    0.163824    0.993899    0.955990    0.998934    0.948718    0.946856    0.925150    0.993957    0.956688    4200        82.001220   0.016526    0.178957    32.560292  
[37m[36mINFO[0m[0m 03/27 15:44:10 | 0.964072    0.958084    0.999504    0.960969    0.167437    1.000000    0.953545    0.999467    0.976496    0.964072    0.958084    0.999046    0.952866    4400        85.906040   0.016308    0.178044    32.256224  
[37m[36mINFO[0m[0m 03/27 15:45:41 | 0.945359    0.922156    0.993293    0.948785    0.298450    0.991458    0.931540    0.995736    0.959402    0.945359    0.922156    0.992684    0.955414    4600        89.810860   0.020031    0.178510    34.379459  
[37m[36mINFO[0m[0m 03/27 15:47:10 | 0.959581    0.943114    0.995430    0.942286    0.246086    0.997559    0.929095    0.994136    0.948718    0.959581    0.943114    0.994593    0.949045    4800        93.715680   0.018930    0.177537    32.447170  
[37m[36mINFO[0m[0m 03/27 15:48:40 | 0.952844    0.925150    0.994230    0.961784    0.177743    0.990238    0.946210    0.996269    0.978632    0.952844    0.925150    0.996183    0.960510    5000        97.620500   0.009511    0.178962    32.335329  
[37m[36mINFO[0m[0m 03/27 15:49:01 | Cumulative gradient change saved at train_output/PACS/ERM/[2]/250327_15-10-48_adam_sharpness/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/27 15:49:02 | ---
[37m[36mINFO[0m[0m 03/27 15:49:02 | test-domain validation(oracle) = 96.033%
[37m[36mINFO[0m[0m 03/27 15:49:02 | training-domain validation(iid) = 95.509%
[37m[36mINFO[0m[0m 03/27 15:49:02 | last = 95.284%
[37m[36mINFO[0m[0m 03/27 15:49:02 | last (inD) = 96.178%
[37m[36mINFO[0m[0m 03/27 15:49:02 | training-domain validation (iid, inD) = 96.734%
[37m[36mINFO[0m[0m 03/27 15:49:02 | === Summary ===
[37m[36mINFO[0m[0m 03/27 15:49:02 | Command: /jsm0707/GENIE/train_all.py adam_sharpness config/resnet50_adam.yaml --algorithm ERM --test_envs 2 --dataset PACS
[37m[36mINFO[0m[0m 03/27 15:49:02 | Unique name: 250327_15-10-48_adam_sharpness
[37m[36mINFO[0m[0m 03/27 15:49:02 | Out path: train_output/PACS/ERM/[2]/250327_15-10-48_adam_sharpness
[37m[36mINFO[0m[0m 03/27 15:49:02 | Algorithm: ERM
[37m[36mINFO[0m[0m 03/27 15:49:02 | Dataset: PACS
