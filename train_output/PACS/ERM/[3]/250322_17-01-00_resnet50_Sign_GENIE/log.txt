[37m[36mINFO[0m[0m 03/22 17:01:00 | Command :: /jsm0707/GENIE/train_all.py resnet50_Sign_GENIE config/resnet50_Sign_GENIE.yaml --algorithm ERM --test_envs 3 --dataset PACS --trial_seed 0 --hparams_seed 16
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: ERM
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_Sign_GENIE.yaml']
	data_dir: data
	dataset: PACS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 16
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_Sign_GENIE
	out_dir: train_output/PACS/ERM/[3]/250322_17-01-00_resnet50_Sign_GENIE
	out_root: train_output/PACS/ERM/[3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [3]
	trial_seed: 0
	unique_name: 250322_17-01-00_resnet50_Sign_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: sign_genie
	freeze_bn: False
	pretrained: True
	lr: 4.249952708249365e-05
	batch_size: 17
	weight_decay: 9.786966598736845e-06
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[PACS] #envs=4, #classes=7
	env0: A (#2048)
	env1: C (#2344)
	env2: P (#1670)
	env3: S (#3929)

[37m[36mINFO[0m[0m 03/22 17:01:01 | n_steps = 5001
[37m[36mINFO[0m[0m 03/22 17:01:01 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/22 17:01:01 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/22 17:01:01 | 
[37m[36mINFO[0m[0m 03/22 17:01:01 | Testenv name escaping te_S -> te_S
[37m[36mINFO[0m[0m 03/22 17:01:01 | Test envs = [3], name = te_S
[37m[36mINFO[0m[0m 03/22 17:01:01 | Train environments: [0, 1, 2], Test environments: [3]
[37m[36mINFO[0m[0m 03/22 17:01:01 | Batch sizes for each domain: [17, 17, 17, 0] (total=51)
[37m[36mINFO[0m[0m 03/22 17:01:01 | steps-per-epoch for each domain: 96.41, 110.35, 78.59 -> min = 78.59
[37m[36mINFO[0m[0m 03/22 17:01:02 | # of params = 23522375
[37m[36mINFO[0m[0m 03/22 17:01:37 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/22 17:01:37 | 0.200382    0.202548    0.270223    0.260011    1.878090    0.242831    0.249389    0.198827    0.177350    0.369012    0.353293    0.200382    0.202548    0           0.000000    1.995510    1.550819    34.172850  
[37m[36mINFO[0m[0m 03/22 17:02:41 | 0.657443    0.643312    0.956360    0.947154    0.150087    0.944478    0.929095    0.932836    0.942308    0.991766    0.970060    0.657443    0.643312    200         2.544910    0.358440    0.151052    32.985340  
[37m[36mINFO[0m[0m 03/22 17:03:44 | 0.676527    0.682803    0.975706    0.958923    0.114214    0.967663    0.941320    0.970682    0.959402    0.988772    0.976048    0.676527    0.682803    400         5.089820    0.130465    0.140890    35.116848  
[37m[36mINFO[0m[0m 03/22 17:04:51 | 0.781170    0.789809    0.976391    0.951265    0.146968    0.967053    0.921760    0.973348    0.952991    0.988772    0.979042    0.781170    0.789809    600         7.634731    0.087717    0.151905    36.819067  
[37m[36mINFO[0m[0m 03/22 17:05:50 | 0.709288    0.714650    0.986581    0.952551    0.169026    0.983527    0.938875    0.979211    0.948718    0.997006    0.970060    0.709288    0.714650    800         10.179641   0.072564    0.137838    30.978647  
[37m[36mINFO[0m[0m 03/22 17:07:14 | 0.794211    0.802548    0.987177    0.962226    0.130490    0.981696    0.948655    0.985075    0.952991    0.994760    0.985030    0.794211    0.802548    1000        12.724551   0.050930    0.259008    32.357723  
[37m[36mINFO[0m[0m 03/22 17:08:17 | 0.796438    0.802548    0.988891    0.958966    0.136074    0.983527    0.938875    0.986141    0.952991    0.997006    0.985030    0.796438    0.802548    1200        15.269461   0.043283    0.152083    33.011586  
[37m[36mINFO[0m[0m 03/22 17:09:19 | 0.728053    0.741401    0.995163    0.967276    0.117504    0.995729    0.953545    0.992004    0.957265    0.997754    0.991018    0.728053    0.741401    1400        17.814371   0.045554    0.141031    33.355190  
[37m[36mINFO[0m[0m 03/22 17:10:41 | 0.700382    0.703185    0.993307    0.960230    0.155655    0.989628    0.948655    0.992537    0.952991    0.997754    0.979042    0.700382    0.703185    1600        20.359281   0.028953    0.253586    31.717514  
[37m[36mINFO[0m[0m 03/22 17:11:42 | 0.728372    0.742675    0.986316    0.957358    0.173195    0.978035    0.941320    0.982409    0.948718    0.998503    0.982036    0.728372    0.742675    1800        22.904192   0.030534    0.143560    32.105060  
[37m[36mINFO[0m[0m 03/22 17:12:46 | 0.763041    0.756688    0.995644    0.971690    0.094544    0.994509    0.953545    0.994670    0.976496    0.997754    0.985030    0.763041    0.756688    2000        25.449102   0.030746    0.147229    34.067780  
[37m[36mINFO[0m[0m 03/22 17:14:00 | 0.793257    0.819108    0.994081    0.963730    0.138796    0.990238    0.943765    0.992004    0.959402    1.000000    0.988024    0.793257    0.819108    2200        27.994012   0.023383    0.214542    31.852239  
[37m[36mINFO[0m[0m 03/22 17:15:00 | 0.793893    0.791083    0.997230    0.971286    0.126503    0.993289    0.960880    0.998401    0.967949    1.000000    0.985030    0.793893    0.791083    2400        30.538922   0.017629    0.133040    33.140787  
[37m[36mINFO[0m[0m 03/22 17:16:07 | 0.780852    0.794904    0.997917    0.971469    0.106856    0.996949    0.958435    0.996802    0.967949    1.000000    0.988024    0.780852    0.794904    2600        33.083832   0.016228    0.169138    32.757328  
[37m[36mINFO[0m[0m 03/22 17:17:19 | 0.730598    0.721019    0.995309    0.958988    0.170841    0.993289    0.946210    0.994136    0.948718    0.998503    0.982036    0.730598    0.721019    2800        35.628743   0.015644    0.198091    32.780550  
[37m[36mINFO[0m[0m 03/22 17:18:18 | 0.736959    0.737580    0.990673    0.961449    0.163430    0.985357    0.943765    0.990405    0.961538    0.996257    0.979042    0.736959    0.737580    3000        38.173653   0.016110    0.134787    31.883517  
[37m[36mINFO[0m[0m 03/22 17:19:37 | 0.796438    0.798726    0.995966    0.962489    0.162582    0.994509    0.941320    0.994136    0.955128    0.999251    0.991018    0.796438    0.798726    3200        40.718563   0.010562    0.226606    33.382212  
[37m[36mINFO[0m[0m 03/22 17:20:41 | 0.781170    0.773248    0.995103    0.969679    0.145580    0.995119    0.963325    0.990938    0.963675    0.999251    0.982036    0.781170    0.773248    3400        43.263473   0.007981    0.156975    32.411921  
[37m[36mINFO[0m[0m 03/22 17:21:41 | 0.790394    0.791083    0.998298    0.960451    0.132022    0.997559    0.943765    0.997335    0.961538    1.000000    0.976048    0.790394    0.791083    3600        45.808383   0.012628    0.140906    31.795088  
[37m[36mINFO[0m[0m 03/22 17:23:03 | 0.743639    0.741401    0.994764    0.952837    0.220875    0.993899    0.938875    0.994136    0.946581    0.996257    0.973054    0.743639    0.741401    3800        48.353293   0.011364    0.244296    33.307390  
[37m[36mINFO[0m[0m 03/22 17:24:07 | 0.747774    0.771975    0.997189    0.969576    0.120426    0.995729    0.960880    0.997335    0.965812    0.998503    0.982036    0.747774    0.771975    4000        50.898204   0.024003    0.153162    33.727402  
[37m[36mINFO[0m[0m 03/22 17:25:09 | 0.780216    0.793631    0.998988    0.970471    0.109399    0.998780    0.958435    0.998934    0.967949    0.999251    0.985030    0.780216    0.793631    4200        53.443114   0.012416    0.142207    33.168751  
[37m[36mINFO[0m[0m 03/22 17:26:12 | 0.782443    0.792357    0.999040    0.972814    0.094949    1.000000    0.963325    0.997868    0.970085    0.999251    0.985030    0.782443    0.792357    4400        55.988024   0.004387    0.147068    33.771182  
[37m[36mINFO[0m[0m 03/22 17:27:13 | 0.766539    0.745223    0.993853    0.966213    0.149011    0.990848    0.948655    0.995203    0.967949    0.995509    0.982036    0.766539    0.745223    4600        58.532934   0.006478    0.143474    32.693833  
[37m[36mINFO[0m[0m 03/22 17:28:23 | 0.773219    0.777070    0.998043    0.971918    0.108124    0.995729    0.965770    0.998401    0.967949    1.000000    0.982036    0.773219    0.777070    4800        61.077844   0.006270    0.178357    33.803534  
