[37m[36mINFO[0m[0m 03/18 16:00:55 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm ERM --test_envs 3 --dataset PACS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: ERM
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: PACS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/PACS/ERM/[3]/250318_16-00-55_resnet50_GENIE
	out_root: train_output/PACS/ERM/[3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [3]
	trial_seed: 0
	unique_name: 250318_16-00-55_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[PACS] #envs=4, #classes=7
	env0: A (#2048)
	env1: C (#2344)
	env2: P (#1670)
	env3: S (#3929)

[37m[36mINFO[0m[0m 03/18 16:00:55 | n_steps = 5001
[37m[36mINFO[0m[0m 03/18 16:00:55 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/18 16:00:55 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/18 16:00:55 | 
[37m[36mINFO[0m[0m 03/18 16:00:55 | Testenv name escaping te_S -> te_S
[37m[36mINFO[0m[0m 03/18 16:00:55 | Test envs = [3], name = te_S
[37m[36mINFO[0m[0m 03/18 16:00:55 | Train environments: [0, 1, 2], Test environments: [3]
[37m[36mINFO[0m[0m 03/18 16:00:55 | Batch sizes for each domain: [32, 32, 32, 0] (total=96)
[37m[36mINFO[0m[0m 03/18 16:00:55 | steps-per-epoch for each domain: 51.22, 58.62, 41.75 -> min = 41.75
[37m[36mINFO[0m[0m 03/18 16:00:56 | # of params = 23522375
[37m[36mINFO[0m[0m 03/18 16:01:29 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/18 16:01:29 | 0.068066    0.066242    0.324555    0.299834    1.844819    0.273337    0.254279    0.269190    0.235043    0.431138    0.410180    0.068066    0.066242    0           0.000000    1.999146    1.058537    31.942552  
[37m[36mINFO[0m[0m 03/18 16:03:04 | 0.672074    0.668790    0.960447    0.955221    0.131165    0.959732    0.941320    0.932836    0.942308    0.988772    0.982036    0.672074    0.668790    200         4.790419    0.281233    0.302218    34.596354  
[37m[36mINFO[0m[0m 03/18 16:04:25 | 0.754135    0.760510    0.986484    0.963811    0.102379    0.982916    0.938875    0.980277    0.961538    0.996257    0.991018    0.754135    0.760510    400         9.580838    0.088719    0.248623    31.283993  
[37m[36mINFO[0m[0m 03/18 16:05:40 | 0.725509    0.733758    0.987822    0.964405    0.112446    0.985967    0.946210    0.979744    0.952991    0.997754    0.994012    0.725509    0.733758    600         14.371257   0.048812    0.220385    30.615362  
[37m[36mINFO[0m[0m 03/18 16:07:13 | 0.690204    0.694268    0.994410    0.970837    0.091696    0.989628    0.953545    0.993603    0.967949    1.000000    0.991018    0.690204    0.694268    800         19.161677   0.032854    0.306861    32.279131  
[37m[36mINFO[0m[0m 03/18 16:08:30 | 0.737595    0.761783    0.987334    0.955523    0.146325    0.982916    0.931540    0.985075    0.952991    0.994012    0.982036    0.737595    0.761783    1000        23.952096   0.020843    0.229906    31.008075  
[37m[36mINFO[0m[0m 03/18 16:09:54 | 0.695929    0.714650    0.995487    0.968986    0.094565    0.993289    0.953545    0.994670    0.959402    0.998503    0.994012    0.695929    0.714650    1200        28.742515   0.019481    0.255296    32.300909  
[37m[36mINFO[0m[0m 03/18 16:11:23 | 0.688931    0.701911    0.984723    0.947588    0.211598    0.988408    0.946210    0.971748    0.929487    0.994012    0.967066    0.688931    0.701911    1400        33.532934   0.011738    0.292767    31.222196  
[37m[36mINFO[0m[0m 03/18 16:12:39 | 0.768766    0.759236    0.996146    0.968209    0.107897    0.992068    0.948655    0.997868    0.967949    0.998503    0.988024    0.768766    0.759236    1600        38.323353   0.015131    0.219329    31.182001  
[37m[36mINFO[0m[0m 03/18 16:14:09 | 0.779580    0.779618    0.998476    0.973305    0.095724    0.997559    0.968215    0.997868    0.963675    1.000000    0.988024    0.779580    0.779618    1800        43.113772   0.010072    0.290769    31.907894  
[37m[36mINFO[0m[0m 03/18 16:15:31 | 0.756361    0.782166    0.998476    0.970331    0.110645    0.997559    0.958435    0.997868    0.961538    1.000000    0.991018    0.756361    0.782166    2000        47.904192   0.011200    0.257756    31.112781  
[37m[36mINFO[0m[0m 03/18 16:16:46 | 0.748728    0.742675    0.996656    0.967558    0.109587    0.995729    0.953545    0.995736    0.970085    0.998503    0.979042    0.748728    0.742675    2200        52.694611   0.007741    0.220962    30.488461  
[37m[36mINFO[0m[0m 03/18 16:18:19 | 0.743957    0.756688    0.998759    0.967587    0.117719    0.997559    0.977995    0.999467    0.948718    0.999251    0.976048    0.743957    0.756688    2400        57.485030   0.006448    0.304429    32.239721  
[37m[36mINFO[0m[0m 03/18 16:19:37 | 0.765903    0.765605    0.999014    0.972528    0.115205    0.999390    0.963325    0.998401    0.972222    0.999251    0.982036    0.765903    0.765605    2600        62.275449   0.007214    0.232644    31.207617  
[37m[36mINFO[0m[0m 03/18 16:20:52 | 0.719784    0.726115    0.997714    0.967622    0.110752    0.996339    0.958435    0.996802    0.959402    1.000000    0.985030    0.719784    0.726115    2800        67.065868   0.005869    0.221782    30.546833  
[37m[36mINFO[0m[0m 03/18 16:22:25 | 0.751272    0.766879    0.999060    0.973892    0.108848    0.998780    0.958435    0.998401    0.972222    1.000000    0.991018    0.751272    0.766879    3000        71.856287   0.004795    0.311834    30.712444  
[37m[36mINFO[0m[0m 03/18 16:23:44 | 0.794847    0.789809    0.997493    0.969290    0.145836    0.994509    0.960880    0.999467    0.967949    0.998503    0.979042    0.794847    0.789809    3200        76.646707   0.008086    0.232068    32.904045  
[37m[36mINFO[0m[0m 03/18 16:25:12 | 0.773537    0.784713    0.997668    0.965318    0.140932    0.996949    0.951100    0.996802    0.965812    0.999251    0.979042    0.773537    0.784713    3400        81.437126   0.004536    0.269196    33.610898  
[37m[36mINFO[0m[0m 03/18 16:26:39 | 0.746501    0.747771    0.998095    0.967417    0.169400    0.996949    0.953545    0.997335    0.963675    1.000000    0.985030    0.746501    0.747771    3600        86.227545   0.003648    0.275109    31.927659  
[37m[36mINFO[0m[0m 03/18 16:27:53 | 0.753181    0.764331    0.999441    0.970654    0.109434    0.999390    0.955990    0.998934    0.967949    1.000000    0.988024    0.753181    0.764331    3800        91.017964   0.005431    0.216816    31.454256  
[37m[36mINFO[0m[0m 03/18 16:29:28 | 0.803753    0.805096    0.998836    0.968232    0.120848    0.999390    0.955990    0.997868    0.963675    0.999251    0.985030    0.803753    0.805096    4000        95.808383   0.006101    0.300619    34.470802  
[37m[36mINFO[0m[0m 03/18 16:30:49 | 0.780216    0.788535    0.999467    0.975236    0.116544    1.000000    0.963325    0.998401    0.974359    1.000000    0.988024    0.780216    0.788535    4200        100.598802  0.002318    0.246393    31.290456  
[37m[36mINFO[0m[0m 03/18 16:32:06 | 0.782761    0.801274    0.999369    0.967520    0.138899    0.999390    0.955990    0.999467    0.961538    0.999251    0.985030    0.782761    0.801274    4400        105.389222  0.002569    0.224083    32.133196  
[37m[36mINFO[0m[0m 03/18 16:33:45 | 0.766539    0.761783    0.998149    0.962587    0.183319    0.995729    0.943765    0.999467    0.967949    0.999251    0.976048    0.766539    0.761783    4600        110.179641  0.003951    0.308746    37.529284  
[37m[36mINFO[0m[0m 03/18 16:35:07 | 0.756043    0.763057    0.998349    0.968723    0.110493    0.998780    0.960880    0.996269    0.957265    1.000000    0.988024    0.756043    0.763057    4800        114.970060  0.007199    0.227795    36.587548  
[37m[36mINFO[0m[0m 03/18 16:36:33 | 0.788486    0.812739    0.998937    0.973812    0.115825    0.997559    0.963325    1.000000    0.970085    0.999251    0.988024    0.788486    0.812739    5000        119.760479  0.002806    0.266560    32.560941  
[37m[36mINFO[0m[0m 03/18 16:36:33 | Cumulative gradient change saved at train_output/PACS/ERM/[3]/250318_16-00-55_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/18 16:36:34 | ---
[37m[36mINFO[0m[0m 03/18 16:36:34 | test-domain validation(oracle) = 78.849%
[37m[36mINFO[0m[0m 03/18 16:36:34 | training-domain validation(iid) = 78.022%
[37m[36mINFO[0m[0m 03/18 16:36:34 | last = 78.849%
[37m[36mINFO[0m[0m 03/18 16:36:34 | last (inD) = 97.381%
[37m[36mINFO[0m[0m 03/18 16:36:34 | training-domain validation (iid, inD) = 97.524%
[37m[36mINFO[0m[0m 03/18 16:36:34 | === Summary ===
[37m[36mINFO[0m[0m 03/18 16:36:34 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm ERM --test_envs 3 --dataset PACS
[37m[36mINFO[0m[0m 03/18 16:36:34 | Unique name: 250318_16-00-55_resnet50_GENIE
[37m[36mINFO[0m[0m 03/18 16:36:34 | Out path: train_output/PACS/ERM/[3]/250318_16-00-55_resnet50_GENIE
[37m[36mINFO[0m[0m 03/18 16:36:34 | Algorithm: ERM
[37m[36mINFO[0m[0m 03/18 16:36:34 | Dataset: PACS
