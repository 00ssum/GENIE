[37m[36mINFO[0m[0m 03/27 15:49:06 | Command :: /jsm0707/GENIE/train_all.py adam_sharpness config/resnet50_adam.yaml --algorithm ERM --test_envs 3 --dataset PACS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: ERM
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_adam.yaml']
	data_dir: data
	dataset: PACS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: adam_sharpness
	out_dir: train_output/PACS/ERM/[3]/250327_15-49-06_adam_sharpness
	out_root: train_output/PACS/ERM/[3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [3]
	trial_seed: 0
	unique_name: 250327_15-49-06_adam_sharpness
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: adam
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[PACS] #envs=4, #classes=7
	env0: A (#2048)
	env1: C (#2344)
	env2: P (#1670)
	env3: S (#3929)

[37m[36mINFO[0m[0m 03/27 15:49:06 | n_steps = 5001
[37m[36mINFO[0m[0m 03/27 15:49:06 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/27 15:49:06 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/27 15:49:06 | 
[37m[36mINFO[0m[0m 03/27 15:49:06 | Testenv name escaping te_S -> te_S
[37m[36mINFO[0m[0m 03/27 15:49:06 | Test envs = [3], name = te_S
[37m[36mINFO[0m[0m 03/27 15:49:06 | Train environments: [0, 1, 2], Test environments: [3]
[37m[36mINFO[0m[0m 03/27 15:49:06 | Batch sizes for each domain: [32, 32, 32, 0] (total=96)
[37m[36mINFO[0m[0m 03/27 15:49:06 | steps-per-epoch for each domain: 51.22, 58.62, 41.75 -> min = 41.75
[37m[36mINFO[0m[0m 03/27 15:49:07 | # of params = 23522375
[37m[36mINFO[0m[0m 03/27 15:49:40 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/27 15:49:40 | 0.085878    0.086624    0.334337    0.307250    1.811671    0.317267    0.305623    0.283049    0.247863    0.402695    0.368263    0.085878    0.086624    0           0.000000    1.999146    1.029588    31.840192  
[37m[36mINFO[0m[0m 03/27 15:51:08 | 0.713104    0.707006    0.964236    0.958070    0.130045    0.962172    0.941320    0.951493    0.950855    0.979042    0.982036    0.713104    0.707006    200         4.790419    0.244809    0.180342    30.947972  
[37m[36mINFO[0m[0m 03/27 15:52:38 | 0.713422    0.727389    0.981840    0.953717    0.161424    0.978035    0.946210    0.967484    0.935897    1.000000    0.979042    0.713422    0.727389    400         9.580838    0.078650    0.180388    32.268977  
[37m[36mINFO[0m[0m 03/27 15:54:06 | 0.771310    0.774522    0.986669    0.959392    0.125961    0.989018    0.938875    0.975480    0.957265    0.995509    0.982036    0.771310    0.774522    600         14.371257   0.044002    0.181368    30.523266  
[37m[36mINFO[0m[0m 03/27 15:55:37 | 0.774809    0.801274    0.995960    0.964340    0.124082    0.992678    0.941320    0.995203    0.963675    1.000000    0.988024    0.774809    0.801274    800         19.161677   0.032433    0.179015    33.504172  
[37m[36mINFO[0m[0m 03/27 15:57:04 | 0.728690    0.726115    0.989495    0.967763    0.118144    0.990238    0.958435    0.979744    0.965812    0.998503    0.979042    0.728690    0.726115    1000        23.952096   0.034388    0.178228    30.318148  
[37m[36mINFO[0m[0m 03/27 15:58:33 | 0.768448    0.777070    0.994094    0.956684    0.142849    0.991458    0.938875    0.993070    0.955128    0.997754    0.976048    0.768448    0.777070    1200        28.742515   0.022135    0.180720    31.164938  
[37m[36mINFO[0m[0m 03/27 16:00:01 | 0.785941    0.816561    0.996905    0.964606    0.132199    0.995729    0.951100    0.995736    0.963675    0.999251    0.979042    0.785941    0.816561    1400        33.532934   0.024990    0.178299    31.146394  
[37m[36mINFO[0m[0m 03/27 16:01:30 | 0.731234    0.738854    0.998561    0.969820    0.145409    0.998780    0.963325    0.998401    0.970085    0.998503    0.976048    0.731234    0.738854    1600        38.323353   0.023272    0.178401    32.825085  
[37m[36mINFO[0m[0m 03/27 16:02:59 | 0.661896    0.677707    0.992136    0.953953    0.186937    0.982916    0.931540    0.995736    0.957265    0.997754    0.973054    0.661896    0.677707    1800        43.113772   0.017336    0.179147    31.231428  
[37m[36mINFO[0m[0m 03/27 16:04:28 | 0.738232    0.735032    0.996762    0.958866    0.168525    0.995729    0.953545    0.996802    0.952991    0.997754    0.970060    0.738232    0.735032    2000        47.904192   0.019694    0.179554    32.140207  
[37m[36mINFO[0m[0m 03/27 16:05:57 | 0.730916    0.750318    0.986522    0.945848    0.264755    0.976205    0.921760    0.985608    0.948718    0.997754    0.967066    0.730916    0.750318    2200        52.694611   0.013883    0.178780    31.937289  
[37m[36mINFO[0m[0m 03/27 16:07:25 | 0.776081    0.777070    0.997671    0.963257    0.148738    0.994509    0.946210    1.000000    0.976496    0.998503    0.967066    0.776081    0.777070    2400        57.485030   0.022183    0.177847    31.094616  
[37m[36mINFO[0m[0m 03/27 16:08:54 | 0.771628    0.757962    0.998811    0.971061    0.124879    0.998780    0.965770    0.998401    0.974359    0.999251    0.973054    0.771628    0.757962    2600        62.275449   0.011064    0.178549    32.229809  
[37m[36mINFO[0m[0m 03/27 16:10:24 | 0.719466    0.712102    0.991456    0.959902    0.144819    0.985357    0.951100    0.992004    0.961538    0.997006    0.967066    0.719466    0.712102    2800        67.065868   0.022644    0.178780    32.185579  
[37m[36mINFO[0m[0m 03/27 16:11:53 | 0.722964    0.738854    0.991320    0.946480    0.233038    0.991458    0.926650    0.987740    0.948718    0.994760    0.964072    0.722964    0.738854    3000        71.856287   0.011844    0.179272    32.729099  
[37m[36mINFO[0m[0m 03/27 16:13:22 | 0.722010    0.719745    0.995003    0.954235    0.167326    0.996339    0.931540    0.998401    0.970085    0.990269    0.961078    0.722010    0.719745    3200        76.646707   0.012792    0.178697    31.541071  
[37m[36mINFO[0m[0m 03/27 16:14:51 | 0.753181    0.765605    0.997290    0.956539    0.157279    0.993899    0.938875    0.999467    0.963675    0.998503    0.967066    0.753181    0.765605    3400        81.437126   0.017601    0.178298    32.345133  
[37m[36mINFO[0m[0m 03/27 16:16:22 | 0.717875    0.719745    0.974876    0.927417    0.360406    0.963392    0.907090    0.982942    0.938034    0.978293    0.937126    0.717875    0.719745    3600        86.227545   0.015244    0.179847    33.432494  
[37m[36mINFO[0m[0m 03/27 16:17:52 | 0.743957    0.726115    0.995960    0.961201    0.162667    0.992678    0.941320    0.995203    0.972222    1.000000    0.970060    0.743957    0.726115    3800        91.017964   0.016989    0.179915    33.424993  
[37m[36mINFO[0m[0m 03/27 16:19:22 | 0.724873    0.733758    0.995395    0.951614    0.192816    0.994509    0.943765    0.994670    0.952991    0.997006    0.958084    0.724873    0.733758    4000        95.808383   0.011611    0.180042    32.832432  
[37m[36mINFO[0m[0m 03/27 16:20:51 | 0.605280    0.617834    0.991670    0.947458    0.236376    0.989628    0.936430    0.989872    0.950855    0.995509    0.955090    0.605280    0.617834    4200        100.598802  0.013571    0.179599    31.319541  
[37m[36mINFO[0m[0m 03/27 16:22:22 | 0.719148    0.724841    0.998963    0.967477    0.151989    0.998170    0.958435    0.999467    0.967949    0.999251    0.976048    0.719148    0.724841    4400        105.389222  0.007716    0.179857    34.438033  
[37m[36mINFO[0m[0m 03/27 16:23:54 | 0.793893    0.798726    0.994804    0.961996    0.143523    0.995729    0.953545    0.994670    0.974359    0.994012    0.958084    0.793893    0.798726    4600        110.179641  0.018818    0.178905    34.416260  
[37m[36mINFO[0m[0m 03/27 16:25:24 | 0.800254    0.797452    0.997917    0.958412    0.153298    0.996949    0.946210    0.996802    0.967949    1.000000    0.961078    0.800254    0.797452    4800        114.970060  0.009580    0.178648    33.354906  
[37m[36mINFO[0m[0m 03/27 16:26:56 | 0.757952    0.746497    0.989962    0.949839    0.241220    0.982916    0.938875    0.995203    0.961538    0.991766    0.949102    0.757952    0.746497    5000        119.760479  0.014238    0.179110    34.697906  
[37m[36mINFO[0m[0m 03/27 16:27:17 | Cumulative gradient change saved at train_output/PACS/ERM/[3]/250327_15-49-06_adam_sharpness/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/27 16:27:19 | ---
[37m[36mINFO[0m[0m 03/27 16:27:19 | test-domain validation(oracle) = 78.594%
[37m[36mINFO[0m[0m 03/27 16:27:19 | training-domain validation(iid) = 77.163%
[37m[36mINFO[0m[0m 03/27 16:27:19 | last = 75.795%
[37m[36mINFO[0m[0m 03/27 16:27:19 | last (inD) = 94.984%
[37m[36mINFO[0m[0m 03/27 16:27:19 | training-domain validation (iid, inD) = 97.106%
[37m[36mINFO[0m[0m 03/27 16:27:19 | === Summary ===
[37m[36mINFO[0m[0m 03/27 16:27:19 | Command: /jsm0707/GENIE/train_all.py adam_sharpness config/resnet50_adam.yaml --algorithm ERM --test_envs 3 --dataset PACS
[37m[36mINFO[0m[0m 03/27 16:27:19 | Unique name: 250327_15-49-06_adam_sharpness
[37m[36mINFO[0m[0m 03/27 16:27:19 | Out path: train_output/PACS/ERM/[3]/250327_15-49-06_adam_sharpness
[37m[36mINFO[0m[0m 03/27 16:27:19 | Algorithm: ERM
[37m[36mINFO[0m[0m 03/27 16:27:19 | Dataset: PACS
