[37m[36mINFO[0m[0m 03/04 01:23:26 | Command :: /jsm0707/GENIE/train_all.py clip_vitb16_sgd config/clip_vitb16_sgd.yaml --algorithm ERM --test_envs 3 --dataset PACS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: ERM
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/clip_vitb16_sgd.yaml']
	data_dir: data
	dataset: PACS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: clip_vitb16_sgd
	out_dir: train_output/PACS/ERM/[3]/250304_01-23-26_clip_vitb16_sgd
	out_root: train_output/PACS/ERM/[3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [3]
	trial_seed: 0
	unique_name: 250304_01-23-26_clip_vitb16_sgd
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: sgd
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: clip_vit-b16
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[PACS] #envs=4, #classes=7
	env0: A (#2048)
	env1: C (#2344)
	env2: P (#1670)
	env3: S (#3929)

[37m[36mINFO[0m[0m 03/04 01:23:26 | n_steps = 5001
[37m[36mINFO[0m[0m 03/04 01:23:26 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/04 01:23:26 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/04 01:23:26 | 
[37m[36mINFO[0m[0m 03/04 01:23:26 | Testenv name escaping te_S -> te_S
[37m[36mINFO[0m[0m 03/04 01:23:26 | Test envs = [3], name = te_S
[37m[36mINFO[0m[0m 03/04 01:23:26 | Train environments: [0, 1, 2], Test environments: [3]
[37m[36mINFO[0m[0m 03/04 01:23:26 | Batch sizes for each domain: [32, 32, 32, 0] (total=96)
[37m[36mINFO[0m[0m 03/04 01:23:26 | steps-per-epoch for each domain: 51.22, 58.62, 41.75 -> min = 41.75
[37m[36mINFO[0m[0m 03/04 01:23:28 | # of params = 86196231
[37m[36mINFO[0m[0m 03/04 01:24:02 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/04 01:24:02 | 0.102735    0.098089    0.122924    0.138636    1.944960    0.104942    0.097800    0.130597    0.132479    0.133234    0.185629    0.102735    0.098089    0           0.000000    1.976249    1.305273    32.103527  
[37m[36mINFO[0m[0m 03/04 01:25:57 | 0.311705    0.292994    0.453452    0.414189    1.743110    0.387431    0.327628    0.400320    0.435897    0.572605    0.479042    0.311705    0.292994    200         4.790419    1.846618    0.420928    31.280790  
[37m[36mINFO[0m[0m 03/04 01:27:52 | 0.610687    0.600000    0.808902    0.760420    1.502114    0.799268    0.757946    0.756930    0.747863    0.870509    0.775449    0.610687    0.600000    400         9.580838    1.621939    0.416331    31.351862  
[37m[36mINFO[0m[0m 03/04 01:29:47 | 0.830789    0.833121    0.948559    0.964202    1.219187    0.940207    0.958435    0.930171    0.955128    0.975299    0.979042    0.830789    0.833121    600         14.371257   1.357470    0.417754    31.653736  
[37m[36mINFO[0m[0m 03/04 01:31:41 | 0.853690    0.857325    0.975728    0.982812    0.945989    0.962172    0.970660    0.971748    0.980769    0.993263    0.997006    0.853690    0.857325    800         19.161677   1.069003    0.413589    31.248835  
[37m[36mINFO[0m[0m 03/04 01:33:37 | 0.850827    0.862420    0.980738    0.988392    0.724032    0.973154    0.977995    0.976546    0.987179    0.992515    1.000000    0.850827    0.862420    1000        23.952096   0.817277    0.415989    32.460652  
[37m[36mINFO[0m[0m 03/04 01:35:31 | 0.824109    0.850955    0.984450    0.988289    0.550517    0.976815    0.975550    0.980277    0.989316    0.996257    1.000000    0.824109    0.850955    1200        28.742515   0.619448    0.412888    31.704820  
[37m[36mINFO[0m[0m 03/04 01:37:25 | 0.850191    0.859873    0.986584    0.988818    0.430412    0.981086    0.977995    0.982409    0.991453    0.996257    0.997006    0.850191    0.859873    1400        33.532934   0.479925    0.415641    31.214307  
[37m[36mINFO[0m[0m 03/04 01:39:19 | 0.842875    0.859873    0.987418    0.989001    0.347472    0.982306    0.975550    0.982942    0.991453    0.997006    1.000000    0.842875    0.859873    1600        38.323353   0.378460    0.408480    31.808042  
[37m[36mINFO[0m[0m 03/04 01:41:13 | 0.861959    0.873885    0.989776    0.989919    0.285359    0.985967    0.980440    0.985608    0.989316    0.997754    1.000000    0.861959    0.873885    1800        43.113772   0.308655    0.414940    31.086326  
[37m[36mINFO[0m[0m 03/04 01:43:08 | 0.869275    0.882803    0.991885    0.989816    0.240656    0.989628    0.977995    0.988273    0.991453    0.997754    1.000000    0.869275    0.882803    2000        47.904192   0.256024    0.415011    31.582417  
[37m[36mINFO[0m[0m 03/04 01:45:01 | 0.857824    0.873885    0.989922    0.991343    0.209998    0.987797    0.980440    0.987207    0.993590    0.994760    1.000000    0.857824    0.873885    2200        52.694611   0.216787    0.411572    31.212181  
[37m[36mINFO[0m[0m 03/04 01:46:55 | 0.858779    0.876433    0.990994    0.989816    0.182454    0.985357    0.977995    0.989872    0.991453    0.997754    1.000000    0.858779    0.876433    2400        57.485030   0.189223    0.414527    31.442867  
[37m[36mINFO[0m[0m 03/04 01:48:50 | 0.862595    0.878981    0.992432    0.991343    0.162951    0.990848    0.980440    0.990938    0.993590    0.995509    1.000000    0.862595    0.878981    2600        62.275449   0.165728    0.415982    31.035556  
[37m[36mINFO[0m[0m 03/04 01:50:46 | 0.858779    0.867516    0.992372    0.993788    0.145931    0.990238    0.987775    0.989872    0.993590    0.997006    1.000000    0.858779    0.867516    2800        67.065868   0.147639    0.424437    31.231198  
[37m[36mINFO[0m[0m 03/04 01:52:39 | 0.863232    0.867516    0.995605    0.992261    0.131869    0.992678    0.985330    0.994136    0.991453    1.000000    1.000000    0.863232    0.867516    3000        71.856287   0.131743    0.409140    31.299795  
[37m[36mINFO[0m[0m 03/04 01:54:32 | 0.856234    0.881529    0.994954    0.992158    0.121702    0.993289    0.982885    0.993070    0.993590    0.998503    1.000000    0.856234    0.881529    3200        76.646707   0.119816    0.406696    31.755797  
[37m[36mINFO[0m[0m 03/04 01:56:25 | 0.868003    0.884076    0.995966    0.992364    0.111730    0.994509    0.987775    0.994136    0.989316    0.999251    1.000000    0.868003    0.884076    3400        81.437126   0.107821    0.407491    31.039388  
[37m[36mINFO[0m[0m 03/04 01:58:18 | 0.857506    0.870064    0.996926    0.994501    0.105078    0.994509    0.987775    0.996269    0.995726    1.000000    1.000000    0.857506    0.870064    3600        86.227545   0.101398    0.412144    31.047232  
[37m[36mINFO[0m[0m 03/04 02:00:13 | 0.867684    0.880255    0.995948    0.992973    0.097411    0.993289    0.985330    0.996802    0.993590    0.997754    1.000000    0.867684    0.880255    3800        91.017964   0.338858    0.419862    31.141244  
[37m[36mINFO[0m[0m 03/04 02:02:06 | 0.859415    0.873885    0.997464    0.993788    0.091465    0.996339    0.987775    0.996802    0.993590    0.999251    1.000000    0.859415    0.873885    4000        95.808383   0.086713    0.405768    31.789245  
[37m[36mINFO[0m[0m 03/04 02:04:02 | 0.874364    0.887898    0.997768    0.994501    0.086414    0.995119    0.987775    0.998934    0.995726    0.999251    1.000000    0.874364    0.887898    4200        100.598802  0.092772    0.415389    32.363538  
[37m[36mINFO[0m[0m 03/04 02:05:56 | 0.858461    0.870064    0.997029    0.991446    0.085058    0.996949    0.982885    0.994136    0.991453    1.000000    1.000000    0.858461    0.870064    4400        105.389222  0.075643    0.417320    31.160491  
[37m[36mINFO[0m[0m 03/04 02:07:52 | 0.862277    0.878981    0.996905    0.993788    0.076177    0.995729    0.987775    0.995736    0.993590    0.999251    1.000000    0.862277    0.878981    4600        110.179641  0.070683    0.417110    32.074452  
[37m[36mINFO[0m[0m 03/04 02:09:48 | 0.857188    0.875159    0.996880    0.992158    0.074066    0.995119    0.982885    0.996269    0.993590    0.999251    1.000000    0.857188    0.875159    4800        114.970060  0.066407    0.423441    31.276776  
[37m[36mINFO[0m[0m 03/04 02:11:43 | 0.873410    0.884076    0.997181    0.993076    0.070571    0.996339    0.987775    0.995203    0.991453    1.000000    1.000000    0.873410    0.884076    5000        119.760479  0.060752    0.418543    31.665421  
[37m[36mINFO[0m[0m 03/04 02:11:43 | Cumulative gradient change saved at train_output/PACS/ERM/[3]/250304_01-23-26_clip_vitb16_sgd/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/04 02:11:47 | ---
[37m[36mINFO[0m[0m 03/04 02:11:47 | test-domain validation(oracle) = 87.436%
[37m[36mINFO[0m[0m 03/04 02:11:47 | training-domain validation(iid) = 85.751%
[37m[36mINFO[0m[0m 03/04 02:11:47 | last = 87.341%
[37m[36mINFO[0m[0m 03/04 02:11:47 | last (inD) = 99.308%
[37m[36mINFO[0m[0m 03/04 02:11:47 | training-domain validation (iid, inD) = 99.450%
[37m[36mINFO[0m[0m 03/04 02:11:47 | === Summary ===
[37m[36mINFO[0m[0m 03/04 02:11:47 | Command: /jsm0707/GENIE/train_all.py clip_vitb16_sgd config/clip_vitb16_sgd.yaml --algorithm ERM --test_envs 3 --dataset PACS
[37m[36mINFO[0m[0m 03/04 02:11:47 | Unique name: 250304_01-23-26_clip_vitb16_sgd
[37m[36mINFO[0m[0m 03/04 02:11:47 | Out path: train_output/PACS/ERM/[3]/250304_01-23-26_clip_vitb16_sgd
[37m[36mINFO[0m[0m 03/04 02:11:47 | Algorithm: ERM
[37m[36mINFO[0m[0m 03/04 02:11:47 | Dataset: PACS
