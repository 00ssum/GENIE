[37m[36mINFO[0m[0m 03/27 14:32:37 | Command :: /jsm0707/GENIE/train_all.py adam_sharpness config/resnet50_adam.yaml --algorithm ERM --test_envs 1 --dataset PACS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: ERM
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_adam.yaml']
	data_dir: data
	dataset: PACS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: adam_sharpness
	out_dir: train_output/PACS/ERM/[1]/250327_14-32-37_adam_sharpness
	out_root: train_output/PACS/ERM/[1]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [1]
	trial_seed: 0
	unique_name: 250327_14-32-37_adam_sharpness
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: adam
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
	attn_tune: False
	auto_lr: False
Dataset:
	[PACS] #envs=4, #classes=7
	env0: A (#2048)
	env1: C (#2344)
	env2: P (#1670)
	env3: S (#3929)

[37m[36mINFO[0m[0m 03/27 14:32:37 | n_steps = 5001
[37m[36mINFO[0m[0m 03/27 14:32:37 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/27 14:32:37 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/27 14:32:37 | 
[37m[36mINFO[0m[0m 03/27 14:32:37 | Testenv name escaping te_C -> te_C
[37m[36mINFO[0m[0m 03/27 14:32:37 | Test envs = [1], name = te_C
[37m[36mINFO[0m[0m 03/27 14:32:37 | Train environments: [0, 2, 3], Test environments: [1]
[37m[36mINFO[0m[0m 03/27 14:32:37 | Batch sizes for each domain: [32, 0, 32, 32] (total=96)
[37m[36mINFO[0m[0m 03/27 14:32:37 | steps-per-epoch for each domain: 51.22, 41.75, 98.25 -> min = 41.75
[37m[36mINFO[0m[0m 03/27 14:32:39 | # of params = 23522375
[37m[36mINFO[0m[0m 03/27 14:33:12 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/27 14:33:12 | 0.223348    0.252137    0.298979    0.291135    1.845758    0.268456    0.295844    0.223348    0.252137    0.385479    0.362275    0.243003    0.215287    0           0.000000    1.975161    1.182013    32.462682  
[37m[36mINFO[0m[0m 03/27 14:34:41 | 0.750533    0.784188    0.958556    0.937752    0.183944    0.954851    0.931540    0.750533    0.784188    0.989521    0.967066    0.931298    0.914650    200         4.790419    0.251227    0.178164    32.003145  
[37m[36mINFO[0m[0m 03/27 14:36:09 | 0.817697    0.844017    0.982038    0.955368    0.139138    0.979866    0.948655    0.817697    0.844017    0.995509    0.976048    0.970738    0.941401    400         9.580838    0.073492    0.179766    30.972172  
[37m[36mINFO[0m[0m 03/27 14:37:39 | 0.759062    0.760684    0.991009    0.965419    0.113135    0.988408    0.951100    0.759062    0.760684    0.999251    0.991018    0.985369    0.954140    600         14.371257   0.054006    0.179072    32.338785  
[37m[36mINFO[0m[0m 03/27 14:39:09 | 0.759595    0.794872    0.991705    0.957513    0.130106    0.993899    0.948655    0.759595    0.794872    0.997754    0.985030    0.983461    0.938854    800         19.161677   0.053407    0.179007    33.296134  
[37m[36mINFO[0m[0m 03/27 14:40:37 | 0.825693    0.850427    0.989837    0.958319    0.158491    0.988408    0.948655    0.825693    0.850427    0.997006    0.967066    0.984097    0.959236    1000        23.952096   0.030658    0.177929    30.939654  
[37m[36mINFO[0m[0m 03/27 14:42:06 | 0.780917    0.818376    0.985119    0.947757    0.186128    0.979866    0.926650    0.780917    0.818376    0.997754    0.979042    0.977735    0.937580    1200        28.742515   0.034194    0.178062    31.760258  
[37m[36mINFO[0m[0m 03/27 14:43:35 | 0.803305    0.844017    0.992727    0.963265    0.183290    0.993899    0.960880    0.803305    0.844017    0.997006    0.976048    0.987277    0.952866    1400        33.532934   0.021383    0.178466    32.928503  
[37m[36mINFO[0m[0m 03/27 14:45:05 | 0.757996    0.777778    0.990292    0.941629    0.222029    0.991458    0.929095    0.757996    0.777778    0.998503    0.976048    0.980916    0.919745    1600        38.323353   0.021383    0.178851    32.784559  
[37m[36mINFO[0m[0m 03/27 14:46:36 | 0.822495    0.831197    0.978707    0.940288    0.273926    0.971934    0.921760    0.822495    0.831197    0.990269    0.964072    0.973919    0.935032    1800        43.113772   0.023079    0.179471    33.121753  
[37m[36mINFO[0m[0m 03/27 14:48:04 | 0.817164    0.839744    0.989748    0.954048    0.187579    0.987187    0.941320    0.817164    0.839744    0.997006    0.973054    0.985051    0.947771    2000        47.904192   0.031257    0.178551    31.059191  
[37m[36mINFO[0m[0m 03/27 14:49:33 | 0.783049    0.809829    0.996693    0.956217    0.177533    0.998780    0.948655    0.783049    0.809829    0.999251    0.976048    0.992048    0.943949    2200        52.694611   0.015740    0.178584    32.299552  
[37m[36mINFO[0m[0m 03/27 14:51:04 | 0.803305    0.811966    0.998533    0.975244    0.114545    0.998780    0.968215    0.803305    0.811966    1.000000    0.997006    0.996819    0.960510    2400        57.485030   0.019460    0.178968    33.960041  
[37m[36mINFO[0m[0m 03/27 14:52:32 | 0.790512    0.820513    0.991068    0.957560    0.196582    0.990848    0.943765    0.790512    0.820513    0.994760    0.976048    0.987595    0.952866    2600        62.275449   0.021096    0.178128    30.839247  
[37m[36mINFO[0m[0m 03/27 14:54:00 | 0.825693    0.826923    0.997029    0.964905    0.134603    0.997559    0.955990    0.825693    0.826923    0.999251    0.982036    0.994275    0.956688    2800        67.065868   0.021036    0.178687    31.500814  
[37m[36mINFO[0m[0m 03/27 14:55:29 | 0.787846    0.801282    0.995409    0.958880    0.183576    0.996949    0.951100    0.787846    0.801282    0.998503    0.979042    0.990776    0.946497    3000        71.856287   0.013690    0.179049    31.972432  
[37m[36mINFO[0m[0m 03/27 14:56:59 | 0.812900    0.829060    0.995218    0.968106    0.141439    0.993289    0.960880    0.812900    0.829060    1.000000    0.988024    0.992366    0.955414    3200        76.646707   0.022619    0.179809    32.504086  
[37m[36mINFO[0m[0m 03/27 14:58:29 | 0.793710    0.805556    0.996098    0.954612    0.193664    0.993289    0.951100    0.793710    0.805556    0.998503    0.970060    0.996501    0.942675    3400        81.437126   0.011950    0.180454    32.331521  
[37m[36mINFO[0m[0m 03/27 14:59:57 | 0.812900    0.820513    0.990201    0.945188    0.197330    0.987797    0.926650    0.812900    0.820513    0.997754    0.970060    0.985051    0.938854    3600        86.227545   0.023777    0.180325    30.959733  
[37m[36mINFO[0m[0m 03/27 15:01:25 | 0.787313    0.786325    0.995024    0.960854    0.152279    0.992068    0.951100    0.787313    0.786325    1.000000    0.976048    0.993003    0.955414    3800        91.017964   0.016673    0.179993    31.025363  
[37m[36mINFO[0m[0m 03/27 15:02:55 | 0.790512    0.809829    0.996458    0.958616    0.173486    0.995119    0.948655    0.790512    0.809829    0.997754    0.973054    0.996501    0.954140    4000        95.808383   0.012262    0.181187    32.019773  
[37m[36mINFO[0m[0m 03/27 15:04:24 | 0.794243    0.841880    0.997126    0.964424    0.125693    0.998170    0.958435    0.794243    0.841880    0.999251    0.973054    0.993957    0.961783    4200        100.598802  0.018097    0.179946    31.344883  
[37m[36mINFO[0m[0m 03/27 15:05:52 | 0.808102    0.824786    0.996788    0.962909    0.137608    0.996949    0.955990    0.808102    0.824786    0.998503    0.976048    0.994911    0.956688    4400        105.389222  0.012542    0.179199    31.387549  
[37m[36mINFO[0m[0m 03/27 15:07:22 | 0.832090    0.848291    0.999275    0.964400    0.164237    0.998780    0.951100    0.832090    0.848291    1.000000    0.979042    0.999046    0.963057    4600        110.179641  0.011983    0.177822    32.881096  
[37m[36mINFO[0m[0m 03/27 15:08:53 | 0.797974    0.822650    0.999326    0.963516    0.132462    1.000000    0.953545    0.797974    0.822650    0.999251    0.979042    0.998728    0.957962    4800        114.970060  0.012596    0.178815    34.061557  
[37m[36mINFO[0m[0m 03/27 15:10:22 | 0.809701    0.829060    0.997344    0.966030    0.181488    0.995119    0.955990    0.809701    0.829060    0.998503    0.979042    0.998410    0.963057    5000        119.760479  0.010380    0.179805    31.612136  
[37m[36mINFO[0m[0m 03/27 15:10:43 | Cumulative gradient change saved at train_output/PACS/ERM/[1]/250327_14-32-37_adam_sharpness/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/27 15:10:44 | ---
[37m[36mINFO[0m[0m 03/27 15:10:44 | test-domain validation(oracle) = 82.569%
[37m[36mINFO[0m[0m 03/27 15:10:44 | training-domain validation(iid) = 80.330%
[37m[36mINFO[0m[0m 03/27 15:10:44 | last = 80.970%
[37m[36mINFO[0m[0m 03/27 15:10:44 | last (inD) = 96.603%
[37m[36mINFO[0m[0m 03/27 15:10:44 | training-domain validation (iid, inD) = 97.524%
[37m[36mINFO[0m[0m 03/27 15:10:44 | === Summary ===
[37m[36mINFO[0m[0m 03/27 15:10:44 | Command: /jsm0707/GENIE/train_all.py adam_sharpness config/resnet50_adam.yaml --algorithm ERM --test_envs 1 --dataset PACS
[37m[36mINFO[0m[0m 03/27 15:10:44 | Unique name: 250327_14-32-37_adam_sharpness
[37m[36mINFO[0m[0m 03/27 15:10:44 | Out path: train_output/PACS/ERM/[1]/250327_14-32-37_adam_sharpness
[37m[36mINFO[0m[0m 03/27 15:10:44 | Algorithm: ERM
[37m[36mINFO[0m[0m 03/27 15:10:44 | Dataset: PACS
