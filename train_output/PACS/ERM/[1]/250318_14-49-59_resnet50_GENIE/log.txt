[37m[36mINFO[0m[0m 03/18 14:49:59 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm ERM --test_envs 1 --dataset PACS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: ERM
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: PACS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE
	out_dir: train_output/PACS/ERM/[1]/250318_14-49-59_resnet50_GENIE
	out_root: train_output/PACS/ERM/[1]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [1]
	trial_seed: 0
	unique_name: 250318_14-49-59_resnet50_GENIE
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[PACS] #envs=4, #classes=7
	env0: A (#2048)
	env1: C (#2344)
	env2: P (#1670)
	env3: S (#3929)

[37m[36mINFO[0m[0m 03/18 14:49:59 | n_steps = 5001
[37m[36mINFO[0m[0m 03/18 14:49:59 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/18 14:49:59 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 03/18 14:49:59 | 
[37m[36mINFO[0m[0m 03/18 14:49:59 | Testenv name escaping te_C -> te_C
[37m[36mINFO[0m[0m 03/18 14:49:59 | Test envs = [1], name = te_C
[37m[36mINFO[0m[0m 03/18 14:49:59 | Train environments: [0, 2, 3], Test environments: [1]
[37m[36mINFO[0m[0m 03/18 14:49:59 | Batch sizes for each domain: [32, 0, 32, 32] (total=96)
[37m[36mINFO[0m[0m 03/18 14:49:59 | steps-per-epoch for each domain: 51.22, 41.75, 98.25 -> min = 41.75
[37m[36mINFO[0m[0m 03/18 14:50:00 | # of params = 23522375
[37m[36mINFO[0m[0m 03/18 14:50:33 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/18 14:50:33 | 0.248934    0.264957    0.271637    0.271134    1.864688    0.237340    0.264059    0.248934    0.264957    0.370509    0.335329    0.207061    0.214013    0           0.000000    1.975161    1.095201    32.049716  
[37m[36mINFO[0m[0m 03/18 14:51:48 | 0.728678    0.741453    0.964413    0.956688    0.134483    0.960952    0.955990    0.728678    0.741453    0.991766    0.979042    0.940522    0.935032    200         4.790419    0.307560    0.217953    31.189871  
[37m[36mINFO[0m[0m 03/18 14:53:18 | 0.767591    0.799145    0.973387    0.950649    0.138601    0.968883    0.933985    0.767591    0.799145    0.993263    0.988024    0.958015    0.929936    400         9.580838    0.096789    0.297074    31.267107  
[37m[36mINFO[0m[0m 03/18 14:54:42 | 0.725480    0.745726    0.988058    0.964136    0.113038    0.987187    0.960880    0.725480    0.745726    0.999251    0.985030    0.977735    0.946497    600         14.371257   0.058888    0.254787    32.736659  
[37m[36mINFO[0m[0m 03/18 14:55:59 | 0.781450    0.788462    0.991487    0.968921    0.108104    0.992068    0.963325    0.781450    0.788462    0.999251    0.988024    0.983142    0.955414    800         19.161677   0.036040    0.221406    32.969376  
[37m[36mINFO[0m[0m 03/18 14:57:32 | 0.776652    0.805556    0.992857    0.966417    0.135032    0.992678    0.951100    0.776652    0.805556    0.999251    0.994012    0.986641    0.954140    1000        23.952096   0.031525    0.303000    31.792215  
[37m[36mINFO[0m[0m 03/18 14:58:50 | 0.803838    0.822650    0.987908    0.963250    0.150186    0.987187    0.943765    0.803838    0.822650    0.996257    0.988024    0.980280    0.957962    1200        28.742515   0.028025    0.227785    32.395632  
[37m[36mINFO[0m[0m 03/18 15:00:11 | 0.783582    0.818376    0.993038    0.963882    0.149262    0.989628    0.948655    0.783582    0.818376    0.997754    0.985030    0.991730    0.957962    1400        33.532934   0.018778    0.239779    33.436754  
[37m[36mINFO[0m[0m 03/18 15:01:43 | 0.788380    0.824786    0.995968    0.970402    0.128203    0.997559    0.968215    0.788380    0.824786    0.999251    0.985030    0.991094    0.957962    1600        38.323353   0.017382    0.305107    30.963530  
[37m[36mINFO[0m[0m 03/18 15:03:01 | 0.824094    0.846154    0.992444    0.961393    0.165543    0.991458    0.953545    0.824094    0.846154    0.997006    0.979042    0.988868    0.951592    1800        43.113772   0.018895    0.220123    33.515572  
[37m[36mINFO[0m[0m 03/18 15:04:30 | 0.799041    0.820513    0.997295    0.967899    0.117988    0.996339    0.955990    0.799041    0.820513    1.000000    0.991018    0.995547    0.956688    2000        47.904192   0.014658    0.290262    31.424592  
[37m[36mINFO[0m[0m 03/18 15:05:55 | 0.796908    0.826923    0.998338    0.967418    0.143522    0.997559    0.958435    0.796908    0.826923    1.000000    0.982036    0.997455    0.961783    2200        52.694611   0.008419    0.263435    32.136511  
[37m[36mINFO[0m[0m 03/18 15:07:11 | 0.773987    0.790598    0.998957    0.969942    0.123351    0.998780    0.951100    0.773987    0.790598    1.000000    0.988024    0.998092    0.970701    2400        57.485030   0.008022    0.220504    31.774765  
[37m[36mINFO[0m[0m 03/18 15:08:44 | 0.779851    0.805556    0.998418    0.964846    0.144645    0.999390    0.951100    0.779851    0.805556    1.000000    0.988024    0.995865    0.955414    2600        62.275449   0.008755    0.306367    31.557739  
[37m[36mINFO[0m[0m 03/18 15:10:01 | 0.797974    0.822650    0.995822    0.968199    0.124639    0.995119    0.963325    0.797974    0.822650    0.997754    0.982036    0.994593    0.959236    2800        67.065868   0.011606    0.230921    31.003182  
[37m[36mINFO[0m[0m 03/18 15:11:20 | 0.792644    0.814103    0.997470    0.971444    0.134968    0.996339    0.955990    0.792644    0.814103    0.999251    0.994012    0.996819    0.964331    3000        71.856287   0.006903    0.235846    32.106451  
[37m[36mINFO[0m[0m 03/18 15:12:54 | 0.826226    0.824786    0.996783    0.965847    0.172742    0.995119    0.958435    0.826226    0.824786    1.000000    0.976048    0.995229    0.963057    3200        76.646707   0.005378    0.308556    32.130725  
[37m[36mINFO[0m[0m 03/18 15:14:11 | 0.799574    0.826923    0.999441    0.974912    0.133007    0.999390    0.970660    0.799574    0.826923    0.999251    0.991018    0.999682    0.963057    3400        81.437126   0.004926    0.220094    32.861086  
[37m[36mINFO[0m[0m 03/18 15:15:43 | 0.777719    0.816239    0.998020    0.973638    0.126783    0.997559    0.970660    0.777719    0.816239    1.000000    0.991018    0.996501    0.959236    3600        86.227545   0.006860    0.297724    32.900081  
[37m[36mINFO[0m[0m 03/18 15:17:06 | 0.784648    0.820513    0.997859    0.969346    0.125240    0.998780    0.963325    0.784648    0.820513    0.999251    0.988024    0.995547    0.956688    3800        91.017964   0.010872    0.255143    31.246349  
[37m[36mINFO[0m[0m 03/18 15:18:20 | 0.798507    0.814103    0.997278    0.966442    0.141245    0.997559    0.958435    0.798507    0.814103    1.000000    0.988024    0.994275    0.952866    4000        95.808383   0.005689    0.216878    30.904174  
[37m[36mINFO[0m[0m 03/18 15:19:52 | 0.779851    0.805556    0.999229    0.967498    0.154942    0.999390    0.963325    0.779851    0.805556    0.999251    0.985030    0.999046    0.954140    4200        100.598802  0.005608    0.305491    31.305901  
[37m[36mINFO[0m[0m 03/18 15:21:08 | 0.771855    0.807692    0.997848    0.963907    0.171492    0.996949    0.955990    0.771855    0.807692    0.998503    0.979042    0.998092    0.956688    4400        105.389222  0.005576    0.227420    30.520231  
[37m[36mINFO[0m[0m 03/18 15:22:28 | 0.779851    0.801282    0.998708    0.972387    0.144045    0.998780    0.958435    0.779851    0.801282    0.999251    0.988024    0.998092    0.970701    4600        110.179641  0.006063    0.236909    31.782161  
[37m[36mINFO[0m[0m 03/18 15:24:01 | 0.821962    0.861111    0.998805    0.965295    0.156566    0.999390    0.958435    0.821962    0.861111    0.999251    0.982036    0.997774    0.955414    4800        114.970060  0.005837    0.311840    30.719688  
[37m[36mINFO[0m[0m 03/18 15:25:17 | 0.785714    0.816239    0.999160    0.969531    0.169772    0.999390    0.968215    0.785714    0.816239    1.000000    0.976048    0.998092    0.964331    5000        119.760479  0.004326    0.222634    31.949384  
[37m[36mINFO[0m[0m 03/18 15:25:17 | Cumulative gradient change saved at train_output/PACS/ERM/[1]/250318_14-49-59_resnet50_GENIE/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 03/18 15:25:18 | ---
[37m[36mINFO[0m[0m 03/18 15:25:18 | test-domain validation(oracle) = 82.196%
[37m[36mINFO[0m[0m 03/18 15:25:18 | training-domain validation(iid) = 79.957%
[37m[36mINFO[0m[0m 03/18 15:25:18 | last = 78.571%
[37m[36mINFO[0m[0m 03/18 15:25:18 | last (inD) = 96.953%
[37m[36mINFO[0m[0m 03/18 15:25:18 | training-domain validation (iid, inD) = 97.491%
[37m[36mINFO[0m[0m 03/18 15:25:18 | === Summary ===
[37m[36mINFO[0m[0m 03/18 15:25:18 | Command: /jsm0707/GENIE/train_all.py resnet50_GENIE config/resnet50_GENIE.yaml --algorithm ERM --test_envs 1 --dataset PACS
[37m[36mINFO[0m[0m 03/18 15:25:18 | Unique name: 250318_14-49-59_resnet50_GENIE
[37m[36mINFO[0m[0m 03/18 15:25:18 | Out path: train_output/PACS/ERM/[1]/250318_14-49-59_resnet50_GENIE
[37m[36mINFO[0m[0m 03/18 15:25:18 | Algorithm: ERM
[37m[36mINFO[0m[0m 03/18 15:25:18 | Dataset: PACS
