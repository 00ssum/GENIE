[37m[36mINFO[0m[0m 01/26 20:15:43 | Command :: /jsm0707/Large-scale/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm SAM --test_envs 0 2 3 --dataset PACS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: SAM
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_sgd.yaml']
	data_dir: data
	dataset: PACS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_sgd
	out_dir: train_output/PACS/SAM/[0, 2, 3]/250126_20-15-43_resnet50_sgd
	out_root: train_output/PACS/SAM/[0, 2, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 2, 3]
	trial_seed: 0
	unique_name: 250126_20-15-43_resnet50_sgd
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: sgd
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	rho: 0.05
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[PACS] #envs=4, #classes=7
	env0: A (#2048)
	env1: C (#2344)
	env2: P (#1670)
	env3: S (#3929)

[37m[36mINFO[0m[0m 01/26 20:15:43 | n_steps = 5001
[37m[36mINFO[0m[0m 01/26 20:15:43 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 01/26 20:15:43 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 01/26 20:15:43 | 
[37m[36mINFO[0m[0m 01/26 20:15:43 | Testenv name escaping te_A_P_S -> te_A_P_S
[37m[36mINFO[0m[0m 01/26 20:15:43 | Test envs = [0, 2, 3], name = te_A_P_S
[37m[36mINFO[0m[0m 01/26 20:15:43 | Train environments: [1], Test environments: [0, 2, 3]
[37m[36mINFO[0m[0m 01/26 20:15:43 | Batch sizes for each domain: [0, 32, 0, 0] (total=32)
[37m[36mINFO[0m[0m 01/26 20:15:43 | steps-per-epoch for each domain: 58.62 -> min = 58.62
[37m[36mINFO[0m[0m 01/26 20:15:44 | # of params = 23522375
[37m[36mINFO[0m[0m 01/26 20:16:11 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 01/26 20:16:11 | 0.127722    0.129414    0.123667    0.113248    2.011602    0.225747    0.190709    0.123667    0.113248    0.097305    0.128743    0.060115    0.068790    0           0.000000    2.494530    1.442103    24.663903  
[37m[36mINFO[0m[0m 01/26 20:17:07 | 0.229807    0.223525    0.309701    0.363248    1.792236    0.273337    0.251834    0.309701    0.363248    0.106287    0.125749    0.309796    0.292994    200         3.411514    2.038353    0.162841    23.688748  
[37m[36mINFO[0m[0m 01/26 20:18:06 | 0.304690    0.297227    0.468017    0.502137    1.669269    0.351434    0.334963    0.468017    0.502137    0.222305    0.239521    0.340331    0.317197    400         6.823028    1.889556    0.172960    24.546259  
[37m[36mINFO[0m[0m 01/26 20:19:02 | 0.344575    0.337063    0.537313    0.576923    1.375060    0.366077    0.354523    0.537313    0.576923    0.315868    0.320359    0.351781    0.336306    600         10.234542   1.745230    0.153747    24.995921  
[37m[36mINFO[0m[0m 01/26 20:20:03 | 0.529211    0.497894    0.696695    0.726496    1.019431    0.521660    0.503667    0.696695    0.726496    0.653443    0.616766    0.412532    0.373248    800         13.646055   1.511476    0.171226    25.676520  
[37m[36mINFO[0m[0m 01/26 20:21:01 | 0.604448    0.578552    0.811834    0.818376    0.749962    0.568639    0.540342    0.811834    0.818376    0.738024    0.703593    0.506679    0.491720    1000        17.057569   1.243103    0.165384    24.904284  
[37m[36mINFO[0m[0m 01/26 20:21:58 | 0.612356    0.587024    0.820362    0.844017    0.591606    0.577791    0.559902    0.820362    0.844017    0.731287    0.691617    0.527990    0.509554    1200        20.469083   1.062916    0.159389    25.302798  
[37m[36mINFO[0m[0m 01/26 20:23:00 | 0.638832    0.619226    0.849147    0.878205    0.492410    0.605857    0.589242    0.849147    0.878205    0.749251    0.715569    0.561387    0.552866    1400        23.880597   0.944646    0.179336    25.848968  
[37m[36mINFO[0m[0m 01/26 20:23:58 | 0.641974    0.615509    0.874733    0.882479    0.432614    0.621721    0.601467    0.874733    0.882479    0.752994    0.712575    0.551209    0.532484    1600        27.292111   0.844847    0.153405    26.690168  
[37m[36mINFO[0m[0m 01/26 20:24:56 | 0.665870    0.639119    0.894989    0.899573    0.379007    0.665040    0.665037    0.894989    0.899573    0.772455    0.718563    0.560115    0.533758    1800        30.703625   0.786699    0.162988    24.811516  
[37m[36mINFO[0m[0m 01/26 20:25:56 | 0.693906    0.671249    0.903518    0.914530    0.331257    0.691275    0.691932    0.903518    0.914530    0.808383    0.757485    0.582061    0.564331    2000        34.115139   0.709230    0.172219    25.385233  
[37m[36mINFO[0m[0m 01/26 20:26:51 | 0.700381    0.673968    0.919510    0.916667    0.310491    0.700427    0.679707    0.919510    0.916667    0.806886    0.757485    0.593830    0.584713    2200        37.526652   0.698745    0.150504    25.424019  
[37m[36mINFO[0m[0m 01/26 20:27:53 | 0.714181    0.690332    0.926439    0.925214    0.275798    0.707138    0.696822    0.926439    0.925214    0.821856    0.775449    0.613550    0.598726    2400        40.938166   0.631164    0.186915    24.040666  
[37m[36mINFO[0m[0m 01/26 20:28:50 | 0.742944    0.723997    0.930171    0.929487    0.246061    0.748627    0.718826    0.930171    0.929487    0.866018    0.835329    0.614186    0.617834    2600        44.349680   0.607262    0.167004    23.222951  
[37m[36mINFO[0m[0m 01/26 20:29:44 | 0.725261    0.707208    0.941365    0.935897    0.226087    0.717511    0.701711    0.941365    0.935897    0.842814    0.817365    0.615458    0.602548    2800        47.761194   0.560497    0.155559    22.438880  
[37m[36mINFO[0m[0m 01/26 20:30:42 | 0.713922    0.696628    0.937633    0.938034    0.217522    0.703478    0.687042    0.937633    0.938034    0.836826    0.805389    0.601463    0.597452    3000        51.172708   0.535285    0.165769    25.360249  
[37m[36mINFO[0m[0m 01/26 20:31:38 | 0.739229    0.717064    0.951493    0.948718    0.199768    0.741916    0.709046    0.951493    0.948718    0.868263    0.838323    0.607506    0.603822    3200        54.584222   0.508584    0.157298    24.217112  
[37m[36mINFO[0m[0m 01/26 20:32:35 | 0.760898    0.742171    0.954691    0.948718    0.185910    0.769372    0.731051    0.954691    0.948718    0.883234    0.871257    0.630089    0.624204    3400        57.995736   0.498936    0.165610    23.200747  
[37m[36mINFO[0m[0m 01/26 20:33:31 | 0.758344    0.741643    0.958422    0.946581    0.175643    0.771812    0.738386    0.958422    0.946581    0.879491    0.871257    0.623728    0.615287    3600        61.407249   0.481649    0.159908    24.041745  
[37m[36mINFO[0m[0m 01/26 20:34:28 | 0.741935    0.725966    0.954691    0.952991    0.171084    0.768761    0.735941    0.954691    0.952991    0.885479    0.871257    0.571565    0.570701    3800        64.818763   0.455072    0.161941    24.578501  
[37m[36mINFO[0m[0m 01/26 20:35:28 | 0.755939    0.736099    0.960021    0.957265    0.162341    0.771202    0.731051    0.960021    0.957265    0.888473    0.877246    0.608142    0.600000    4000        68.230277   0.418561    0.179076    23.848899  
[37m[36mINFO[0m[0m 01/26 20:36:26 | 0.756092    0.738501    0.966418    0.952991    0.161236    0.760830    0.738386    0.966418    0.952991    0.877994    0.859281    0.629453    0.617834    4200        71.641791   0.427268    0.166303    25.016053  
[37m[36mINFO[0m[0m 01/26 20:37:21 | 0.756683    0.745901    0.965885    0.957265    0.147612    0.767541    0.748166    0.965885    0.957265    0.883234    0.874251    0.619275    0.615287    4400        75.053305   0.400301    0.153948    24.413640  
[37m[36mINFO[0m[0m 01/26 20:38:21 | 0.765294    0.745533    0.969083    0.955128    0.140360    0.782184    0.745721    0.969083    0.955128    0.889970    0.883234    0.623728    0.607643    4600        78.464819   0.394388    0.182285    23.321099  
[37m[36mINFO[0m[0m 01/26 20:39:17 | 0.760962    0.740094    0.970149    0.952991    0.144098    0.770592    0.738386    0.970149    0.952991    0.886976    0.874251    0.625318    0.607643    4800        81.876333   0.368983    0.160300    23.882364  
[37m[36mINFO[0m[0m 01/26 20:40:13 | 0.756173    0.739291    0.974947    0.959402    0.135688    0.757779    0.733496    0.974947    0.959402    0.878743    0.865269    0.631997    0.619108    5000        85.287846   0.372679    0.159876    23.880156  
[37m[36mINFO[0m[0m 01/26 20:40:13 | Cumulative gradient change saved at train_output/PACS/SAM/[0, 2, 3]/250126_20-15-43_resnet50_sgd/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 01/26 20:40:15 | ---
[37m[36mINFO[0m[0m 01/26 20:40:15 | test-domain validation(oracle) = 75.668%
[37m[36mINFO[0m[0m 01/26 20:40:15 | training-domain validation(iid) = 75.617%
[37m[36mINFO[0m[0m 01/26 20:40:15 | last = 75.617%
[37m[36mINFO[0m[0m 01/26 20:40:15 | last (inD) = 95.940%
[37m[36mINFO[0m[0m 01/26 20:40:15 | training-domain validation (iid, inD) = 95.940%
[37m[36mINFO[0m[0m 01/26 20:40:15 | === Summary ===
[37m[36mINFO[0m[0m 01/26 20:40:15 | Command: /jsm0707/Large-scale/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm SAM --test_envs 0 2 3 --dataset PACS
[37m[36mINFO[0m[0m 01/26 20:40:15 | Unique name: 250126_20-15-43_resnet50_sgd
[37m[36mINFO[0m[0m 01/26 20:40:15 | Out path: train_output/PACS/SAM/[0, 2, 3]/250126_20-15-43_resnet50_sgd
[37m[36mINFO[0m[0m 01/26 20:40:15 | Algorithm: SAM
[37m[36mINFO[0m[0m 01/26 20:40:15 | Dataset: PACS
