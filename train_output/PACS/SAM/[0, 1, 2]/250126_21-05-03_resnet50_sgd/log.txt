[37m[36mINFO[0m[0m 01/26 21:05:03 | Command :: /jsm0707/Large-scale/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm SAM --test_envs 0 1 2 --dataset PACS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: SAM
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_sgd.yaml']
	data_dir: data
	dataset: PACS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_sgd
	out_dir: train_output/PACS/SAM/[0, 1, 2]/250126_21-05-03_resnet50_sgd
	out_root: train_output/PACS/SAM/[0, 1, 2]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 1, 2]
	trial_seed: 0
	unique_name: 250126_21-05-03_resnet50_sgd
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: sgd
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	rho: 0.05
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[PACS] #envs=4, #classes=7
	env0: A (#2048)
	env1: C (#2344)
	env2: P (#1670)
	env3: S (#3929)

[37m[36mINFO[0m[0m 01/26 21:05:03 | n_steps = 5001
[37m[36mINFO[0m[0m 01/26 21:05:03 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 01/26 21:05:03 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 01/26 21:05:03 | 
[37m[36mINFO[0m[0m 01/26 21:05:03 | Testenv name escaping te_A_C_P -> te_A_C_P
[37m[36mINFO[0m[0m 01/26 21:05:03 | Test envs = [0, 1, 2], name = te_A_C_P
[37m[36mINFO[0m[0m 01/26 21:05:03 | Train environments: [3], Test environments: [0, 1, 2]
[37m[36mINFO[0m[0m 01/26 21:05:03 | Batch sizes for each domain: [0, 0, 0, 32] (total=32)
[37m[36mINFO[0m[0m 01/26 21:05:03 | steps-per-epoch for each domain: 98.25 -> min = 98.25
[37m[36mINFO[0m[0m 01/26 21:05:04 | # of params = 23522375
[37m[36mINFO[0m[0m 01/26 21:05:32 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 01/26 21:05:32 | 0.138741    0.143662    0.048346    0.075159    2.120323    0.225747    0.190709    0.095416    0.117521    0.095060    0.122754    0.048346    0.075159    0           0.000000    2.885298    1.068320    26.606067  
[37m[36mINFO[0m[0m 01/26 21:06:35 | 0.192263    0.182721    0.431616    0.392357    1.685356    0.202563    0.198044    0.222281    0.209402    0.151946    0.140719    0.431616    0.392357    200         2.035623    1.929872    0.186068    25.998863  
[37m[36mINFO[0m[0m 01/26 21:07:30 | 0.208537    0.190828    0.526399    0.538854    1.446124    0.179378    0.163814    0.279318    0.264957    0.166916    0.143713    0.526399    0.538854    400         4.071247    1.693365    0.155458    22.822289  
[37m[36mINFO[0m[0m 01/26 21:08:29 | 0.236558    0.221314    0.596692    0.611465    1.191398    0.200122    0.190709    0.309701    0.290598    0.199850    0.182635    0.596692    0.611465    600         6.106870    1.496590    0.180262    23.241794  
[37m[36mINFO[0m[0m 01/26 21:09:25 | 0.248627    0.230109    0.658397    0.668790    1.019001    0.210494    0.193154    0.323561    0.305556    0.211826    0.191617    0.658397    0.668790    800         8.142494    1.344595    0.157249    24.052333  
[37m[36mINFO[0m[0m 01/26 21:10:20 | 0.262926    0.251678    0.709606    0.713376    0.848980    0.221477    0.224939    0.342751    0.320513    0.224551    0.209581    0.709606    0.713376    1000        10.178117   1.207301    0.156599    23.107063  
[37m[36mINFO[0m[0m 01/26 21:11:19 | 0.260287    0.242083    0.750318    0.749045    0.796579    0.224527    0.210269    0.327292    0.318376    0.229042    0.197605    0.750318    0.749045    1200        12.213740   1.111895    0.176382    23.688858  
[37m[36mINFO[0m[0m 01/26 21:12:13 | 0.275189    0.269694    0.800254    0.812739    0.654458    0.239780    0.229829    0.347015    0.354701    0.238772    0.224551    0.800254    0.812739    1400        14.249364   0.987307    0.150879    23.610052  
[37m[36mINFO[0m[0m 01/26 21:13:15 | 0.274706    0.262875    0.816794    0.811465    0.645601    0.239170    0.237164    0.341684    0.341880    0.243263    0.209581    0.816794    0.811465    1600        16.284987   0.867934    0.192717    23.507560  
[37m[36mINFO[0m[0m 01/26 21:14:11 | 0.313287    0.306356    0.842875    0.835669    0.532338    0.286150    0.288509    0.375267    0.376068    0.278443    0.254491    0.842875    0.835669    1800        18.320611   0.867417    0.156945    24.318187  
[37m[36mINFO[0m[0m 01/26 21:15:09 | 0.324127    0.324109    0.861005    0.859873    0.452302    0.293472    0.300733    0.386994    0.408120    0.291916    0.263473    0.861005    0.859873    2000        20.356234   0.748455    0.172076    23.408625  
[37m[36mINFO[0m[0m 01/26 21:16:07 | 0.342565    0.332401    0.869275    0.858599    0.454502    0.310555    0.308068    0.403518    0.401709    0.313623    0.287425    0.869275    0.858599    2200        22.391858   0.729359    0.161014    25.094464  
[37m[36mINFO[0m[0m 01/26 21:17:02 | 0.367246    0.356629    0.883588    0.872611    0.420368    0.339231    0.325183    0.430171    0.442308    0.332335    0.302395    0.883588    0.872611    2400        24.427481   0.656294    0.153520    24.193311  
[37m[36mINFO[0m[0m 01/26 21:18:00 | 0.382266    0.367145    0.888995    0.878981    0.391391    0.356315    0.344743    0.442431    0.427350    0.348054    0.329341    0.888995    0.878981    2600        26.463104   0.669200    0.172054    23.078713  
[37m[36mINFO[0m[0m 01/26 21:18:55 | 0.378779    0.363157    0.893448    0.882803    0.400079    0.358145    0.344743    0.441365    0.412393    0.336826    0.332335    0.893448    0.882803    2800        28.498728   0.611822    0.151236    24.332060  
[37m[36mINFO[0m[0m 01/26 21:19:58 | 0.394858    0.387396    0.904262    0.905732    0.331391    0.366687    0.352078    0.469083    0.480769    0.348802    0.329341    0.904262    0.905732    3000        30.534351   0.608173    0.196610    23.714591  
[37m[36mINFO[0m[0m 01/26 21:20:54 | 0.389910    0.386200    0.912214    0.901911    0.317486    0.369128    0.364303    0.456290    0.467949    0.344311    0.326347    0.912214    0.901911    3200        32.569975   0.572435    0.158872    24.386806  
[37m[36mINFO[0m[0m 01/26 21:21:52 | 0.409155    0.397158    0.913804    0.896815    0.313997    0.391092    0.374083    0.473348    0.470085    0.363024    0.347305    0.913804    0.896815    3400        34.605598   0.560806    0.176470    23.037701  
[37m[36mINFO[0m[0m 01/26 21:22:50 | 0.384897    0.373578    0.917621    0.899363    0.321739    0.369128    0.352078    0.443497    0.442308    0.342066    0.326347    0.917621    0.899363    3600        36.641221   0.535010    0.161023    25.195036  
[37m[36mINFO[0m[0m 01/26 21:23:43 | 0.408870    0.391109    0.927163    0.912102    0.278060    0.388652    0.369193    0.478678    0.465812    0.359281    0.338323    0.927163    0.912102    3800        38.676845   0.501873    0.151710    22.829304  
[37m[36mINFO[0m[0m 01/26 21:24:46 | 0.429005    0.422730    0.921120    0.903185    0.279309    0.406345    0.396088    0.498934    0.512821    0.381737    0.359281    0.921120    0.903185    4000        40.712468   0.476832    0.182741    25.697653  
[37m[36mINFO[0m[0m 01/26 21:25:41 | 0.426723    0.424577    0.935751    0.922293    0.267834    0.399634    0.396088    0.508529    0.536325    0.372006    0.341317    0.935751    0.922293    4200        42.748092   0.462340    0.154037    24.016162  
[37m[36mINFO[0m[0m 01/26 21:26:45 | 0.430847    0.423297    0.935751    0.917197    0.261304    0.408786    0.396088    0.504264    0.523504    0.379491    0.350299    0.935751    0.917197    4400        44.783715   0.474052    0.196636    24.841808  
[37m[36mINFO[0m[0m 01/26 21:27:41 | 0.421278    0.410209    0.940522    0.927389    0.239520    0.403905    0.403423    0.498401    0.497863    0.361527    0.329341    0.940522    0.927389    4600        46.819338   0.430681    0.155436    24.402021  
[37m[36mINFO[0m[0m 01/26 21:28:38 | 0.427334    0.411368    0.945611    0.929936    0.230814    0.412447    0.393643    0.496802    0.502137    0.372754    0.338323    0.945611    0.929936    4800        48.854962   0.423536    0.169197    23.304898  
[37m[36mINFO[0m[0m 01/26 21:29:36 | 0.418854    0.409677    0.947201    0.929936    0.227203    0.391702    0.383863    0.493603    0.497863    0.371257    0.347305    0.947201    0.929936    5000        50.890585   0.391549    0.156400    26.578453  
[37m[36mINFO[0m[0m 01/26 21:29:36 | Cumulative gradient change saved at train_output/PACS/SAM/[0, 1, 2]/250126_21-05-03_resnet50_sgd/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 01/26 21:29:37 | ---
[37m[36mINFO[0m[0m 01/26 21:29:37 | test-domain validation(oracle) = 42.672%
[37m[36mINFO[0m[0m 01/26 21:29:37 | training-domain validation(iid) = 42.733%
[37m[36mINFO[0m[0m 01/26 21:29:37 | last = 41.885%
[37m[36mINFO[0m[0m 01/26 21:29:37 | last (inD) = 92.994%
[37m[36mINFO[0m[0m 01/26 21:29:37 | training-domain validation (iid, inD) = 92.994%
[37m[36mINFO[0m[0m 01/26 21:29:37 | === Summary ===
[37m[36mINFO[0m[0m 01/26 21:29:37 | Command: /jsm0707/Large-scale/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm SAM --test_envs 0 1 2 --dataset PACS
[37m[36mINFO[0m[0m 01/26 21:29:37 | Unique name: 250126_21-05-03_resnet50_sgd
[37m[36mINFO[0m[0m 01/26 21:29:37 | Out path: train_output/PACS/SAM/[0, 1, 2]/250126_21-05-03_resnet50_sgd
[37m[36mINFO[0m[0m 01/26 21:29:37 | Algorithm: SAM
[37m[36mINFO[0m[0m 01/26 21:29:37 | Dataset: PACS
