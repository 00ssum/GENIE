[37m[36mINFO[0m[0m 01/26 20:40:19 | Command :: /jsm0707/Large-scale/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm SAM --test_envs 0 1 3 --dataset PACS
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: SAM
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_sgd.yaml']
	data_dir: data
	dataset: PACS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_sgd
	out_dir: train_output/PACS/SAM/[0, 1, 3]/250126_20-40-19_resnet50_sgd
	out_root: train_output/PACS/SAM/[0, 1, 3]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: None
	tb_freq: 10
	test_envs: [0, 1, 3]
	trial_seed: 0
	unique_name: 250126_20-40-19_resnet50_sgd
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: sgd
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	rho: 0.05
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[PACS] #envs=4, #classes=7
	env0: A (#2048)
	env1: C (#2344)
	env2: P (#1670)
	env3: S (#3929)

[37m[36mINFO[0m[0m 01/26 20:40:19 | n_steps = 5001
[37m[36mINFO[0m[0m 01/26 20:40:19 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 01/26 20:40:19 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 01/26 20:40:19 | 
[37m[36mINFO[0m[0m 01/26 20:40:19 | Testenv name escaping te_A_C_S -> te_A_C_S
[37m[36mINFO[0m[0m 01/26 20:40:19 | Test envs = [0, 1, 3], name = te_A_C_S
[37m[36mINFO[0m[0m 01/26 20:40:19 | Train environments: [2], Test environments: [0, 1, 3]
[37m[36mINFO[0m[0m 01/26 20:40:19 | Batch sizes for each domain: [0, 0, 32, 0] (total=32)
[37m[36mINFO[0m[0m 01/26 20:40:19 | steps-per-epoch for each domain: 41.75 -> min = 41.75
[37m[36mINFO[0m[0m 01/26 20:40:20 | # of params = 23522375
[37m[36mINFO[0m[0m 01/26 20:40:45 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_in     env1_out    env2_in     env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 01/26 20:40:45 | 0.127242    0.124146    0.110778    0.137725    2.039911    0.223307    0.198044    0.100213    0.113248    0.110778    0.137725    0.058206    0.061146    0           0.000000    2.437899    1.095130    24.128629  
[37m[36mINFO[0m[0m 01/26 20:41:42 | 0.367709    0.384138    0.938623    0.937126    0.649878    0.584503    0.638142    0.224414    0.207265    0.938623    0.937126    0.294211    0.307006    200         4.790419    1.634281    0.160297    24.402396  
[37m[36mINFO[0m[0m 01/26 20:42:40 | 0.414844    0.415744    0.988772    0.988024    0.124736    0.677242    0.704156    0.281983    0.262821    0.988772    0.988024    0.285305    0.280255    400         9.580838    0.591813    0.168245    24.783458  
[37m[36mINFO[0m[0m 01/26 20:43:37 | 0.426795    0.430373    0.993263    0.988024    0.071980    0.685784    0.704156    0.293710    0.286325    0.993263    0.988024    0.300891    0.300637    600         14.371257   0.340545    0.165641    23.790178  
[37m[36mINFO[0m[0m 01/26 20:44:34 | 0.424618    0.430380    0.994012    0.991018    0.059981    0.694936    0.711491    0.276119    0.271368    0.994012    0.991018    0.302799    0.308280    800         19.161677   0.274403    0.158392    24.085103  
[37m[36mINFO[0m[0m 01/26 20:45:31 | 0.436464    0.443310    0.997754    0.991018    0.049935    0.704698    0.721271    0.297441    0.292735    0.997754    0.991018    0.307252    0.315924    1000        23.952096   0.238343    0.173095    23.013607  
[37m[36mINFO[0m[0m 01/26 20:46:28 | 0.438162    0.446043    0.997006    0.988024    0.045749    0.693106    0.718826    0.304904    0.297009    0.997006    0.988024    0.316476    0.322293    1200        28.742515   0.212184    0.170806    22.782958  
[37m[36mINFO[0m[0m 01/26 20:47:26 | 0.442855    0.449398    0.997754    0.985030    0.042697    0.705308    0.723716    0.318230    0.309829    0.997754    0.985030    0.305025    0.314650    1400        33.532934   0.192310    0.156811    25.536574  
[37m[36mINFO[0m[0m 01/26 20:48:23 | 0.446348    0.454295    0.997006    0.985030    0.040312    0.704698    0.721271    0.329957    0.333333    0.997006    0.985030    0.304389    0.308280    1600        38.323353   0.170907    0.175718    22.458596  
[37m[36mINFO[0m[0m 01/26 20:49:20 | 0.445168    0.448967    0.998503    0.985030    0.040877    0.702868    0.706601    0.327292    0.326923    0.998503    0.985030    0.305344    0.313376    1800        43.113772   0.164795    0.160470    23.694044  
[37m[36mINFO[0m[0m 01/26 20:50:18 | 0.444446    0.450802    0.999251    0.985030    0.040281    0.701037    0.706601    0.324094    0.324786    0.999251    0.985030    0.308206    0.321019    2000        47.904192   0.148807    0.159476    26.231275  
[37m[36mINFO[0m[0m 01/26 20:51:17 | 0.442314    0.451446    1.000000    0.988024    0.036168    0.699207    0.711491    0.323028    0.326923    1.000000    0.988024    0.304707    0.315924    2200        52.694611   0.135535    0.169594    24.751525  
[37m[36mINFO[0m[0m 01/26 20:52:15 | 0.445492    0.452597    0.999251    0.985030    0.036156    0.700427    0.711491    0.331023    0.335470    0.999251    0.985030    0.305025    0.310828    2400        57.485030   0.133566    0.169771    23.859249  
[37m[36mINFO[0m[0m 01/26 20:53:14 | 0.443314    0.454179    0.997754    0.988024    0.035124    0.698597    0.718826    0.324094    0.329060    0.997754    0.988024    0.307252    0.314650    2600        62.275449   0.135578    0.173903    24.142994  
[37m[36mINFO[0m[0m 01/26 20:54:13 | 0.441652    0.451501    1.000000    0.988024    0.035395    0.697987    0.716381    0.318763    0.318376    1.000000    0.988024    0.308206    0.319745    2800        67.065868   0.123021    0.165640    25.626479  
[37m[36mINFO[0m[0m 01/26 20:55:16 | 0.443203    0.453055    1.000000    0.985030    0.034003    0.694936    0.709046    0.331557    0.335470    1.000000    0.985030    0.303117    0.314650    3000        71.856287   0.117048    0.191890    24.988843  
[37m[36mINFO[0m[0m 01/26 20:56:11 | 0.443696    0.450932    1.000000    0.988024    0.034303    0.695546    0.709046    0.335288    0.335470    1.000000    0.988024    0.300254    0.308280    3200        76.646707   0.111315    0.155267    23.738818  
[37m[36mINFO[0m[0m 01/26 20:57:08 | 0.445031    0.454583    0.998503    0.985030    0.035232    0.697987    0.711491    0.330490    0.337607    0.998503    0.985030    0.306616    0.314650    3400        81.437126   0.109303    0.164718    24.039991  
[37m[36mINFO[0m[0m 01/26 20:58:05 | 0.446407    0.455685    0.999251    0.988024    0.031935    0.694326    0.704156    0.339552    0.341880    0.999251    0.988024    0.305344    0.321019    3600        86.227545   0.110485    0.172263    22.252284  
[37m[36mINFO[0m[0m 01/26 20:59:02 | 0.447195    0.455493    0.999251    0.988024    0.031594    0.694326    0.709046    0.345416    0.350427    0.999251    0.988024    0.301845    0.307006    3800        91.017964   0.096653    0.162760    23.852632  
[37m[36mINFO[0m[0m 01/26 21:00:03 | 0.446596    0.454007    0.998503    0.988024    0.030552    0.697987    0.711491    0.335821    0.333333    0.998503    0.988024    0.305980    0.317197    4000        95.808383   0.101703    0.193976    22.591443  
[37m[36mINFO[0m[0m 01/26 21:00:58 | 0.442844    0.451076    0.999251    0.991018    0.031060    0.696766    0.706601    0.323561    0.320513    0.999251    0.991018    0.308206    0.326115    4200        100.598802  0.099135    0.156525    23.366688  
[37m[36mINFO[0m[0m 01/26 21:02:01 | 0.443542    0.452446    1.000000    0.991018    0.029875    0.691275    0.711491    0.333689    0.331197    1.000000    0.991018    0.305662    0.314650    4400        105.389222  0.090540    0.197888    22.943117  
[37m[36mINFO[0m[0m 01/26 21:02:57 | 0.445221    0.450864    0.999251    0.985030    0.029318    0.693716    0.704156    0.343284    0.337607    0.999251    0.985030    0.298664    0.310828    4600        110.179641  0.091978    0.160009    24.913840  
[37m[36mINFO[0m[0m 01/26 21:03:59 | 0.443880    0.449083    0.998503    0.988024    0.030693    0.694936    0.709046    0.334222    0.331197    0.998503    0.988024    0.302481    0.307006    4800        114.970060  0.090924    0.185754    24.571896  
[37m[36mINFO[0m[0m 01/26 21:04:57 | 0.448703    0.451829    1.000000    0.988024    0.030414    0.690665    0.696822    0.349147    0.344017    1.000000    0.988024    0.306298    0.314650    5000        119.760479  0.088435    0.162314    25.072481  
[37m[36mINFO[0m[0m 01/26 21:04:57 | Cumulative gradient change saved at train_output/PACS/SAM/[0, 1, 3]/250126_20-40-19_resnet50_sgd/sum_cumulative_g_change.npy
[37m[36mINFO[0m[0m 01/26 21:04:58 | ---
[37m[36mINFO[0m[0m 01/26 21:04:58 | test-domain validation(oracle) = 44.641%
[37m[36mINFO[0m[0m 01/26 21:04:58 | training-domain validation(iid) = 42.462%
[37m[36mINFO[0m[0m 01/26 21:04:58 | last = 44.870%
[37m[36mINFO[0m[0m 01/26 21:04:58 | last (inD) = 98.802%
[37m[36mINFO[0m[0m 01/26 21:04:58 | training-domain validation (iid, inD) = 99.102%
[37m[36mINFO[0m[0m 01/26 21:04:58 | === Summary ===
[37m[36mINFO[0m[0m 01/26 21:04:58 | Command: /jsm0707/Large-scale/train_all.py resnet50_sgd config/resnet50_sgd.yaml --algorithm SAM --test_envs 0 1 3 --dataset PACS
[37m[36mINFO[0m[0m 01/26 21:04:58 | Unique name: 250126_20-40-19_resnet50_sgd
[37m[36mINFO[0m[0m 01/26 21:04:58 | Out path: train_output/PACS/SAM/[0, 1, 3]/250126_20-40-19_resnet50_sgd
[37m[36mINFO[0m[0m 01/26 21:04:58 | Algorithm: SAM
[37m[36mINFO[0m[0m 01/26 21:04:58 | Dataset: PACS
