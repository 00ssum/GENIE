[37m[36mINFO[0m[0m 03/28 13:12:13 | Command :: /jsm0707/GENIE/train_all.py resnet50_GENIE_ma09 config/resnet50_GENIE.yaml --algorithm GENIE_hp --test_envs 0 --dataset PACS --steps 400
Environment:
	Python: 3.8.10
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
Args:
	algorithm: GENIE_hp
	attn_tune: False
	auto_lr: False
	checkpoint_freq: None
	configs: ['config/resnet50_GENIE.yaml']
	data_dir: data
	dataset: PACS
	debug: False
	deterministic: True
	dump_scores: False
	dump_similarities: False
	evalmode: all
	evaluate: False
	full_data: False
	holdout_fraction: 0.2
	hparams_seed: 0
	in_domain: False
	model_save: None
	mpa: False
	name: resnet50_GENIE_ma09
	out_dir: train_output/PACS/GENIE_hp/[0]/250328_13-12-13_resnet50_GENIE_ma09
	out_root: train_output/PACS/GENIE_hp/[0]
	prebuild_loader: False
	resume_path: checkpoints/
	seed: 0
	show: False
	small_bs: False
	steps: 400
	tb_freq: 10
	test_envs: [0]
	trial_seed: 0
	unique_name: 250328_13-12-13_resnet50_GENIE_ma09
	warmup: False
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	linear_steps: -1
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: genie
	freeze_bn: False
	pretrained: True
	lr: 5e-05
	batch_size: 32
	weight_decay: 0.0
	convergence_rate: 0.015
	p: 0.4
	swad: False
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	attn_tune: False
	auto_lr: False
Dataset:
	[PACS] #envs=4, #classes=7
	env0: A (#2048)
	env1: C (#2344)
	env2: P (#1670)
	env3: S (#3929)

[37m[36mINFO[0m[0m 03/28 13:12:13 | n_steps = 400
[37m[36mINFO[0m[0m 03/28 13:12:13 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/28 13:12:13 | n_steps is updated to 400 => 401 for checkpointing
[37m[36mINFO[0m[0m 03/28 13:12:13 | 
[37m[36mINFO[0m[0m 03/28 13:12:13 | Testenv name escaping te_A -> te_A
[37m[36mINFO[0m[0m 03/28 13:12:13 | Test envs = [0], name = te_A
[37m[36mINFO[0m[0m 03/28 13:12:13 | Train environments: [1, 2, 3], Test environments: [0]
[37m[36mINFO[0m[0m 03/28 13:12:13 | Batch sizes for each domain: [0, 32, 32, 32] (total=96)
[37m[36mINFO[0m[0m 03/28 13:12:13 | steps-per-epoch for each domain: 58.62, 41.75, 98.25 -> min = 41.75
